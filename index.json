[{"content":"type Pool struct Pool 是一组可以单独保存和检索的临时对象。 储存在 Pool 中的任何物品都可以在任何时间自动移除，无需通知。如果在此发生时 Pool 持有唯一的引用，则可能会释放该元素。 Pool 可以被多个goroutines同时使用。 Pool's 的目的是缓存已分配但未使用的项，以便以后重用，减轻垃圾收集器的压力。也就是说，它使构建高效的、线程安全的空闲列表变得容易。但它并不适用于所有空闲链表。 Pool 的适当使用是管理一组在包的并发独立客户端之间共享和可能被重用的临时项。Pool 提供了一种在多个客户端之间摊销分配开销的方法。 一个良好使用 Pool 的例子是fmt包，它维护了一个动态大小的临时输出缓冲区存储。store在负载下扩展(当许多goroutines正在积极打印时)，在静默时收缩。 另一方面，作为生存期较短的对象的一部分维护的空闲列表不适合用于 Pool，因为在这种情况下开销不能很好地分摊。 在第一次使用后，不能复制池。 sync.Pool 是协程安全的，使用前，设置好对象的 New 函数，用在 Pool 里没有缓存的对象时，创建一个。之后在程序的任何地方、任何时候仅通过 Get() 和 Put() 方法就可以取和还对象了 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 // A Pool is a set of temporary objects that may be individually saved and // retrieved. // // Any item stored in the Pool may be removed automatically at any time without // notification. If the Pool holds the only reference when this happens, the // item might be deallocated. // // A Pool is safe for use by multiple goroutines simultaneously. // // Pool\u0026#39;s purpose is to cache allocated but unused items for later reuse, // relieving pressure on the garbage collector. That is, it makes it easy to // build efficient, thread-safe free lists. However, it is not suitable for all // free lists. // // An appropriate use of a Pool is to manage a group of temporary items // silently shared among and potentially reused by concurrent independent // clients of a package. Pool provides a way to amortize allocation overhead // across many clients. // // An example of good use of a Pool is in the fmt package, which maintains a // dynamically-sized store of temporary output buffers. The store scales under // load (when many goroutines are actively printing) and shrinks when // quiescent. // // On the other hand, a free list maintained as part of a short-lived object is // not a suitable use for a Pool, since the overhead does not amortize well in // that scenario. It is more efficient to have such objects implement their own // free list. // // A Pool must not be copied after first use. type Pool struct { // 使得内嵌了noCopy的对象在进行go vet静态检查的时候，可以检查出是否被复制 noCopy noCopy // 访问时根据P的id去访问对应下标的local[pid] // 通过这样的设计，多个goroutine使用同一个Pool时，减少了竞争，提升了性能 // local字段指向存储[P]poolloacl数组的指针，类型为[P]poolLocal // // local 是 [P]poolLocal 数组的首地址 // P 是当前P的数量，一般默认为CPU的核数 local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal // localSize 是上面 local 数组的大小 // 根据 localSize 判断是否初始化，pid为P的id改值是一个0的递增值 // 1. localSize 为0时，没有初始化 // 2. localSize \u0026lt;= pid 时，可能是没有初始化，也可能是P的数量发生了变化，变多了 localSize uintptr // size of the local array // victim 和 victimSize 作为次级缓存使用，GC时将对象放入其中，下一次GC来临之前如果有Get调用则会从p.victim中取，直到再一次GC来时回收 // 从 p.victim 中取出对象使用完毕之后并未返回 p.victim 中（而是放回p.local）中，在一定程度上也减小了下一次GC的开销 // 原来1次GC的开销被拉长到2次切会有一定程度的开销减小，这就是 p.victim 引入的意图 // victim 和 victimSize 会在一轮GC到来时，分别\u0026#34;接管\u0026#34; local 和 localSize // victim 的机制用于减少GC后冷启动导致的性能抖动，让分配对象更平滑 // sync.Pool 引入的意图在于降低GC压力的同时提高命中率 victim unsafe.Pointer // local from previous cycle 来自上一个周期的local victimSize uintptr // size of victims array\t来自上一个周期的local的大小 // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. // // New可选地指定一个函数，用于在Get返回nil时生成一个值。 // 它不能在调用Get时同时改变。 New func() any\t// 我们指定的新建对象的方法 } // \u0026gt; ----------------------------------------------------------------------------------- type poolLocal struct { poolLocalInternal\t// 32 bytes // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . // // 将poolLocal补齐至128字节（即两个cache line）的倍数，防止false sharing伪共享 // 仅占位用，防止在cache line上分配多个 poolLocalInternal // 确保CPU缓存机制不同，一般建议确保有128字节距离 pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte\t// 使poolLocal总共占128字节 // CPU Cache // 现代cpu中，cache都划分成以cache line(cache block)为单位，在x86_64体系下一般都是64字节，cache line是操作的最小单元 // 程序即使只想读内存中的1个字节数据，也要同时把附近63节字加载到cache中，如果读取超个64字节，那么就要加载到多个cache line中 // 这样，访问后续63字节数据时就可以直接从cache line中读取，性能有很大提升 // false sharing // 伪共享的非标准定义为： // 缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行， // 就会令整个 cache line 失效，无意中影响彼此的性能，这就是伪共享 // 如果没用pad字段时，那么当需要访问0号索引的poolLocal时，CPU同时会把0号和1号索引同时加载到cpu cache，在只修改0号索引的情况下， // 会让1号索引的poolLocal失效。这样，当其他线程想要读取1号索引时，发生cache miss，还得重新再加载，对性能有损， // 增加一个pad，补齐缓存行，让相关的字段能独立地加载到缓存行就不会出现false sharding了 } // \u0026gt; ----------------------------------------------------------------------------------- // Local per-P Pool appendix. type poolLocalInternal struct { // private只有当前P能用 private any // Can be used only by the respective P. // 其他P都可以用，当private没有时优先去当前P的local.shared中取，如果还没有就去其他P中的local.shared中窃取一个来用 shared poolChain // Local P can pushHead/popHead; any P can popTail. } Variables 全局变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 var ( allPoolsMu Mutex\t// 全局互斥锁 // allPools is the set of pools that have non-empty primary // caches. Protected by either 1) allPoolsMu and pinning or 2) // STW. // // allPools 是具有非空主键缓存的 pool 集合 // 受任何一方保护 1) allPoolsMu 和 pinning 2) STW // 在Get函数中，初始化时被保存在这里 allPools []*Pool\t// 保存来自用户创建的Pool实例，用户端可能创建多个Pool，比如fmt包创建的Pool也会保存在这里 // oldPools is the set of pools that may have non-empty victim // caches. Protected by STW. // // oldPools是一组可能具有非空victim caches的池。受STW保护。 // 在GC开始时，保存allPools中的值 oldPools []*Pool\t// oldPools只是保存了 allPools 的值，可见是防止被GC回收相关数据 ) type poolLocal struct 本地 Pool，对齐Cache line的倍数。 1 2 3 4 5 6 7 8 9 type poolLocal struct { poolLocalInternal // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . // // 用 128 mod (cache line size) = 0 防止在广泛传播的平台上 false sharing。 pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } type poolLocalInternal struct 1 2 3 4 5 6 7 8 9 // Local per-P Pool appendix. type poolLocalInternal struct { // private 私有的，只能由相应的P使用。 private any // Can be used only by the respective P. // shared 共享的，local P 可以 pushHead/popHead; 任何P可以 popTail // 当当前P的private没有，那么优先从当前P的shared中取，还没有则从其他P的shared中取， // 还是没有如果New函数存在则使用该函数生成 shared poolChain // Local P can pushHead/popHead; any P can popTail. } type poolChain struct poolChain是poolDequeue的动态版本。 参看 poolqueue.go 文档。（第二篇中介绍） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // poolChain is a dynamically-sized version of poolDequeue. // // This is implemented as a doubly-linked list queue of poolDequeues // where each dequeue is double the size of the previous one. Once a // dequeue fills up, this allocates a new one and only ever pushes to // the latest dequeue. Pops happen from the other end of the list and // once a dequeue is exhausted, it gets removed from the list. type poolChain struct { // head is the poolDequeue to push to. This is only accessed // by the producer, so doesn\u0026#39;t need to be synchronized. head *poolChainElt // tail is the poolDequeue to popTail from. This is accessed // by consumers, so reads and writes must be atomic. tail *poolChainElt } Pool Methods Get() 优先从当前 P 的 local.private 中取，没有则从当前 P 的 local.shared 中取，还没有则去其他 P 中 local.shared 中窃取一个 调用者不应该认为Get的返回值和传递给Put值之间有任何关系 假如Get方法没有取得 item，如 p.New 非 nil，Get返回调用 p.New 的结果；否则返回nil 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // Get selects an arbitrary item from the Pool, removes it from the // Pool, and returns it to the caller. // Get may choose to ignore the pool and treat it as empty. // Callers should not assume any relation between values passed to Put and // the values returned by Get. // // If Get would otherwise return nil and p.New is non-nil, Get returns // the result of calling p.New. func (p *Pool) Get() any { if race.Enabled { race.Disable() } l, pid := p.pin()\t// 返回当前工作线程所在的*poolLocal和pid x := l.private\t// 取当前private上数据 l.private = nil\t// 并清零private // 如果 local private 没有 if x == nil {\t// Try to pop the head of the local shard. We prefer // the head over the tail for temporal locality of // reuse. // // 尝试从local shard的head取出。对于重复使用一时的locality我们更喜欢head而不是tail x, _ = l.shared.popHead()\t// 尝试从shared的head弹出一个数据 if x == nil { x = p.getSlow(pid)\t// 如果上面还未空，则去其他P中偷取，或从victim cache去拿去 } } runtime_procUnpin()\t// 允许当前工作线程被抢占 if race.Enabled { race.Enable() if x != nil { race.Acquire(poolRaceAddr(x)) } } // 如果上面都没有拿到数据并且又定义了New方法调用该方法创建数据 if x == nil \u0026amp;\u0026amp; p.New != nil {\tx = p.New() } return x } pin() pin 将当前 goroutine 固定到 P，禁用抢占并为 P 和 P 的id返回 poolLocal池。 调用者在处理池时必须调用runtime_procUnpin()。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 // pin pins the current goroutine to P, disables preemption and // returns poolLocal pool for the P and the P\u0026#39;s id. // Caller must call runtime_procUnpin() when done with the pool. func (p *Pool) pin() (*poolLocal, int) { // 该函数主要作用是加锁M禁止当前M被抢占，然后返回M正绑定的P的id pid := runtime_procPin()\t// In pinSlow we store to local and then to localSize, here we load in opposite order. // Since we\u0026#39;ve disabled preemption, GC cannot happen in between. // Thus here we must observe local at least as large localSize. // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness). // // 在pinSlow中，我们存储到local，然后存储到localSize，在这里我们按相反的顺序加载。 // 因为我们已经禁用了抢占，所以GC不能在这两者之间发生。 // 因此，这里我们必须注意local至少为large localSize。 // 我们可以观察到一个 更新/更大 的 local，这是没问题的(我们必须观察到它的零初始化)。 s := runtime_LoadAcquintptr(\u0026amp;p.localSize) // load-acquire;\t原子读取p.localSize值 l := p.local // load-consume;\t存储数据的数组地址 // uintptr(pid) \u0026gt;= s; 可能 1)没有初始化过 2)P的数量变多了 if uintptr(pid) \u0026lt; s { return indexLocal(l, pid), pid } return p.pinSlow()\t// 初始化去 } // \u0026gt; --------------------------------------------------------------------------------- // go1.19.3/src/runtime/proc.go //go:linkname sync_runtime_procPin sync.runtime_procPin //go:nosplit func sync_runtime_procPin() int { return procPin() } // \u0026gt; --------------------------------------------------------------------------------- // go1.19.3/src/runtime/proc.go //go:nosplit func procPin() int { _g_ := getg() mp := _g_.m mp.locks++ return int(mp.p.ptr().id) } // \u0026gt; --------------------------------------------------------------------------------- // go1.19.3/src/runtime/proc.go //go:linkname sync_runtime_procUnpin sync.runtime_procUnpin //go:nosplit func sync_runtime_procUnpin() { procUnpin() } // \u0026gt; --------------------------------------------------------------------------------- // go1.19.3/src/runtime/proc.go //go:nosplit func procUnpin() { _g_ := getg() _g_.m.locks-- } // \u0026gt; --------------------------------------------------------------------------------- // go1.19.3/src/sync/pool.go //go:linkname runtime_LoadAcquintptr runtime/internal/atomic.LoadAcquintptr func runtime_LoadAcquintptr(ptr *uintptr) uintptr // \u0026gt; --------------------------------------------------------------------------------- // go1.19.3/src/runtime/proc.go // l是p.local，i是pid func indexLocal(l unsafe.Pointer, i int) *poolLocal { // 获取到i下标的数据地址 lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{})) return (*poolLocal)(lp) } pinSlow() pinSlow 主要是完成 pool.local 的初始化创建 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 func (p *Pool) pinSlow() (*poolLocal, int) { // Retry under the mutex. // Can not lock the mutex while pinned. runtime_procUnpin() allPoolsMu.Lock()\tdefer allPoolsMu.Unlock()\tpid := runtime_procPin()\t// poolCleanup won\u0026#39;t be called while we are pinned. s := p.localSize l := p.local // 再次检查的意义在于，可能出现此时Pool已经被初始化 if uintptr(pid) \u0026lt; s { return indexLocal(l, pid), pid } if p.local == nil { // 新初始化的Pool记录到allPools allPools = append(allPools, p)\t// allPools是存储[]*Pool切片 } // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one. // 如果 GOMAXPROCS 在 GC 之间发生变化，我们将重新分配数组并丢失旧数组 // runtime.GOMAXPROCS 函数 参数是0或原大小值直接返回CPU中数量，其他则修改P的数量 size := runtime.GOMAXPROCS(0)\t// 返回P的总数量 local := make([]poolLocal, size)\t// 创建poolLocal类型切片，长度和容量都为size atomic.StorePointer(\u0026amp;p.local, unsafe.Pointer(\u0026amp;local[0])) // store-release runtime_StoreReluintptr(\u0026amp;p.localSize, uintptr(size)) // store-release return \u0026amp;local[pid], pid } // \u0026gt; --------------------------------------------------------------------------------- //go:linkname runtime_StoreReluintptr runtime/internal/atomic.StoreReluintptr func runtime_StoreReluintptr(ptr *uintptr, val uintptr) uintptr getSlow() 从其他 P 的 share 中去偷取元素 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 func (p *Pool) getSlow(pid int) any { // See the comment in pin regarding ordering of the loads. // 请参阅pin中关于负载排序的注释。 // 原子读取 p.localSize size := runtime_LoadAcquintptr(\u0026amp;p.localSize) // load-acquire locals := p.local // load-consume // Try to steal one element from other procs. // 尝试从其他进程中窃取一个元素。 for i := 0; i \u0026lt; int(size); i++ { // 偷取顺序从当前P的下一个P开始遍历一圈 l := indexLocal(locals, (pid+i+1)%int(size))\tif x, _ := l.shared.popTail(); x != nil { return x } } // Try the victim cache. We do this after attempting to steal // from all primary caches because we want objects in the // victim cache to age out if at all possible. // // 试试 victim cache。我们试图从所有primary caches中窃取数据后才这样做， // 因为我们希望victim cache中的对象尽可能的过期 size = atomic.LoadUintptr(\u0026amp;p.victimSize)\t// 原子读取victimSize if uintptr(pid) \u0026gt;= size { return nil } locals = p.victim l := indexLocal(locals, pid)\t// 取出pid对应Pool // 先从 private 中取 if x := l.private; x != nil { l.private = nil return x } // 从其他P的 share 中取 for i := 0; i \u0026lt; int(size); i++ { l := indexLocal(locals, (pid+i)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Mark the victim cache as empty for future gets don\u0026#39;t bother // with it. // // 将 victim cache 标记为空，以便将来获取，不要费心处理它。 atomic.StoreUintptr(\u0026amp;p.victimSize, 0) return nil } indexLocal() 1 2 3 4 func indexLocal(l unsafe.Pointer, i int) *poolLocal { lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{})) return (*poolLocal)(lp) } Put() Put方法将x放入 pool 中 把 x 放入池子中时，建议清除上面相关数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // Put adds x to the pool. func (p *Pool) Put(x any) { if x == nil { return } if race.Enabled { if fastrandn(4) == 0 { // Randomly drop x on floor. return } race.ReleaseMerge(poolRaceAddr(x)) race.Disable() } // 获取 P 对应的 *poolLocal l, _ := p.pin() // 如果当前private为nil则把这个存储在这里，等待下次优先被使用 if l.private == nil { l.private = x x = nil } if x != nil {\t// 这种情况是private已经有数据了，则放入shared队列中 l.shared.pushHead(x) } runtime_procUnpin()\t// 允许当前工作线程被抢占，原因是pin函数里面加了锁的这里需要解锁 if race.Enabled { race.Enable() } } init() 注册 poolCleanup 函数，在GC开始时调用 对于 Pool 而言，并不能无限扩展，否则对象占用内存太多会引起内存溢出（几乎所有的池技术中都会在某个时刻清空或清除部分缓存对象。Go发生在GC时清除部分内存） 在 pool.go 文件的 init 函数里，注册GC发生时，如何清理 Pool 的函数 poolCleanup 1 2 3 4 5 6 7 8 9 10 11 12 func init() { runtime_registerPoolCleanup(poolCleanup) } // go1.19.3/src/runtime/mgc.go //go:linkname sync_runtime_registerPoolCleanup sync.runtime_registerPoolCleanup func sync_runtime_registerPoolCleanup(f func()) { poolcleanup = f } // go1.19.3/src/runtime/mgc.go var poolcleanup func() 使用示例 Pool：是一个可以分别存取的临时对象的集合 Pool：中保存的任何 item 都可能随时不做通告的释放掉 如果Pool持有该对象的唯一引用，这个 item 就可能被回收 Pool：可以安全的被多个线程同时使用 Pool：的目的是缓存申请但未使用 item 用于之后的重用，已减轻GC的压力 也就是说，让创建高效而线程安全的空闲列表更容易 但Pool并不适合用于多有空闲列表 Pool：的合理用法是用于管理一组静静的被多个独立并发线程共享并可能重用的临时 item Pool提供了让多个线程分摊内存申请消耗的方法 Pool：的一个好例子在fmt包里面 该Pool维护一个动态大小的临时输出缓存仓库 该创库会在过载（许多线程活跃的打印时）增大，在沉寂时缩小 另一方面，管理这短寿命对象的空闲列表不适合使用Pool 因为这种情况下内存申请消耗不能很好的分配 这时应该由这些对象自己实现空闲列表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var pool *sync.Pool type Person struct { Name string } func initPool() { pool = \u0026amp;sync.Pool { New: func() interface{} { fmt.Println(\u0026#34;Creating a new Person\u0026#34;) return new(Person) }, } } func main() { initPool() // pool.Get() 返回interface{} // 然后断言 是否为 *Person p := pool.Get().(*Person) fmt.Println(\u0026#34;首次从 pool 里获取：\u0026#34;, p) p.Name = \u0026#34;first\u0026#34; fmt.Printf(\u0026#34;设置 p.Name = %s\\n\u0026#34;, p.Name) // 将p放回池中 pool.Put(p) fmt.Println(\u0026#34;Pool 里已有一个对象：\u0026amp;{first}，调用 Get：\u0026#34;, pool.Get().(*Person)) fmt.Println(\u0026#34;Pool 没有对象了，调用 Get：\u0026#34;, pool.Get().(*Person)) } Creating a new Person 首次从 pool 里获取： \u0026amp;{} 设置 p.Name = first Pool 里已有一个对象：\u0026amp;{first}，调用 Get： \u0026amp;{first} Creating a new Person Pool 没有对象了，调用 Get： \u0026amp;{} 首先，需要初始化 Pool，唯一需要的就是设置好New函数 当调用 Get 方法时，如果池子里缓存了对象，就直接返回缓存的对象 如果没有存货，则调用New函数创建一个新的对象 另外，我们发现Get方法取出来的对象和上次Put进去的对象实际上是同一个，Pool没有做任何“清空”的处理 但我们不应当对此有任何假设，因为在实际的并发使用场景中 无法保证这种顺序，最好的做法是在Put前，将对象清空 ","permalink":"https://heliu.site/posts/golang/sync/pool/","summary":"Pool是一组可以单独保存和检索的临时对象。","title":"sync.Pool"},{"content":"type RWMutex struct 🚀 在runtime/rwmutex.go中有这个文件的修改过的副本。如果你在这里做了任何更改，看看是否应该在那里也做更改。 RWMutex 是一种 读/写 互斥锁。该锁可以由任意数量的读或单个写持有。 RWMutex 的零值是一个未锁定的互斥锁。RWMutex 在第一次使用后不能复制。 如果一个goroutine持有一个用于读取的RWMutex，而另一个goroutine可能会调用Lock， 那么任何goroutine都不应该期望能够获得一个读锁，直到初始的读锁被释放。 特别是，这禁止了递归读锁定。这是为了确保锁最终可用。被阻塞的锁调用会排除新的读取器获取锁。 RWMutex：读写互斥锁 1) 该锁可以被同时多个读取者持有或唯一写入者持有 2) RWMutex可以创建为其他结构体的字段 3) 零值为解锁状态 RWMutex 类型的锁也和线程无关，可以由不同的线程加读取锁/写入和解读取锁/写入锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // There is a modified copy of this file in runtime/rwmutex.go. // If you make any changes here, see if you should make them there. // A RWMutex is a reader/writer mutual exclusion lock. // The lock can be held by an arbitrary number of readers or a single writer. // The zero value for a RWMutex is an unlocked mutex. // // A RWMutex must not be copied after first use. // // If a goroutine holds a RWMutex for reading and another goroutine might // call Lock, no goroutine should expect to be able to acquire a read lock // until the initial read lock is released. In particular, this prohibits // recursive read locking. This is to ensure that the lock eventually becomes // available; a blocked Lock call excludes new readers from acquiring the // lock. type RWMutex struct { // 1) 一把互斥锁，保护以下字段 // 所有写goroutine争抢sync.Mutex锁的goroutine都这这里排队等待 w Mutex // held if there are pending writers // 2) semaphore 读写等待池 // 获取到 sync.Mutex 锁gorutine，并等待正在运行 读goroutine 时，该写goroutine在这里等待 // 因此这里只可能是只有一个写goroutine在等待或者没有 writerSem uint32 // semaphore for writers to wait for completing readers // readerSem 记录着所有等待读的协程，当有写操作正在进行中，后面来的读操作全部排队等待在这里 // 等待正在进行中的读操作完成后释放writerSem中的写操作完成后，这里排队的读协程将被释放 readerSem uint32 // semaphore for readers to wait for completing writers // 3) 读等待数量 // readerCount 记录的所有的读goroutine数量（【正在执行的goroutine】+【等待在readerSem中的goroutine】）， // 调用RLock方法该值就会加一 // 当有写goroutine获取到sync.Mutex时，会将该值原子操作减去rwmutexMaxReaders变成负数， // 告知RLock方法有写操作在进行，goroutine去readerSem吧 readerCount int32 // number of pending readers // 在获取到Mutex后，记录当前【正在进行的读goroutine数量】，不包括存在readerSem排队的，这些读goroutine正在工作线程上运行 // 在当前写操作开始时等待正在运行全部读goroutine的数量，注意这里可以是负数 readerWait int32 // number of departing readers } const 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 2^30 = 1,073,741,824\t完全能满足读取的数量 const rwmutexMaxReaders = 1 \u0026lt;\u0026lt; 30\t// 最大读取数量 // Happens-before relationships are indicated to the race detector via: // - Unlock -\u0026gt; Lock: readerSem // - Unlock -\u0026gt; RLock: readerSem // - RUnlock -\u0026gt; Lock: writerSem // // The methods below temporarily disable handling of race synchronization // events in order to provide the more precise model above to the race // detector. // // For example, atomic.AddInt32 in RLock should not appear to provide // acquire-release semantics, which would incorrectly synchronize racing // readers, thus potentially missing races. // // Happens-before关系通过以下方式指示竞争检测器: // Unlock -\u0026gt; Lock: readerSem // Unlock -\u0026gt; RLock: readerSem // RUnlock -\u0026gt; Lock: writerSem // // 下面的方法暂时禁用了竞争同步事件的处理，以便为竞争检测器提供更精确的模型。 // 例如，RLock中的 atomic.AddInt32 看起来不应该提供 获取-释放语义，这将不正确地同步竞争的阅读器，从而可能错过竞争。 字段和方法描述 Lock()、Unlock() 写操作时调用的方法，如果锁已被reader或waiter持有，那么Lock方法会一直阻塞，直到能获取到锁 写操作时，如果锁被readers持有，那么将等待所有的reader解锁，返回写操作获得锁，这期间还有来的reader全部去排队等待，等待写操作解锁写操作解锁期间先把等待在排队的全部释放出来，然后再去解锁互斥锁。在互斥锁解锁小段时间来的读操作直接获取锁不需要去排队，互斥锁解锁后才允许排队的写操作或正在来的写操作去争抢互斥写锁 写操作时，如果锁已被waiter持有，那么当前写操作等待在RWRutex.w.seam信号量中，等待前面一个写锁完成，此时来的读操作全部阻塞起，已经在进行的读操作正常进行 Unlock方法是配对的释放锁的方法 RLock()、RUnlock() 读操作时调用的方法，如果锁已经被writer持有的话，RLock方法会一直阻塞，直到能获取到锁，否则就直接返回 读操作时没有waiter持有锁情况，直接记录readerCount加一，返回就返回，表示获取到锁 读操作时存在waiter持有锁情况，则当前读操作排队在readerSem，等待当前写完成 而RUnlock是reader释放锁的方法 RLocker() 这个方法的作用是为读操作返回一个Locker接口的对象，它的Lock方法会调用RWMutex的RLock方法，它的Unlock方法会调用RWMutex的RUnlock方法 Lock() Lock 锁定 rw 用于写入。 如果锁已经锁定用于读或写，那么锁将阻塞，直到锁可用为止。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // Lock locks rw for writing. // If the lock is already locked for reading or writing, // Lock blocks until the lock is available. func (rw *RWMutex) Lock() { if race.Enabled { _ = rw.w.state race.Disable() } // 1) 尝试获取 sync.Mutex 锁 // First, resolve competition with other writers. // // 首先，解决与其他 writers 的竞争。 // 如果存在多个写gorutine的都在调用Lock竞争锁，这里需要先去竞争锁 rw.w.Lock()\t// sync.Mutex // 2) 原子修改readerCount值，告诉后面读goroutine调用Rlock函数需要去readerSem中挂起 // 由于刚获取到锁，因此此时只存在正在运行读goroutine和等待在writerSem中写goroutine，不存在等待在readerSem中的goroutine // 因此 readerCount 存储的是正在运行读goroutine，在下面这行原子操作执行前都认为读goroutine是不需要挂起的 // Announce to readers there is a pending writer. // // 通过把rw.readerCount设置成一个负数，来告知其他读goroutine当前有写的goroutine正在等待进入临界区 // atomic.AddInt32(\u0026amp;rw.readerCount, -rwmutexMaxReaders); 告诉后面来的读操作去排队等待，你们应该在本次写操作完后再去读取数据 // 由于当前刚获取到 Mutex,所以这里的 r 应该表示当前正在运行的读goroutine的数量，不包含被挂起的 goroutine r := atomic.AddInt32(\u0026amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders\t// 原子操作表示当前有写的协程来了 // 在上面这行原子操作执行后，都有来的读goroutine在调用RLock方法时，都会被挂起在readerSem中 // 因此 r 是所有正在运行读goroutine的数量 // 上面的原子操作与RLock函数的原子操作形成一对临界区域互斥 // Wait for active readers. // // 1. r != 0：存在正在运行的读goroutine // 2. atomic.AddInt32(\u0026amp;rw.readerWait, r) != 0：继续判断这段时间呢这些读goroutine是否全部读取完， // 没有读取完这里需要把当前写goroutine挂起在writerSem // 这里的原子操作与RUlock函数的 \u0026#34;atomic.AddInt32(\u0026amp;rw.readerWait, -1) == 0\u0026#34; 形成临界区域互斥 if r != 0 \u0026amp;\u0026amp; atomic.AddInt32(\u0026amp;rw.readerWait, r) != 0 {\t// readerWait记录着正在运行中，还没有调用RUnlock的goroutine // 存在需要等待读的协程，把当前协程加入writerSem写信息池 // false：这里加入的是尾部，由于writerSem只可能存一个写goroutine runtime_SemacquireMutex(\u0026amp;rw.writerSem, false, 0)\t} if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(\u0026amp;rw.readerSem)) race.Acquire(unsafe.Pointer(\u0026amp;rw.writerSem)) } } Unlock() Unlock 方法解除rw的写入锁状态。 如果 rw 在进入解锁时没有锁定写入，这是一个运行时错误。 与 Mutexes 一样，一个被锁的 RWMutex 与一个特定的 goroutine 无关。 一个 goroutine 可以 RLock(锁定)一个 RWMutex，然后安排另一个 goroutine 运行 RUnlock(解锁)它。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // Unlock unlocks rw for writing. It is a run-time error if rw is // not locked for writing on entry to Unlock. // // As with Mutexes, a locked RWMutex is not associated with a particular // goroutine. One goroutine may RLock (Lock) a RWMutex and then // arrange for another goroutine to RUnlock (Unlock) it. func (rw *RWMutex) Unlock() { if race.Enabled { _ = rw.w.state race.Release(unsafe.Pointer(\u0026amp;rw.readerSem)) race.Disable() } // 1) 当Unlock方法被调用，也就说明数据的相关写操作已经完成了，此时其他来读的goroutine可以正常读取新数据 // Announce to readers there is no active writer. // // 告诉所有RLock的协程，没有正在写的锁，此时来读的协程不必等待直接可以读取到数据 // 因为程序调用了Unlock方法代表我们前面以把数据更新了，此时在信号量中等待读的协程和此时后面来读的协程都可以安全读取数据了 // 这里与RLock函数的 \u0026#34;atomic.AddInt32(\u0026amp;rw.readerCount, 1) \u0026lt; 0\u0026#34; 形成临界区互斥 r := atomic.AddInt32(\u0026amp;rw.readerCount, rwmutexMaxReaders)\t// 这里的r全都是等待在信号量的数量 // 没有调用Lock方法，而是直接调用Unlock方法这里会报错 if r \u0026gt;= rwmutexMaxReaders { race.Enable() throw(\u0026#34;sync: Unlock of unlocked RWMutex\u0026#34;) } // Unblock blocked readers, if any. // // 释放掉等待在信号量的协程，注意这里是释放完了才把互斥锁解锁的才允许其他写操作进行 // 因为前面的数据已经更新了，所以这里需要把在信号量中的协程全部放在P本地队列或全局队列中等待调度器调度去来运行 // 这里也是为什么其他写goroutine获取到Mutex锁时，不存在等待在readerSem上的读goroutine的原因，因为Mutex解锁在后面一步 for i := 0; i \u0026lt; int(r); i++ { runtime_Semrelease(\u0026amp;rw.readerSem, false, 0)\t// 取出等待在readerSem的写goroutine } // Allow other writers to proceed. // // 允许其他 writers 继续 rw.w.Unlock()\t// sync.Mutex if race.Enabled { race.Enable() } } TryLock() TryLock 试图锁定 rw 进行写入，并报告是否成功。 请注意，虽然确实存在正确使用 TryLock 的情况，但很少，而且 TryLock 的使用通常表明互斥量的特定使用中存在更深层的问题。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // TryLock tries to lock rw for writing and reports whether it succeeded. // // Note that while correct uses of TryLock do exist, they are rare, // and use of TryLock is often a sign of a deeper problem // in a particular use of mutexes. func (rw *RWMutex) TryLock() bool { if race.Enabled { _ = rw.w.state race.Disable() } // 尝试获取Mutex锁 if !rw.w.TryLock() { if race.Enabled { race.Enable() } return false } // 原子交换 readerCount 由 0 -\u0026gt; -rwmutexMaxReaders // 可见只有在没有读goroutine的时候，TryLock函数才会返回成功 if !atomic.CompareAndSwapInt32(\u0026amp;rw.readerCount, 0, -rwmutexMaxReaders) { // 存在其他正在读写协程 rw.w.Unlock()\t// 解锁互斥锁 if race.Enabled { race.Enable() } return false } if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(\u0026amp;rw.readerSem)) race.Acquire(unsafe.Pointer(\u0026amp;rw.writerSem)) } return true } RLock() RLock设置rw读锁。 它不应该用于递归的读锁定;被阻塞的锁调用会排除新的读取器获取锁。请参阅RWMutex类型的文档。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // RLock locks rw for reading. // // It should not be used for recursive read locking; a blocked Lock // call excludes new readers from acquiring the lock. See the // documentation on the RWMutex type. func (rw *RWMutex) RLock() { if race.Enabled { _ = rw.w.state race.Disable() } // 把rw.readerCount加一，如果该值小于0，说明存在其他goroutine正在写操作，也就是前面的Lock方法 // 这里也表明了readerCount字段是记录所有写goroutine的数量 if atomic.AddInt32(\u0026amp;rw.readerCount, 1) \u0026lt; 0 { // A writer is pending, wait for it. // // 一个写锁正在继续，等待它完成 runtime_SemacquireMutex(\u0026amp;rw.readerSem, false, 0)\t// 将当前读goroutine挂在readerSem上 } if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(\u0026amp;rw.readerSem)) } } RUnlock() RUnlock 解除一个 RLock 调用。 它不会影响其他同时阅读的读者。 如果rw在进入RUnlock时没有锁定读取，则是一个运行时错误。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // RUnlock undoes a single RLock call; // it does not affect other simultaneous readers. // It is a run-time error if rw is not locked for reading // on entry to RUnlock. func (rw *RWMutex) RUnlock() { if race.Enabled { _ = rw.w.state race.ReleaseMerge(unsafe.Pointer(\u0026amp;rw.writerSem)) race.Disable() } // 把前面读加锁减一，如果r小于0，说明正在进行写操作中 // 这里也有一种可能是没有存在写操作中又没有调用Rlock函数调用了RUnlock函数导致总有一个goroutine这里rw.readerCount=-1 if r := atomic.AddInt32(\u0026amp;rw.readerCount, -1); r \u0026lt; 0 { // Outlined slow-path to allow the fast-path to be inlined // // 有存在写在进行，因此需要判断当前是否需要取出该写goroutine // 原因是可能存在读goroutine在运行中，该写goroutine在writerSem中等待 rw.rUnlockSlow(r)\t} if race.Enabled { race.Enable() } } rUnlockSlow() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func (rw *RWMutex) rUnlockSlow(r int32) { // 判断没有调用RLock函数调用RUnlock函数报错 // 1. r+1 == -rwmutexMaxReaders =\u0026gt; r + rwmutexMaxReaders == 1 // 2. r+1 == 0，就是判断上面没有调用RLock函数调用RUnlock函数时情况 if r+1 == 0 || r+1 == -rwmutexMaxReaders { race.Enable() throw(\u0026#34;sync: RUnlock of unlocked RWMutex\u0026#34;) } // A writer is pending. // // rw.readerWait 记录着当前正在运行的goroutine没在信号池的数量，这里判断是否已经是最后一个 // 这里的原子操作和Lock函数中的 \u0026#34;atomic.AddInt32(\u0026amp;rw.readerWait, r) != 0\u0026#34; 形成临界区互斥 if atomic.AddInt32(\u0026amp;rw.readerWait, -1) == 0 {\t// 如果是最后一个，把等待写的goroutine取出 // The last reader unblocks the writer. runtime_Semrelease(\u0026amp;rw.writerSem, false, 1)\t// 从writerSem中取出等待在这里的读goroutine } } TryRLock() 尝试获取读锁，该方法只要不存在写协程都会获取读锁成功。 TryRLock 试图锁定 rw 以进行读取，并报告是否成功。 请注意，虽然确实存在对 TryRLock 的正确使用，但很少，而且 TryRLock 的使用通常表明互斥量的特定使用中存在更深层的问题。 该方法在没有写操作的情况下是一定能拿去到锁的。存在写操作时才会返回 false。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // TryRLock tries to lock rw for reading and reports whether it succeeded. // // Note that while correct uses of TryRLock do exist, they are rare, // and use of TryRLock is often a sign of a deeper problem // in a particular use of mutexes. func (rw *RWMutex) TryRLock() bool { if race.Enabled { _ = rw.w.state race.Disable() } // TryRLock 函数获取到读锁只能发生在 readerCount \u0026gt;= 0 状态下 for { c := atomic.LoadInt32(\u0026amp;rw.readerCount)\t// 原子读取 readerCount if c \u0026lt; 0 { // 写操作在进行中或者在等待读完成。 if race.Enabled { race.Enable() } return false } // 尝试原子交换 readerCount 值 // 如果交换失败可能有其他读操作或写操作发生，再次循环。 if atomic.CompareAndSwapInt32(\u0026amp;rw.readerCount, c, c+1) { if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(\u0026amp;rw.readerSem)) } return true\t// 获取到锁后 } } } RLocker() RLocker 返回一个 Locker 接口，通过调用 rw 实现 Lock 和 Unlock 方法。RLock 和 rw.RUnlock。 意义在于返回接口Locker限制只能调用接口的，比如 sync.Cond 中需要的锁 1 2 3 4 5 // RLocker returns a Locker interface that implements // the Lock and Unlock methods by calling rw.RLock and rw.RUnlock. func (rw *RWMutex) RLocker() Locker { return (*rlocker)(rw) } type Locker interface Locker接口代表一个可以加锁和解锁的对象。 该接口定义在sync/mutex.go文件中。 1 2 3 4 type Locker interface { Lock() Unlock() } type rlocker RWMutex 1 type rlocker RWMutex\t// sync.RWMutex Lock() 1 2 3 4 5 6 func (r *rlocker) Lock() { // 因为 rlocker 和 RWMutex是两个类型，虽然底层一样 // 但是 rlocker 只支持 Lock() 和 Unlock() 方法 // 需要转换成 (*RWMutex) 才能调用 RLock() 方法。 (*RWMutex)(r).RLock() } Unlock() 1 2 3 func (r *rlocker) Unlock() { (*RWMutex)(r).RUnlock() } 使用示例 读写锁：是多读单写互斥锁，分别针对读操作和写操作进行锁定和解锁操作 经常用于读次数远远多于写次数的场合 在Go语言中，读写锁由结构体类型 sync.RWMutex 实现 基本遵守原则： 写锁定情况下，对读写锁定进行读锁定或写锁定，都将阻塞，而且读锁与写锁之间是互斥的 读锁定情况下，对读写锁进行写锁定，将阻塞 加读锁时不会阻塞，即可多读 对未被写锁定的读写锁进行写解锁，会引发运行时异常 对未被读读锁定的读写锁进行读解锁时也会引发运行时异常 写解锁在进行的同时会试图唤醒所有因进行读锁定而被阻塞的协程 读解锁在进行的时候则会试图唤醒一个因进行写锁定而被阻塞的协程 与互斥锁类型，sync.RWMutex 类型的零值就已经是立即可用的读写锁了 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var m *sync.RWMutex func main() { wg := sync.WaitGroup{} wg.Add(20) var rwMutex sync.RWMutex Data := 0 for i := 0; i \u0026lt; 10; i++ { go func(t int) { rwMutex.RLock()\t// 读加锁 defer rwMutex.RUnlock()\t// 读解锁 fmt.Printf(\u0026#34;读数据：%v %d\\n\u0026#34;, Data, i) wg.Done() time.Sleep(1 * time.Second) // 这句代码第一次运行后，读解锁 // 循环到第二个时， 读锁定后，这个goroutine就没有阻塞，同时读成功 }(i) go func(t int) { rwMutex.Lock()\t// 写加锁 defer rwMutex.Unlock()\t// 写解锁 Data += 1 fmt.Printf(\u0026#34;写数据：%v %d\\n\u0026#34;, Data, t) wg.Done() // 对读写锁进行读锁定或者写锁定，都将阻塞 // 写锁定下是需要解锁后才能写的 time.Sleep(5 * time.Second) }(i) } wg.Wait() } 读数据：0 3 写数据：1 2 读数据：1 10 读数据：1 10 读数据：1 10 读数据：1 10 读数据：1 10 读数据：1 10 读数据：1 10 读数据：1 10 读数据：1 10 写数据：2 1 写数据：3 3 写数据：4 4 写数据：5 5 写数据：6 6 写数据：7 0 写数据：8 9 写数据：9 7 写数据：10 8 通过程序运行的输出可以看到，在写锁定情况下，对读写锁进行锁定或者写锁定，都将阻塞 把写数据中的Sleep设置更长时间，在第一次写锁定后，读数据也没有进行 再次写锁定是在 rwMutex.Unlock() 完成后，才能进行 rwMutex.lock() 而读数据时则可以多次读，不一定需要等 rwMutex.RUnlock() 完成 ","permalink":"https://heliu.site/posts/golang/sync/rwmutex/","summary":"RWMutex是一种读写互斥锁。","title":"sync.RwMutex"},{"content":"type Once struct 🚀 Once是只执行一次动作的对象，应用场景，比如加载配置文件只需要加载一次。 首次使用Once后，不能复制Once。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // Once is an object that will perform exactly one action. // // A Once must not be copied after first use. type Once struct { // done indicates whether the action has been performed. // It is first in the struct because it is used in the hot path. // The hot path is inlined at every call site. // Placing done first allows more compact instructions on some architectures (amd64/386), // and fewer instructions (to calculate offset) on other architectures. // // done 表示操作是否已经执行。 // 它在结构体中位于首位，因为它在 hot path 中使用。 // hot path 内联在每个调用点。 // 在某些体系结构上(amd64/386)，将done放在第一位可以让指令更紧凑，而在其他体系结构上可以让指令更少(用于计算偏移量)。 done uint32\t// 0.未被调用过 1.已被调用过 m Mutex\t// 互斥锁 } // 其中解释了为什么将 done 置为 Once 的第一个字段：done 在热路径中，done 放在第一个字段，能够减少 CPU 指令，也就是说，这样做能够提升性能。 // 1. 热路径(hot path)是程序非常频繁执行的一系列指令，sync.Once 绝大部分场景都会访问 o.done，在热路径上是比较好理解的， //\t如果 hot path 编译后的机器码指令更少，更直接，必然是能够提升性能的。 // 2. 为什么放在第一个字段就能够减少指令呢？因为结构体第一个字段的地址和结构体的指针是相同的，如果是第一个字段，直接对结构体的指针解引用即可。 // 如果是其他的字段，除了结构体指针外，还需要计算与第一个值的偏移(calculate offset)。在机器码中，偏移量是随指令传递的附加值， // CPU 需要做一次偏移值与指针的加法运算，才能获取要访问的值的地址。因为，访问第一个字段的机器代码更紧凑，速度更快。 Do() 当且仅当 Do 是第一次为 Once 实例调用函数 f 时，Do 才会调用函数 f。 换句话说，给定var once Once，如果 once.Do(f) 被多次调用，只有第一次调用会调用f，即使每次调用 f 的值不同。 每个函数执行时都需要一个 Once 的新实例。 Do 用于必须只运行一次的初始化。 由于 f 是 niladic，因此可能需要使用函数字面量来捕获Do调用的函数的参数:config.once.Do(func() { config.init(filename) }) niladic：被解释为不带参数的闭包函数。 因为只有在对 f 的调用返回之前，才会返回对 Do 的调用，如果 f 导致Do被调用，它就会死锁。（f函数内不能在调用外层的Do函数） 如果f发生panic，Do认为它回来了;Do的后续调用不需要调用f。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 // Do calls the function f if and only if Do is being called for the // first time for this instance of Once. In other words, given // var once Once // if once.Do(f) is called multiple times, only the first call will invoke f, // even if f has a different value in each invocation. A new instance of // Once is required for each function to execute. // // Do is intended for initialization that must be run exactly once. Since f // is niladic, it may be necessary to use a function literal to capture the // arguments to a function to be invoked by Do: // config.once.Do(func() { config.init(filename) }) // // Because no call to Do returns until the one call to f returns, if f causes // Do to be called, it will deadlock. // // If f panics, Do considers it to have returned; future calls of Do return // without calling f. func (o *Once) Do(f func()) { // Note: Here is an incorrect implementation of Do: // //\tif atomic.CompareAndSwapUint32(\u0026amp;o.done, 0, 1) { //\tf() //\t} // // Do guarantees that when it returns, f has finished. // This implementation would not implement that guarantee: // given two simultaneous calls, the winner of the cas would // call f, and the second would return immediately, without // waiting for the first\u0026#39;s call to f to complete. // This is why the slow path falls back to a mutex, and why // the atomic.StoreUint32 must be delayed until after f returns. // // 注意:下面是一个不正确的Do实现。 // 以下形式不能保证Do函数返回时f函数已执行完，因为我们是先标记后执行f的。 // if atomic.CompareAndSwapUint32(\u0026amp;o.done, 0, 1) { // f() // } // // Do 保证当它返回时，f 已经完成 // 这种实现不会实现这种保证:给定两个同时调用，cas的赢家将调用f，而第二个将立即返回，而无需等待第一个调用完成。 // 这就是慢路径回退到互斥量的原因，也是原子性的原因。StoreUint32必须延迟到f返回之后。 // 后续大部分情况会从这里判断失败 if atomic.LoadUint32(\u0026amp;o.done) == 0 { // Outlined slow-path to allow inlining of the fast-path. o.doSlow(f) } } doSlow() 1 2 3 4 5 6 7 8 9 10 11 12 func (o *Once) doSlow(f func()) { o.m.Lock() // 获取锁 defer o.m.Unlock() // 延迟释放锁 // 当出现并发时，这里会拦住等待着的协程 if o.done == 0 {\t// 在f()执行完后才会标记done为1。 defer atomic.StoreUint32(\u0026amp;o.done, 1) // 需要保证f函数不会发生panic // 如果发生panic，则o.done会被标记为1，后续不会在调用f函数 f() } } 使用场景 sync.Once 是 Go 标准库提供的使函数只执行一次的实现。 常应用于【单例模式】，例如【初始化配置】、【保持数据库连接】等。作用与 init 函数类似，但有区别。 init 函数是当所在的 package 首次被加载时执行，若迟迟未被使用，则既浪费了内存，又延长了程序加载时间。 sync.Once 可以在代码的任意位置初始化和调用，因此可以延迟到使用时再执行，并发场景下是线程安全的。 在多数情况下，sync.Once 被用于控制变量的初始化，这个变量的读写满足如下三个条件： 当且仅当第一次访问某个变量时，进行初始化（写）。 变量初始化过程中，所有读都被阻塞，直到初始化完成。 变量仅初始化一次，初始化完成后驻留在内存里。 sync.Once 仅提供了一个方法 Do，参数 f 是对象初始化函数。 func (o *Once) Do(f func())。 使用示例 简单的示例 考虑一个简单的场景，函数 ReadConfig 需要读取环境变量，并转换为对应的配置。 环境变量在程序执行前已经确定，执行过程中不会发生改变。 ReadConfig 可能会被多个协程并发调用，为了提升性能（减少执行时间和内存占用），使用 sync.Once 是一个比较好的方式。 在这个例子中，声明了 2 个全局变量，once 和 config。 config 是需要在 ReadConfig 函数中初始化的(将环境变量转换为 Config 结构体)，ReadConfig 可能会被并发调用。 如果 ReadConfig 每次都构造出一个新的 Config 结构体，既浪费内存，又浪费初始化时间。 如果 ReadConfig 中不加锁，初始化全局变量 config 就可能出现并发冲突。 这种情况下，使用 sync.Once 既能够保证全局变量初始化时是线程安全的，又能节省内存和初始化时间。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 type Config struct { Server string Port int64 } var ( once sync.Once config *Config ) func ReadConfig() *Config { once.Do(func() { var err error config = \u0026amp;Config{Server: os.Getenv(\u0026#34;TT_SERVER_URL\u0026#34;)} config.Port, err = strconv.ParseInt(os.Getenv(\u0026#34;TT_PORT\u0026#34;), 10, 0) if err != nil { config.Port = 8080 // default port } log.Println(\u0026#34;init config\u0026#34;) }) return config } func main() { for i := 0; i \u0026lt; 10; i++ { go func() { _ = ReadConfig() }() } time.Sleep(time.Second) } 标准库中的使用 比如 package html 中，对象 entity 只被初始化一次。 字典 entity 包含 2005 个键值对，若使用 init 在包加载时初始化，若不被使用，将会浪费大量内存。 html.UnescapeString(s) 函数是线程安全的，可能会被用户程序在并发场景下调用，因此对 entity 的初始化需要加锁，使用 sync.Once 能保证这一点。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 var populateMapsOnce sync.Once var entity map[string]rune func populateMaps() { entity = map[string]rune{ \u0026#34;AElig;\u0026#34;: \u0026#39;\\U000000C6\u0026#39;, \u0026#34;AMP;\u0026#34;: \u0026#39;\\U00000026\u0026#39;, \u0026#34;Aacute;\u0026#34;: \u0026#39;\\U000000C1\u0026#39;, \u0026#34;Abreve;\u0026#34;: \u0026#39;\\U00000102\u0026#39;, \u0026#34;Acirc;\u0026#34;: \u0026#39;\\U000000C2\u0026#39;, // 省略 2000 项 } } func UnescapeString(s string) string { populateMapsOnce.Do(populateMaps) i := strings.IndexByte(s, \u0026#39;\u0026amp;\u0026#39;) if i \u0026lt; 0 { return s } // 省略后续的实现 } 普通示例 对只需要运行一次的代码，如全局性的初始化操作，或者防止多次重复执行（比如重复提交等）都有很好的作用 无论 sync.Once.Do(f func()) 里面的f函数是否变化，只要 Once.Do() 运行一次就没有机会再次运行了 Once 是一个结构体，通过判断 done 值来确定是否执行下一步 当 done 为1时直接返回，否则锁定后执行f函数以及置done值为1 而对 done 的值得修改使用了 atomic.StoreUint32（原子级的操作） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var once sync.Once func onces() { fmt.Println(\u0026#34;once\u0026#34;) } func onced() { fmt.Println(\u0026#34;onced\u0026#34;) } func main() { for i, v := range make([]string, 10){ once.Do(onces) fmt.Println(\u0026#34;v:\u0026#34;, v, \u0026#34;--i:\u0026#34;, i) } for i := 0; i \u0026lt; 10; i++ { go func(i int) { once.Do(onced) fmt.Println(i) }(i) } time.Sleep(3 * time.Second) } once v: --i: 0 v: --i: 1 v: --i: 2 v: --i: 3 v: --i: 4 v: --i: 5 v: --i: 6 v: --i: 7 v: --i: 8 v: --i: 9 0 1 3 4 2 6 5 7 8 9 ","permalink":"https://heliu.site/posts/golang/sync/once/","summary":"Once是只执行一个动作的对象。","title":"sync.Once"},{"content":"type Mutex struct 🚀 包说明：\nsync 包提供了基本的同步原语，如互斥锁。 除了 Once 和 WaitGroup 类型之外，大多数都供底层库例程使用。 更高层次的同步最好通过 channels 和通信来完成。 包含在此包中定义的类型的值不应被复制。 1 2 3 4 5 6 7 // Package sync provides basic synchronization primitives such as mutual // exclusion locks. Other than the Once and WaitGroup types, most are intended // for use by low-level library routines. Higher-level synchronization is // better done via channels and communication. // // Values containing the types defined in this package should not be copied. package sync Mutex 是一把互斥锁。互斥锁的零值是未锁定的。 Mutex 在第一次使用后不能被复制。 在 Go 内存模型的术语中，第 n 次调用 Unlock，第 m 次调用 Lock 在同步完成以前 任何 n \u0026lt; m。 成功调用 TryLock 等同于调用 Lock。调用 TryLock 失败根本不会建立任何关系 在同步完成以前。 它是一把结合了【自旋锁】和【信号量】优化过的锁。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // A Mutex is a mutual exclusion lock. // The zero value for a Mutex is an unlocked mutex. // // A Mutex must not be copied after first use. // // In the terminology of the Go memory model, // the n\u0026#39;th call to Unlock “synchronizes before” the m\u0026#39;th call to Lock // for any n \u0026lt; m. // A successful call to TryLock is equivalent to a call to Lock. // A failed call to TryLock does not establish any “synchronizes before” // relation at all. type Mutex struct { // Mutex 的状态信息 state int32\t// 初始时为 0 // semaphore 相关字段，该字段也是为什么 Mutex 不让拷贝的原因 sema uint32 // 初始时为 0 } Mutex 的内存布局： Mutex 是一个互斥锁，可以创建为其他结构体的字段，零值为解锁状态。 Mutex 类型的锁和线程无关，可以由不同的线程加锁和解锁。 Mutex 结构布局： state 记录 Mutex 的相关信息。 sema 在 Mutex 中没有任何作用，主要是在 semaphore 中，该字段是 Mutex 不能被拷贝的根本原因，在 semaphore 中主要标识有 wakeup 发生。 【正常模式】和【饥饿模式】： 正常模式：一个尝试加锁的 goroutine 会先自旋几次，尝试通过原子操作获得锁，若几次自旋之后仍不能获得锁，则通过信号量（semaphore）排队等待。所有的等待者会按照先入先出（FIFO）的顺序排队，但是当一个等待者被唤醒后并不会直接拥有锁，而是需要和后来者（处于自旋阶段，尚未排队等待的协程）竞争。这种情况下后来者更有优势，一方面原因是后来者正在CPU上运行，自然比刚唤醒的 goroutine 更有优势，另一方面处于自旋状态的 goroutine 可以有很多，而被唤醒的 goroutine 每次只有一个，所以被唤醒的 goroutine 有很大概率获取不到锁，这种情况下它会被重新插入队列的头部，而不是尾部。当一个 goroutine 本次加锁等待的时间超过了 1ms 后，它会把当前 Mutex 切换至饥饿状态。 饥饿模式：Mutex 的所有权从执行 Unlock 的 goroutine 直接传递给等待队列头部的 goroutine。后来者不会自旋，也不会尝试获得锁，它们会直接从队列的尾部排队等待，即使 Mutex 处于 Unlocked 状态。当一个等待者获得了锁之后，它会在以下两种情况时将 Mutex 由饥饿模式切换回正常模式：(1)它是最后一个等待者，即等待队列空了。(2)它的等待时间小于1ms，也就是它刚来不久，后面自然更没有饥饿的 goroutine 了。 正常模式下 Mutex 有更好的性能，但是饥饿模式对于防止尾端延长（队列尾端的 goroutine 迟迟抢不到锁）来讲特别重要。 const 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 const ( // 是否上锁标志位；0-未上锁，1-已上锁； mutexLocked = 1 \u0026lt;\u0026lt; iota\t// 001 // 是否有 goroutine 从阻塞中被唤醒；0-没有；1-有； // 当该标志位被设置时，Unlock 操作不会唤醒排队的 goroutine。 mutexWoken\t// 010 // 是否处于饥饿模式；0-非饥饿，1-饥饿； mutexStarving\t// 100 // 最低位存在3个bit位标识特俗信息，分别为上述的 mutexLocked、mutexWoken、mutexStarving mutexWaiterShift = iota\t// 3 // 互斥公平 // 互斥量可以有两种操作模式:正常(normal)和饥饿(starvation)。 // 在正常模式(normal mode)下：等待的waiters按FIFO(先进先出)顺序排队，但被唤醒的waiter不拥有互斥锁，并与新到达的goroutines竞争所有权。 // 新加入的goroutines有一个优势，它们已经在CPU上运行，并且可能有很多，所以唤醒的waiters很有可能会失败。 // 在这种情况下，它被重新安排在等待队列的前面。如果waiter超过1ms未能获取互斥锁，它将互斥锁切换到饥饿模式。 // 在饥饿模式(starvation mode)下：互斥锁的所有权直接从正在解锁的goroutine移交给队列前面的waiter。 // 新到达的goroutines不会尝试获取互斥锁，即使它看起来已经解锁，也不会尝试旋转。相反，它们把自己排在等待队列的尾部。 // 如果一个waiter收到互斥锁的所有权，并且发现 //\t1) 它是队列中最后一个waiter，或者 //\t2) 它等待的时间少于1毫秒，它会将互斥锁切换回正常工作模式。 // 普通模式(Normal mode)具有更好的性能，因为goroutine可以连续多次获取互斥量，即使有阻塞的等待。 // 饥饿模式(Starvation mode)对于预防有些g一值获取不到锁的尾延迟具有重要意义。(该模式防止有些始终拿不到锁的一直等待在信号池里面的goroutine) // 正常模式 \u0026lt;-\u0026gt; 饥饿模式 相互转换的时间阀门 // 饥饿模式，当前从semaphore中wakeup的goroutine的sleep时间超过1ms，再次获取锁失败时会被标记为饥饿模式 // 饥饿模式下：state 值的 mutexLocked和mutexWoken 位可能为0或1，被唤醒的goroutine mutexLocked和mutexWoken 位都为0 starvationThresholdNs = 1e6\t// sync.Mutex 进入饥饿模式的等待时间阈值1ms。 ) Lock() Lock 锁住 m。 如果锁已经被使用，调用 goroutine 会阻塞，直到 mutex 可用。 Lock 和 Unlock 是一对操作。 该方法主要通过 atomic 函数实现了Fast path，相应的Slow path被单独放在了lockSlow()方法中。 根据源码注释的说法，这样是为了便于编译器对 Fast path 进行内联优化。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // Lock locks m. // If the lock is already in use, the calling goroutine // blocks until the mutex is available. func (m *Mutex) Lock() { // 1) 使用CAS尝试获取锁 // Fast path期望 Mutex 处于 Unlocked 状态，没有 goroutine 在排队，更不会饥饿。 // 理想状态下，一个CAS操作就可以获得锁。 // Fast path: grab unlocked mutex. // // 快速路径：获取解锁的互斥量。 // 原子操作比较 m.state 的旧值为 0 并交换成新值 1，成功则表示获取到锁。 // 这种情况发生在 state=0 时，没有等待的goroutine。 if atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // 2) m.state != 0 时都会走 Slow path // CAS 操作没能获得锁，就需要进入 Slow path了。 // Slow path (outlined so that the fast path can be inlined) // // 如果上面快速方式拿取不到锁，则去和其他竞争。上面情况拿不到锁，可能： // 1. 存在有其他goroutine正在持有锁。 // 2. 不存在其他goroutine持有锁，存在被唤醒的goroutine或还有等待的goroutine。 // 当前可能处于【正常模式】或【饥饿模式】 m.lockSlow() } lockSlow() 如果调用者拿取不到锁，则下面操作流程是先自旋试图拿去锁，实在拿取不到锁则进入信号池去等待拿取锁。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 // 竞争获取锁 // 1. 先自旋等待其他goroutine解锁（满足自旋条件时） // 2. 尝试修改 state 值竞争锁 // 3. 竞争成功，获取锁退出 // 4. 竞争失败，sleep goroutine func (m *Mutex) lockSlow() { // 1. 当前goroutine首次进入semaphore池sleep的时间/纳秒，下次wakeup后用于判断 正常模式 \u0026lt;-\u0026gt; 饥饿模式 转换 // 2. queueLifo := waitStartTime != 0; 进入 semaphore 池的首或尾，false.尾 true.首 var waitStartTime int64\t// mutex模式 【false.正常模式】 【true.饥饿模式】 // 1. 正常模式下，新来获取锁的goroutine如果满足条件会进行自旋等待锁被释放，如果还拿取不到锁则去信号池最前面等待。 // 2. 饥饿模式下，新来获取锁的goroutine不会进行自旋，直接去信号池的末尾去等待。 starving := false\t// 是否有goroutine被唤醒 false.没有 // 有被唤醒的goroutine时，会试图去拿去锁，可能是跟当前正在获取锁的goroutine竞争 // 1. 在自旋情况下满足条件设置 awoke 为 true // 2. 非饥饿模式下被唤醒的goroutine awoke 会被设置为 true // 3. 在饥饿模式下 awoke 变量没有用 awoke := false\t// 用于原子设置 mutexWoken 位，通知 Unlock 函数有 woken 的goroutine了，不要去wakeup goroutine // 记录旋转的次数，当没有获取锁时，会尝试4次去自旋获取 iter := 0\t// 自旋计数器\t// 以下代码都是从 old -\u0026gt; new 的原子操作，去尝试修改 state 值 old := m.state\t// 旧值state // 该循环只有在获取到锁的时候才会退出，因此所有未获取到锁的goroutine都将在这里等待获取锁 for { // 1) 饥饿模式下不要自旋，因为所有权按照顺序传递，自旋没有意义。 // 正常模式下锁没有被释放满足自旋条件需要自旋。 // Don\u0026#39;t spin in starvation mode, ownership is handed off to waiters // so we won\u0026#39;t be able to acquire the mutex anyway. // // 不要在饥饿模式下旋转，所有权已移交给waiters，因此我们无论如何都无法获得互斥锁 // 1. old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked; Mutex没有处于饥饿模式并且已被锁定。 // 2. runtime_canSpin(iter); 报告当前旋转要求条件。 //\t主动旋转条件： //\t旋转次数小于4次 并且 多核CPU运行 并且除了当前P还有其他P正在运行（不是空闲或自旋状态的P）并且 当前P没有其他g了 //\t这种情况需要去尝试自旋获取下锁，其他情况则不需要自旋去获取锁 // 以下自旋的意义，停留片刻等待其他goroutine让出锁，然后标记mutexWoken存在被唤醒的goroutine使自己获取锁优先级更高 if old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) {\t// 自旋在这里 // Active spinning makes sense. // Try to set mutexWoken flag to inform Unlock // to not wake other blocked goroutines. // // 主动旋转是有道理的。 // 尝试设置 mutexflag 来通知 Unlock 不要唤醒其他被阻塞在信号池的goroutines。 // 以下逻辑是处于自旋，自旋的意义在于标记有正在被唤醒的goroutine，其他线程不要再次唤醒导致过多goroutine被唤醒 // // 1. !awoke; ：没有标记当前goroutine被唤醒 // 2. old\u0026amp;mutexWoken == 0; ：没有被唤醒的goroutine，包括其他g和当前g // 3. old\u0026gt;\u0026gt;mutexWaiterShift != 0; ：存在等待排队在信号池的goroutine // 4. atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken); //\t设置标志有goroutine被唤醒，这里设置成功那unlock则不会再去唤醒goroutine if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { // 标记为唤醒状态，主要是告诉unlock不要再去唤醒goroutine了，这里有自旋的在等待 awoke = true } // 短暂延迟一段时间，主要是等待其他g解锁 // 如果此时Unlock了第一个if则不会再判断为true，直接去争抢锁了 runtime_doSpin()\titer++ old = m.state\t// 从新赋值给old continue } // 2) 锁可能已被释放尝试竞争获取，或锁还未解除去sleep。 // 代码执行到这里，只可能处于以下几种情况 // 1. 自旋次数以完，状态依然是 mutexLocked。 // 2. 状态是 mutexStarving 处于饥饿状态。 // 3. 状态是未加锁状态，锁已被解除。 // （处于饥饿模式） 或 （自旋次数超过4次） 或 （当前其他goroutine已Unlock）或 （不满足自旋条件） //\t如果锁已Unlock，那么尝试去获取锁；如果锁处于Lock，那么也尝试获取，否则加入到信号池中等待 // old 是本轮原子操作的 state 值 // new 是本轮需要争抢锁修改后的 state 值 // 正常模式下: // 1. 在old未持有锁情况下，谁先原子操作从 old 修改为 new 谁就先获取到锁 // 2. 在old持有锁情况下，当前goroutine需要sleep new := old // 2.1) 正常模式下需要争抢锁，因此需要设置mutexLocked状态 // Don\u0026#39;t try to acquire starving mutex, new arriving goroutines must queue. // // 不要尝试获取处于饥饿的Mutex，后来的goroutines必须排队。 // // 处于饥饿模式下，为什么不需要设置mutexLocked标志呢？ // 1. 处于饥饿模式下锁的持有权是手把手交给后面等待的goroutine，因此mutexLocked标志设置不设置不重要 // 2. 对于新来的goroutine，mutexLocked位可能为0或1，但是当前goroutine不会去挣抢锁直接sleep，因此mutexLocked位不重要 // 3. 对于从sleep中wakeup的goroutine，一定是来自Unlock函数而来自该函数mutexLocked位一定是0，已被解锁 if old\u0026amp;mutexStarving == 0 {\t// 处于正常模式 // new表示新值修改的状态 mutexLocked需要锁，不管当前是Lock或Unlock当前都需要设置mutexLocked表示需要去争抢锁 new |= mutexLocked\t} // 2.2) 锁还未被释放 或 处于饥饿模式下 这两种情况下都会去sleep，因此需要加一。 // 如果old锁没释放 或 处于饥饿状态，那么当前的goroutine则是需要被加入到信号池里面去的 if old\u0026amp;(mutexLocked|mutexStarving) != 0 {\t// 处于Lock或则饥饿模式当前g需要加入到信号池 new += 1 \u0026lt;\u0026lt; mutexWaiterShift\t// 数量增加1 } // 2.3) 当前 goroutine 将 mutex 切换至饥饿模式 // 如果 mutex 已经处于 unlocked 状态，就不要切换了， // 因为 Unlock() 函数认为处于饥饿模式的 mutex 等待队列不为空。 // The current goroutine switches mutex to starvation mode. // But if the mutex is currently unlocked, don\u0026#39;t do the switch. // Unlock expects that starving mutex has waiters, which will not // be true in this case. // // 当前的 goroutine 将互斥锁切换到饥饿模式，但如果互斥锁当前已解锁，就不要切换。 // Unlock期望处于饥饿状态的互斥锁有waiters，但在本例中并非如此。 // // starving=true 发生在：这个goroutine被加入到信号池后再度被唤醒去争抢锁时，发现等待时间已经超过1ms时 // old\u0026amp;mutexLocked != 0，表示这个被唤醒的goroutine再次争抢锁时锁没被其他gorutine释放，这次再争抢将失败则会标记成饥饿模式 if starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 {\t// 这种情况下当前goroutine基本拿去不到锁 new |= mutexStarving // 标记成饥饿模式时，锁一定被其他持有；但是唤醒的g处于饥饿模式时，锁一定是Unlock状态 } // 2.4) 当前goroutine是被唤醒的，检查并清除标志位 // awoke=true 表示来自自旋或被唤醒的goroutine两种形式 // 1. 自旋状态下 awoke=true，state 中 mutexWoken 位已被设置为 1 // 2. 被唤醒的goroutine下 awoke=true 在本函数的唤醒后被设置，而 state 中 mutexWoken 位在Unlock函数中被设置 // 因此 awoke=true 就一定存在 state 中 mutexWoken 位为1，new\u0026amp;mutexWoken != 0成立 if awoke {\t// awoke有等待的goroutine被唤醒 // The goroutine has been woken from sleep, // so we need to reset the flag in either case. // // goroutine 已经从睡眠中唤醒，所以我们需要在任何一种情况下重置标志 if new\u0026amp;mutexWoken == 0 {\t// 不论来自自旋或被唤醒的goroutine这里都不能为0，正常状况下 throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } new \u0026amp;^= mutexWoken // 清除被唤醒标志位mutexWoken，因为下面即将去争抢锁，或者载入去信号池等待 } // 尝试使用原子修改state，所有的goroutine都会通过该条件，但是一轮只能成功一个 // 这里修改m.state成功了，并不代表一定获取到了锁，也有可能是当前g需要加入到信号池中去 if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) {\t// 如果上一个拿去到锁的state是正常模式并没有锁，则这里直接退出，这里表示当前goroutine获取到了锁，正常模式都是从这里退出的 // 正常模式下获取到锁的情况，这里不会出现标记成饥饿模式但这里又判断为true退出了的情况，原因是标记成饥饿模式的前置条件是当前old是Lock if old\u0026amp;(mutexLocked|mutexStarving) == 0 {\t// 谁先拿到锁退出，接到执行goroutine后面代码 break // locked the mutex with CAS } // 后面处理逻辑是之前有锁，这个goroutine需要去排队情况，或当前模式处于饥饿模式，直接把该goroutine加入到尾部 // If we were already waiting before, queue at the front of the queue. // // 如果我们之前已经在等待，请在队列的前面排队 // waitStartTime如果不等于0说明先前入队过有被唤醒过，正常第一次入队这里是false // 被唤醒之后没有抢到锁，需要插入队列头部，而不是尾部。 queueLifo := waitStartTime != 0 // 首次进入信号池去等待时 if waitStartTime == 0 {\t// 这里表示这个goroutine从信号池中第一次被唤醒依然没有获取到锁，从新设置时间 waitStartTime = runtime_nanotime()\t// 注意：除第一次入队后后面每次缓存waitStartTime时间都不会被刷新 } // 这里存在被唤醒但是还是没拿到锁的情况会再次被入队 // runtime_SemacquireMutex的queueLifo参数为true则是插入的信号池头部，false插入到尾部 //\t首次进入信号池，则直接排在尾部 //\t从信号池中出来又争抢失败进入信号池排在头部 // 如我们取出gorutine则是从头部开始往后取，这也就是我们说的先进先出 // 因为第一次加入信号池的都是插入到尾部，当再被唤醒依然没有获取到锁时，则是被放回到头部 // 当前goroutine去排队，这里当前groutine被调离工作线程等待抢到锁后继续后面执行 runtime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1)\t// 被唤醒的g，接到从这里执行尝试去获取锁；可能当前处于饥饿模式或处于正常模式，唤醒g的相关代码位于Unlock函数 // 如果等待的时间大于1ms则标记成饥饿模式，以下逻辑是当前goroutine被唤醒后再次尝试获取锁 // 等待时间超过了1ms，等待时间太久需要被标记为饥饿状态 starving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state\t// 获取当前的状态 // 如果处于饥饿模式，处于饥饿模式下唤醒的goroutine立即获取锁，因为正常来抢的goroutine都会被入队， // 然后一个个来获取 // 所有饥饿模式下获取锁的出口都在这里，该条件满足说明当前goroutine获取到锁持有权 if old\u0026amp;mutexStarving != 0 {\t// If this goroutine was woken and mutex is in starvation mode, // ownership was handed off to us but mutex is in somewhat // inconsistent state: mutexLocked is not set and we are still // accounted as waiter. Fix that. // // 当前代码位置的 goroutine 肯定是被唤醒的，而且 Mutex 处于饥饿模式 // 所有权被直接交给当前 goroutine // 但是这种情况下 mutex 的 state 会与实际情况不一致 // mutexLocked 标志位没有设置 // 而且等待者计数中也没有减去当前 goroutine。需要修复 state // 注意饥饿模式下传递 mutex 所有权不会设置 mutexWoken 标志，只有正常模式下唤醒才会 // // 饥饿模式下 old\u0026gt;\u0026gt;mutexWaiterShift != 0，当前一定不能是最后一个， // 因为下面 old\u0026gt;\u0026gt;mutexWaiterShift == 1 会退出饥饿模式 // old\u0026amp;(mutexLocked|mutexWoken) != 0 因为处于饥饿模式下，所有的goroutine都会去排队sleep， // 被wakeup的goroutine一定来自Unlock函数， // 此时mutexLocked一定解锁，mutexWoken一定是被清除的 if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { // 饥饿模式下，mutexLocked和mutexWoken必定为0，参看上面代码。 throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } // +mutexLocked -1\u0026lt;\u0026lt;mutexWaiterShift delta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift)\t// 将等待的数量减一 // 等待时间小于1ms 或 当前goroutine是队列最后一个，则标记退出饥饿模式 if !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { // Exit starvation mode. // Critical to do it here and consider wait time. // Starvation mode is so inefficient, that two goroutines // can go lock-step infinitely once they switch mutex // to starvation mode. delta -= mutexStarving\t// 退出饥饿模式 } atomic.AddInt32(\u0026amp;m.state, delta) // 修改state，返回直接返回，应为该goroutine 获取到锁了 break\t// 饥饿模式从这里退出，因此饥饿模式下被唤醒的goroutine直接从这里退出 } // 正常模式下，设置为唤醒去争抢锁 awoke = true\t// state的mutexWoken位在Unlock函数中被设置 iter = 0\t// 自旋次数重置 } else { // 从old-\u0026gt;new 原子设置，如果设置失败从新再来 old = m.state } } if race.Enabled { race.Acquire(unsafe.Pointer(m)) } } sync_runtime_canSpin() sync.Mutex 主动旋转条件。 不主动旋转条件： 【旋转次数大于等于4次】或【单核CPU在运行】 或【除了当前P其他P都处于空闲或自旋状态】，不需要主动去旋转等待获取锁。 如果当前P的runq不为空，也没必要去自旋，因为里面的g还等着去执行，直接把当前g挂起。 主动旋转条件： 【旋转次数小于4次】并且【多核CPU运行】并且【除了当前P还有其他P正在运行】（不是空闲或自旋状态的P）并且 【当前P没有其他g了】。 这种情况需要去尝试自旋获取下锁，其他情况则不需要自旋去获取锁。 runtime/proc.go文件中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // Active spinning for sync.Mutex. //go:linkname sync_runtime_canSpin sync.runtime_canSpin //go:nosplit func sync_runtime_canSpin(i int) bool { // sync.Mutex is cooperative, so we are conservative with spinning. // Spin only few times and only if running on a multicore machine and // GOMAXPROCS\u0026gt;1 and there is at least one other running P and local runq is empty. // As opposed to runtime mutex we don\u0026#39;t do passive spinning here, // because there can be work on global runq or on other Ps. // // sync.Mutex是合作性的，所以我们对spinning是保守的。 // 只旋转几次，且仅当运行在多核计算机和GOMAXPROCS\u0026gt;1上，并且至少有一个其他运行P且本地runq为空时。 // 与运行时互斥锁相反，我们在这里不做被动旋转，因为可以在全局runq或其他P上进行工作。 // // 以下条件满足一项都不会再次自旋去获取锁 // 1. const active_spin = 4; 最多尝试4次自旋获取 // 2. var ncpu int32 \u0026lt;= 1; 如果是单核CPU // 3. gomaxprocs \u0026lt;= int32(sched.npidle+sched.nmspinning)+1; // 3.1 gomaxprocs：表示总的P // 3.2 sched.npidle空闲的P数量 // 3.3 sched.nmspinning正在自旋的M数量(这里面可能存在正在争抢锁，处在自旋都是只有一个g的情况) // 除了当前P其他的P都很闲，也不必要自旋了。 if i \u0026gt;= active_spin || ncpu \u0026lt;= 1 || gomaxprocs \u0026lt;= int32(sched.npidle+sched.nmspinning)+1 { return false } // 这里不像 runtime.mutex 那样进行消极自旋，因为全局 runq 或其他 P 上或许还有可运行的任务。 // 当前本地P不为空，也不需要自旋再出去尝试获取锁，其他goroutine还等起的。 if p := getg().m.p.ptr(); !runqempty(p) { return false } return true } sync_runtime_doSpin() 短暂的延迟。 runtime/proc.go 文件中。 1 2 3 4 5 6 //go:linkname sync_runtime_doSpin sync.runtime_doSpin //go:nosplit func sync_runtime_doSpin() { // 循环30次等待 procyield(active_spin_cnt)\t// active_spin_cnt=30 } procyield() 短暂的延迟。 1 2 3 4 5 6 7 8 # runtime/asm_amd.64.s TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL\tcycles+0(FP), AX\t# AX=30 参数 again: PAUSE # 自旋降低CPU发热和性能优化。 SUBL\t$1, AX\t# AX -= 1 JNZ\tagain RET Unlock() Unlock解锁m。 如果m在进入解锁时没有被锁定，则是一个运行时错误。 一个锁定的互斥量与一个特定的goroutine无关。 允许一个goroutine锁定一个互斥量，然后安排另一个goroutine解锁它。 该方法主要通过 atomic 函数实现了 Fast path，相应的 Slow path被单独放在了 unlockSlow() 方法中。 根据源码注释的说法，这样是为了便于编译器对 Fast path 进行内联优化。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // Unlock unlocks m. // It is a run-time error if m is not locked on entry to Unlock. // // A locked Mutex is not associated with a particular goroutine. // It is allowed for one goroutine to lock a Mutex and then // arrange for another goroutine to unlock it. func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // 1) 通过原子操作从 state 中减去 mutexLocked，也就是释放锁 // 然后根据 state 的新值(new)来判断是否需要执行 Slow path。 // Fast path: drop lock bit. // // Fast path: 直接把锁标志位放开 // 如果之前mutexLocked位为1则修改为0；如果之前mutexLocked位为0则修改为1； new := atomic.AddInt32(\u0026amp;m.state, -mutexLocked)\t// 如果删除了锁的bit位，state等于0说明没有等待抢锁的goroutine直接返回 // new为0，意味着没有其他 goroutine 在排队，所以不需要执行额外操作。 // new不为0，则可能需要唤醒某个 goroutine。 // Unlock 执行完后mutex.state!=0 则存在以下可能 // 正常模式下 // 1. 当前存在等待的goroutine去唤醒它 //\t2. 当前存在自旋等待的goroutine，则不唤醒其他等待的goroutine // 饥饿模式下 // 1. 直接将锁交给等待队列的第一个goroutine if new != 0 {\t// 还存在其他等待队列中的goroutine // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. // // 概述了慢速路径以允许内联快速路径 // 为了在跟踪过程中隐藏 unlockSlow，我们在跟踪 GoUnblock 时会跳过一个额外的帧 m.unlockSlow(new) } } unlockSlow() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 func (m *Mutex) unlockSlow(new int32) { // 判断未加锁的情况下不能多次调用unlock // 正常逻辑这里 new+mutexLocked 应该为1 if (new+mutexLocked)\u0026amp;mutexLocked == 0 {\t// 这种情况判断之前根本就没加过锁，则去解锁这会直接报错误 throw(\u0026#34;sync: unlock of unlocked mutex\u0026#34;) } // 正常模式下 if new\u0026amp;mutexStarving == 0 { // 从 old -\u0026gt; new 原子操作，主要是唤醒goroutine old := new for {\t// 以下代码是通过唤醒goroutine和其他正在运行的goroutine去争抢锁 // If there are no waiters or a goroutine has already // been woken or grabbed the lock, no need to wake anyone. // In starvation mode ownership is directly handed off from unlocking // goroutine to the next waiter. We are not part of this chain, // since we did not observe mutexStarving when we unlocked the mutex above. // So get off the way. // // 如果没有waiters，或goroutine已经被叫醒或抢了锁，没有必要叫醒任何人。 // 在饥饿模式下，所有权会从解锁goroutine直接移交给下一个waiter。 // 我们不是这个链的一部分，因为我们在上面解锁互斥锁时没有观察到mutexStarving。所以别挡道。 // // 没有等待的goroutine 或 (有其他的goroutine已近获得锁 或 有被唤醒的goroutine 或 当前处于饥饿模式下) if old\u0026gt;\u0026gt;mutexWaiterShift == 0 || old\u0026amp;(mutexLocked|mutexWoken|mutexStarving) != 0 { return\t// 直接返回，不需要再去后续处理 } // Grab the right to wake someone. // // 等在被唤醒的goroutine数量减一，设置有被唤醒标志 new = (old - 1\u0026lt;\u0026lt;mutexWaiterShift) | mutexWoken\t// 设置需要唤醒一个goroutine的新状态 if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) {\t// 原子设置成功，说明没有其他正在争抢或当前争抢成功 runtime_Semrelease(\u0026amp;m.sema, false, 1)\t// 取出等待的goroutine放入本地P等待被调度，饭后返回 return } old = m.state\t// 没有获取成功，则直接替换旧state，再次尝试 } } else {\t// 饥饿模式下 // Starving mode: handoff mutex ownership to the next waiter, and yield // our time slice so that the next waiter can start to run immediately. // Note: mutexLocked is not set, the waiter will set it after wakeup. // But mutex is still considered locked if mutexStarving is set, // so new coming goroutines won\u0026#39;t acquire it. // // 饥饿模式：将mutex所有权移交给下一个waiter，并让出我们的时间片，以便下一个waiter可以立即开始运行 // 注意：mutexLocked 没有设置，waiter会在唤醒后设置 // 但是如果设置了 mutexStarving，mutex 仍然被认为是锁定的，所以新的 goroutines 不会获取它 // 处于饥饿模式下从这里唤醒的goroutine，state中mutexLocked位，一定为0 runtime_Semrelease(\u0026amp;m.sema, true, 1)\t// 饥饿模式下只从首部取出goroutine等待被调度即可 // 这里在饥饿模式下为甚不判断等待的goroutine数量？ // 原因是：处于饥饿模式下等待的goroutine数量一定是\u0026gt;=1的。 // 因为最后一个goroutine会把模式切换成正常模式，相关代码位于Lock函数 } } TryLock() TryLock试图锁定m并报告是否成功。 请注意，虽然确实存在正确使用TryLock的情况，但很少，而且TryLock的使用通常表明互斥量的特定使用中存在更深层的问题。 TryLock 可以用于在业务比较繁忙时去尝试获取锁，失败则提示相关文案等 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // TryLock tries to lock m and reports whether it succeeded. // // Note that while correct uses of TryLock do exist, they are rare, // and use of TryLock is often a sign of a deeper problem // in a particular use of mutexes. func (m *Mutex) TryLock() bool { old := m.state // 当前锁存在 或 当前处于饥饿模式 if old\u0026amp;(mutexLocked|mutexStarving) != 0 { return false\t// 获取失败 } // There may be a goroutine waiting for the mutex, but we are // running now and can try to grab the mutex before that // goroutine wakes up. // // 可能有一个goroutine在等待互斥量，但我们现在正在运行，并且可以尝试在goroutine唤醒之前获取互斥量。 // // 尝试去争抢锁，这里的old一定是没加锁并处于正常模式下去尝试争抢 if !atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexLocked) { return false\t// 争抢失败情况 } if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return true\t// 争抢成功 } type Locker interface Locker接口代表一个可以加锁和解锁的对象 1 2 3 4 5 // A Locker represents an object that can be locked and unlocked. type Locker interface { Lock() Unlock() } 使用示例 sync.Mutex 互斥锁：是传统的并发程序对共享资源进行访问控制的主要手段，Go语言中推荐使用通道(channel)来实现资源共享和通信 互斥锁：由标准库 sync 包中分的 Mutex 结构体类型实现 只有两个公开方法： Lock() ：获得锁 Unlock() ：释放锁 同一个协程中同步调用使用Lock()加锁后，不能再对其加锁，否则会引发运行时异常，只能在 Unlock() 之后再次 Lock() 多个协程中异步调用Lock()没有问题，但每个协程只能调用一次Lock()，由于多个协程之间产生了锁竞争，因此不会有运行时异常 互斥锁：适用于只允许有一个读或者写的场景，所以该锁也叫全局锁 如果在使用 Unlock() 前未加锁，就会引起一个运行错误，已经锁定的 Mutex 并不与特定的协程相关，这样可以利用一个协程对其加锁，在利用其它协程对其解锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 // LockA() 中有 Lock() // LockB() 中也有 Lock() // LockB() 的 Lock() 运行时，锁还没有 Unlock()，程序发生 panic // 这是在同步调用互斥锁中常见的问题，一般在一对互斥锁中间不要调用其它函数，即使要用也尽量采用异步方式 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var mutex sync.Mutex func main() { LockA() time.Sleep(10) } func LockA() { mutex.Lock()\t// 加锁 fmt.Println(\u0026#34;Lock in A\u0026#34;) LockB() time.Sleep(5) fmt.Println(\u0026#34;Wake up in A\u0026#34;) mutex.Unlock()\t// 解锁 fmt.Println(\u0026#34;Unlock in A\u0026#34;) } func LockB() { fmt.Println(\u0026#34;B\u0026#34;) mutex.Lock()\t// 加锁\tmain goroutine在这里被阻塞，导致deadlock fmt.Println(\u0026#34;Lock in B\u0026#34;) mutex.Unlock()\t// 解锁 fmt.Println(\u0026#34;Unlock in B\u0026#34;) } /* Lock in A B fatal error: all goroutines are asleep - deadlock! goroutine 1 [semacquire]: sync.runtime_SemacquireMutex(0x593b24, 0x0, 0x1) D:/True-False/Go/src/runtime/sema.go:71 +0x4e sync.(*Mutex).lockSlow(0x593b20) D:/True-False/Go/src/sync/mutex.go:138 +0x103 sync.(*Mutex).Lock(...) D:/True-False/Go/src/sync/mutex.go:81 main.LockB() D:/True-False/WWW/GoLang/src/xuexi/mutex.go:28 +0x194 main.LockA() D:/True-False/WWW/GoLang/src/xuexi/mutex.go:19 +0xa2 main.main() D:/True-False/WWW/GoLang/src/xuexi/mutex.go:12 +0x29 exit status 2 */ 把上面同步改为异步，把LockA()的LockB()改为go LockB() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var mutex sync.Mutex func main() { LockA() time.Sleep(10) } func LockA() { mutex.Lock()\t// 加锁 fmt.Println(\u0026#34;Lock in A\u0026#34;) go LockB() time.Sleep(5) fmt.Println(\u0026#34;Wake up in A\u0026#34;) mutex.Unlock()\t// 解锁 fmt.Println(\u0026#34;Unlock in A\u0026#34;) } func LockB() { fmt.Println(\u0026#34;B\u0026#34;) mutex.Lock()\t// 加锁\tlockB goroutine等待LockA解锁，先自旋再是被挂起 fmt.Println(\u0026#34;Lock in B\u0026#34;) mutex.Unlock()\t// 解锁 fmt.Println(\u0026#34;Unlock in B\u0026#34;) } /* Lock in A B Wake up in A Unlock in A Lock in B Unlock in B */ 建议：同一个互斥锁的成对锁定和解锁操作可以放在同一层次的代码块中 经典用法如下： 1 2 3 4 5 6 7 8 var lck sync.Mutex func foo() { lck.Lock()\t// 加锁 defer lck.Unlock()\t// 解锁 // ... ... } // lck.Lock() 会阻塞直到获取锁，然后利用defer语句在函数返回时自动释放锁 示例代码，通过三个协程来体现sync.Mutex对资源的访问控制特征 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { //var wg sync.WaitGroup wg := sync.WaitGroup{} var mutex sync.Mutex fmt.Println(\u0026#34;Locking (G0)\u0026#34;) mutex.Lock()\t// 加锁 fmt.Println(\u0026#34;locked (G0)\u0026#34;) wg.Add(3) for i := 1; i \u0026lt; 4; i++ { go func(i int) { fmt.Printf(\u0026#34;Locking (G%d)\\n\u0026#34;, i) mutex.Lock()\t// 加锁 fmt.Printf(\u0026#34;Locked (G%d)\\n\u0026#34;, i) time.Sleep(time.Second * 2)\t// 延迟2s mutex.Unlock()\t// 解锁 fmt.Printf(\u0026#34;unlocked (G%d)\\n\u0026#34;, i) wg.Done() }(i) } time.Sleep(time.Second * 5) fmt.Println(\u0026#34;ready unlock (G0)\u0026#34;) mutex.Unlock()\t// 解锁 fmt.Printf(\u0026#34;unlocked (G0)\u0026#34;) wg.Wait() } // 程序运行结果可以看出，当有锁释放时，才能进行加锁动作 // 运行结果如下 Locking (G0) locked (G0) Locking (G1) Locking (G2) Locking (G3) ready unlock (G0) unlocked (G0)Locked (G1) unlocked (G1) Locked (G2) unlocked (G2) Locked (G3) unlocked (G3) Mutex 也可以作为结构体的一部分，这样结构体在被多线程处理时数据安全才有保障 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Book struct { BookName string L *sync.Mutex } func (bk *Book) SetName(wg *sync.WaitGroup, name string) { defer func() { fmt.Println(\u0026#34;Unlock set name:\u0026#34;, name) bk.L.Unlock()\t// 解锁 wg.Done() }() bk.L.Lock()\t// 加锁 fmt.Println(\u0026#34;Lock set name:\u0026#34;, name) time.Sleep(1 * time.Second) bk.BookName = name } func main() { bk := Book{} //bk.L = \u0026amp;sync.Mutex{} bk.L = new(sync.Mutex) //wg := new(sync.WaitGroup) wg := \u0026amp;sync.WaitGroup{} books := []string{\u0026#34;\u0026lt;\u0026lt;三国演义\u0026gt;\u0026gt;\u0026#34;, \u0026#34;\u0026lt;\u0026lt;道德经\u0026gt;\u0026gt;\u0026#34;, \u0026#34;\u0026lt;\u0026lt;西游记\u0026gt;\u0026gt;\u0026#34;} for _, book := range books { wg.Add(1) go bk.SetName(wg, book) } wg.Wait() } Lock set name: \u0026lt;\u0026lt;西游记\u0026gt;\u0026gt; Unlock set name: \u0026lt;\u0026lt;西游记\u0026gt;\u0026gt; Lock set name: \u0026lt;\u0026lt;三国演义\u0026gt;\u0026gt; Unlock set name: \u0026lt;\u0026lt;三国演义\u0026gt;\u0026gt; Lock set name: \u0026lt;\u0026lt;道德经\u0026gt;\u0026gt; Unlock set name: \u0026lt;\u0026lt;道德经\u0026gt;\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var m sync.Mutex go func() { m.Lock() defer m.Unlock() fmt.Println(\u0026#34;1\u0026#34;) m.Lock()\t// 这里当前goroutine将被永久保存到信号池中得不到运行机会 fmt.Println(\u0026#34;2\u0026#34;) defer m.Unlock() fmt.Println(\u0026#34;3\u0026#34;) }() time.Sleep(5 * time.Second) // Output: // 1 } 注意事项 Lock() 和 UnLock() 方法应该成对出现。 sync.Mutex 不允许被值拷贝，拷贝地址可以。 ","permalink":"https://heliu.site/posts/golang/sync/mutex/","summary":"Mutex是一种互斥锁。","title":"sync.Mutex"},{"content":" 定义结构体、接口、类型别名等。 定义自定义类型： 自定义类型由一组值以及作用于这些值的方法组成。 类型一般有类型别名，往往从现有类型组合通过type关键字构造出一个新的类型。 自定义类型 Go基础数据类型： bool、complex64、complex128、float32、float64。 int、int8、int16、int32、int64、rune、string。 uint、uint8、uint16、uint32、uint64、byte、uintptr。 使用type关键字可以定义自己的类型，可以使用type定义一个新的结构体。 也可以把一个已经存在的类型作为基础类型而定义新类型，然后在代码中使用新的类型名字。 1 type IZ int IZ是一种新类型，然后可以使用下面方式声明变量。 1 var a IZ = 5 可以看到int是变量a的底层类型，这也使得他们之间成为相互转化的可能。 定义多个类型如下： 1 2 3 4 5 type ( IZ int FZ float64 STR string ) 在type IZ int中，IZ就是在int类型基础上构建的新名称，这称为自定义类型，使用IZ来操作int类型的数据。 这种方法定义之后的类型可以拥有更多的特性，但是在类型转换时必须显示转换。 每个值都必须在经过编译后属于某个类型（编辑器必须能够推断出所有值得类型）因为Go是一种静态类型语言。 在必要以及可行的情况下，一种类型的值可以被转换成另外一种类型的值。 Go语言不存在隐式转换，因此所有的转换都必须显式说明，就像调用一个函数一样（类型在这里的作用可以看作是一种函数）。 1 valueOfTypeB = typeB(valueOfTypeA) 类型B的值 = 类型B(类型A的值)。 type TZ int中，新类型TZ不会拥有原基础类型所附带的方法。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;fmt\u0026#34; ) type A struct { Face int } func (a A) f () { fmt.Println(\u0026#34;hi \u0026#34;, a.Face) } // 自定义新类型Aa。没有基础类型A的方法 type Aa A func main() { var s A = A{Face:9} s.f() // hi 9 var sa Aa = Aa{Face:90} //sa.f() // 方法不存在 fmt.Println(sa) // {90} } 通过type关键字在原有类型基础上构造出一个新类型，需要针对新类型来重新创建新方法。 类型别名 类型别名在Go1.9版本中实现，将别名类型和原类型这两个类型视为完全一致。 1 type IZ = int 与type IZ int不同，type IZ = int只是为int取了个别名，而type IZ int却是定义了新类型。 自定义类型不会拥有原类型附带的方法，而别名拥有原类型附带的方法，类型别名拥有原类型全部的方法。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;fmt\u0026#34; ) type A struct { Face int } func (a A) f () { fmt.Println(\u0026#34;hi \u0026#34;, a.Face) } // 自定义新类型Aa。没有基础类型A的方法 type Aa = A func main() { var s A = A{Face:9} s.f() // hi 9 var sa Aa = Aa{Face:90} sa.f() // hi 90 fmt.Println(sa) // {90} } Go语言不存在类型继承。 函数也是一个确定的类型，就是以函数签名作为类型，函数签名：函数的参数和返回值。 1 type typeFunc func(int, int) int 可以在函数体中的某处返回使用类型为typeFunc的变量varfunc。 1 return varfunc 自定义类型不会继承原有类型的方法，但接口方法或组合类型的内嵌元素则保留原有的方法。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;fmt\u0026#34; ) // Mutex 用两种方法，Lock和Unlock type Mutex struct{} func (m *Mutex) Lock() {} func (m *Mutex) Unlock() {} //NewMutex 和 Mutex 的数据结构一样，但是其方法是空的 type NewMutex Mutex // PtrMutex 的方法也是空的 type PtrMutex Mutex // PrintableMutex 拥有Lock和Unlock方法 type PrintableMutex struct { Mutex\t// 组合 } func main() {} ","permalink":"https://heliu.site/posts/golang/type/typ/","summary":"Golang type关键字用法介绍。","title":"type"},{"content":"Golang 软件安装 首先需要下载Go语言安装包。 下载地址：https://golang.org/dl/。（中国大陆可能访问不到） 国内下载地址：https://golang.google.cn/dl/。 官方安装教程：https://golang.google.cn/doc/install。 官方的教程很详细（https://golang.google.cn/doc）。 Linux UNIX / Linux / Mac OS和FreeBSD系统可以使用如下源码安装方法。 Mac系统下可以使用以.pkg为扩展名的安装包直接双击来完成安装，安装目录在/usr/local/go/下。 Linux下安装golang步骤 下载安装包wget https://golang.google.cn/dl/go1.17.3.linux-amd64.tar.gz。 32-bit Linux下载安装包 https://golang.google.cn/dl/go1.17.3.linux-386.tar.gz。 64-bit Linux下载安装包 https://golang.google.cn/dl/go1.17.3.linux-amd64.tar.gz。 删除老版本（如果存在则执行，不存在则忽略）rm -rf /usr/local/go。 解压安装包sudo tar -xzf go1.17.3.linux-amd64.tar.gz -C /usr/local。 配置环境变量：使用go env -w命令一般只是本次生效。 PATH环境变量export PATH=$PATH:/usr/local/go/binGoLang工具位置，包含gofmt工具。 GOROOT变量export GOROOT=/usr/local/goGoLang安装包位置。 使用go env -w GOROOT=/usr/local/go配置也是可以的。 GOPATH变量export GOPATH=/var/local/goGoLang 1.11版本前项目管理包位置。 使用go env -w GOPATH=/var/local/go配置也是可以的。 打印Go版本号go version。 如果上面(第4步)环境变量配置不成功，那么执行如下步骤配置： sudo vim ~/.bashrc命令打开文件。 在文件最后添加： 1 2 3 4 5 6 7 export GOROOT=/usr/local/go export GOPATH=/var/local/go export PATH=$PATH:$GOROOT/bin:$GOPATH/bin export GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; # 在linux中设置临时目录，windows不用 export TMPDIR=/tmp 最后使配置生效 source ~/.bashrc。 Windows 下载 https://golang.google.cn/dl/go1.17.3.windows-amd64.zip，直接解压到安装目录。 如D:\\Go，然后把D:\\Go\\bin目录添加到PATH环境变量中。 设置GOPATH和GOROOT环境变量： GOPATH=D:\\goproject。 GOROOT=D:\\GO\\。 也可以选择 https://golang.google.cn/dl/go1.17.3.windows-amd64.msi，双击运行程序，根据提示来操作安装。 GOROOT、GOPATH GOROOT Go软件的安装包绝对路径，默认是/usr/local/go。 GOPATH $GOPATH允许有多个目录，当有多个目录时，请注意分隔符，Windows中的分隔符是分号(;)。 当有多个目录时默认将go get命令获取的包存放在第一个目录下，当在GOPATH模式下运行时是这样处理的。 $GOPATH目录下约定有三个子目录： src目录：存放源代码（如.go，.c，.h，.s等文件）。 按照Go默认约定，src目录是go run，go install等命令的当前工作路径（即在此路径下执行上述命令）。 src也是用户代码存放的主要目录，所有的源代码都存放在这个目录下面，一般一个项目和一个目录对应。 当在GOPATH模式下运行时是这样处理的，但是Go官方在Go 1.11版本后不再推荐使用GOPATH模式编写Go代码，因此src目录无用处。 pkg目录：存放编译时生成的中间文件（比如：.a）。 bin目录：存放编译后生成的可执行文件，比如后面安装的delve插件或多版本go软件就是在这个目录里。 管理Go安装 安装多个Go版本 在同一台机器上安装多个Go版本。例如，我们可能希望在多个Go版本上测试代码。 注意：需要使用这种形式安装需要先安装git。 多版本go安装步骤 要安装其他Go版本，运行go install命令，指定要安装的版本的下载位置。如下示例安装版本1.10.7： go install golang.org/dl/go1.10.7@latest这里使用go install编译并安装指定的包来实现多版本go安裝，生成后的可执行文件在bin目录下（$GOPATH/bin）。 go1.10.7 download下载，需要切换到$GOPATH/bin下去执行，生成的安装路径在/root/sdk/go1.10.7。 1 2 $ go install golang.org/dl/go1.10.7@latest # 安装并编译go1.10.7版本 $ go1.10.7 download 要使用新下载的版本运行命令，如下所示： 1 2 $ go1.10.7 version go version go1.10.7 linux/amd64 当你安装了多个版本时，可以使用如下命令查看每个版本的安装位置： 1 $ go1.10.7 env GOROOT 要卸载下载的版本时，只需要删除其由GOROOT环境变量和go.X.Y.Z二进制文件指定的安装目录即可。 卸载Go 使用如下所描述的步骤从系统中删除Go。 Linux / macOS / FreeBSD 删除go目录：通常是/usr/local/go目录。 从PATH环境变量中删除Go bin目录。 在Linux和FreeBSD下，编辑/etc/profile或$HOME/.profile。 如果您使用macOS软件包安装了Go，请删除/etc/paths.d/go文件。 Windows 删除Go的最简单方法是通过Windows控制面板中的 Add/Remove 程序： 在控制面板中，双击Add/Remove程序。 在Add/Remove程序中，选择要卸载的软件，单击卸载，然后按照提示进行操作。 要使用工具删除Go，您还可以使用命令行： 通过运行以下命令使用命令行卸载：msiexec /x go{{version}}.windows-{{cpu-arch}}.msi /q 注意：对 Windows 使用此卸载过程将自动删除由原始安装创建的 Windows 环境变量。 ","permalink":"https://heliu.site/posts/golang/install/install/","summary":"Go 软件安装。","title":"Install Golang"},{"content":"type WaitGroup struct 🚀 WaitGroup 等待 goroutine 集合完成。 main goroutine 调用 Add 来设置要等待的 goroutine 的数量。然后每个 goroutine 运行并在完成时调用 Done。 同时，可以使用 Wait 来阻塞，直到所有 goroutine 完成。 WaitGroup 在第一次使用后不能被复制。 WaitGroup：用于等待一组线程的结束，父线程调用Add方法来设定应等待的线程的数量。 每个被等待的线程在结束时应调用Done方法，同时，主线程里可以调用Wait方法阻塞至所有线程结束。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // A WaitGroup waits for a collection of goroutines to finish. // The main goroutine calls Add to set the number of // goroutines to wait for. Then each of the goroutines // runs and calls Done when finished. At the same time, // Wait can be used to block until all goroutines have finished. // // A WaitGroup must not be copied after first use. type WaitGroup struct { // WaitGroup 首次使用后不能被拷贝的原因【是 \u0026amp;state2 地址会发生变化】 // semaPhore 要求 \u0026amp;state2 地址是一个，不然从其中唤醒 goroutine 会找不到 noCopy noCopy\t// 编译器检查WaitGroup对象是否被拷贝过 // 64-bit value: high 32 bits are counter, low 32 bits are waiter count. // 64-bit atomic operations require 64-bit alignment, but 32-bit // compilers only guarantee that 64-bit fields are 32-bit aligned. // For this reason on 32 bit architectures we need to check in state() // if state1 is aligned or not, and dynamically \u0026#34;swap\u0026#34; the field order if // needed. // // 64位值: 高32位是 counter 计数，低32位是 waiter 计数。 // 64-bit = ( uint64(counter) \u0026lt;\u0026lt; 32 ) | uint32( waiter ) // 【64位原子操作需要64位对齐】，但是32位编译器只保证64位字段是32位对齐的。 // 因此，在32位架构上，我们需要检查在state()是否将state1对齐，并在需要时动态 “交换” 字段顺序。 // 意思是：在32位操作系统下使用64位原子操作时，被操作地址必须是64位对齐的，不然会宕机。 state1 uint64\t// (uint64(counter) \u0026lt;\u0026lt; 32) | uint32(waiter) state2 uint32 } type noCopy struct noCopy 可以嵌入到第一次使用后不得复制的结构中. sync/cond.go文件。 1 2 3 4 5 6 7 8 9 10 11 12 // noCopy may be embedded into structs which must not be copied // after the first use. // // See https://golang.org/issues/8005#issuecomment-190753527 // for details. type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. // // Lock 是 `go vet` 的 -copylocks 检查器使用的无操作 func (*noCopy) Lock() {} func (*noCopy) Unlock() {} WaitGroup 结构布局 Semaphore：信号量用于挂起 Wait 函数的调用者的 goroutine。（需要一个 uint32 类型） Counter：等待的运行的 goroutine 数量，该值在 Add 和 Done 函数中被操作。 Waiter：等待在 Semaphore 中的 goroutine 数量。 为什么需要这么设计呢？因为 Waiter + Counter 是一个整体作为64位，被原子操作，而64位原子操作又要求必须是64位对齐的。（具体参看state()源码） 在1.22版本中，state1也就是Waiter和Counter使用atomic.Uint64替代了。以下图是1.18前版本的。 Sema、Counter、Waiter WaitGroup 结构设计目的是等待集合中的goroutine完成，因此 main goroutine 就是产生这个等待集合的，它等待集合中的所有goroutine完成再继续后续。 Counter 则是计数当前等待集合中的goroutine的数量，一个goroutine被创建放入集合时就应该计数Counter值，一个goroutine完成时也应该计数Counter。 因此goroutine被加入到等待集合中都是在main goroutine中操作包括Counter的计数，一个goroutine完成计数Counter应该在这goroutine完成时操作。 Semaphore 则是 main goroutine 在调用Wait()函数时，main goroutine需要等待等待集合goroutine完成而挂起在Semaphore池子里。 Waiter 则是记录Semaphore中等待的goroutine的数量。 Add() 和 Done() 函数是计数Counter的相关方法，在等待集合goroutine中最后一个goroutine完成时，如果有等待在Semaphore的goroutine应该全部唤醒。 Wait() 函数是等待等待集合goroutine完成，main goroutine主动挂起自己的相关逻辑。 state() State 返回指向存储在 wg.state* 中的 State 和 sema 字段的指针。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // state returns pointers to the state and sema fields stored within wg.state*. func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { // unsafe.Alignof(wg.state1) == 8：说明state1字段对齐为8字节，这种情况是64位平台 // uintptr(unsafe.Pointer(\u0026amp;wg.state1))%8 == 0：说明wg.state1的地址按照8字节对齐的，可能是64或32平台 if unsafe.Alignof(wg.state1) == 8 || uintptr(unsafe.Pointer(\u0026amp;wg.state1))%8 == 0 { // state1 is 64-bit aligned: nothing to do. // state1 是 64 位对齐的：无事可做 return \u0026amp;wg.state1, \u0026amp;wg.state2\t// state1是64位对齐，state1就是state，state2就是sema } else { // state1 is 32-bit aligned but not 64-bit aligned: this means that // (\u0026amp;state1)+4 is 64-bit aligned. // // State1是32位对齐，而不是64位对齐:这意味着 (\u0026amp;state1)+4 是64位对齐。 // 这种情况处理就是为了满足后续：64位原子操作需要64位对齐 state := (*[3]uint32)(unsafe.Pointer(\u0026amp;wg.state1))\treturn (*uint64)(unsafe.Pointer(\u0026amp;state[1])), \u0026amp;state[0] } } Add() Add 将 delta (可能是负数)添加到 WaitGroup counter。 如果 counter 变为0，所有在等待时被阻塞的 goroutine 都会被释放。如果 counter 变为负数，则会 painc。 请注意，当 counter 为0时，delta为正的调用必须发生在等待之前。 使用负的delta调用，或者从 counter 大于零开始使用正的delta调用，都可能在任何时候发生。 通常，这意味着对Add的调用应该在创建goroutine语句或其他要等待的事件之前执行。 如果重用一个 WaitGroup 来等待几个独立的事件集，那么新的Add调用必须在所有先前的wait调用都返回之后发生。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 // Add adds delta, which may be negative, to the WaitGroup counter. // If the counter becomes zero, all goroutines blocked on Wait are released. // If the counter goes negative, Add panics. // // Note that calls with a positive delta that occur when the counter is zero // must happen before a Wait. Calls with a negative delta, or calls with a // positive delta that start when the counter is greater than zero, may happen // at any time. // Typically this means the calls to Add should execute before the statement // creating the goroutine or other event to be waited for. // If a WaitGroup is reused to wait for several independent sets of events, // new Add calls must happen after all previous Wait calls have returned. // See the WaitGroup example. func (wg *WaitGroup) Add(delta int) { // 1) 原子操作 statep += delta // statep *uint64：【Waiter + Counter】 // semap *uint32：【semaphore】 // *statep = (uint64(counter) \u0026lt;\u0026lt; 32) | uint32(waiter) statep, semap := wg.state() if race.Enabled { _ = *statep // trigger nil deref early if delta \u0026lt; 0 { // Synchronize decrements with Wait. race.ReleaseMerge(unsafe.Pointer(wg)) } race.Disable() defer race.Enable() } // 原子操作 {counter += delta; state = counter;} delta 可能为负数 // 这里的64位原子操作也就是为什么需要 state 函数的原因 state := atomic.AddUint64(statep, uint64(delta)\u0026lt;\u0026lt;32) // counter += delta // 注意这里是 int32 类型，原因是 delta 是来自用户传入，可能最后导致 v \u0026lt; 0 情况发生 v := int32(state \u0026gt;\u0026gt; 32)\t// counter 高32位 w := uint32(state)\t// waiter 低32位 if race.Enabled \u0026amp;\u0026amp; delta \u0026gt; 0 \u0026amp;\u0026amp; v == int32(delta) { // The first increment must be synchronized with Wait. // Need to model this as a read, because there can be // several concurrent wg.counter transitions from 0. race.Read(unsafe.Pointer(semap)) } // 2) counter 不能为负数 // counter 不应该出现为负数情况 if v \u0026lt; 0 { panic(\u0026#34;sync: negative WaitGroup counter\u0026#34;) } // 3) Add(\u0026gt;0) 和 Wait 函数不能并发调用 // Add(\u0026gt;0) 和 Wait() 函数并发被调用 // 1. w != 0 存在等待的waiter // 2. delta \u0026gt; 0 本次调用是添加不是减少 // 3. v == int32(delta) 当前添加的数量就是总数量，之前为0 if w != 0 \u0026amp;\u0026amp; delta \u0026gt; 0 \u0026amp;\u0026amp; v == int32(delta) { panic(\u0026#34;sync: WaitGroup misuse: Add called concurrently with Wait\u0026#34;) } // 4) if ( v \u0026gt; 0 || (v == 0 \u0026amp;\u0026amp; w == 0) ) return // Counter计数数量大于零 或 没有等待的waiter直接返回 // 1. v \u0026gt; 0：代表不是最后一个，因此直接返回 // 2. v == 0 \u0026amp;\u0026amp; w == 0：也是直接返回 if v \u0026gt; 0 || w == 0 {\t// 这里的条件比较关键 return } // 5) v == 0 \u0026amp;\u0026amp; w \u0026gt; 0 // 这种情况需要去把 semap 上面挂起的 goroutine 全部唤醒 // This goroutine has set counter to 0 when waiters \u0026gt; 0. // Now there can\u0026#39;t be concurrent mutations of state: // - Adds must not happen concurrently with Wait, // - Wait does not increment waiters if it sees counter == 0. // Still do a cheap sanity check to detect WaitGroup misuse. // // 当 waiters \u0026gt; 0 时，此 goroutine 将 counter 设置为 0 // 现在不能有并发的 state 突变： // - Add 不能与 Wait 同时发生 // - 如果看到 counter == 0，Wait 不会增加 waiter // 仍然要做一个廉价的健全检查来检测WaitGroup的滥用。 // // WaitGroup误用:Add与Wait并发调用 // 这种情况发生在：最后一个goroutine运行完需要唤醒等待的waiter此时Add方法有被调用 if *statep != state { panic(\u0026#34;sync: WaitGroup misuse: Add called concurrently with Wait\u0026#34;) } // Reset waiters count to 0. *statep = 0\t// 重置 Counter = 0，Waiter = 0 for ; w != 0; w-- { // false正常模式 // 将等待在 semaphore 中的goroutine取出等待调度 runtime_Semrelease(semap, false, 0) } } Done() Done 将 WaitGroup counter 减1。 1 2 3 4 // Done decrements the WaitGroup counter by one. func (wg *WaitGroup) Done() { wg.Add(-1) } Wait() Wait 阻塞，直到 WaitGroup counter 为0。 Wait 函数的调用期间，可能处于多个goroutine在调用 Done 函数。 Wait() 函数允许被多个线程同时调用。Wait() 函数一定要所有的Counter都标记完毕后才调用该方法。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 // Wait blocks until the WaitGroup counter is zero. func (wg *WaitGroup) Wait() { // statep *uint64：【Waiter + Counter】 // semap *uint32：【semaphore】 // *statep = (uint64(counter) \u0026lt;\u0026lt; 32) | uint32(waiter) statep, semap := wg.state() if race.Enabled { _ = *statep // trigger nil deref early race.Disable() } for { state := atomic.LoadUint64(statep)\t// 原子读取 statep v := int32(state \u0026gt;\u0026gt; 32)\t// counter w := uint32(state)\t// waiter // 这种情况，比如在调用Wait函数时先调用sleep睡眠很长一段时间 // 也就是 Wait 函数还没开始执行 其他goroutine 已经执行完了，因此直接返回即可 if v == 0 {\t// Counter is 0, no need to wait. // // 计数器为 0，无需等待 if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(wg)) } return } // Increment waiters count. // // 增加waiter数量，正常逻辑下在这里等待的只有main goroutine一个 // 这里可能会失败，可能有很多goroutine正在调用Add或Done方法修改Counter导致这里原子操作失败 if atomic.CompareAndSwapUint64(statep, state, state+1) { if race.Enabled \u0026amp;\u0026amp; w == 0 { // Wait must be synchronized with the first Add. // Need to model this is as a write to race with the read in Add. // As a consequence, can do the write only for the first waiter, // otherwise concurrent Waits will race with each other. race.Write(unsafe.Pointer(semap)) } // 该方法最后会调用semacquire1，我们在sync.Mutex中已经讨论过 // 这里会把当前goroutine入队，注意这里入队的是main goroutine // runtime_Semacquire 将当前 goroutine 加入到 semaphore 的尾部 runtime_Semacquire(semap)\t// 主线程在这里被调离工作线程，下次恢复时从这里接到执行 // 当前goroutine被Done函数唤醒时，一定是 *statep == 0，不然流程有问题 if *statep != 0 { panic(\u0026#34;sync: WaitGroup is reused before previous Wait has returned\u0026#34;) } if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(wg)) } return\t// 直接返回到调用Wait方法位置处 } } } 使用示例 WaitGroup：用于线程总同步，它等待一组线程集合完成，才会继续向下执行。 主线程调用 Add() 方法来设置等待的协程数量： 然后每个协程运行，并在完成后调用 Done() 方法，Add(-1) 和 Done() 效果一致，都表示等到的协程数量减少一个。 同时，Wait() 方法用来阻塞主线程，直到所有协程完成才会向下执行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var wg sync.WaitGroup wg.Add(10)\t// (\u0026amp;wg).Add(10) -\u0026gt; (*WaitGroup).Add(\u0026amp;wg, 10) for i := 0; i \u0026lt; 10; i++ { //wg.Add(1)\t// (\u0026amp;wg).Add(1)\t-\u0026gt; (*WaitGroup).Add(\u0026amp;wg, 1) go func(i int) { defer wg.Done()\t// (\u0026amp;wg).Done() -\u0026gt; (*WaitGroup).Done(\u0026amp;wg) fmt.Println(i) }(i) } fmt.Println(\u0026#34;我在循环外\u0026#34;) // 阻塞主线程，等所有协程完成 wg.Wait()\t// (\u0026amp;wg).Wait() -\u0026gt; (*WaitGroup).Wait(\u0026amp;wg) // Output: // 1 // 9 // 3 // 4 // 我在循环外 // 5 // 6 // 7 // 8 // 2 // 0 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var wg sync.WaitGroup var urls []string = []string{ \u0026#34;http://baidu.com/\u0026#34;, \u0026#34;https://wzapi.myzx.cn/\u0026#34;, } wg.Add(len(urls)) for _, url := range urls { // wg.Add(1) go func(url string) { defer wg.Done() response, err := http.Get(url) fmt.Println(response, err, url) }(url) } wg.Wait() fmt.Println(\u0026#34;over\u0026#34;) // Output: // \u0026amp;{200 OK 200 HTTP/1.1 1 1 map[Accept-Ranges:[bytes] Cache-Control:[max-age=86400] Connection:[Keep-Alive] Content-Length:[81] Content-Type:[text/html] Date:[Thu, 22 Apr 2021 03:19:50 GMT] Etag:[\u0026#34;51-47cf7e6ee8400\u0026#34;] Expires:[Fri, 23 A // pr 2021 03:19:50 GMT] Last-Modified:[Tue, 12 Jan 2010 13:48:00 GMT] Server:[Apache]] 0xc00003a140 81 [] false false map[] 0xc000044000 \u0026lt;nil\u0026gt;} \u0026lt;nil\u0026gt; http://baidu.com/ // \u0026amp;{200 OK 200 HTTP/1.1 1 1 map[Access-Control-Allow-Headers:[Origin, X-Requested-With, Content-Type, Acceptfecshop-uuid, fecshop-lang, fecshop-currency, access-token, x-token, authorization] Access-Control-Allow-Methods:[*] Access-Co // ntrol-Allow-Origin:[*] Cache-Control:[no-cache, private] Connection:[keep-alive] Content-Type:[text/html; charset=UTF-8] Date:[Thu, 22 Apr 2021 03:19:50 GMT] Etag:[W/\u0026#34;be34c7da7adc79dfee6c76195ba1dbdad7b5bc9b\u0026#34;] Server:[MYBWS/1.1] Set // -Cookie:[acw_tc=2760829816190615907855703e97def055d99950b742716bbf6b2d8e6e2288;path=/;HttpOnly;Max-Age=1800 XSRF-TOKEN=eyJpdiI6IjFPZm9TcTYzblc5c0JJMFdSSW5EZ0E9PSIsInZhbHVlIjoiTXhEbHNlbVRXelMwTnR4UE5nY1JsNTRDTEJ4SmUzaFFsQkZTak9nTEtib // m5rczF3VlF6bVE1YitjNU5EbzlXMms4bTZLV0RiRTk4WXZMSFBBMFoxQ0V0OUpuYWxwN1ppYmpydjFFUzRQWXVBbktaNW82dFNVXC9BXC9FOG9Qb094VSIsIm1hYyI6IjNmYTMyZDUyYzk0ZWY0ZjJkNzJjOGY3M2FiYWYzZDYwNTA4YjFmZTBiZTljMzI1ZTI1MzY1MGQyZDAxYjQwN2QifQ%3D%3D; expires // =Thu, 22-Apr-2021 05:19:50 GMT; Max-Age=7200; path=/ laravel_session=eyJpdiI6IlA2cXcxRHVWYVgxa3VZRnNFY09LbkE9PSIsInZhbHVlIjoiK1ptMGIwOTdZbGp5dlwvRlNMK2pWb3hLVVErV0wxOFBQSmp1dVRkWExcL1VZbm1zVFwvUmRGT0dZcXJlcTZSRmhoWk1hdkJxYU9kUUFrNjB // RK3o4cW5TanZVZXZSYjVEN29CNUU2bEVHdHVoUVVESkhJcG1ETDVCS3FSTmtwYkJTcDciLCJtYWMiOiIwMTM3NDg2NTJlNDJkMGFhN2Y0NDA2YzJhYzcyMTQ4MzY1NDU1YzlmMjYwOTUxNjM0ZDJkYjUzYWJmMmMxZTE1In0%3D; expires=Thu, 22-Apr-2021 05:19:50 GMT; Max-Age=7200; path=/ // ; httponly]] 0xc0001220a0 -1 [chunked] false true map[] 0xc00010a000 0xc00004e0b0} \u0026lt;nil\u0026gt; https://wzapi.myzx.cn/ // over } 总结 sync.WaitGroup 更多是 多个goroutine通知一个goroutine,更像是main goroutine等待集合的所有goroutine完成一项任务，多对一 sync.Cond 则更像多个goroutine等待main goroutine的工作完成，一对多，更像是广播形式 使用注意 以下使用方式是不正确的。 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var wg sync.WaitGroup // 【不能另外启动协程去执行Add()和Done()，因为main的Wait()不会阻塞等待】 go func() { for i := 0; i \u0026lt; 10; i++ { wg.Add(1)\t// (\u0026amp;wg).Add(1)\t-\u0026gt; (*WaitGroup).Add(\u0026amp;wg, 1) go func(i int) { defer wg.Done()\t// (\u0026amp;wg).Done() -\u0026gt; (*WaitGroup).Done(\u0026amp;wg) fmt.Println(i) }(i) } }() // 这里并不会阻塞等待，因为计数器为0 wg.Wait() // Output: } ","permalink":"https://heliu.site/posts/golang/sync/waitgroup/","summary":"WaitGroup等待一组goroutine完成。","title":"sync.WaitGroup"},{"content":"基本数据类型 布尔类型 布尔型值只能是常量true或false。 1 2 3 4 5 // true 和 false 是两个无类型的布尔值 const ( true = 0 == 0 // 无类型布尔值 false = 0 != 0 // 无类型布尔值（默认值false） ) Go语言中不允许将整型强制转布尔型，也不允许将布尔型强制转整型。 如：b := (int)(false)，a := (bool)(1)这都是错误的。 布尔型无法参与数值运算，也无法与其他类型进行转换，布尔类型仅用在条件判断中。 通过指针运算(unsafe)可以实现0或1转布尔类型。 boolean 内存布局 布尔类型占一字节，也就是8bit，其在内存中存储的值是0或非0。8bit全是0表示false，其他情况表示true。 假设定义变量b，var b bool，默认值为false其内存存储为0； 给变量b赋值true，b = true，其内存设置为1。 给变量b赋值false，b = false，其内存设置为0。 布尔类型作为条件判断时，其内存值为0，则判断为true；非0则判断为false。 更多关于布尔类型的元结构类型，参看_type结构，记录着布尔型的相关参数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 // 关于定义布尔类型示例 var b bool = false // 定义布尔类型变量b并设置其值为false var a bool // 定义布尔类型变量a并设置其值为false // --------------------------------------------------------------- // 1) 布尔值是以怎样的形式保存在内存中的 // ------------------------------------------------------- // false：在内存中存储的是0b0000_0000也就是整型0 // true： 在内存中存储的是0b0000_0001也就是整型1 // ------------------------------------------------------- // 示例中是 bool转int8类型，当然也能转其他类型 // ------------------------------------------------------- var b0 bool = false // 假设b0地址 0xc000014090 var b1 bool = true // *bool -\u0026gt; *int8 // i1 存储的是b0的地址0xc000014090 类型为*int8 // 注意区别：*(*int8)(unsafe.Pointer(\u0026amp;b0)) 存储的是b0的值 类型为int8 // 注意区别：(**int8)(unsafe.Pointer(\u0026amp;b0)) *bool -\u0026gt; **int8 i1 := (*int8)(unsafe.Pointer(\u0026amp;b0)) i2 := (*int8)(unsafe.Pointer(\u0026amp;b1)) fmt.Println(*i1, *i2) // 0 1 // --------------------------------------------------------------- // 2) 整数类型转换成布尔值是怎样个情况 // ------------------------------------------------------- // 0b0000_0000 转布尔是 false，其他全是 true // 0：转布尔是 false // 32768：(2^15)转布尔是 false // 1：转布尔是 true // 2：转布尔是 true // -1：转布尔是 true 注意转换时布尔值只需要1字节长度8bit // ------------------------------------------------------- var b0 int8 = 0 var b1 int8 = 1 i1 := (*bool)(unsafe.Pointer(\u0026amp;b0)) i2 := (*bool)(unsafe.Pointer(\u0026amp;b1)) fmt.Println(*i1, *i2) // false true // -------------------------------------------------------- // 3) 下面我们把其他类型转换成布尔值然后再转回之前的类型 // -------------------------------------------------------- // 以下代码说明使用unsafe转换仅仅是把第一个字节指向bool地址 // -------------------------------------------------------- // 3.1) int8 -\u0026gt; bool -\u0026gt; int8 var b0 int8 = 0 var b1 int8 = -125 // 1000 0011 i1 := (*bool)(unsafe.Pointer(\u0026amp;b0)) i2 := (*bool)(unsafe.Pointer(\u0026amp;b1)) fmt.Println(*i1, *i2) // false true i11 := (*int8)(unsafe.Pointer(i1)) i22 := (*int8)(unsafe.Pointer(i2)) fmt.Println(*i11, *i22) // 0 -125 // 3.2) int -\u0026gt; bool -\u0026gt; int var b0 int = 0 var b1 int = 55536 i1 := (*bool)(unsafe.Pointer(\u0026amp;b0)) i2 := (*bool)(unsafe.Pointer(\u0026amp;b1)) fmt.Println(*i1, *i2) // false true i11 := (*int)(unsafe.Pointer(i1)) i22 := (*int)(unsafe.Pointer(i2)) fmt.Println(*i11, *i22) // 0 55536 // 3.3) uint16 -\u0026gt; bool 修改 -\u0026gt; uint16 var b0 uint16 = 0 var b1 uint16 = 0b10000000_11111111 i1 := (*bool)(unsafe.Pointer(\u0026amp;b0)) i2 := (*bool)(unsafe.Pointer(\u0026amp;b1)) fmt.Println(*i1, *i2) // false true *i2 = false i11 := (*uint16)(unsafe.Pointer(i1)) i22 := (*uint16)(unsafe.Pointer(i2)) // 32768 -\u0026gt; 0b10000000_00000000 fmt.Println(*i11, *i22) // 0 32768 // 4) 上面发现将布尔类型赋值为false会将内存的8为bit全部设置为0，也就是85行代码处 // 那么将一个本就是布尔true类型赋值为true，内存中是否记录的大小为1？ var b1 int = 12 bb := (*bool)(unsafe.Pointer(\u0026amp;b1)) *bb = true fmt.Println(*(*int)(unsafe.Pointer(bb))) // 1 // 通过代码测试 布尔的赋值就是把内存中的数值false改为0 true改为1 总结： Go内存字段排序是，低字节在前高字节在后。（不同的硬件设备可能不同）。 比如33007二进制如10000000_11101111，在内存中是第一个字节11101111第二个字节10000000。 布尔类型占1字节（8bit），所有位都为0时表示false，否则表示true。 因此10000000_00000000这种形式转bool第一个字节是00000000返回false。 使用unsafe转换类型仅仅是把首字节转bool的地址。 也就是上面的33007（10000000_11101111）转bool，把11101111这个第一个字节地址给布尔值。 布尔类型在被赋值时，true会修改内存存储值为1，false会修改存储值为0。 整数类型 有符号整型 类型 长度(B/字节) 范围(科学计数) 范围 默认值 int8 1B (8bit) [-2^7, 2^7-1] [-128, 127] 0 int16 2B (16bit) [-2^15, 2^15-1] [-32768, 32767] 0 int32 4B (32bit) [-2^31, 2^31-1] [-2147483648, 2147483647] 0 int64 8B (64bit) [-2^63, 2^63-1] [-9223372036854775808, 9223372036854775807] 0 int 与系统有关，32位下4字节，64位下8字节 0 补码与源码 有符号负数类型转二进制，负数整型数值都是采用补码形式保存，当然正数的补码就是自己。 先是将对应的正整数转换成二进制后。 对二进制取反。 然后对结果再加一。 补码的运算：两个补码相加，与二进制加法相同，和仍然是补码（补码计算后可能存在溢出情况） 补码转源码。 正数：符号位为0时，即补码就是源码 负数：符号位为1时，即补码的补码就是源码 # -42存储形式：假设这里是int8类型 8位bit位 # 1. 42转二进制，00101010 # 2. 00101010 取反 11010101 # 3. 11010101加一，11010101 + 00000001 = 11010110\t补码 # 最终-42的二进制表示形式，11010110 # 11010110 补码转源码 # 1. 最高位为1表示负数 # 2. 11010110 取反 00101001 # 3. 00101001加一，00101001 + 00000001 = 00101010\t源码 # 总结：- 号的操作逻辑就是上面步骤2(取反)和步骤3(加一) # 最高位表示符号位 0.正数 1.负数 # 内存中都是采用补码形式存储的 1 2 3 4 5 6 7 // 验证 -42 是否是 11010110 var b0 int8 = -42 // i1 := uint8(b0) i1 := (*uint8)(unsafe.Pointer(\u0026amp;b0)) fmt.Printf(\u0026#34;%.8b\u0026#34;, *i1)\t// 11010110 例如：-1是11111111，127是01111111，最高位bit表示符号位，0表示正数(+)，1表示负数(-)。 # -1 转二进制 # 1 -\u0026gt; 00000001 # ~1 -\u0026gt; 11111110 取反 # +1\t-\u0026gt; 11111111 加一 # 127 转二进制 # 127\t-\u0026gt; 01111111 -号：操作在整型中的操作步骤(取反)然后(加一)。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 在time.Duration中的String()方法中有这样一段代码 // d 为int64类型，这里正是利用了-(-42)=42, u=(-42) func (d Duration) String() string { // ... u := uint64(d) // 这里如果是负数，则转换后一定是个很大的数字 neg := d \u0026lt; 0 // neg为true表示是负数，为false表示是正数或0 if neg { u = -u // 这里再次按照负数存储形式，正数的二进制取反加1等到正数也就是(-d) } // ... } // 比如我们使用上面方法写一个abs取绝对值函数，并转换无符号类型为有符号类型 type i int64 func (i i) abs() uint64 { if i \u0026gt; 0 { return uint64(i) } return -uint64(i) } 无符号整型(unsigned) 类型 长度(B/字节) 范围 范围 默认值 uint8 1B (8bit) [0, 2^8-1] [0, 255] 0 uint16 2B (16bit) [0, 2^16-1] [0, 65535] 0 uint32 4B (32bit) [0, 2^32-1] [0, 4294967295] 0 uint64 8B (64bit) [0, 2^64-1] [0, 18446744073709551615] 0 uint 与系统有关，32位下4字节，64位下8字节 0 无符号转二进制 除二取余，然后倒序排列，高位补零 # 示例42转二进制，正整数转二进制 除二 求余 排序方向 十进制 42 || 2 | 42 .... 42/2 余 .... 0 ^ 0*2^0 = 0 |_______ + 2 | 21 .... 21/2 余 .... 1 | 1*2^1 = 2 |_______ + 2 | 10 .... 10/2 余 .... 0 | 0*2^2 = 0 |_______ + 2 | 5 .... 5/2 余 .... 1 | 1*2^3 = 8 |________ + 2 | 2 .... 2/2 余 .... 0 | 0*2^4 = 0 |________ + 1 .... 1/2 余 .... 1 | 1*2^5 = 32 # 42 对应二进制位 00101010 -\u0026gt; 0*2^0 + 1*2^1 + 0*2^2 + 1*2^3 + 0*2^4 + 1*2^5 = 42 其他整数类型 类型 等价于 长度(B/字节) 备注 默认值 byte type byte = uint8 1B 存储一字节内容 0 rune type rune = int32 4B 存储一字符内容(Unciode编码) 0 uintptr uint 4B或8B 刚好能存储变量地址 0 1 2 3 4 5 6 7 // type byte = uint8 var b byte // 默认值 0 // type rune = int32 var r rune // 默认值 0 fmt.Printf(\u0026#34;b: %T\\n\u0026#34;, b)\t// b: uint8 fmt.Printf(\u0026#34;r: %T\\n\u0026#34;, r)\t// r: int32 浮点数类型 类型 描述 默认值 float32 IEEE-754 32位浮点型数4字节，大约存储小数位数7位（十进制科学计数法n.xxx*e+10情况下），这里的7位是x的位数 0.0 float64 IEEE-754 64位浮点型数8字节，大约存储小数位数16位（十进制科学计数法n.xxx*e+10情况下），这里的16位是x的位数 0.0 IEEE-754 浮点数在内存中如何存储 浮点数需要先转换成二进制才能存储在内存中，因此拆分成正数和小数： 对于正数部分： 按照有符号规则计算即可，比如42或-42是00101010，符号位后面单独处理。 对于小数部分： 对小数点以后的数乘以2，取结果的整数部分(不是1就是0)，然后再用小数部分再乘以2，再取结果的整数部分。 以此类推，直到小数部分为0或者位数已经够了就结束。 然后把取的整数部分按先后次序排列，就构成了二进制小数部分的序列。 # 如42.635648，处理小数部分就是0.635648 小数部位乘2 = 取正数位 排序方向 十进制 0.6328125 || 0.635648 * 2 = 1.271296 ... 取正数位 ... 1 | 2^-1 1/2 0.5 0.271296 * 2 = 0.542592 ... 取正数位 ... 0 | 0 + 0.542592 * 2 = 1.085184 ... 取正数位 ... 1 | 2^-3 1/2^3 0.125 0.085184 * 2 = 0.170368 ... 取正数位 ... 0 | 0 0.170368 * 2 = 0.340736 ... 取正数位 ... 0 | 0 + 0.340736 * 2 = 0.681472 ... 取正数位 ... 0 | 0 0.681472 * 2 = 1.362944 ... 取正数位 ... 1 v 2^-7 1/2^7 0.0078125 ... ... # 组成二进制 1010001... -\u0026gt; 2^5 + 2^3 + 2^1 + 2^-1 + 2^-3 + 2^-7 # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - # 如-0.1，处理小数部分就是0.1 小数部位乘2 = 取正数位 排序方向 十进制 0.099609375 || 0.1 * 2 = 0.2 ... 取正数位 ... 0 | 0 0.2 * 2 = 0.4 ... 取正数位 ... 0 | 0 0.4 * 2 = 0.8 ... 取正数位 ... 0 | 0 0.8 * 2 = 1.6 ... 取正数位 ... 1 | 1/2^4 0.0625 0.6 * 2 = 1.2 ... 取正数位 ... 1 | 1/2^5 0.03125 0.2 * 2 = 0.4 ... 取正数位 ... 0 | 0 + 0.4 * 2 = 0.8 ... 取正数位 ... 0 | 0 0.8 * 2 = 1.6 ... 取正数位 ... 1 | 1/2^8 0.00390625 0.6 * 2 = 1.2 ... 取正数位 ... 1 | 1/2^9 0.001953125 0.2 * 2 = 0.4 ... 取正数位 ... 0 v 0 ... ... # 组成二进制 0001100110... 然后把整数部分转二进制和小数部分转二进制加一起，如(101010.1010001...)。 浮点数是如何存储在内存中 比如上面的101010.1010001...转换二进制科学计数法表示1.010101010001... * 2^5。 十进制 二进制 计算方式 二进制科学计数法表示 3.5 11.1 3.5 = 2^1 + 2^0 + 2^-1 11.1 = 1.11 * 2^1 10.625 1010.101 10.625 = 2^3 + 2^1 + 2^-1 + 2^-3 1010.101 = 1.010101 * 2^3 0.6 0.10011001.. 0.6 = 2^-1 + 2^-4 + 2^-5 + 2^-8 .. 0.100110011001.. = 1.00110011001.. * 2^-1 从上面可以观察到，对于任何数来说，表示成二进制科学计数法后，都可以转换成1.xxx * 2^n形式。 对于负数来说，则可以表示成-1.xxx * 2^n形式。 浮点数的存储形式可以分为三部分： 符号位（S） 尾数(xxx)（M） 指数(n)（E） 根据指数又分为三种类型：规格数(normal number)、非规格数(subnormal number)、特殊数(non-number)。 指数位 -\u0026gt; 全为0 不全为0且不全为1 全为1 对应的数 -\u0026gt; 非规格数(subnormal number) 规格数(normal number) 特殊数(non-number) 非规格数(subnormal number)：指数位全为0，用于表示0或非常接近0的数。 规格数(normal number)：指数位不全为0且不全为1，用于表示正常的数值。 特殊数(non-number)：指数位全为1，用于表示±infinity或NaN。 偏移量：\n4字节浮点数的偏移量为+127，float32字节的指数位是占8bit，最大值255。 8字节浮点数的偏移量为+1023，float64字节的指数位是占11bit，最大值2047。 为何偏移量都取一半作为使用？原因是作为指数n存在负数或正数情况，E是在此基础上做加法。 7 表示为 00000111 0为符号位，代表它是一个正数。 如果把 7 和 +7 统一加上偏移量 127，那么 7 就变成 134 ，二进制表示为 10000110。 -7变成 120 ，二进制表示为 01111000。 两者进行比较大小的时候，计算机便无需比较两者的符号位。 尾数位的四种舍入方式：因为浮点数并不能表示所有的实数，因此为了尽量的逼近真实数字有如下舍入方式。\n向偶舍入：这是最常用的舍入方式，也称为“四舍六入五成双”。 向零舍入：即朝着数轴零点方向舍入，即直接截尾。 向上舍入：向着数轴越大的数舍入。 向下舍入：向着数轴越小的数舍入。 下面以十进制为例，分析向偶舍入： 1.40尾数\u0026lt;=0.4，直接舍弃，值为1。 1.60尾数\u0026gt;=0.6，入位，值为2。 1.5尾数为0.5，向偶舍入为2。 2.50尾数为0.5，向偶舍入为2。 -1.50尾数为0.5，向偶舍入为-2。 方式 1.40 1.60 1.50 2.50 -1.50 向偶舍入 1 2 2 2 -2 向零舍入 1 1 1 2 -1 向下舍入 1 1 1 2 -2 向上舍入 2 2 2 3 -1 用RR\u0026hellip;RDD\u0026hellip;D来表示一个二进制小数，R表示保留位，D表示舍去位，那么有以下规则： DD\u0026hellip;D \u0026lt; 10\u0026hellip;0 -\u0026gt; 直接舍去 DD\u0026hellip;D \u0026gt; 10\u0026hellip;0 -\u0026gt; 向上舍入 DD\u0026hellip;D = 10\u0026hellip;0 -\u0026gt; 向偶数舍入，细则： RR\u0026hellip;R = XX\u0026hellip;0，直接舍去 RR\u0026hellip;R = XX\u0026hellip;1，向上舍入 var f float64 = -0.1 转换成 1.100110011001.. * 2^-4，尾数以1001重复，因此进入加一。 最后的尾数为1001加一为1010 var f float64 = -0.1 转换成 1.100110011001.. * 2^-4，尾数以1001重复，因此进入加一。 最后的尾数为1001加一为1010 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 验证 float32 存储 0.6 var b0 float32 = 0.6 i1 := (*uint32)(unsafe.Pointer(\u0026amp;b0)) fmt.Printf(\u0026#34;%b\u0026#34;, *i1)\t// 00111111 00011001 10011001 10011010 // float32情况下，最后体现了 11001 -\u0026gt; 11010 0舍1入 // 0.6 -\u0026gt; 00111111000110011001100110011010 //-0.6 -\u0026gt; 10111111000110011001100110011010 // 验证 float64 存储 -0.1 var b0 float64 = -0.1 i1 := (*uint64)(unsafe.Pointer(\u0026amp;b0)) // 10111111 10111001 10011001 10011001 10011001 10011001 10011001 10011010 fmt.Printf(\u0026#34;%b\u0026#34;, *i1)\t1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // math/const.go 文件 // Floating-point limit values. // Max is the largest finite value representable by the type. // SmallestNonzero is the smallest positive, non-zero value representable by the type. const ( // 2**127 * (2**24 - 1) / 2**23 == 2^128 - 2^104 == (2^127+...+2^0+1) - (2^103+...2^0+1) // 2^127 + 2^126 + ... + 2^104 == 1.11111111_11111111_1111111*2^127\t实际存储存储 // 32bit全部存储如 0_11111110_11111111111111111111111 // 32为规范数的指数范围在[-126,127]，因为指数全零为全壹表示其他数，偏移量127，指数方位[1,254] MaxFloat32 = 3.40282346638528859811704183484516925440e+38 // 2**127 * (2**24 - 1) / 2**23 // 1 / 2**(127 - 1 + 23) == 1.0 * 2^-149 == 0.00000000_00000000_0000010 * 2^-127 // 32bit全部存储如 0_00000000_00000000000000000000001\t这里是因为0.的0也被存储到内存中了，这就是当指数为0时是一种特殊情况 // 2^-127 --\u0026gt; 0_00000000_1000000_00000000_00000000 // 2^-128 --\u0026gt; 0_00000000_0100000_00000000_00000000 // 2^-129 --\u0026gt; 0_00000000_0010000_00000000_00000000 // 2^-149 --\u0026gt; 0_00000000_0000000_00000000_00000001\t当指数全为0时，系数以 0. 开头 SmallestNonzeroFloat32 = 1.401298464324817070923729583289916131280e-45 // 1 / 2**(127 - 1 + 23) MaxFloat64 = 1.797693134862315708145274237317043567981e+308 // 2**1023 * (2**53 - 1) / 2**52 SmallestNonzeroFloat64 = 4.940656458412465441765687928682213723651e-324 // 1 / 2**(1023 - 1 + 52) ) 复数类型 复数是在浮点数的基础上进行存储的，那么也就很好理解浮点数的存储形式。 complex64是由两个float32格式形式保存的，因此实部和虚部都是float32形式保存，共占8字节。 complex128是由两个float64格式形式保存的，因此实部和虚部都是float64形式保存，共占16字节。 类型 长度 内存对齐 complex64 32位浮点数构造复数 占8字节 4B complex128 64位浮点数构造复数 占16字节 8B 1 2 3 4 5 6 7 8 9 10 11 // complex64 等价于 type clx64 struct { real float32 // 实数 4Byte imag float32 // 虚数 4Byte } // complex128 等价于 type clx128 struct { real float64 // 实数 8Byte imag float64 // 虚数 8Byte } 声明复数，以及real()和imag()函数使用。 1 2 3 4 5 6 7 8 9 var c complex128 = 1.0 + 1i // %v 以原形式输出 fmt.Printf(\u0026#34;value %v\u0026#34;, c) // value (1+1i) // complex()函数创建 complex128类型 cc := complex(2, -3) fmt.Printf(\u0026#34;value %v\u0026#34;, cc) // value (2-3i) // real()获取复数实部 imag()函数获取复数虚部 fmt.Println(real(cc), imag(cc))\t// 2 -3 验证复数的内存存储结构。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // complex64 类型验证，我们前面验证过float32类型的0.6格式这里也使用0.6 var b0 complex64 = 0.6 + 0.6i i1 := (*uint64)(unsafe.Pointer(\u0026amp;b0)) // 11111100011001100110011001101000111111000110011001100110011010 fmt.Printf(\u0026#34;%b\\n\u0026#34;, *i1)\t// 00111111000110011001100110011010 -\u0026gt; 0.6 实部 // 00111111000110011001100110011010 -\u0026gt; 0.6 虚部 // \u0026gt; ------------------------------------------------------------------ // complex128是占16字节 var b0 complex128 = 0.6 - 0.6i i1 := (*float64)(unsafe.Pointer(\u0026amp;b0)) fmt.Println(*i1) // 0.6 i11 := (*uint64)(unsafe.Pointer(\u0026amp;b0)) // 0011111111100011001100110011001100110011001100110011001100110011 -\u0026gt; 0.6 实部 fmt.Printf(\u0026#34;%64b\\n\u0026#34;, *i11)\ti2 := (*float64)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;b0)) + unsafe.Sizeof(uint64(0)))) fmt.Println(*i2) // -0.6 i22 := (*uint64)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;b0)) + unsafe.Sizeof(uint64(0)))) // 1011111111100011001100110011001100110011001100110011001100110011 -\u0026gt; -0.6 虚部 fmt.Printf(\u0026#34;%64b\\n\u0026#34;, *i22)\t字符串类型 字符串是一串固定长度的字符连接起来的字符序列，字符串是由单个字节连接起来的，字节使用UTF-8编码标识的Unicode文本。 编译阶段字符串存储在只读数据段，所以字符串在硬件底层阻止被修改。 但是在运行阶段字符串则是被分配在堆上但是也不允许被修改，原因是在语言层面被阻止的，但是我们可以使用unsafe绕过语言层面进行修改。 首先字符串是UTF-8编码标识的Unicode文本，需要先了解Unicode编码的处理，再看Unicode转UTF-8。 需要记住字符的存储形式。 1 2 3 4 5 6 type StringStruct struct { // 存储联系内存的首地址，这里也就是[...]byte类型的数组，连续的字节是utf8编码的数据 Data unsafe.Pointer // 字符串长度 Len uintptr } 更多关于字符讨论参看后面字符串文档。 复合类型 指针类型（pointer），也就是如 *int、*string等类型，存储的是基础类型的引用地址。 数组类型（array），连续内存分布存储的，其数组长度保存在类型结构中，这也就是导致不同长度的相同类型的数组属于不同类型的原因(类型hash不同)。 结构体（struct），连续内存分布存储的。 通道类型（chan），hchan结构体的引用地址。 函数类型（function），funcval结构体的引用地址。 切片类型（slice），结构与字符串的结构大体相同只多了个Cap字段存储容量，存储形式大体相当。 接口类型（interface），eface和iface结构体的 ，存储类型元素数据、动态类型相关信息。 字典类型（map），hmap结构体的引用地址。 错误类型 Go语言预定义类型，也就是iface结构体，非空接口类型。 错误类型是接口，nil值表示无错误。 只要实现接口的方法及继承了该接口。 1 2 3 4 // Error接口 type error interface { Error() string } 总结 数组(array)和结构体(struct)都是聚合类型，长度固定。 切片(slice)和字典(map)都是动态数据结构，长度可变。 参考 浮点数存储 ","permalink":"https://heliu.site/posts/golang/basic/type/","summary":"Golang 内置的基本类型介绍。","title":"内置类型"},{"content":" 变量名让你能够把程序中准备使用的每一段数据都赋值给一个简短、易于记忆的名字。 变量声明及使用 变量的定义 1 2 // 关键字 标识符 [类型] = 值 var identifier [type] = value 显示声明变量：在声明变量时指定变量的类型。 隐式声明变量：在声明变量时并未指定变量的类型，而是在编译阶段编译器根据变量值自动判断类型。 整数类型(正数或负数，十进制、十六进制、八进制、二进制)：编译器会全部识别为int类型，如：var a = 123。 字符串：编译器识别为string类型，如：var b = \u0026quot;a1\u0026quot;。 浮点数：编译器识别为float64类型，如：var c = -1.0。 复数：编译器识别为complecx128类型，如：var d = 1i。 字符类型：编译器识别为rune (int32) 类型，如：var e = 'a'。 其他类型根据情况判断，如：var f = map[string]int{}这一定是map，其他类似。 1 2 3 4 5 6 7 8 9 10 11 // 显式声明 设置值 // 结构 data=\u0026#34;hello world!\u0026#34; len=12 var name string = \u0026#34;hello world!\u0026#34;\tvar sex uint8 sex = 1 // 显式声明 未设置值 默认取值 \u0026#34;\u0026#34; var name string\t// 隐式声明 编辑器会自动推断变量类型，而常量则是在上下文中转换 var name = \u0026#34;hello\u0026#34;\t// 系统默认推导为string类型 简单声明 简单申明使用:=，当声明一个变量时当前变量在当前作用域内未被声明过时。(只能用于函数内) 1 name := \u0026#34;hello\u0026#34; // 系统默认推导string 多变量赋值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 1. 不同数据类型 // name和sex变量，编辑器默认推导为string类型 // age变量，编辑器默认推断为int类型 var name, sex, age = \u0026#34;hello\u0026#34;, \u0026#34;男\u0026#34;, 1 // 2. 相同数据类型，a、b、c变量都为bool类型 var a, b, c bool a, b, c = false, true, false // 3. 一起声明 var ( aa uint // 数值类型 默认值 0 bb string // 字符串类型 默认值 \u0026#34;\u0026#34; cc [3]int // 数组类型 默认值 [0,0,0] ) // 4. 或者在函数内 // 这种形式比较特殊，当前name或sex或age中只要有一个变量在【当前作用域】中未被声明过时才能使用 // 其余的全部退还为赋值操作，比较常用的是f, err := os.Open(\u0026#34;./t.txt\u0026#34;)这里的err被多次使用退化为赋值操作 name, sex, age := \u0026#34;hello\u0026#34;, \u0026#34;男\u0026#34;, 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 在if的作用域中时（这里的bb和err在该作用域中都没有声明过，因此默认为内部变量） if bb, err := tt(); err != nil { // bb declared and not used log.Println(err, bb) } // 等价于 { // if的作用域内，声明bb和err【局部】变量 bb, err := tt() if err != nil { log.Println(err, bb) } } // \u0026gt; --------------------------------------------------------------- var bb byte = \u0026#39;a\u0026#39; // 作用域外的 bb 变量 // 这里bb在if外，而err在if内作用域，因此if内的bb会生成if内的变量覆盖外层bb变量 if bb, err := tt(); err != nil { // bb declared and not used log.Println(err, bb) // 作用域内的 bb 变量 } // 等价于 var bb byte = \u0026#39;a\u0026#39; { // if的作用域内，声明bb和err【局部】变量，因为在该作用域内都没有bb和err变量 bb, err := tt() if err != nil { log.Println(err, bb) } } 总结，:=会在当前作用域寻找变量，如果找到则使用它，如果未找到则声明一个新变量。 注意，:=必须要求左边存在至少一个未定义的变量。:=只能在函数内使用。 变量交换 1 2 3 4 5 6 7 8 9 10 var a, b string = \u0026#34;world\u0026#34;, \u0026#34;hello\u0026#34; fmt.Println(a, b) // world hello // 1. 交换变量值 a, b = b, a fmt.Println(a, b) // hello world // 2. 变量交换等价于 temp := a a = b b = temp 标识符 由字母、数字、下划线（_）组成，其中首字符不能为数字，区分大小写（同一字母的大小写代表不同的标识）。 Go语言规范： 标识符：命名程序实体，如变量名和类型名。 标识符是一个或多个Unicode字母和数字的序列。 标识符中的一个字符必须是Unicode字母（下划线_也被认为是字母）。 identifiter = letter {letter | unicode_digit} letter = unicode_letter | _：letter 包含字母（包括除英文字母以外的字母）和下划线。 unicode_digit = 0 1 2 3 4 5 6 7 8 9：数字（这里也包括除阿拉伯数字以外的数字）。 在Go语言中，命名标识符时，通常选择英文的52个大小写字母以及数字0~9和下划线来组合成合适的标识符。 1 2 3 4 5 6 7 8 9 10 // Go语言变量声明使用关键字 var // 下面这种形式 多用于定义全局变量，通常在函数外被定义 var ( a int b bool str string 浮点 float32\t// 中文也可以作为变量标识符，在Unicode里的字符都能 ) var a, b int 关键字 Go语言中关键字是保留字，不能作为变量标识符，关键字一共有25个。 Go 关键字 break：用于跳出for循环，跳出switch和select块。 switch和select都默认自带break（如果写了break默认跳出当前块）。 continue：用于for循环，表示结束本次循环继续下次循环。 default：用于switch和select结构的默认分支，当所有case都不满足时执行default分支。 func：用于定义函数或方法或函数类型变量。 interface：用于定义接口类型。 select：选择结构，主要用于chan类型在，注意在select中不能使用关键字fallthrough。 case：用于select和switch关键字中，表示一个分支块。 defer：主要用于func关键字定义的函数和方法体中，表示当前语句在函数退出时执行。 go：主要用于创建一个goroutine放入P中等待被线程调用，这也是创建协程的关键。 map：用于定义字典类型。 struct：用于定义结构体类型。 chan：用于定义通道类型，chan的主要作用是在各个goroutine间通信的通道。 else：与if关键字配合使用，当上面所有条件都不满足时默认执行else分支的代码块。 goto：跳转语句，配合标签能任意跳转到指定代码处，多在函数内使用。 package：用于.go文件的包声明，多用于.go文件的第一行代码。 switch：选择分支结构，常与case、default、fallthrough一起使用。 const：用于定义常量。 fallthrough：用于switch的case块中，表示继续运行下一个case块代码而不检查是否满足条件。 该关键字多用于迁移其他语言代码兼用使用，正常开发中不建议使用。 if：分支选择结构多与else或else if一起使用。 range：与for关键字一起使用，从slice、map、string、array、chan等中迭代元素。 注意range会拷贝slice、array需要迭代的集合副本，以便于原集合区分。 type：多用于定义类型关键字。 for：用于开始一个循环。 import：导入其他包文件关键字。 return：用于函数或方法中，表示结束当前函数并返回给定值。 在没有返回值的函数中也可以使用return来返回函数。 var：用于定义变量的关键字。 注意事项 变量必须先定义才能使用，变量的类型和赋值的类型必须一致。 变量名不能冲突（同一个作用域内不能冲突）。 简短定义方式，只能在函数内被定义。 同一个作用域中，已存在同名的变量，则之后的声明初始化，则退化为赋值操作。 前提是，最少要有一个新的变量被定义，且在同一作用域。 变量定义了如不使用编译通不过。 1 2 3 4 5 6 x := 12 // 定义变量x默认推导为int类型 x, y = 1, \u0026#34;hello\u0026#34; // 变量x重新赋值为1， 定义变量y默认推导为string类型 // 这种情况经常出现在接收错误情况下，第二个err变量退化为赋值操作 file1, err := os.Open(\u0026#34;a.txt\u0026#34;) // 在当前作用域声明file1和err变量 file2, err := os.Open(\u0026#34;b.txt\u0026#34;) // 当前作用域已有err变量直接使用，声明file2变量 作用域 在顶层声明的常量（如const a int = 1），类型（如type a int），变量（如var a = 1）函数的标识符（如func name() int）的范围是包块。 导入包名称范围是包含导入声明的文件的文件块。 导入包名称范围是包含导入声明的文件的文件块。 在函数内声明的常量或变量标识符的范围从声明语句的末尾开始，到最内层包含块的末尾结束。 在函数内声明的类型标识符的范围从标识符开始，到最内层包含块的末尾结束。 块中声明的标识符可以在内部块中重新声明。 作用域就类似一棵树结构，而每个树枝相当于块，在树干定义的变量能被这个树干分成出的树枝或树枝的树枝使用，而在树枝中重复定义树干的变量则会屏蔽调树干定义的变量。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; ) // 全局变量 var x int = 10 // ---------- 假设全局作用域就是树干编号SU01 func main() { fmt.Println(x) // 10\t// 局部变量 x := 1 // ---------- 而在main函数中的局部变量就SU01的树枝SZ01 fmt.Println(x) // 1 // 局部块 { fmt.Println(x) // 1 // 局部变量 x := 2 // ---------- 而在SZ01定义的块及是SZ01的树枝SZ02 fmt.Println(x) // 2 } fmt.Println(x) // 1 // Output: // 10 // 1 // 1 // 2 // 1 } 未使用的变量 未使用的全局变量编译不会报错。 函数内未使用定义的变量编译会报错，import导入的包，未使用编译会报错。 1 2 3 4 5 6 7 8 9 10 11 12 package main import ( //\u0026#34;fmt\u0026#34; // 1. 未使用的import包，编译会报错 ) var x int = 10 // 未使用的全局变量编译不会报错 func main() { // 2. 函数内未使用的变量编译会报错 x := 1\t// 10:2: x declared and not used } 下划线 _ ：是特殊标识符，用来忽略结果。该变量是只写，并且是系统定义好的变量，可以随意使用不分作用域。 下划线在import中 import：导入其他package包文件。 当前 _ 用于 import 中，仅仅是为了调用 init() 函数，所以无法通过包名来调用包中的其他函数和全局变量。 项目目录结构如下： src目录 | +--- main.go | +--- hello目录 | +--- hello.go 1 2 3 4 5 6 7 8 9 10 11 // ./src/main.go 文件 package main import _ \u0026#34;./hello\u0026#34; // 这里导入使用下划线 func main() { // hello.Print() // 编译报错：./main.go:6:5: undefined: hello // Output: // imp-init() come here. } 1 2 3 4 5 6 7 8 9 10 11 12 // ./src/hello/hello.go 文件 package hello import \u0026#34;fmt\u0026#34; func init() { fmt.Println(\u0026#34;imp-init() come here.\u0026#34;) } func Print() { fmt.Println(\u0026#34;Hello!\u0026#34;) } 其他示例 1 2 3 4 5 6 7 import \u0026#34;database/sql\u0026#34; import _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; // 第二个import就是不直接使用mysql包 // 1. 只是执行一下这个包的init函数 // 2. 把mysql的驱动注册到sql包里 // 3. 然后程序里就可以使用sql包来访问mysql数据库了 下划线当做变量使用 _ ：当做变量使用，表示丢弃，是只写变量，不能读取。 下划线用作判断切片下标是否越界时，_ = a[3]，有助于帮助编译器进行边界越界检查。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;os\u0026#34; ) func main() { buf := make([]byte, 1024) // os.Open 打开文件 返回文件句柄 *os.File 和错误类型 error f, _ := os.Open(\u0026#34;/Users/***/Desktop/text.txt\u0026#34;) // _表示抛弃函数返回的err defer f.Close() for { n, _ := f.Read(buf) if n == 0 { break } os.Stdout.Write(buf[:n]) } } 下划线在编译原理中 在编译原理中语法分析中，分析const ()关键字区分组时存在这样结构。 1 2 3 4 // 取地址 表示一类分组地址 type Group struct { _ int } 总结 下划线用在import中，仅仅是执行导入包的所有init()函数。 下划线在变量中，表示抛弃该值： 不占用命名空间，不会分配内存。 多次使用不存在重复声明问题。 很多时候_用于占位，表示忽略值。 我们可以把_当做是一个系统已经声明的全局只写变量，直接使用即可，不需要像_ := a这种形式 参考 为什么指针被誉为 C 语言灵魂？，关于指针。 ","permalink":"https://heliu.site/posts/golang/basic/variable/","summary":"Golang 变量的声明及使用。","title":"变量"},{"content":"常量的定义及使用 常量是一个简单的标识符，运行时不会被修改，没使用的常量在编译时候不会报错（全局变量未使用也不会报错）。 常量在其他语言一般建议使用全大写字母，但是在 Go 中大写字母开头的表示可导出。 常量中的数据类型只可以是布尔型(bool)、数值型（整数型、浮点型、复数）和字符串型(string)，不能是复合类型。 不能获取常量的地址（也没必要），如 \u0026amp;a，a为常量，常量通常是与代码一起被保存在代码段。 字符串单个字符也不能取地址如\u0026amp;s[0](s为string类型)，字符串是只读类型，在语言层面阻止。 注意字符串\u0026amp;s和\u0026amp;s[0]代表的不是同一个地址的区别。 字典的单个key也不能取地址\u0026amp;m[\u0026quot;o\u0026quot;](m为map类型)，字典使用哈希桶形式存储，一个桶存8个key-value。 常量的定义 const identifier [type] = value const：定义常量关键字。 identifier：常量名称标识符。 [type]：类型，可选。 value：常量值。 1 2 // 关键字 标识符 [类型] = 值 const identifier [type] = value 1 2 3 4 5 // 指定类型常量 const IDENTIFIER bool = false // 显式类型定义 // 无类型常量，推断类型行为bool const IDENTIFIER = true // 隐式类型定义 定义多个常量 1 2 // 1. 推断类型 A为bool B为int C为string const A, B, C = true, 52, \u0026#34;golang\u0026#34;\t// 多重赋值 1 2 3 4 5 6 // 2. const ( UNKNOWN = 0 // 推断为int类型 FEMALE = 1 // 推断为int类型 MALE = 2 // 推断为int类型 ) 1 2 3 4 5 6 7 // 同时声明多个常量时，如果省略了值则表示和上面一行的值相同 const ( A uint16 = 255 // 255 B // 255 C = \u0026#34;hello\u0026#34; // hello D // hello ) 无类型常量 没有指明常量类型的常量。const PI = 3.14159 无类型常量具有默认类型，该类型在需要类型化值得上下文中隐式转换常量的类型： 在简式声明中：i := 0 没有显示类型，这与变量的无类型声明不同。 无类型常量的默认类型分别是 bool、rune、int、float64、comolex128或string。 具体决定于它是布尔值、字符、整数、浮点数、复数还是字符串。 常量的值必须是在编译时就能确定的。 可以在赋值表达式中涉及计算过程，但是所有用于计算的值必须在编译期间就能获得。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import ( \u0026#34;fmt\u0026#34; ) func main() { const a = 5 // 无类型常量在使用时根据上下文语境转换 var intVar int = a var int32Var int32 = a var float64Var float64 = a var complex64Var complex64 = a fmt.Println(intVar, int32Var, float64Var, complex64Var) // 5 5 5 (5+0i) const aa = 5.0 var intVV int = aa // 浮点数不能默认转int类型 fmt.Println(intVV) // 5 //const aaa = 5.1 //var intVVV int = aaa // constant 5.1 truncated to integer //fmt.Println(intVVV) } iota 特殊常量，可以被编译器修改的常量。 每遇到const关键字，iota将被重置为0。 每当 iota 在新的一行被使用时，iota会自动加一，iota++。其实并不是iota在新的一行中出现就会加一，不出现也会自增。 【iota的准确定义是】：iota表示const声明块的行索引（下标从0开始），解释就是iota表示当前const的行号，不管使用没使用iota。 【const还有一个重要的特点是】：第一个常量必须指定一个表达式，后续的常量如果没有表达式，则继承上面的表达式。 iota使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 const ( A = iota // 0 (iota == 0)\tB = iota // 1 (iota == 1) C = iota // 2 (iota == 2) ) const ( AA = iota // 0 (iota == 0) BB // 1 (iota == 1) 等效于 BB = iota CC // 2 (iota == 2) 等效于 CC = iota ) // 不管conts中是否有使用iota，都是按照行号递增的 const ( one = 3 // 3 (iota == 0) two = iota // 1 (iota == 1) three = iota // 2 (iota == 2) four // 3 (iota == 3) five // 4 (iota == 4) ) type CAPACITY uint const ( B CAPACITY = 1 \u0026lt;\u0026lt; (iota * 10)// 1 == 2^0 (iota == 0) // 等效于 KB CAPACITY = 1 \u0026lt;\u0026lt; (iota * 10) KB // 1024 == 2^10 (iota == 1) // 等效于 MB CAPACITY = 1 \u0026lt;\u0026lt; (iota * 10) MB // 1024 * 1024 = 2^20 (iota == 2) ) const ( D1 = iota // 0 (iota == 0) D2 // 1 (iota == 1) 等效于 D2 = iota D3 // 2 (iota == 2) 等效于 D3 = iota D4 // 3 (iota == 3) 等效于 D4 = iota D5 = \u0026#34;HELLO\u0026#34; // HELLO (iota == 4) D6 // HELLO (iota == 5) 等效于 D6 = \u0026#34;HELLO\u0026#34; D7 = 23 // 23 (iota == 6)\tD8 // 23 (iota == 7) 等效于 D7 = 23 D9 = iota // 8 (iota == 8) D10 // 9 (iota == 9) 等效于 D10 = iota ) const ( D1, D2 = 1 \u0026lt;\u0026lt; iota, 1 \u0026lt;\u0026lt; iota - 1 // 1 0 iota == 0\t00000001 \u0026lt;\u0026lt; 0 == 0 , 00000001 \u0026lt;\u0026lt; 0 - 1 == 0 // 等效于 D3, D4 = 1 \u0026lt;\u0026lt; iota, 1 \u0026lt;\u0026lt; iota - 1 D3, D4 // 2 1 iota == 1\t00000001 \u0026lt;\u0026lt; 1 == 2 , 00000001 \u0026lt;\u0026lt; 1 - 1 == 1 // 等效于 D5, D6 = 1 \u0026lt;\u0026lt; iota, 1 \u0026lt;\u0026lt; iota - 1 D5, D6 // 4 3 iota == 2\t00000001 \u0026lt;\u0026lt; 2 == 4 , 00000001 \u0026lt;\u0026lt; 2 - 1 == 3 ) 参考 Go高阶指南05，iota 实现原理 ","permalink":"https://heliu.site/posts/golang/basic/const/","summary":"Golang 常量的定义及使用。","title":"常量"},{"content":"基本运算符 算数运算符 适用于数值类型，运算结果类型与除数类型一致。（除数是浮点数结果为浮点数，除数为整数结果为整数） 求余（%）运算结果符号与除数符号一致（除数是负数结果符号为负数）。 运算符 描述 适用范围 示例 + 加法运算符或字符串拼接符 适用于整数、浮点数、复数、字符串 5 + 3 = 8 - 减法运算符 适用于整数、浮点数、复数 5 - 3 = 2 * 乘法运算符 适用于整数、浮点数、复数 5 * 3 = 15 / 除法运算符 适用于整数、浮点数、复数 5 / 2 = 2 % 求余运算 适用于整数（有符号、无符号） -5 % 2 = -1，-5 % -2 = -1，5 % 2 = 1 ++ 自增 适用于整数（有符号、无符号） a++ -- 自减 适用于整数（有符号、无符号） a-- 变量 变量 商 取余 x y x/y x%y 5 3 1 2 -5 3 -1 -2 5 -3 -1 2 -5 -3 1 -2 关系运算符 双目运算符作比较，结果为布尔值。 运算符 含义 示例（A 小于 B） == 等于 A == B false != 不等于 A != B true \u0026gt; 大于 A \u0026gt; B false \u0026lt; 小于 A \u0026lt; B true \u0026gt;= 大于等于 A \u0026gt;= B false \u0026lt;= 小于等于 A \u0026lt;= B true 逻辑运算符 双目运算符，处理左右布尔值。 运算符 描述 示例 \u0026amp;\u0026amp; 逻辑与运算符（左右两边都为true返回true，否则返回false） (true \u0026amp;\u0026amp; false) == false || 逻辑或运算符（左右两边都为false返回false，否则返回true） (false || false) == false ! 逻辑非运算符（一位运算符true取反为false，false取反为true） !true == false 位运算符 操作二进制数。 运算符 含义 \u0026amp; 按为与，双目运算符。参与运算的两数各对应的位相与（同1得1） | 按为或，双目运算符。参与运算的两数各对应的位相或（有1得1） ^ 按为异或，双目运算符。参与运算的两数各对应的位异或（相同得0）或 ^作为一元运算符是按位取反 \u0026laquo; 左移运算符，双目运算符。把左边的运算数的各位全部左移若干位，高位丢弃，低位补0 \u0026raquo; 右移运算符，双目运算符。把右边的运算数的各位全部左移若干位 变量1 变量2 与运算 或运算 异或运算 p q p\u0026amp;q p|q p^q 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 变量1 变量2 左移运算 右移运算 p q p\u0026lt;\u0026lt;q p\u0026gt;\u0026gt;q 00001101 3 01101000 00000001 赋值运算符 运算符 含义 示例 = 赋值运算符 += 相加后再赋值 C += A 等于 C = C + A -= 相减后再赋值 C -= A 等于 C = C - A *= 相乘后再赋值 C *= A 等于 C = C * A /= 相除后再赋值 C /= A 等于 C = C / A %= 求余后再赋值 C %= A 等于 C = C % A \u0026lt;\u0026lt;= 左移后再赋值 C \u0026lt;\u0026lt;= 2 等于 C = C \u0026lt;\u0026lt; 2 \u0026gt;\u0026gt;= 右移后再赋值 C \u0026gt;\u0026gt;= 2 等于 C = C \u0026gt;\u0026gt; 2 \u0026amp;= 按位与后赋值 C \u0026amp;= 2 等于 C = C \u0026amp; 2 ^= 按位异或后赋值 C ^= 2 等于 C = C ^ 2 |= 按位或后赋值 C |= 2 等于 C = C | 2 指针运算符 运算符 含义 实例 \u0026amp; 返回变量存储地址 \u0026amp;a 将输出变量的实际地址 * 指针变量 *a 是一个指针变量 Go语言运算符汇总 运算符 运算符 运算符 运算符 运算符 + \u0026amp; += \u0026amp;= \u0026amp;\u0026amp; - | -= |= || * ^ *= ^= \u0026lt;- / \u0026laquo; /= \u0026laquo;= ++ % \u0026raquo; || \u0026raquo;= \u0026ndash; == \u0026lt; \u0026gt; = ! != \u0026lt;= \u0026gt;= := \u0026hellip; ( [ { , . ) ] } ; : \u0026amp;^ \u0026amp;^= 运算符优先级 一元运算符具有最高优先级。（++和--运算符是形成语句而不是表达式，所以他们不属于运算符层次结构，语句*p++与(*p)++相同） 二元运算符有五个层次结构，如下优先级数字越大表示优先级越高。 可以使用()来临时提高优先级。 优先级 运算符 5 * / % \u0026lt;\u0026lt; \u0026gt;\u0026gt; \u0026amp; \u0026amp;^ 4 + - | ^ 3 == != \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= 2 \u0026amp;\u0026amp; 1 || 特殊运算符 位清除 \u0026amp;^ 将指定位置上的值设置为0。将运算符左边数据相异的位保留，相同位清零。 如果Y某位上的数是0，则取X上对应位置的值。如果Y某位上为1，则结果位上取0。 如果右侧是0，则左侧数保持不变。 如果右侧是1，则左侧数一定清零。 功能与a\u0026amp;(^b)相同。 X = 0b0000_0010 // 0000 0010 Y = 0b0000_0100 // 0000 0100 X \u0026amp;^ Y == X \u0026amp; (^Y) // 0000 0010 1 2 3 4 5 6 7 8 // 相异的保留，相同位清零 // a \u0026amp;^ b // 如果右侧(a)位是0，则左侧数保持不变 // 如果右侧(a)为是1，则左侧数一定清零 { // 清除a的第7位 a \u0026amp;^ (1\u0026lt;\u0026lt;7) // 10000000 128 } ^ 异或（XOR） 在Go语言中XOR是作为二元运算符存在。如果作为一元运算符出现，意思是按位取反。 作为二元运算符，XOR是不进位加法计算，也就是异或运算。 设置第n位为1 1 2 3 4 5 { var a uint8 a = a | (1 \u0026lt;\u0026lt; 7) // 10000000 } 设置第n位为0 \u0026amp;^：清零某位。 1 2 3 4 5 { var a uint8 = 0b0010_0001 a = a \u0026amp;^ (1 \u0026lt;\u0026lt; 5) // 1 } ","permalink":"https://heliu.site/posts/golang/basic/operator/","summary":"Golang 相关的运算符介绍。","title":"运算符"},{"content":" 字面量是指由字母、数字等构成的字符串或数值，它只能作为右值出现。 整数字面量 表示整数常量的数字序列。 42 // 十进制 0600 // 八进制 6*8^2 + 0*8^1 + 0*8^0 oxBadFace // 十六进制 11*16^6 + 10*16^5 + ... ob11110000 // 二进制 ob1111_0000 // 二进制 1 2 3 4 5 6 7 8 func Example() { var o int = 067 // 6*8+7 var ox int = 0xBa77 // 11*16^3 + 10*16^2 + 7*16 + 7 fmt.Println(o, ox) // Output: // 55 47735 } 浮点数字面量 浮点常量的十进制表示。 科学计数法：一个整数部分、一个小数点、一个小数部分和一个指数部分。 0. // 0 72.40 // 72.4 072.40 // 72.4 2.712 1.e+0 6.654e-11 // 科学计数法 6.654 * 10^-11 1E6\t.25 // 0.25 .12345E+5 // 0.12345E+5 1 2 3 4 5 6 7 func Example() { a, b, c, d := 0., 072.40, 1.e+0, .1254E+5 fmt.Println(a, b, c, d) // Output: // 0 72.4 1 12540 } 虚数字面量 虚数字面量是复数常数的虚数的十进制表示。 0i 011i // 11i 0.1 2.2454i 1.e+0i 6.67e-11i 1E6i .25i 1 2 3 4 5 6 7 func Example() { a, b, c, d := 0i, 011i, 0.1, 6.67e-11i fmt.Println(a, b, c, d) // Output: // (0+0i) (0+11i) 0.1 (0+6.67e-11i) } Rune字面量 Rune 别名 长度 范围 rune int32 4B -2147483648 ~ 2147483647 Rune字面量是标识Unicode代码点的整数值。（Unicode是定长两个字节） Rune字面量表示用单引号括起来的一个或多个字符。'x'或'\\n'。 单引号字符表示字符本身的Unicode值。而以反斜杠开头的字符序列表示各种格式编码值。 Go源码是以UTF-8编码的Unicode字符，因此多个UTF-8编码的字节可以表示单个整数值。 'a'表示是a的单个字节，Unicode U+0061，值为0x61。 \u0026ldquo;好\u0026rdquo; 编码0x597d包含两个字节 ，U+00E4值为0xe4。 将整数值表示为数字常量。 \\x后跟恰好两个十六进制数字\\x00 ~ \\xff (0 ~ 255) 1B (2^8)\t1字节。 \\u后跟恰好四个十六进制数字\\u0000 ~ \\uffff (0 ~ 65535) 2B (2^16) 2字节。 \\U后跟恰好八个十六进制数字\\U00000000 ~ \\Uffffffff (0 ~ 4294967295) 4B 4字节。 \\ 后跟恰好三个八进制数字\\000 ~ \\777 (0 ~ 511)。 Unicode 最大值 0x10FFF 69631。 \u0026#39;a\u0026#39; \u0026#39;笨\u0026#39; \u0026#39;\\t\u0026#39; \u0026#39;\\000\u0026#39; \u0026#39;\\007\u0026#39; \u0026#39;\\xff\u0026#39; \u0026#39;\\u12e4\u0026#39; \u0026#39;\\U00101234\u0026#39; \u0026#39;aa\u0026#39; // 非法 多个字符 \u0026#39;\\xa\u0026#39; // 非法 十六进制数字太少 \u0026#39;\\0\u0026#39; // 非法八进制数字不正确 \u0026#39;\\U001000000\u0026#39; // 非法 无效的Unicode代码点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func Example() { // rune = int32 // byte = uint8 var a rune = \u0026#39;\\n\u0026#39; var b rune = \u0026#39;好\u0026#39; var c byte = \u0026#39;\\007\u0026#39; var d rune = \u0026#39;\\xff\u0026#39; var e rune = \u0026#39;\\u12e4\u0026#39; fmt.Println(a, b, c, d, e) fmt.Printf(\u0026#34;%c %c %c %c %c\u0026#34;, a, b, c, d, e) // Output: // 10 22909 7 255 4836 // // 好 ÿ ዤ } 字符串字面量 原始字符串字面量：反引号之间的字符序列。 解释的字符串：双引号之间的字符序列。 在双引号内，除了换行符和未转义的双引号外，任何字符都可以出现。 引号之间的文本形成文字的rune值，反斜杠转义符被解释为符文(rune)。 `abc` // \u0026#34;abc\u0026#34; `\\n \\n` // \u0026#34;\\\\n\\n\\\\n\u0026#34; \u0026#34;\\n\u0026#34;\t\u0026#34;\\\u0026#34;\u0026#34; // `\u0026#34;` \u0026#34;Hello,World!\\n\u0026#34; \u0026#34;洒水\u0026#34; \u0026#34;\\u65e5 本\\U00008a9e\u0026#34; \u0026#34;\\xff\\u00FF\u0026#34; ","permalink":"https://heliu.site/posts/golang/basic/literal/","summary":"Golang 相关字面量介绍。","title":"字面量"},{"content":"Go 内置类型的零值 当一个变量被var声明之后，如果没有为其明确指明初始值，Go语言会自动初始化其值为此类型对应的零值。 类型 零值 integer 整数类型，包括的byte和rune 0 uintptr 整数类型 0 float 浮点数类型 0.0 bool 布尔值类型 false string 字符串类型 空字符串\u0026quot;\u0026quot; complex 复数类型 0+0i *T 指针类型 nil interface、error、function、map、slice、channel nil uintptr的默认值 uintptr是整数类型不是指针，该类型只是用于指针地址做偏移运算。 1 2 3 4 5 6 7 8 9 10 11 package main func main() { var s uintptr // 0 if s == 0 { print(123) } // Output: // 123 } nil零值 1 2 3 4 5 6 7 8 9 10 11 12 package main import ( //\u0026#34;fmt\u0026#34; ) func main() { // 此处编译不通过，nil赋值给x，编译器判断不出具体类型 var x = nil\t// use of untyped nil _ = x } 在一个nil的切片中添加元素是没有问题的。 因为nil的切片并没用分配内存，但是添加元素必须使用append函数，该函数会初始化nil的切片。（原因是会导致扩容从新分配内存） 但是对一个字典做同样的事将发生异常。 nil的map并没有分配内存，map添加元素是直接map[x] = x形式，所以会报错误。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // type sliceStruct struct {pointer, len, cap} // data=nil len=0 cap=0 var a []string // nil // 注意 与 a := []string{} 的区别，这种是已经初始化过的也就是系统默认调用过make方法其零值不为nil // 更多 var a []string 和 a := []string{} 形式将在切片一节中讨论 // append 会初始化a a1 := append(a, \u0026#34;s\u0026#34;) fmt.Println(a, a1) // [] [s] //var m map[string]int //m[\u0026#34;one\u0026#34;] = 1 // panic: assignment to entry in nil map // data len // make会初始化 var m1 map[string]int = make(map[string]int, 2) m1[\u0026#34;one\u0026#34;] = 1 fmt.Println(m1)\t// map[one:1] var ss *string = new(string) *ss = \u0026#34;abc\u0026#34; fmt.Println(ss, *ss) // 0xc000088260 abc // panic: runtime error: invalid memory address or nil pointer dereference //var s *int // 此时s的默认值为nil，*s并没有分配内存 //*s = 10 // 报错 s 并没有分配内存空间 } 注意nil用于的类型： nil是一个预先声明的标识符，表示a的零值 pointer, channel, func, interface, map, or slice type。 类型必须是 pointer, channel, func, interface, map, or slice type. 1 2 var s string = \u0026#34;hello,world\u0026#34; c := s[0] // c的类型为 byte 也就是 uint8 ","permalink":"https://heliu.site/posts/golang/basic/zero/","summary":"Golang 类型的默认零值。","title":"类型零值"},{"content":"局部变量与全局变量 局部变量：函数体内、代码块内、参数(函数参数和接收器参数)和返回值变量。 在函数体或代码块内声明的变量称为局部变量，它们的作用域只在代码块内。 参数和返回值变量也是局部变量(接收器参数也是局部变量)。 全局变量：函数体外声明的变量。 在函数体外声明的变量称为全局变量，它们的作用域是全局的。（在本包范围内） 全局变量可以在整个包甚至外部包（被导出后）使用，全局变量可以在任何函数中使用。 简式变量： 使用 := 声明的变量，一般也是局部变量。（变量可能逃逸到堆里面） 如果新局部变量Ga与同名已定义变量（全局变量Ga）不在同一个作用域中，Go语言会在此作用域新定义局部变量Ga，遮住全局变量Ga，因此尽量全局变量与局部变量不同名。 显式与隐式代码块 Go语言中的标识符作用域是基于代码块的，代码块是包裹在一对花括号{}内部的声明和语句，并且是可嵌套的。 代码块如：函数的函数体、for循环的循环体等。 还有隐式的（implicit）代码块。 1 2 3 4 5 6 7 8 9 10 11 12 13 // 使用最多的if语句类型只有if而没有else分支 if simplestms; expression { ... ... } // 在这种类型的if语句中，有两个代码块：一个隐式的代码块和一个显示的代码块 // 上面代码等价于 { // 隐式的代码块 simplestms if expression { // 显式代码块 ... ... } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import \u0026#34;fmt\u0026#34; func main() { // 这里需要注意变量声明的先后顺序 if a := 1; false { fmt.Println(11) } else if b := 2; false { fmt.Println(22) } else if c := 3; false { fmt.Println(33) } else { fmt.Println(a, b, c) } // 上面代码 等价于如下代码 因此不同位置定义的变量作用域不同 { aa := 1 if false { fmt.Println(11) } else { bb := 2 if false { fmt.Println(22) } else { cc := 3 if false { fmt.Println(33) } else { fmt.Println(aa, bb, cc) } } } } // Output: // 1 2 3 // 1 2 3 } 变量被遮盖 相同名字的标识符会遮住前面的标识符，这种情况只能是在不同的块中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; ) // Ga 全局变量 var ( Ga int = 99 ) // v 全局常量 const ( v int = 199 ) func main() { // 覆盖外部声明变量Ga Ga := \u0026#34;string\u0026#34; fmt.Println(\u0026#34;main函数中:\u0026#34;, Ga) // main函数中: string b := GetGa() fmt.Println(\u0026#34;main函数中：\u0026#34;, b(), b(), b(), b()) printGVariable() fmt.Println(v) // 注意这里屏蔽了全局常量v v := 1 { v := 2 fmt.Println(v) { v := 3 fmt.Println(v) } } fmt.Println(v) // Output: // main函数中: string // GetGa if中： 55 // GetGa 循环中： 2 // GetGa函数中: 99 // main函数中： 100 101 102 103 // 103 // 199 // 2 // 3 // 1 } // GetGa 返回值为函数 func() int func GetGa() func() int { rand1 := rand.Intn(10) // 返回随机数 [0,10] 之间 // 局部变量 Ga if Ga := 55; Ga + rand1 \u0026lt; 60 { fmt.Println(\u0026#34;GetGa if中：\u0026#34;, Ga) } // 局部变量 Ga for Ga := 2; ; { fmt.Println(\u0026#34;GetGa 循环中：\u0026#34;, Ga) break } // 全局变量 Ga fmt.Println(\u0026#34;GetGa函数中:\u0026#34;, Ga) // 关于闭包的情况参看函数章节 return func() int { // 此处Ga的作用域认定上下文是99 Ga += 1 // 全局变量Ga return Ga } } func printGVariable() { // 全局变量Ga fmt.Println(Ga) } 总结 有花括号一般都存在作用域。 :=标识新声明一个变量，在不同的块中可能会屏蔽所有上层代码块中的相同名称的变量（常量）。 在if等语句中存在隐式代码块，需要注意。 闭包函数可以理解为一个代码块，并且可以使用包含它的函数内的变量。 简单声明(:=)变量只能在函数内部出现，它会覆盖函数外的同名变量。 简单声明(:=)左侧只有一个变量的情况下不能重复声明一个变量，有多个变量时允许的，但这些变量中至少要有一个新的变量，经常是情况是file, err := os.Open(\u0026quot;txt.txt\u0026quot;)这里的err变量接收错误在相同块的多个地方被使用。 约定和惯例 可见性规则： Go语言中标识符必须以一个大写字母开头（参看Unicode编码集定义的大写字母集），才能被外部包的代码使用，这称为导出。 标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的。 命名规范以及语法惯例： 当某个函数需要被外部包调用的时候需要以大写字母开头，并遵守Pascal命名法。（大驼峰命名法） 否则就遵守（小驼峰命名法），即第一个单词的首字母小写，其余单词的首字母大写。 单词之间不以空格断开或连接号（-）、下划线（_）连接，第一个单词首字母采用大写字母，后续单词的首字母也用大写字母（FirstName、LastName）。 左花括号{不能独占一行，这是编辑器的强制规定，右花括号}需要独占一行。(这与Go没有;相关，编译器会加上默认的;) 在定义接口名时也有惯例，一个单方法接口由方法名称加上-er后缀或者-able后缀来命名或者I开头。 注释 行注释：// 注释。 块注释：/* 注释 */。 ","permalink":"https://heliu.site/posts/golang/basic/scope/","summary":"Golang 相关作用域介绍。","title":"作用域"},{"content":" Go语言中的指针不能进行偏移和运算，是安全指针。 指针地址、指针类型和指针取值。 Go语言中的函数传参都是值拷贝，当我们想要修改某个变量的时候，我们可以创建一个指向该变量地址的指针变量。 传递数据使用指针，而无须拷贝数据。 类型指针不能进行偏移和运算。 Go语言中的指针操作非常简单，只需要记住两个符号： \u0026amp;（取地址）、*（根据地址取值）。 指针地址与指针类型 每个变量在运行时都拥有一个地址，这个地址代表变量在内存中的位置，Go语言中使用\u0026amp;字符放在变量前面对变量进行**“取地址”**操作。 Go语言中的值类型（int、float、bool、string、array、struct），对应的指针 *int、*int64、*string等。 1 2 3 4 5 6 // 取变量指针地址语法 ptr := \u0026amp;v // v的类型为T // v: 代表被取地址的变量，类型为T // ptr：用于接收地址的变量，ptr的类型就为*T，称做T的指针类型 // * 代表指针 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import \u0026#34;fmt\u0026#34; func main() { a := 10\t// int类型 b := \u0026amp;a\t// *int类型 // a:10 ptr:0xc00001a078 type:int fmt.Printf(\u0026#34;a:%d ptr:%p type:%T\\n\u0026#34;, a, \u0026amp;a, a) // b:0xc00001a078 type:*int fmt.Printf(\u0026#34;b:%p type:%T\\n\u0026#34;, b, b) // 0xc00000e018 fmt.Println(\u0026amp;b) } 指针取值 在对普通变量使用\u0026amp;操作符取地址后会获得这个变量的指针，然后可以对指针使用*操作，也就是指针取值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import \u0026#34;fmt\u0026#34; func main() { a := 10 // int类型 // 取变量a的地址，将指针保存到b中 b := \u0026amp;a // *int类型 fmt.Printf(\u0026#34;type of b:%T\\n\u0026#34;, b) // type of b:*int // 指针取值（根据指针去内存取值） c := *b fmt.Printf(\u0026#34;type of c:%T\\n\u0026#34;, c) // type of c:int fmt.Printf(\u0026#34;value of c:%v\\n\u0026#34;, c)// value of c:10 *b = 11 fmt.Println(a, *b, c) // 11 11 10 } 空指针 当一个指针被定义后没有分配到任何变量时，它的值为 nil。 空指针的判断。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import \u0026#34;fmt\u0026#34; func main() { var p *string fmt.Println(p) // \u0026lt;nil\u0026gt; fmt.Printf(\u0026#34;p的值是%v\\n\u0026#34;, p) // p的值是\u0026lt;nil\u0026gt; if p != nil { fmt.Println(\u0026#34;非空\u0026#34;) } else { fmt.Println(\u0026#34;空值\u0026#34;) // 空值 } } 类型转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { var ff float64 = 12.23 ii := *(*uint64)(unsafe.Pointer(\u0026amp;ff)) // uint64 类型 fmt.Printf(\u0026#34;%064b \\n\u0026#34;, ii) ff1 := *(*float64)(unsafe.Pointer(\u0026amp;ii)) fmt.Println(ff1) // Output: // 0100000000101000011101011100001010001111010111000010100011110110 // 12.23 } 指针练习 程序定义一个int变量num的地址并打印。 将num的地址赋给指针ptr，并通过ptr去修改num的值。 1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func main() { var a int fmt.Println(\u0026amp;a) var p *int p = \u0026amp;a *p = 20 fmt.Println(a) } 使用注意 【常量】不能使用\u0026amp;取地址，常量是只读类型因此取地址没啥意义。 【字符串元素】，比如\u0026amp;string[0]不能取地址，字符串也是只读类型对字符串中的符号取地址意义也不大。 【字典元素】，比如\u0026amp;map[‘key’]不能取地址，字典的存储位置是经常变化的，因此对字典中元素取地址意义不大。 总结 取地址操作符\u0026amp;和取值操作符*是一对互补操作符。 \u0026amp;：取出地址；*：根据地址取出地址指向的值。 变量、指针地址、指针变量、取地址、取值的相互关系和特性如下： 对变量进行取地址（\u0026amp;）操作，可以获得这个变量的存储地址。 指针变量的值是指针地址。 对指针变量进行取值（*）操作，可以获得指针变量指向的原变量的值。 指针传值例子。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import \u0026#34;fmt\u0026#34; func main() { a := 10 modify1(a) fmt.Println(a) // 10 modify2(\u0026amp;a) fmt.Println(a) // 100 } func modify1(x int) { x = 100 } func modify2(x *int) { *x = 100 } ","permalink":"https://heliu.site/posts/golang/basic/pointer/","summary":"Golang 指针介绍。","title":"指针"},{"content":" 使用反引号(``)或双引号(\u0026quot;\u0026quot;)来定义字符串，反引号表示原生的字符串，即不进行转义。 双引号 字符串使用双引号括起来，其中相关的转义字符将被替换。 1 str := \u0026#34;hello world! \\n Hello \\n\u0026#34; // \\n 表示换行 1 2 3 4 5 6 7 8 9 func Example() { str := \u0026#34;hello world! \\n Hello \\n\u0026#34; fmt.Printf(\u0026#34;%s\u0026#34;, str) // Output: // hello world! // Hello // } 反引号 字符串使用反引号括起来，其中相关的转义字符不会被替换。 1 str := `hello world! \\n Hello \\n`\t// \\n 表示换行 1 2 3 4 5 6 7 func Example() { str := `hello world! \\n Hello \\n` fmt.Printf(\u0026#34;%s\u0026#34;, str) // Output: // hello world! \\n Hello \\n } 双引号和反引号存储的区别。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import \u0026#34;fmt\u0026#34; func main() { // 验证两种形式字符串的区别 s1 := \u0026#34;hello,\\nworld\u0026#34; // 12 s2 := `hello,\\nworld` // 13 // 可见(双引号中，\\n当作转义字符在处理)，当作一个字节 // (反引号中，\\n当作两个字符处理)当作两个字节 fmt.Println(len(s1), len(s2)) // Output: // 12 13 } 字符串 Go语言中的string类型是一种值类型，存储的字符串是不可变的。 如果需要修改string的内容，需要将string转换为[]byte或[]rune，并且修改后的string内容是重新生成的。 Go默认使用UTF-8编码，对Unicode的支持非常好。 字符串存储结构： 1 2 3 4 5 6 type StringStruct struct { // 指向字符串的底层数组的首字节地址，就是一个指针地址 Data unsafe.Pointer // 保存字符串的长度，其实就是int类型大小 Len uintptr } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 type stringStruct struct { str unsafe.Pointer len uintptr } { var aa1 [32]byte var ll1 uintptr = 6 // 字符串一样被分配在只读内存上， // 只是该底层数组不能操作但是能替换stringStruct.str存储的值 var sss string = \u0026#34;b\u0026#34; // 替换掉原先指向的只读内存位置到aa1栈上的数据， // 以下代码是使sss底层数组和aa1相关联起来，操作aa1也就是操作sss s2s1 := (*stringStruct)(unsafe.Pointer(\u0026amp;sss)) s2s1.str = unsafe.Pointer(\u0026amp;aa1)\t// 替换该值 s2s1.len = ll1 bbb1 := aa1[:ll1] bbb1[1] = \u0026#39;a\u0026#39; // [0 97 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] // a // [0 97 0 0 0 0] fmt.Println(aa1, sss, bbb1) } byte 和 rune 这两个类型是处理字符相关。 type byte = uint8、type rune = int32。 1 2 3 4 5 6 7 // byte 和 rune type byte = uint8 // 长度 1B type rune = int32 // 长度 4B // 类型string类型的零值是长度为零的字符串，即空字符串 \u0026#34;\u0026#34; var b byte = \u0026#39;a\u0026#39; // ASCII码相对应数值 var r rune = \u0026#39;好\u0026#39; // Unicode相对应编码 Unicode 转 UTF-8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unicode/utf8\u0026#34; ) func main() { var s string = \u0026#34;hello Go语言\u0026#34;\t// 8 + 2*3 = 14 fmt.Println(len(s)) // 14 字节 fmt.Println(utf8.RuneCountInString(s)) // 10 字符 // 把字符串s显示转换为[]byte类型，此时会分配新的底层数组空间而不是共用之前 slice1 := []byte(s) // utf-8编码 转 unicode // | Unicode符号范围 | UTF-8编码方式，编码模板 // n | 十六进制 | 二进制 // --+-----------------------+-------------------------------------------------------- // 1 | 0000 0000 - 0000 007F | 0xxxxxxx // 2 | 0000 0080 - 0000 07FF | 110xxxxx 10xxxxxx // 3 | 0000 0800 - 0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx // 4 | 0001 0000 - 0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx utf8最大4字节 // 5 | 0020 0000 - 03FF FFFF | 111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx // 6 | 0400 0000 - 7FFF FFFF | 1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx // --+-----------------------+-------------------------------------------------------- // 232 175 173\t=utf8转二进制=\u0026gt; 11101000 10101111 10101101 =转unicode=\u0026gt; 10001011 11101101 =\u0026gt; 35821 语 // 232 168 128\t=utf8转二进制=\u0026gt; 11101000 10101000 10000000 =转unicode=\u0026gt; 10001010 00000000 =\u0026gt; 35328 言 fmt.Println(slice1) // [104 101 108 108 111 32 71 111 232 175 173 232 168 128] // 把字符串s显示转换为[]rune类型 slice2 := []rune(s) fmt.Println(slice2) // [104 101 108 108 111 32 71 111 35821 35328] for i, v := range s { // int, rune fmt.Printf(\u0026#34;i:%d %#U %d \\n\u0026#34;, i, v, v) } /* * i:0 U+0068 \u0026#39;h\u0026#39; 104 * i:1 U+0065 \u0026#39;e\u0026#39; 101 * i:2 U+006C \u0026#39;l\u0026#39; 108 * i:3 U+006C \u0026#39;l\u0026#39; 108 * i:4 U+006F \u0026#39;o\u0026#39; 111 * i:5 U+0020 \u0026#39; \u0026#39; 32 * i:6 U+0047 \u0026#39;G\u0026#39; 71 * i:7 U+006F \u0026#39;o\u0026#39; 111 * i:8 U+8BED \u0026#39;语\u0026#39; 35821 * i:11 U+8A00 \u0026#39;言\u0026#39; 35328 */ // 232 175 173\t=\u0026gt; 35821 // E8 AF AD =\u0026gt; 8BED // 字符串的单个字符是byte也就是uint8类型 fmt.Printf(\u0026#34;%T\\n\u0026#34;, s[0]) // uint8 // 字符串使用切片后依然是字符串类型 fmt.Printf(\u0026#34;%T\\n\u0026#34;, s[:]) // string } 字符串比较 一般的比较运算符（==、!=、\u0026lt;、\u0026lt;=、\u0026gt;=、\u0026gt;）通过在内存中接字节比较来实现字符串的对比。 比较源码函数： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 //go:linkname runtime_cmpstring runtime.cmpstring func runtime_cmpstring(a, b string) int { l := len(a) // l记录a和b最小的一个长度 if len(b) \u0026lt; l {\tl = len(b) } for i := 0; i \u0026lt; l; i++ { // 遍历 c1, c2 := a[i], b[i] if c1 \u0026lt; c2 { // a \u0026lt; b 返回 -1 return -1 } if c1 \u0026gt; c2 { // a \u0026gt; b 返回 +1 return +1 } } // 这里说明前面字串都一样，现在比较谁长 // 由于上面遍历的最短长度的所以需要再次判断长度比较 if len(a) \u0026lt; len(b) {\treturn -1 } if len(a) \u0026gt; len(b) { return +1 } // a == b 返回 0 return 0 } 字符串长度 len()函数获取字符串所占的字节长度，由字符串的结构可知字符串的长度保存在字符串的第二个字段中。 1 2 // ASCII中 a-\u0026gt;97 A-\u0026gt;65 fmt.Println(\u0026#39;a\u0026#39; \u0026gt; \u0026#39;A\u0026#39;) // true 内置的len()函数获取的是字节的长度和，而不是字符数量。 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unicode/utf8\u0026#34; ) func main() { s := \u0026#34;其实就是rune\u0026#34; fmt.Println(len(s)) // 16 字节 4*3 + 4 fmt.Println(utf8.RuneCountInString(s)) // 8 字符 } 字符串的内容(纯字节)可以通过标准索引来获取，在中括号[]内写入索引，索引从0开始。 字符串str的第一个字节 str[0]。 第 i 字节 str[i - 1]。 最后1个字节 str[len(str) - 1]。 1 2 3 4 5 6 7 s1 := \u0026#34;hello, world!\u0026#34; fmt.Printf(\u0026#34;%c\\n\u0026#34;, s1[0]) // h fmt.Printf(\u0026#34;%c\\n\u0026#34;, s1[7]) // w // 不能使用\u0026amp;s1[0]这种形式取地址，因为字符串是不可变类型这种形式的取地址没有任何意义 // 但是获取到s1[0]的地址也是有办法的，通过unsafe 如果字符串含有中文等字符，可以看到每个中文字符的索引值相差3。 Go的range循环在处理字符串的时候，会自动隐式解码UTF-8字符串，关于循环的处理参看for相关文档。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;fmt\u0026#34; ) func main() { s := \u0026#34;其实就是rune\u0026#34; // v 其实就是rune类型值 for k, v := range s{ // 【int, rune】 fmt.Printf(\u0026#34;K: %d, V: %c === %d\\n\u0026#34;, k, v, v) } // Output: // K: 0, V: 其 === 20854 // K: 3, V: 实 === 23454 // K: 6, V: 就 === 23601 // K: 9, V: 是 === 26159 // K: 12, V: r === 114 // K: 13, V: u === 117 // K: 14, V: n === 110 // K: 15, V: e === 101 } 字符串拼接 将多个字符串拼接成一个字符串。 + 拼接 下面的示例，字符串都是不可变的，每次运算都会产生一个新的字符串，所以会产生很多临时的字符串。 不仅没用还会给垃圾回收带来额外负担，所以性能比较差。 数量较少的 + 还行，比如 5 个或以下。 1 2 3 4 5 6 7 // 这种由于编辑器会在代码行尾自动补全分号的缘由，加号必须放在第一行 str := \u0026#34;hello\u0026#34; + \u0026#34;,world\u0026#34; // += 形式拼接字符串 s := \u0026#34;hello\u0026#34; + \u0026#34;,world\u0026#34; s += \u0026#34;!\u0026#34; fmt.Sprintf() 内部使用[]byte实现，不像直接使用+拼接产生临时的字符串。 但是内部逻辑比较复杂，很多额外的判断，用到了接口，所以性能一般。 1 fmt.Sprintf(\u0026#34;%d:%s\u0026#34;, 2021, \u0026#34;Golang\u0026#34;) // 2021:Golang strings.Join() Join会先根据字符串数组的内容，计算一个拼接之后的长度。 然后申请对应大小的内存，一个一个字符串填入。 在已有一个数组的情况下效率很高，但是构造一个本来没有的数据代价也不小。 1 strings.Join([]string{\u0026#34;hello,\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;Golang\u0026#34;}, \u0026#34;!!!\u0026#34;) // hello,!!!world!!!Golang bytes.Buffer 比较理想，可以当成可变字符使用，对内存的增长也有优化。 如果能预估字符串的长度，可以使用buffer.Grow()接口来设置capacity，就是设置切片容量，避免翻倍扩容造成性能下降。 1 2 3 4 5 var buffer bytes.Buffer buffer.WriteString(\u0026#34;hello\u0026#34;) buffer.WriteString(\u0026#34;,\u0026#34;) buffer.WriteString(\u0026#34;world!\u0026#34;) fmt.Print(buffer.String()) strings.Builder 内部通过切片来保存和管理内容。 切片内部则是通过一个指针指向实际保存内容的数组。 strings.Builder同样也提供了Grow()来支持预定于容量，就是设置切片容量，避免翻倍扩容造成性能下降。 当可以预定义需要使用的容量时，strings.Builder就能避免因扩容产生新的切片。 strings.Builder是非线程安全的，性能和bytes.Buffer相差无几。 1 2 3 4 var b1 string.Builder b1.WriteString(\u0026#34;hello,\u0026#34;) b1.WriteString(\u0026#34;world!\u0026#34;) fmt.Print(b1.String()) 字符串处理 标准库四个对字符串处理包：bytes、strings、strconv、unicode。 包 描述 strings 提供了许多如字符串的查询、替换、比较、截断、拆分和合并等功能 bytes 该包也提供了类似strings功能的函数，但是针对和字符串有着相同结构的[]byte类型，因为字符串只是只读，因此逐步构建字符串会导致很多分配和复制。在这种情况下，使用bytes.Buffer类型将更有效 strconv 提供了布尔型、整型数、浮点数和对应字符串的相互转换，还提供了双引号转义相关的转换 unicode 提供了IsDigit、IsLetter、IsUpper和IsLower等类似功能，用于给定字符分类 判断以某字符串开头或结尾 strings.HasPrefix(s, prefix string) bool 判断是否以某个字符串开头。 strings.HasSuffix(s, suffix string) bool 判断是否以某个字符串结尾。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { s := `快樂 \\n Ak` fmt.Println(strings.HasPrefix(s, \u0026#34;快樂\u0026#34;)) // true fmt.Println(strings.HasPrefix(s, \u0026#34;A\u0026#34;)) // false // Output: // true // false } 字符串分割 strings.Split(s, sep string) []string 使用sep字符串分隔s字符串。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { s := `A,B,C,D,E,F,G,H` fmt.Println(strings.Split(s, \u0026#34;,\u0026#34;)) // [A B C D E F G H] // Output: // [A B C D E F G H] } 返回子串索引 strings.Index(s, substr string) int 返回第一次匹配到的索引。 strings.LastIndex(a, substr string) int 返回最后一个匹配到的索引。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { s := `A,B,C,D,E,F,G,H` fmt.Println(strings.Index(s, \u0026#34;,\u0026#34;)) // 1 fmt.Println(strings.LastIndex(s, \u0026#34;,\u0026#34;)) // 13 fmt.Println(strings.Index(s, \u0026#34;D\u0026#34;)) // 6 fmt.Println(strings.LastIndex(s, \u0026#34;D\u0026#34;)) // 6 fmt.Println(strings.Index(s, \u0026#34;M\u0026#34;)) // -1 fmt.Println(strings.LastIndex(s, \u0026#34;M\u0026#34;)) // -1 } 字符串连接 strings.Join(a []string, sep string) string 使用sep字符串拼接a字符串切片。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { s := []string{\u0026#34;A\u0026#34;,\u0026#34;D\u0026#34;,\u0026#34;G\u0026#34;,\u0026#34;R\u0026#34;,\u0026#34;G\u0026#34;,\u0026#34;S\u0026#34;,\u0026#34;F\u0026#34;} // 注意这里的s必须是切片[]string类型 fmt.Println(strings.Join(s, \u0026#34;,\u0026#34;)) // A,D,G,R,G,S,F // Output: // A,D,G,R,G,S,F } 字符串替换 strings.Replace(s, old, new string, n int) string 在s字符串中搜索old字符串并替换成new字符串，n替换个数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { s := \u0026#34;A,D,G,R,G,S,F,D,G,f,d,D,,FW,A,D\u0026#34; old := \u0026#34;,D\u0026#34; new := \u0026#34;-A-\u0026#34; // strings.Replace(s, old, new string, n int) // s 原字符串 // old 需要被替换旧的字符串 // new 需要被替换新的字符串 // 替换个数 n\u0026lt;0 默认替换全部 | n=0 不替换 | n=1 默认替换一个 fmt.Println(strings.Replace(s, old, new, -1)) // A-A-,G,R,G,S,F-A-,G,f,d-A-,,FW,A-A- fmt.Println(strings.Replace(s, old, new, 0)) // A,D,G,R,G,S,F,D,G,f,d,D,,FW,A,D fmt.Println(strings.Replace(s, old, new, 1)) // A-A-,G,R,G,S,F,D,G,f,d,D,,FW,A,D fmt.Println(strings.Replace(s, old, new, 3)) // A-A-,G,R,G,S,F-A-,G,f,d-A-,,FW,A,D fmt.Println(strings.Replace(s, old, new, 30)) // A-A-,G,R,G,S,F-A-,G,f,d-A-,,FW,A-A- } 统计字符在字符串中的次数 strings.Count(s, substr string) int 统计substr字符串在s字符串中出现的次数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { s := \u0026#34;A,D,G,R,G,S,F,D,G,f,d,D,,FW,A,D\u0026#34; fmt.Println(strings.Count(s, \u0026#34;,\u0026#34;)) // 15 fmt.Println(strings.Count(s, \u0026#34;D\u0026#34;)) // 4 // Output: // 15 // 4 } 判断字符串的包含关系 strings.Contains(s, substr string) bool 判断s字符串是否包含substr字符串。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { s := \u0026#34;A,D,G,R,G,S,F,D,G,f,d,D,,FW,A,D\u0026#34; fmt.Println(strings.Contains(s, \u0026#34;,D\u0026#34;)) // true fmt.Println(strings.Contains(s, \u0026#34;DD\u0026#34;)) // false // Output: // true // false } 字符串转义符 Go 语言的字符串常见转义符包含回车、换行、单双引号、制表符等，如下表所示。 转义 含义 \\r 回车符（返回行首） \\n 换行符（直接跳到下一行的同列位置） \\t 制表符 \\' 单引号 \\\u0026quot; 双引号 \\ 反斜杠 1 2 3 4 5 6 7 8 9 10 11 12 package main import ( \u0026#34;fmt\u0026#34; ) func main() { fmt.Println(\u0026#34;str := \\\u0026#34;c:\\\\pprof\\\\main.exe\\\u0026#34;\u0026#34;) // Output: // str := \u0026#34;c:\\pprof\\main.exe\u0026#34; } byte和rune类型 组成每个字符串的元素叫做字符。 可以通过遍历或者单个获取字符串元素获得字符。 字符用英文单引号（'）包裹起来。 1 2 3 4 5 // 以下字符类型都默认 rune类型 var a := \u0026#39;中\u0026#39; // rune var b := \u0026#39;x\u0026#39; // rune fmt.Printf(\u0026#34;b:%T\\n\u0026#34;, b) // b:int32 fmt.Printf(\u0026#34;a:%T\\n\u0026#34;, a) // a:int32 Go 语言的字符有以下两种： uint8类型，或者叫byte型，代表了ASCII码的一个字符。 rune类型，代表一个Unicode字符。 当需要处理中文、日文或者其他复合字符时，则需要用到rune类型。 rune类型实际是一个int32。 Go 使用了特殊的 rune 类型来处理 Unicode，让基于Unicode的文本处理更为方便。 也可以使用 byte 型进行默认字符串处理。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 遍历字符串 func traversalString() { s := \u0026#34;pprof.cn博客\u0026#34; for i := 0; i \u0026lt; len(s); i++ { // 【int, byte】 fmt.Printf(\u0026#34;%v(%c) \u0026#34;, s[i], s[i]) } fmt.Println() for _, r := range s { // 【int, rune】 fmt.Printf(\u0026#34;%v(%c) \u0026#34;, r, r) } fmt.Println() } 修改字符串 要修改字符串，需要先将其转换成[]rune 或 []byte，完成后再转换为string。 无论哪种转换，都会重新分配内存。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func changeString() { s1 := \u0026#34;hello\u0026#34; // 强制类型转换 byteS1 := []byte(s1) byteS1[0] = \u0026#39;H\u0026#39; fmt.Println(string(byteS1)) s2 := \u0026#34;博客\u0026#34; runeS2 := []rune(s2) runeS2[0] = \u0026#39;狗\u0026#39; fmt.Println(string(runeS2)) } // 类型转化，下面可见类型转换都是新分配内存地址 // 内存分布是低字节在前高字节在后排序的，不同的平台不同 var u1 uint16 = 0b00000111_00000011 u2 := (uint8)(u1) fmt.Println(u2, \u0026amp;u1, \u0026amp;u2) // Output: // 3 0xc0000140b0 0xc0000140b2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 type StringStruct struct { Data uintptr Len uintptr } type SliceStruct struct { Data uintptr Len uintptr Cap uintptr } func str() { s1 := \u0026#34;hello\u0026#34; fmt.Println(\u0026amp;s1) // 0xc0000102d0 fmt.Printf(\u0026#34;%#x\\n\u0026#34;, *(*uintptr)(unsafe.Pointer(\u0026amp;s1))) // 0x4a116b // 看一下s1的存储的结构 s := *(*StringStruct)(unsafe.Pointer(\u0026amp;s1)) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, s) // main.StringStruct{Data:0x4a116b, Len:0x5} byteS1 := []byte(s1) // 看看byteS1存储的结构，下面结果可见是从新分配的内存 ss := *(*SliceStruct)(unsafe.Pointer(\u0026amp;byteS1)) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, ss) // main.SliceStruct{Data:0xc000074e28, Len:0x5, Cap:0x20} // 这里为什么容量是32，比5大那么多，具体参看 []byte(s1) 转换的源码 fmt.Println(cap(byteS1)) // 32 // Output: // 0xc0000102d0 // 0x4a116b // main.StringStruct{Data:0x4a116b, Len:0x5} // main.SliceStruct{Data:0xc000074e28, Len:0x5, Cap:0x20} // 32 } 类型转换 Go语言中只有显示类型转换，没有隐式类型转换，该语法只能在两个类型之间支持相互转换的时候使用。 强制类型转换的基本语法如下： T(表达式)：注意区分函数调用情况。因为函数调用与显示转换类型形式相似。 T表示要转换的类型。 如计算直角三角形的斜边长时使用math包的Sqrt()函数。 该函数接收的是float64类型的参数，而变量a和b都是int类型的，这个时候就需要将a和b强制类型转换为float64类型。 1 2 3 4 5 6 7 8 func sqrtDemo() { var a, b = 3, 4 var c int // math.Sqrt()接收的参数是float64类型，需要强制转换 c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c) } 总结 字符串被设计成只读数据，这样在多线程时操作字符串时不需要加锁避免并发。 ","permalink":"https://heliu.site/posts/golang/basic/string/","summary":"Golang 字符串使用介绍。","title":"字符串"},{"content":"内存结构 字符串结构 1 2 3 4 5 6 type stringStruct struct { // 指向底层数组，连续分配的字节 Data unsafe.Pointer // 记录着字符串的字节长度 Len int } 字符串内存分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { // 如上：str的地址为0x01f050存储的值是0x4a1160，0x4a1160则是字符h的首地址存储的值是0x68(字符h) var str string = \u0026#34;hello world!\u0026#34; // 把变量str当成StringStruct结构看待 // 字符串的内存大小存在_type.size中，更多参考runtime/type.go文件 sizeOf := unsafe.Sizeof(str) // 字符串占用内存大小(B):16 fmt.Printf(\u0026#34;字符串占用内存大小(B):%d\\n\u0026#34;, sizeOf) // \u0026amp;str:0x01f050 // 这里需要明白的是结构体存储的是第一个字段的地址 fmt.Printf(\u0026#34;\u0026amp;str:%#x\\n\u0026#34;, \u0026amp;str) // \u0026amp;StringStruct.data // \u0026amp;StringStruct.Len l := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;str)) + unsafe.Sizeof(int(0)))) // 字符串长度:12 (0x0c) fmt.Printf(\u0026#34;字符串长度:%d\\n\u0026#34;, *l) data := *(*int)(unsafe.Pointer(\u0026amp;str)) // 数据存储地址：0x4a1160 fmt.Printf(\u0026#34;数据存储地址：%#x\\n\u0026#34;, data) // 获取指定数据，不推荐分开操作指针比如这里的data写成两个表达式 // uintptr(unsafe.Pointer(nil)) =\u0026gt; 0 //b0 := *(*byte)(unsafe.Pointer(uintptr(unsafe.Pointer(nil)) // + uintptr(data))) b0 := **(**byte)(unsafe.Pointer(\u0026amp;s1))\t// h // str[0]:h fmt.Printf(\u0026#34;str[0]:%c\\n\u0026#34;, b0) // 不建议这样分开写成两段，取str[8]的值 //b8 := *(*byte)(unsafe.Pointer(uintptr(unsafe.Pointer(nil)) + // uintptr(data) + 8*unsafe.Sizeof(byte(\u0026#39;0\u0026#39;)))) b8 := (**(**[9]byte)(unsafe.Pointer(\u0026amp;str)))[8] // str[8]:r fmt.Printf(\u0026#34;str[8]:%c\\n\u0026#34;, b8) // Output: // 字符串占用内存大小(B):16 // \u0026amp;str:0xc000088230 // 字符串长度:12 // 数据存储地址：0x103fb6b // str[0]:h // str[8]:r } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) // stringHeader 字符串结构 type stringHeader struct { Data uintptr Len uintptr } func main() { var s0 string = \u0026#34;hello\u0026#34; // 获取字符串长度 l := (*stringHeader)(unsafe.Pointer(\u0026amp;s0)).Len fmt.Printf(\u0026#34;字符串长度：%d\\n\u0026#34;, l) // s0[0] s00 := **(**byte)(unsafe.Pointer(\u0026amp;s0)) fmt.Printf(\u0026#34;s[0]：%c\\n\u0026#34;, s00) // s0[4] // *(*uintptr)(unsafe.Pointer(\u0026amp;s0)) s04 := *(*byte)(unsafe.Pointer(uintptr(unsafe.Pointer(nil)) + *(*uintptr)(unsafe.Pointer(\u0026amp;s0)) + 4*unsafe.Sizeof(byte(\u0026#39;0\u0026#39;)))) fmt.Printf(\u0026#34;s[4]：%c\\n\u0026#34;, s04) // ------------------------------------------------------------------------------------------------------- // 获取字符每个字符 s1 := \u0026#34;helxo\u0026#34; fmt.Printf(\u0026#34;%c\\n\u0026#34;, **(**byte)(unsafe.Pointer(\u0026amp;s1))) // h fmt.Printf(\u0026#34;%c\\n\u0026#34;, **(**uint16)(unsafe.Pointer(\u0026amp;s1)) \u0026gt;\u0026gt; 8) // e fmt.Printf(\u0026#34;%c\\n\u0026#34;, **(**uint32)(unsafe.Pointer(\u0026amp;s1)) \u0026gt;\u0026gt; 16 \u0026amp; 0b00000000_11111111) // l fmt.Printf(\u0026#34;%c\\n\u0026#34;, **(**uint32)(unsafe.Pointer(\u0026amp;s1)) \u0026gt;\u0026gt; 24) // x fmt.Printf(\u0026#34;%c\\n\u0026#34;, **(**uint64)(unsafe.Pointer(\u0026amp;s1)) \u0026gt;\u0026gt; 32 \u0026amp; 0b00000000_00000000_00000000_11111111)\t// o a := **(**[5]byte)(unsafe.Pointer(\u0026amp;s1)) fmt.Println(a) // 字符不允许被修改，所以这里需要处理一下 str1 := \u0026#34;hello world!\u0026#34; // 编译时会被分配到只读代码段 str1 = str1 + \u0026#34; ds\u0026#34; // 运行时会分配到内存中，语言层面上限制了只读 // ab1 是 [12]byte 类型 ab1 := **(**[12]byte)(unsafe.Pointer(\u0026amp;str1))\t// 对比下面的区别 ab1[0] = 101 fmt.Println(ab1, str1) // [101 101 108 108 111 32 119 111 114 108 100 33] hello world! ds // ab 是 *[12]byte 类型 ab := *(**[12]byte)(unsafe.Pointer(\u0026amp;str1)) (*ab)[0] = 101 fmt.Println(*ab, str1) // [101 101 108 108 111 32 119 111 114 108 100 33] eello world! ds // 指针数组对比上面 ac := new([12]byte) // *[12]byte (*ac)[0] = 96 fmt.Println(*ac) // [96 0 0 0 0 0 0 0 0 0 0 0] } 字符串按值传参 以下我们可以看出，字符串在函数间传递传递的是stringStruct结构体。 按值传参也是直接新创建个变量地址保存stringStruct结构体，其字符串指向的底层数组是没有发生变化的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { var str string = \u0026#34;hello world!\u0026#34; fmt.Printf(\u0026#34;\u0026amp;str:%#x\\n\u0026#34;, \u0026amp;str) // 以下区别： // uintptr(unsafe.Pointer(\u0026amp;str)) 得到uintptr类型就是\u0026amp;str地址，这是一个特例其他类型不允许这样转换 // (*uintptr)(unsafe.Pointer(\u0026amp;str)) 得到*uintptr类型也是\u0026amp;str地址，不建议使用 // *(*uintptr)(unsafe.Pointer(\u0026amp;str)) 得到uintptr类型是str存储首uintptr长度字节的值 l := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;str)) + unsafe.Sizeof(int(0)))) // 字符串长度:12 fmt.Printf(\u0026#34;字符串长度:%d\\n\u0026#34;, *l) data := *(*int)(unsafe.Pointer(\u0026amp;str)) // 数据存储地址：0x103fb6b fmt.Printf(\u0026#34;数据存储地址：%#x\\n\u0026#34;, data) ts(str) // Output: // \u0026amp;str:0xc000036240 // 字符串长度:12 // 数据存储地址：0x9dfb6b // \u0026amp;s:0xc000036250 // 字符串长度:12 // 数据存储地址：0x9dfb6b } func ts(s string) { fmt.Printf(\u0026#34;\u0026amp;s:%#x\\n\u0026#34;, \u0026amp;s) l := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + unsafe.Sizeof(int(0)))) // 字符串长度:12 fmt.Printf(\u0026#34;字符串长度:%d\\n\u0026#34;, *l) data := *(*int)(unsafe.Pointer(\u0026amp;s)) // 数据存储地址：0x103fb6b fmt.Printf(\u0026#34;数据存储地址：%#x\\n\u0026#34;, data) } 1 2 3 4 5 6 7 8 9 10 11 func ts() { // 0xc00000a028 -\u0026gt; 0xc00001c0a8 -\u0026gt; 1 str1 := 1 // int str := \u0026amp;str1 // *int fmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;str) // 0xc00000a028 fmt.Printf(\u0026#34;%p\\n\u0026#34;, str) // 0xc00001c0a8 fmt.Printf(\u0026#34;%#v\\n\u0026#34;, uintptr(unsafe.Pointer(\u0026amp;str))) // 0xc00000a028 fmt.Printf(\u0026#34;%#v\\n\u0026#34;, (*uintptr)(unsafe.Pointer(\u0026amp;str))) // (*uintptr)(0xc00000a028) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, *(*uintptr)(unsafe.Pointer(\u0026amp;str))) // 0xc00001c0a8 } []byte与string []byte和string都可以表示字符串，它们数据结构不同，其衍生出来的方法也不同。 string擅长的场景： 需要字符串比较、不需要nil字符串。 []byte擅长的场景： 修改字符串的时候、函数返回值，需要使用nil来表示含义、需要切片操作。 str2 := str1 字符串间赋值会共用同一个底层数组？ 字符串间赋值，【会】共用同一个底层数组。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { var str1 = \u0026#34;hello\u0026#34; str2 := str1 // 同用了一个底层数组 // 因为字符串时只读类型，因此赋值共用同一个底层也没有问题。 fmt.Println(*(*stringStruct)(unsafe.Pointer(\u0026amp;str1))) // {15567553 5} fmt.Println(*(*stringStruct)(unsafe.Pointer(\u0026amp;str2))) // {15567553 5} }\ttype stringStruct struct { str uintptr len uintptr } s := []byte(str) 字符串强制转成[]byte是否共用同一个底层数组？ 【不会】同用一个底层数组。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { str := \u0026#34;hello\u0026#34; s := []byte(str) s[0] = \u0026#39;e\u0026#39; fmt.Println(str, s) // 探究字符串强制转换成切片底层数组是否发生变化 fmt.Printf(\u0026#34;字符串指向底层数组：%x\\n\u0026#34;, *(*uintptr)(unsafe.Pointer(\u0026amp;str))) fmt.Printf(\u0026#34;str[0]:%c\\n\u0026#34;, *(*byte)(unsafe.Pointer(uintptr(unsafe.Pointer(nil)) + *(*uintptr)(unsafe.Pointer(\u0026amp;str))))) fmt.Printf(\u0026#34;切片指向的底层数组：%x\\n\u0026#34;, *(*uintptr)(unsafe.Pointer(\u0026amp;s))) fmt.Printf(\u0026#34;切片s[0]地址：%p\\n\u0026#34;, \u0026amp;s[0]) // Output: // hello [101 101 108 108 111] // 字符串指向底层数组：12e9c2 // str[0]:h // 切片指向的底层数组：c00000e0b0 // 切片s[0]地址：0xc00000e0b0 } string 转 []byte 1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func main() { s := \u0026#34;hello Go语言\u0026#34; // 下面代码可以看出，s和b并【没有】共用同一个底层数组 b := []byte(s) // 这里会调用 runtime.stringtoslicebyte 函数 fmt.Println(b) } stringtoslicebyte() string转slice byte，string -\u0026gt; []byte。 参数： buf *tmpBuf：type tmpBuf [32]byte，[32]byte数组用于转换大小在32字节的临时存储转换容器。上一章的\u0026quot;修改字符串\u0026quot;节string转[]byte后cap值为32就是这个参数的原因。 s string：转换字符串。 返回值： []byte：转换后的slice byte。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 func stringtoslicebyte(buf *tmpBuf, s string) []byte { var b []byte // nil // tmpBuf 容量够 s 的本次转换 if buf != nil \u0026amp;\u0026amp; len(s) \u0026lt;= len(buf) { // 这里也就是 []byte(string) 没用共用一个底层数组的原因所在 *buf = tmpBuf{} // 清空 并 初始化新的容量 {0xxxx, 0, 32} b = buf[:len(s)]\t} else { // 容器大小不够，需要重新申请大小 b = rawbyteslice(len(s)) } // copy([]byte, string) int copy(b, s) // 拷贝字符串中的数据 return b } rawbyteslice() rawbyteslice分配一个新的byte slice。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // rawbyteslice allocates a new byte slice. The byte slice is not zeroed. func rawbyteslice(size int) (b []byte) { // 因为是 byte 所以直接传 size 大小即可，匹配最近接的内存块规格大小 cap := roundupsize(uintptr(size)) // 调整size大小 // 这里是 []byte(string) 没用共用一个底层数组的原因所在 p := mallocgc(cap, nil, false) // 申请cap大小内存，p是申请后的内存地址 if cap != uintptr(size) { // 清零多余的这部分内存块 memclrNoHeapPointers(add(p, uintptr(size)), cap-uintptr(size)) } // 将申请的大小赋值个返回值b *(*slice)(unsafe.Pointer(\u0026amp;b)) = slice{p, size, int(cap)} return } []byte 转 string 1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func main() { b := []byte{\u0026#39;h\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;} // 下面源码可以看出，b和s并【没有】共用同一个底层数组 s := string(b) // 这里会调用 runtime.slicebytetostring 函数 fmt.Println(s) } slicebytetostring() slicebytetostring将字节切片转换为字符串，string([]byte)。 它由编译器插入到生成的代码中。 ptr是一个指针，指向切片的第一个元素; n是切片的长度。 buf是一个固定大小的缓冲区，如果结果没有escape转义字符，它就不是nil。 参数： buf *tmpBuf：type tmpBuf [32]byte，[32]byte数组 用于转换大小在32字节的临时存储转换容器。 ptr *byte：[]byte切片的底层数组地址，也就是slice.data的值。 n int：切片的长度，也就是slice.len的值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // slicebytetostring converts a byte slice to a string. // It is inserted by the compiler into generated code. // ptr is a pointer to the first element of the slice; // n is the length of the slice. // Buf is a fixed-size buffer for the result, // it is not nil if the result does not escape. func slicebytetostring(buf *tmpBuf, ptr *byte, n int) (str string) { // 没有需要转换的 if n == 0 { // Turns out to be a relatively common case. // Consider that you want to parse out data between parens in \u0026#34;foo()bar\u0026#34;, // you find the indices and convert the subslice to string. return \u0026#34;\u0026#34; } if raceenabled { racereadrangepc(unsafe.Pointer(ptr), uintptr(n), getcallerpc(), abi.FuncPCABIInternal(slicebytetostring)) } if msanenabled { msanread(unsafe.Pointer(ptr), uintptr(n)) } if asanenabled { asanread(unsafe.Pointer(ptr), uintptr(n)) } // 当[]byte 只有一个字符时 if n == 1 {\t// staticuint64s是一个[256]uint64的数组，也就是ASCII的数组数组 // 这里可以看出并不是用的同一个底层数组。 p := unsafe.Pointer(\u0026amp;staticuint64s[*ptr])\tif goarch.BigEndian {\t// 某些平台需要字节对齐 p = add(p, 7) } stringStructOf(\u0026amp;str).str = p // 赋值给字符串的str stringStructOf(\u0026amp;str).len = 1 // 赋值给字符串的len return } var p unsafe.Pointer if buf != nil \u0026amp;\u0026amp; n \u0026lt;= len(buf) { // 当长度在32范围内时 p = unsafe.Pointer(buf)\t// 直接使用buf的容量当做地址 } else { p = mallocgc(uintptr(n), nil, false) // 申请n大小的内存地址备用 } stringStructOf(\u0026amp;str).str = p stringStructOf(\u0026amp;str).len = n memmove(p, unsafe.Pointer(ptr), uintptr(n)) // 将ptr地址长度为n字节的内容移动到p中 return } 1 2 3 4 5 6 7 8 type stringStruct struct { str unsafe.Pointer len int } func stringStructOf(sp *string) *stringStruct { return (*stringStruct)(unsafe.Pointer(sp)) } string 转 []rune 1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func main() { s := \u0026#34;hello Go语言\u0026#34; // 下面代码可以看出，s和b并【没有】共用同一个底层数组 b := []rune(s) // 这里会调用 runtime.stringtoslicerune 函数 fmt.Println(b) } stringtoslicerune() string转slice rune，[]rune(string)。 参数： buf *[tmpStringBufSize]rune：*[32]rune 32位缓存rune。 s string：目标字符串。 返回值： []rune：转换后的切片。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // string to slice rune func stringtoslicerune(buf *[tmpStringBufSize]rune, s string) []rune { // two passes. // unlike slicerunetostring, no race because strings are immutable. n := 0 for range s { // 遍历s统计rune的总量 n++ } var a []rune if buf != nil \u0026amp;\u0026amp; n \u0026lt;= len(buf) { // 满足32字节 *buf = [tmpStringBufSize]rune{} a = buf[:n] } else { a = rawruneslice(n) // 向系统申请n大小的内存 } n = 0 for _, r := range s { // 通过遍历将s存储到a中 a[n] = r n++ } return a } rawruneslice() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // rawruneslice allocates a new rune slice. The rune slice is not zeroed. func rawruneslice(size int) (b []rune) { if uintptr(size) \u0026gt; maxAlloc/4 { // 内存溢出情景 throw(\u0026#34;out of memory\u0026#34;) } // rune = int32 占4字节，匹配最接近的内存块 mem := roundupsize(uintptr(size) * 4) // 这里是没有使用同一个地址的原因 // 向系统申请内存的大小是直接，而size表示的字符的个数，所以这里是需要乘以4的 p := mallocgc(mem, nil, false)\tif mem != uintptr(size)*4 { memclrNoHeapPointers(add(p, uintptr(size)*4), mem-uintptr(size)*4) // 清零未使用的那部分内存块 } *(*slice)(unsafe.Pointer(\u0026amp;b)) = slice{p, size, int(mem / 4)} // 申请后的赋值返回 return } []rune 转 string 1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func main() { b := []rune{104, 101, 108, 108, 111, 32, 71, 111, 35821, 35328} // 下面源码可以看出，b和s并【没有】共用同一个底层数组 s := string(b) // 这里会调用 runtime.slicerunetostring 函数 fmt.Println(s) } slicerunetostring() slice rune 转 string，string([]rune)。 参数： buf *tmpBuf：type tmpBuf [32]byte，[32]byte数组用于转换大小在32字节的临时存储转换容器。 a []rune：转换的切片。 返回值： string：转换后的字符串。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // slice rune to string func slicerunetostring(buf *tmpBuf, a []rune) string { if raceenabled \u0026amp;\u0026amp; len(a) \u0026gt; 0 { racereadrangepc(unsafe.Pointer(\u0026amp;a[0]), uintptr(len(a))*unsafe.Sizeof(a[0]), getcallerpc(), abi.FuncPCABIInternal(slicerunetostring)) } if msanenabled \u0026amp;\u0026amp; len(a) \u0026gt; 0 { msanread(unsafe.Pointer(\u0026amp;a[0]), uintptr(len(a))*unsafe.Sizeof(a[0])) } if asanenabled \u0026amp;\u0026amp; len(a) \u0026gt; 0 { asanread(unsafe.Pointer(\u0026amp;a[0]), uintptr(len(a))*unsafe.Sizeof(a[0])) } var dum [4]byte // 临时容器 // 记录[]rune切片转string需要的总字节数量 byte size1 := 0\tfor _, r := range a { // 【int rune】 // encoderune 函数解码r并把值存入第一个参数中，返回解码的字节数量 size1 += encoderune(dum[:], r)\t} // 返回一个s和b底层数组相关联的，这里size1+3是为了兼容最后一个是ASCII情况 s, b := rawstringtmp(buf, size1+3)\tsize2 := 0\t// 统计数量 for _, r := range a { // check for race // 可能存在 []rune 中 \u0026#39;\u0026#39; 这种数据 if size2 \u0026gt;= size1 { break } // 也就是这里实现了将数据写入字符串地址中，因为切片和字符串共用同一个底层数组 // encoderune该函数的作用是将r解码并存入第一个参数位置，并返回r的编码字节长度 size2 += encoderune(b[size2:], r)\t} return s[:size2] // 切割字符串s得到的依然是字符串类型 } rawstringtmp() 1 2 3 4 5 6 7 8 9 10 // 返回一个s和b共用同一个底层数组 func rawstringtmp(buf *tmpBuf, l int) (s string, b []byte) { if buf != nil \u0026amp;\u0026amp; l \u0026lt;= len(buf) { // 如果满足32字节内 b = buf[:l] s = slicebytetostringtmp(\u0026amp;b[0], len(b)) // 处理s和b的关联关系 } else { s, b = rawstring(l) // 从新申请一块内存 关联s和b的底层数组关联关系 } return } slicebytetostringtmp() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // slicebytetostringtmp returns a \u0026#34;string\u0026#34; referring to the actual []byte bytes. // // Callers need to ensure that the returned string will not be used after // the calling goroutine modifies the original slice or synchronizes with // another goroutine. // // The function is only called when instrumenting // and otherwise intrinsified by the compiler. // // Some internal compiler optimizations use this function. // - Used for m[T1{... Tn{..., string(k), ...} ...}] and m[string(k)] // where k is []byte, T1 to Tn is a nesting of struct and array literals. // - Used for \u0026#34;\u0026lt;\u0026#34;+string(b)+\u0026#34;\u0026gt;\u0026#34; concatenation where b is []byte. // - Used for string(b)==\u0026#34;foo\u0026#34; comparison where b is []byte. func slicebytetostringtmp(ptr *byte, n int) (str string) { if raceenabled \u0026amp;\u0026amp; n \u0026gt; 0 { racereadrangepc(unsafe.Pointer(ptr), uintptr(n), getcallerpc(), abi.FuncPCABIInternal(slicebytetostringtmp)) } if msanenabled \u0026amp;\u0026amp; n \u0026gt; 0 { msanread(unsafe.Pointer(ptr), uintptr(n)) } if asanenabled \u0026amp;\u0026amp; n \u0026gt; 0 { asanread(unsafe.Pointer(ptr), uintptr(n)) } // 通过参数返回一个ptr和返回str相关联的底层数组 stringStructOf(\u0026amp;str).str = unsafe.Pointer(ptr)\tstringStructOf(\u0026amp;str).len = n return } rawstring() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // rawstring allocates storage for a new string. The returned // string and byte slice both refer to the same storage. // The storage is not zeroed. Callers should use // b to set the string contents and then drop b. func rawstring(size int) (s string, b []byte) { // 向系统申请内存 p := mallocgc(uintptr(size), nil, false) stringStructOf(\u0026amp;s).str = p stringStructOf(\u0026amp;s).len = size *(*slice)(unsafe.Pointer(\u0026amp;b)) = slice{p, size, size} return } string -\u0026gt; string[:] 这种情况下没有新申请内存，而是【共用】的之前的内存。 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;fmt\u0026#34; func main() { s := \u0026#34;hello Go语言\u0026#34; // 字符串使用切片生成的依然是字符串类型，同用一个底层数据。 // 下面我们来分析下main.main的汇编码 看看这一行是如何操作的 s1 := s[:] fmt.Println(s1) // s1的类型为string } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # s1 := s[:] 情况 # 比较栈是否溢出 r14存储的当前groutine string.go:5\t0x496680 493b6610 cmp rsp, qword ptr [r14+0x10]\tstring.go:5\t0x496684 0f86b9000000 jbe 0x496743 # 给main.main函数栈预分配0x78大小 string.go:5\t0x49668a 4883ec78 sub rsp, 0x78\t# 将runtime.main函数的栈基址rsp入栈，以便main.main执行完好恢复 string.go:5\t0x49668e 48896c2470 mov qword ptr [rsp+0x70], rbp\t# 将rbp指向main.main的新栈基位置，表示main.main的栈信息范围 string.go:5\t0x496693 488d6c2470 lea rbp, ptr [rsp+0x70]\t# 该操作等于将字符串s的底层数组地址放入rcx string.go:6\t0x496698 488d0de87c0100 lea rcx, ptr [rip+0x17ce8]\t# 则部操作为给s.str赋值。s.data=rip+0x17ce8 string.go:6\t0x49669f 48894c2438 mov qword ptr [rsp+0x38], rcx # 该操作为给s.len赋值，标明字符串长度大小。s.len=14 string.go:6\t0x4966a4 48c74424400e000000 mov qword ptr [rsp+0x40], 0xe\t# 以下两行是第9行代码 s1 := s[:]\t# 可以看见是公共用的同一个底层数组。 string.go:9\t0x4966ad 48894c2428 mov qword ptr [rsp+0x28], rcx\tstring.go:9\t0x4966b2 48c74424300e000000 mov qword ptr [rsp+0x30], 0xe 修改第10行s1 := s[:]为s1 := s[:5]。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # s1 := s[:5] 情况 string.go:5\t0x496680 493b6610 cmp rsp, qword ptr [r14+0x10] string.go:5\t0x496684 0f86c6000000 jbe 0x496750 string.go:5\t0x49668a 4883ec78 sub rsp, 0x78 string.go:5\t0x49668e 48896c2470 mov qword ptr [rsp+0x70], rbp string.go:5\t0x496693 488d6c2470 lea rbp, ptr [rsp+0x70] # 这里几行给s赋值 string.go:6\t0x496698 488d0de87c0100 lea rcx, ptr [rip+0x17ce8]\tstring.go:6\t0x49669f 48894c2438 mov qword ptr [rsp+0x38], rcx string.go:6\t0x4966a4 48c74424400e000000 mov qword ptr [rsp+0x40], 0xe string.go:9\t0x4966ad eb00 jmp 0x4966af string.go:9\t0x4966af eb00 jmp 0x4966b1 # 这几行s[:5]，为什么这里的rip+0x17ccf和上面的rip+0x17ce8不一致？ # 原因是Go采用的地址加偏移量的形式，这里与前面的差量所以偏移量有所变化 # 还有个原因是编译阶段的字符串是被存储在代码段的，所以通过这种形式， # 如果是被存储在栈或堆上呢，栈则是rsp+偏移量的形式 string.go:9\t0x4966b1 488d0dcf7c0100 lea rcx, ptr [rip+0x17ccf]\tstring.go:9\t0x4966b8 48894c2428 mov qword ptr [rsp+0x28], rcx string.go:9\t0x4966bd 48c744243005000000 mov qword ptr [rsp+0x30], 0x5 # 更多s1 := s[2:5]基本和上面情况差不多 注意 不要命名标识符和包名称一样，这样会导致引用包名称时需要添加特殊别名称，比如命名函数名称bytes()和bytes包一致，导致bytes包需要别名称bytes2 \u0026quot;bytes\u0026quot;。 参考 字符串内存布局 字符串内存布局 字符串内存 unicode、utf8、utf16、utf32 ","permalink":"https://heliu.site/posts/golang/basic/string-memory/","summary":"Golang 介绍字符串的内存结构。","title":"字符串(内存布局)"},{"content":"+字符串拼接 golang中使用+拼接字符串会调用concatstringX()相关函数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // a0 + a1 func concatstring2(buf *tmpBuf, a0, a1 string) string { return concatstrings(buf, []string{a0, a1}) } // a0 + a1 + a2 func concatstring3(buf *tmpBuf, a0, a1, a2 string) string { return concatstrings(buf, []string{a0, a1, a2}) } // a0 + a1 + a2 + a3 func concatstring4(buf *tmpBuf, a0, a1, a2, a3 string) string { return concatstrings(buf, []string{a0, a1, a2, a3}) } // a0 + a1 + a2 + a3 + a4 func concatstring5(buf *tmpBuf, a0, a1, a2, a3, a4 string) string { return concatstrings(buf, []string{a0, a1, a2, a3, a4}) } const 1 2 3 4 5 6 // The constant is known to the compiler. // There is no fundamental theory behind this number. // // 该常量是编译器已知的 // 这个数字背后没有基本理论 const tmpStringBufSize = 32 type 1 2 // 当要拼接的字符串长度小于等于32字节大小，使用该临时缓存容器，否则重新生成一个内存空间使用 type tmpBuf [tmpStringBufSize]byte\t// tmpBuf只是用于定义一个*[32]byte的缓冲 concatstrings() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 // concatstrings implements a Go string concatenation x+y+z+... // The operands are passed in the slice a. // If buf != nil, the compiler has determined that the result does not // escape the calling function, so the string data can be stored in buf // if small enough. // // concatstrings 实现了一个 Go 字符串连接 x+y+z+... 操作数在切片 a 中传递 // 如果 buf != nil，编译器已经确定结果不会转义调用函数，所以如果足够小，字符串数据可以存储在 buf 中 func concatstrings(buf *tmpBuf, a []string) string { idx := 0 // 记录a中最后一个不为空的下标索引值 l := 0 // 统计a切片中所有字符串元素的字节数量，该值主要用于统计拼接总大小用于确定内存 count := 0 // 统计a切片中有效的元素数量，不为空的字符串 for i, x := range a { n := len(x) // 获取字符串长度字节 if n == 0 { continue } // 该情况发生在字符串数量太长导致int类型溢出情况 if l+n \u0026lt; l {\tthrow(\u0026#34;string concatenation too long\u0026#34;) } l += n // 加上当前字符串的长度，记录的是所有的字节B数量 count++ // 切片a中所有有效的的字符串，也就是不是空串的字符串数量 idx = i // 记录最有一个有效的字符串的索引下标数 } if count == 0 { return \u0026#34;\u0026#34; } // If there is just one string and either it is not on the stack // or our result does not escape the calling frame (buf != nil), // then we can return that string directly. // // 如果只有一个字符串并且它不在堆栈上，或者我们的结果没有转义调用帧（buf！= nil），那么我们可以直接返回该字符串 // !stringDataOnStack(a[idx]) 如果为true表示当前a[idx]不在当前goroutine的运行栈中，那么表示可以返回 // 因为goroutine的栈会在g被运行完销毁，所以不适合直接返回 // a[idx]在goroutine栈上时，继续去下面 rawstringtmp if count == 1 \u0026amp;\u0026amp; (buf != nil || !stringDataOnStack(a[idx])) { return a[idx] // 如果count为1那么 idx存储的就是这个唯一的有效的字符串索引值 } // s与b是长度为l的底层数组相互关联的，这所以这样是字符串是不可变类型我们需要通过切片处理 s, b := rawstringtmp(buf, l)\t// 把来自a的字符串拷贝到b中，也就是拷贝到s中 for _, x := range a { // 拷贝x到b\t// int copy([]byte, string) // 这一步操作是因为copy函数的拷贝机制 copy(b, x)\tb = b[len(x):]\t} return s // s则是拼接后的字符串 } stringDataOnStack() 1 2 3 4 5 6 7 8 9 // stringDataOnStack reports whether the string\u0026#39;s data is // stored on the current goroutine\u0026#39;s stack. // // stringDataOnStack 报告字符串的数据是否存储在当前 goroutine 的堆栈中 func stringDataOnStack(s string) bool { ptr := uintptr(stringStructOf(\u0026amp;s).str) // ptr获取是字符串的底层值 stk := getg().stack\t// stk是当前正在运行的goroutine的栈顶和栈底范围 return stk.lo \u0026lt;= ptr \u0026amp;\u0026amp; ptr \u0026lt; stk.hi // 判断当前字符串是否在这个范围内 } stringStructOf() 1 2 3 4 5 6 7 8 9 func stringStructOf(sp *string) *stringStruct { /* type stringStruct struct { str unsafe.Pointer len int } */ return (*stringStruct)(unsafe.Pointer(sp)) } rawstringtmp() 1 2 3 4 5 6 7 8 9 10 11 // s和b都分别指向buf，并且长度为l func rawstringtmp(buf *tmpBuf, l int) (s string, b []byte) { // 当前要处理的长度l在buf的范围内 if buf != nil \u0026amp;\u0026amp; l \u0026lt;= len(buf) { b = buf[:l] // buf是数字指针，因此b是切片引用buf s = slicebytetostringtmp(\u0026amp;b[0], len(b)) // 将buf与s关联起来 } else { s, b = rawstring(l) // 重新分配内存，把s和b关联起来 } return } slicebytetostringtmp() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // slicebytetostringtmp returns a \u0026#34;string\u0026#34; referring to the actual []byte bytes. // // Callers need to ensure that the returned string will not be used after // the calling goroutine modifies the original slice or synchronizes with // another goroutine. // // The function is only called when instrumenting // and otherwise intrinsified by the compiler. // // Some internal compiler optimizations use this function. // - Used for m[T1{... Tn{..., string(k), ...} ...}] and m[string(k)] // where k is []byte, T1 to Tn is a nesting of struct and array literals. // - Used for \u0026#34;\u0026lt;\u0026#34;+string(b)+\u0026#34;\u0026gt;\u0026#34; concatenation where b is []byte. // - Used for string(b)==\u0026#34;foo\u0026#34; comparison where b is []byte. func slicebytetostringtmp(ptr *byte, n int) (str string) { if raceenabled \u0026amp;\u0026amp; n \u0026gt; 0 { racereadrangepc(unsafe.Pointer(ptr), uintptr(n), getcallerpc(), abi.FuncPCABIInternal(slicebytetostringtmp)) } if msanenabled \u0026amp;\u0026amp; n \u0026gt; 0 { msanread(unsafe.Pointer(ptr), uintptr(n)) } if asanenabled \u0026amp;\u0026amp; n \u0026gt; 0 { asanread(unsafe.Pointer(ptr), uintptr(n)) } // 使str指向ptr，长度为n stringStructOf(\u0026amp;str).str = unsafe.Pointer(ptr) stringStructOf(\u0026amp;str).len = n return } rawstring() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // rawstring allocates storage for a new string. The returned // string and byte slice both refer to the same storage. // The storage is not zeroed. Callers should use // b to set the string contents and then drop b. func rawstring(size int) (s string, b []byte) { p := mallocgc(uintptr(size), nil, false)\t// 重新申请内存 // 关联s和b stringStructOf(\u0026amp;s).str = p stringStructOf(\u0026amp;s).len = size *(*slice)(unsafe.Pointer(\u0026amp;b)) = slice{p, size, size} return } ","permalink":"https://heliu.site/posts/golang/basic/string-splice/","summary":"Golang +拼接介绍。","title":"字符串(+拼接)"},{"content":"数据结构及类型结构 数据结构及类型结构组成图：（关于类型构成详细后面文章介绍） 数据结构 数据结构记录字符串记录的内存数据相关信息。比如【字符串的内容】以及【字符串的长度】。 String.data：是一个指针，指向一个byte类型数组的首地址。 String.len：记录当前字符串的长度，以字节为单位。 1 2 3 4 type String struct { data unsafe.Pointer len int } 类型结构 类型结构记录字符串类型相关信息。比如字符串【占用内存大小】【包含指针数量】【字段对齐】等信息。 _type：记录类型原数据结构，用于表示所有类型共有的属性结构。 关于_type的具体含义在相关章节列出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type u struct { _type } type _type struct { size uintptr ptrdata uintptr hash uint32 tflag tflag align uint8 fieldAlign uint8 kind uint8 equal func(unsafe.Pointer, unsafe.Pointer) bool gcdata *byte str nameOff ptrToThis typeOff } ","permalink":"https://heliu.site/posts/golang/basic/string-type/","summary":"Golang 字符串的类型结构介绍。","title":"字符串(类型结构)"},{"content":"if语句 if语句后紧跟一个或多个语句组成，注意布尔表达式不能用0或1。 如果表达式求值为true，则执行\u0026quot;if\u0026quot;分支，否则执行\u0026quot;else\u0026quot;分支。 GoLang不支持三目运算 a \u0026gt; b ? a : b，官方的解释是三目运算会导致复杂的表达式。 1 2 3 4 5 6 7 8 // 1) if expr { } //\tOR // 2) if Init; expr { } if 布尔表达式 {\t// 布尔表达式为true时执行 } else { // 布尔表达式为false时执行 } 由于if和switch都接受初始化语句，因此通常会看到用于设置局部变量的语句。 该语句在计算表达式之前执行。 if和else if后都可以跟【Init; expr】语句。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 这里注意，这里使用的是 ; 不是 , // 1. ;分号：用于分隔语句 // 2. ,逗号：常用语分隔变量多返回赋值形式 if x := 1; x \u0026lt; 10 { fmt.Println(\u0026#34;12345\u0026#34;) } else if x \u0026gt; 0 { // else if x = 2; x \u0026gt; 0 {} fmt.Println(\u0026#34;6789\u0026#34;) } else { fmt.Println(\u0026#34;147258369\u0026#34;) } // be equivalent to // 注意：xx 的作用域，当前分支以后都适用 { xx := 1 if xx \u0026lt; 10 { fmt.Println(\u0026#34;12345\u0026#34;) } else { if xx \u0026gt; 0 { fmt.Println(\u0026#34;6789\u0026#34;) } else { fmt.Println(\u0026#34;147258369\u0026#34;) } } } // else if 全部都可以转换成if else形式，这里是为了更好的理解初始化语句所在块位置 // Output: // 12345 // 12345 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func Ts() { rand.Seed(time.Now().UnixNano()) n := rand.Intn(100) // 1. 验证 if Init; expr {} 语句 // 2. 验证 else if Init; expr {} 语句 if x := 2; x+n \u0026gt; 5 { print(x) // 2 } else if x = 1; x-n \u0026gt; 2 { print(x) // 1 } else if n == 2 { print(x) // 1 } else { print(x) // 1 } } 当if语句没有进入下一个语句，即正文以break、continue、goto或return结尾时，省略不必要的else。 1 2 3 4 f, err := os.Open(name) if err != nil { return err } break语句 一个break的作用范围为该语句出现的最内部的结构，它可以用于任何形式的for循环。 在switch或select语句中，break语句的作用是跳过整个代码块，继续执行switch或select外后续的代码。 语句中如果有标签，则必须是包含for、switch或select语句的标签。并且该标签是可以执行终止的。 break两个作用： 针对for关键字结束循环。 针对switch、select关键字跳出整个代码块。但switch和select的case后是默认自带break，如果显示写上也只是跳出switch和select块。 break在switch中可以作为if分支结束条件。 1 2 3 4 5 6 7 switch { case true: if true { break\t// 比如这里，退出case分支 } // 其他代码 ... } 因此在switch或select块中使用break关键字只能跳出【当前】switch或select块。如果想跳出外层for循环则需要break Label加上标签名称。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package main import ( \u0026#34;fmt\u0026#34; ) func main() { fmt.Println(\u0026#34;start\u0026#34;) OuterLoop:\t// 定义标签 for i := 0; i \u0026lt; 3; i++ { fmt.Println(\u0026#34;i 循环：\u0026#34;, i) for j := 0; j \u0026lt; 3; j++ { fmt.Println(\u0026#34;j 循环：\u0026#34;, j) // switch和select默认是自带break的 switch j { case 0: fmt.Println(\u0026#34;break\u0026#34;) break // break 只是跳出switch语句块，不会跳出到for块 case 2: fmt.Println(\u0026#34;2 OuterLoop\u0026#34;) // switch默认带有break语句，这里指明break语句要跳出的标签位置 break OuterLoop // 直接跳出整个循环 } fmt.Println(\u0026#34;switch:\u0026#34;, j) } } fmt.Println(\u0026#34;end\u0026#34;) // Output: // start // i 循环： 0 // j 循环： 0 // break // switch: 0 // j 循环： 1 // switch: 1 // j 循环： 2 // 2 OuterLoop // end } 注意break label; label(标签)只能是之前出现的，continue关键字也是。但是goto关键字却可以跳转到后面的标签处。 continue语句 关键字continue用在关键字for（结束本次循环，继续下次循环），但不是无条件执行下一次循环，执行之前依旧需要满足循环的判断条件。 如果有一个标签，那么它必须是一个封闭的for语句，并且是当前执行进程的标签。 1 2 3 4 5 6 7 8 9 RowLoop: for y, row := range rows { for x, data := range row { if data == endOfRow { continue RowLoop } row[x] = data + bias(x, y) } } 使用示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func main() { rows := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} rowLoop: for _, row := range rows { for _, data := range row { if data == \u0026#39;l\u0026#39; { // continue 用于结束本次循环，进行下一次循环 continue rowLoop } fmt.Printf(\u0026#34;%c\\n\u0026#34;, data) } } // Output: // h // e // w // o // r } 标签 for、switch、select语句都可以配合标签（label）形式的标识符使用。标签可以在代码的任何地方（函数体内）。 即某一行第一个可以冒号（:）结尾的单词（Gofmt 会将后续代码自动移至下一行） 标签的名称是大小写敏感的，为了提升可读性（可以首字母大小，可读性比较高就行）。 1 2 ERROR: // Error or err log.Panic(\u0026#34;error\u0026#34;)\t// 标签后的代码 标签用于break、continue、goto语句，定义从未使用的标签是非法的，不能编译成功。（定义了标签一定要使用） goto语句 goto语句是跳转到具体有相同函数内相应标签的语句。（结合标签使用，通常用在一些公共代码部分或循环逻辑处） 1 goto ERROR Go语言不鼓励多层嵌套使用标签和goto语句，因为它们会导致非常糟糕的程序设计，而且总有更加可读的替代方案来实现相同得需求。 块外的goto语句不能跳转到该块内的标签。（只能平级跳或跳出到外层块） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 以下代码不能通过编译 package main import \u0026#34;fmt\u0026#34; var x int = 10 func main() { if x % 2 == 1 { goto L1 // L1标签在块内 } for x \u0026lt; 10 { x-- fmt.Println(x) L1: // 在for内部 x-- fmt.Println(x) } } goto语句是可以跳转到后面出现的标签的，前提是满足块外的goto语句不能跳转到块内的标签。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;fmt\u0026#34; ) var x = 10 func main() { goto TL // 向后跳转到TL处，这种比较少用，因为接下面的代码永久不会执行 fmt.Println(x) // 这行代码不会执行 TL: fmt.Println(\u0026#34;TL\u0026#34;) // Output: // TL } goto多用于跳转到前面代码的标签处，这样就形成了循环。 总结 goto、break、continue：三个语句都可以配合标签(label)使用。 标签名区分大小写，定义后若不使用会造成编译错误。 continue、break配合标签(label)可用于多层循环跳出。 goto是调整执行位置，与continue、break配合标签(label)的结果并不相同。 ","permalink":"https://heliu.site/posts/golang/process/if/","summary":"Golang if、break、contine、goto介绍。","title":"流程控制(条件语句)"},{"content":"for计数器迭代 1 for 初始化语句; 条件语句; 修饰语句 {} 由三部分组成循环的头部，相互之间使用英文分号（;）隔开，但并不需要括号将它们括起来。 区别其他语言形式如【for (初始化语句; 条件语句; 修饰语句) {} 】其实使用括号包起来也可以。 同时使用多个计数器 这得益于Go语言具有平行赋值的特性。 区别总结： for关键字后面不需要括号。 初始化语句和修饰语句可以使用平行赋值的特性。 1 2 3 4 // 注意这里的 【初始化语句】 和 【修饰语句】 // 初始化语句：i, j := 0, N // 修饰语句：i, j = i+1, j-1 for i, j := 0, N; i \u0026lt; j; i, j = i+1, j-1 {} for{} 可以认为这是没有【初始化语句】和【修饰语句】的for结构，因此;;便是多余的了。 即使是条件语句也可以省略，如【i: = 0; ;i++】或【for {} 或 for ;; {}】多余的;;会在使用时移除，这些循环的本质就是无限循环。 也可以写成【for true {}】一般都是直接写成【for {}】。 如果for循环的头部没有条件语句，默认为true和switch没有表达式类似默认为true。 一般Go处理类似情况的常用法则，因此循环体内必须有相关的条件判断以确保会在某个时刻退出循环。 区别总结： 【for {}】我们可以理解为【for 条件语句 {}】这种形式，省略了初始化语句和修饰语句，与其他语言【while (true) {}】用法类似。 1 for {} // 等价于 for true {} 使用示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 创建[]int切片 a := []int{1,2,3,4,5,6} // 交换切片首尾数据 for i,j := 0,len(a)-1; i \u0026lt; j; i,j = i+1,j-1 { a[i], a[j] = a[j], a[i] } fmt.Println(a) // [6 5 4 3 2 1] // 多重循环满足条件退出 for j := 0; j \u0026lt; 5; j++ { for i := 0; i \u0026lt; 10; i++ { if i \u0026gt; 5 { break } fmt.Printf(\u0026#34;%d \u0026#34;, i) } fmt.Println() } // Output: // [6 5 4 3 2 1] // 0 1 2 3 4 5 // 0 1 2 3 4 5 // 0 1 2 3 4 5 // 0 1 2 3 4 5 // 0 1 2 3 4 5 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 s := \u0026#34;abc\u0026#34; // 1) 常见的 for 循环，支持初始化语句 for i,n := 0,len(s); i \u0026lt; n; i++ { fmt.Printf(\u0026#34;%c\\n\u0026#34;, s[i]) } // Output: // a // b // c n := len(s) // 2) 替代 while (n \u0026gt; 0) {} for n \u0026gt; 0 { fmt.Println(s[n-1]) n-- } // Output: // 99 // 98 // 97 // 3) 替换 while (true) {} 或 for (;;) {} for { fmt.Println(s) } // Output: // abc // ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package main import \u0026#34;fmt\u0026#34; func main() { var b int = 15 var a int // [1, 2, 3, 5, 0, 0] numbers := [6]int{1, 2, 3, 5} // 1) for 循环 for a := 0; a \u0026lt; 10; a++ { fmt.Printf(\u0026#34;a 的值为：%d\\n\u0026#34;, a) } // 2) for true for a \u0026lt; b { a++ fmt.Printf(\u0026#34;a 的值为：%d\\n\u0026#34;, a) } // 3) for range for i, x := range numbers { fmt.Printf(\u0026#34;第 %d 位 x 的值 = %d\\n\u0026#34;, i, x) } // Output: // a 的值为：0 // a 的值为：1 // a 的值为：2 // a 的值为：3 // a 的值为：4 // a 的值为：5 // a 的值为：6 // a 的值为：7 // a 的值为：8 // a 的值为：9 // a 的值为：1 // a 的值为：2 // a 的值为：3 // a 的值为：4 // a 的值为：5 // a 的值为：6 // a 的值为：7 // a 的值为：8 // a 的值为：9 // a 的值为：10 // a 的值为：11 // a 的值为：12 // a 的值为：13 // a 的值为：14 // a 的值为：15 // 第 0 位 x 的值 = 1 // 第 1 位 x 的值 = 2 // 第 2 位 x 的值 = 3 // 第 3 位 x 的值 = 5 // 第 4 位 x 的值 = 0 // 第 5 位 x 的值 = 0 } 判断一个数是否是质数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; ) func main() { for i := uint64(2) ; i \u0026lt; 100; i++ { if isPrime(i) { fmt.Printf(\u0026#34;%d 是素数\\n\u0026#34;, i) } } } // isPrime 判断num是否是素数(质数) 素数只能被1和本身整除 func isPrime(num uint64) bool { // 假设A是条件，B是结论 // 由A可以推出B，由B可以推出A，则A是B的 (充要条件) // 由A可以推出B，由B不可以推出A，则A是B的 (充分不必要条件) // 由A不可以推出B，由B可以推出A，则A是B的 (必要不充分条件) // 由A不可以推出B，由B不可以推出A，则A是B的 (既不充分也不必要条件) // 大于等于5的质数一定和6的倍数相邻 (充分不必要条件) // 与6的倍数相邻的数不一定是大于等于5的质数 // 证明：(n \u0026gt;= 1, n属于自然数) // 6n + 0\t=\u0026gt; 2*3*n\t=\u0026gt; 合数 // 6n + 1 -----\u0026gt; 可能是素数(7)，也可能是合数(25) // 6n + 2\t=\u0026gt; 2*(3n+1)\t=\u0026gt; 合数 // 6n + 3\t=\u0026gt; 3*(2n+1)\t=\u0026gt; 合数 // 6n + 4\t=\u0026gt; 2*(3n+2)\t=\u0026gt; 合数 // 6n + 5 -----\u0026gt; 可能是素数(11)，也可能是合数(35) // 上面的列表能表示所有\u0026gt;=5的自然数，因此大于等于5的质数一定和6的倍数相邻 // 5以下的质数分别为 2和3 if num == 2 || num == 3 { return true } // 大于等于5的质数一定和6的倍数相邻，相反不在6的倍数两侧的一定是合数 // 这里排除了所有被2和3整除的合数，因此后面的for循环只需验证是否能被其他质数整除即可 if num % 6 != 1 \u0026amp;\u0026amp; num % 6 != 5 { return false } // 一个数能进行因式分解，那么分解时得到的两个数 // 一定是一个小于等于 sqrt(n) 和 一个大于等于 sqrt(n) // 故遍历循环的次数就是sqrt(n)向上取整次数 tmp := uint64(math.Ceil(math.Sqrt(float64(num)))) // 与6的倍数相邻的数不一定是大于等于5的质数(质数) var i uint64 = 5 // 这里i表示第一个素数5 // 这里的i += 6包含所有当前num因式分解的所有公因式，也就是所有的素数 for ; i \u0026lt;= tmp; i += 6 { // i 和 i + 2 是6的倍数前后两个数字 // 判断num是否能因式分解，能进行因式分解则是合数，否则是素数 if num % i == 0 || num % (i + 2) == 0 { return false } } return true } /* Output: 2 是素数 3 是素数 5 是素数 7 是素数 11 是素数 13 是素数 17 是素数 19 是素数 23 是素数 29 是素数 31 是素数 37 是素数 41 是素数 43 是素数 47 是素数 53 是素数 59 是素数 61 是素数 67 是素数 71 是素数 73 是素数 79 是素数 83 是素数 89 是素数 97 是素数 */ for-range 【for - range】结构是Go语言特有的一种迭代结构，它在许多情况下都非常有用。 可以迭代任何一个集合，也包括数组(array)和字典(map)和字符串(string)和通道(channel)和切片(slice)，同时可以获得每次迭代所对应的索引和值。 1 2 // ix：索引 val：值 for ix, val := range coll {} 如果只需要range里的索引值，可以只写key省略value。 1 for key := range coll {} val值始终为集合中对应索引的副本，因此它一般只具有只读性质。 对它所有的任何修改都不会影响到集合中原有的值。 如果val为指针，则会产生指针的副本，依旧可以修改集合中的原值。 range遍历的也是副本。 for循环的range格式可以对slice、map、array、string、chan等进行迭代循环。 Golang的range类似迭代器操作，返回【(索引, 值) 】或【(键, 值)】。 类型 key value 描述 string index 是 int 类型 s[index] 是 rune 类型 字符串 array/slice index 是 int 类型 s[index] 是存储的元素类型 数组/切片 map key m[key] 是map存储类型 字典，遍历顺序是随机的 channel element 是chan存储类型 通道 可以忽略不想要的返回值，或使用_这个特殊变量。注意_是内置已经声明的，因此不能使用这种形式_:=1，不能使用:=应该使用=。 使用示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package main import \u0026#34;fmt\u0026#34; func main() { s := \u0026#34;abc\u0026#34; // range 变量字符串是按照Unicode遍历的 // 1) 忽略第二个参数, 支持 string/array/slice/map for i := range s { // 【int, rune】 fmt.Printf(\u0026#34;%d %c\\n\u0026#34;, i, s[i]) } // Output: // 0 a // 1 b // 2 c // 2) 忽略 第一个参数 for _, c := range s { // 【int, rune】 fmt.Println(c) } // Output: // 97 // 98 // 99 // 3) 忽略全部返回值，仅迭代 n := 0 // s为字符串时，统计rune字符数量 for range s { // 【int, rune】 n++ } fmt.Println(n) m := map[string]int{\u0026#34;a\u0026#34;:1, \u0026#34;b\u0026#34;:2} // 返回 (key, value) // 遍历map，顺序是随机的 for k, v := range m { // 【string, int】 fmt.Println(k, v) } // Output: // b 2 // a 1 } for-range会拷贝遍历对象 注意下面的代码range复制了a对象数据所以输出结果和预期的不同。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { // 数组布局 内存中连续分配 // 地址 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\t字节B // |\u0026lt;---a[0]----\u0026gt;| |\u0026lt;-------a[1]------\u0026gt;| |\u0026lt;--------a[2]------\u0026gt;| a := [3]int{0, 1, 2} // 查看a的内存占用大小 int 在64位系统下占8字节 3*8 = 24字节 fmt.Println(unsafe.Sizeof(a)) // 24 // index、value 都是从复制品中取出 for i, v := range a { // 【int, int】 // 在修改前，我们先修改原数组 if i == 0 { a[1], a[2] = 999, 999 // 确认修改有效，输出[0, 999, 999] fmt.Println(a) // [0 999 999] } // 使用复制品中取出的 value 修改原数组 a[i] = v + 100 } // 注意这里的输出 fmt.Println(a) // [100 101 102] // Output: // 24 // [0 999 999] // [100 101 102] } for-range遍历切片 改用引用类型，其底层数据不会被复制，注意下面代码。 另外两种引用类型map、channel是指针包装，而不像slice是struct。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import \u0026#34;fmt\u0026#34; func main() { // 布局 type slice struct { pointer, len, cap } // slice pointer len cap // | 5 5 // v // array 0 1 2 3 4 5 ... // 假设以下切片的结构如下struct {0x01f00, 5, 5} s := []int{1, 2, 3, 4, 5} // range遍历切片，复制结构体struct {0x01f00, 5, 5}用于遍历 // 遍历时指向pointer指针移动获取数据 for i, v := range s { // 【int, int】 if i == 0 { // 修改s的切片结构为struct {0x01f00, 3, 5}，而复制的副本不变struct {0x01f00, 5, 5} s = s[:3] // [low:high:max] len=high-low、cap=max-low // 修改[0x01f00+2*8,0x01f00+3*8)地址位置从3修改为100 s[2] = 100 } fmt.Println(i, v) } fmt.Println(s) // Output: // 0 1 // 1 2 // 2 100 // 3 4 // 4 5 // [1 2 100] } for-range遍历字符串 字符串是Unicode编码的字符集合使用for-range结构迭代字符串。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( \u0026#34;fmt\u0026#34; ) func main() { for pos, char := range \u0026#34;语言\\x80雨\u0026#34; { // 【int, rune】 fmt.Printf(\u0026#34;%d character %#U starts at byte position %d\\n\u0026#34;, char, char, pos) } // Output: // 35821 character U+8BED \u0026#39;语\u0026#39; starts at byte position 0 // 35328 character U+8A00 \u0026#39;言\u0026#39; starts at byte position 3 // 65533 character U+FFFD \u0026#39;�\u0026#39; starts at byte position 6 // 38632 character U+96E8 \u0026#39;雨\u0026#39; starts at byte position 7 } 注意 遍历切片：下面程序上有没有可优化的空间？ 1 2 3 4 5 func rangeTest(slice []int) { for index, value := range slice { _, _ = index, value } } 解析：使用 range 遍历，每次迭代会对 index,value 进行赋值，若数据很大或 value 类型为 string 时，对 value 的赋值操作可以进行优化，即忽略 value 值，使用 slice[index] 来获取 value 的值。 解析：使用 range 遍历，每次迭代会对 index,value 进行赋值，若数据很大或 value 类型为 string 时，对 value 的赋值操作可以进行优化，即忽略 value 值，使用 slice[index] 来获取 value 的值。 1 2 3 4 5 func rangeTest(slice []int) { for index, _ := range slice { _, _ = index, slice[index] } } 动态遍历：下面程序上能否正常结束？ 1 2 3 4 5 6 7 8 9 func main() { v := []int{1,2,3} // 我们知道range遍历的是v的副本，也就是 v1 := v 遍历的是v1 所以下面只会循环3次 for i := range v { v = append(v, i) } fmt.Println(v) // [1 2 3 0 1 2] // 最后变量完 v = []int{1,2,3,0,1,2} } 解析：会正常结束。循环内再改变切片的长度，不影响循环次数，循环次数在循环开始前就已经是确定了的。 遍历Map：下面程序上有没有可优化的空间？ 1 2 3 4 5 func rangeTest(mapTest map[int]string) { for key, _ := range mapTest { _, _ = key, mapTest[key] } } 解析：使用 range 遍历，根据第一题经验，我们根据 key 值来获取value 的值，看似减少了一次赋值，但使用 mapTest[key] 来获取 value 值的性能消耗可能高于赋值消耗。能否优化取决于 map 所存储数据结构特征，应结合实际情况进行。 我们知道mapTest[key]的取值是一个非常复杂的函数调用，mapTest[key]的使用反而会增加负担。 参考 range 实现原理 ","permalink":"https://heliu.site/posts/golang/process/for/","summary":"Golang for循环介绍。","title":"流程控制(循环语句)"},{"content":"迭代string range迭代string，key为int类型，value为rune类型。 1 2 3 4 5 str := \u0026#34;hello world! Gopher\u0026#34; for i, v := range str { // 【int, rune】 fmt.Println(i, v) // original body } 上面迭代字符串代码等效于下面代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // 1) 获取字符串长度 // 字符串总长度，该长度是字节数量用于遍历字符串的总长度 lenTemp := len(str) // 下一次遍历的下标位置，这是由于utf8是不定长编码需要记录上一次处理后的位置 var nextIndexTemp int\t// 2) key/value // 注意：这里的key和value，定义在for外，也是\u0026amp;i和\u0026amp;v是固定的原因 var i int // 遍历用到的索引，也就是index var v rune // 遍历出来存储的值，也就是value // 遍历字符串 for indexTemp := 0; indexTemp \u0026lt; lenTemp; indexTemp = nextIndexTemp { // 获取开头8bit的大小，因为该8bit能区分存储的是ASCII 1bit还是多个使用utf8编码的字节 valueTemp := rune(str[indexTemp])\t// utf8.RuneSelf = 0x80 = 128 单字符最大值 // ASCII码字符占1字节，该条件满足说明，存储的是ASCII码占用一个字节 if valueTemp \u0026lt; utf8.RuneSelf {\tnextIndexTemp = indexTemp + 1 } else { // 该条件满足说明是使用utf8编码的多个字节占用， // 使用decoderune获取该Unicode值和在Utf8中编码占用的字节大小数目 // decoderune解码字符串str从indexTemp位置开始，具体方法在runtime/utf8.go文件中 // 该函数与utf8编码相关 // valueTemp解析的rune，nextIndexTemp当前的indexTemp+解析的rune的长度 valueTemp, nextIndexTemp = decoderune(str, indexTemp)\t} // 3) 拷贝赋值 // 注意：这里就是为什么for range中取\u0026amp;i和\u0026amp;v地址是固定的原因 i = indexTemp // 当前获取到的索引 v = valueTemp // 当前获取到的字符 fmt.Println(i, v) // original body } decoderune()。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 // runtime/utf8.go 文件中decoderune方法 // decoderune returns the non-ASCII rune at the start of // s[k:] and the index after the rune in s. // // decoderune assumes that caller has checked that // the to be decoded rune is a non-ASCII rune. // // If the string appears to be incomplete or decoding problems // are encountered (runeerror, k + 1) is returned to ensure // progress when decoderune is used to iterate over a string. func decoderune(s string, k int) (r rune, pos int) { pos = k // 解析开始位置 if k \u0026gt;= len(s) { // 已经到字符串的最大长度了 return runeError, k + 1 } s = s[k:] // 从k位置分割字符串 switch { // [t2, t3) --\u0026gt; [11000000, 11100000) case t2 \u0026lt;= s[0] \u0026amp;\u0026amp; s[0] \u0026lt; t3: // 该字段2字节编码 // 0080-07FF two byte sequence // [locb, hicb] 是第二个字节的范围大小 [10000000, 10111111] if len(s) \u0026gt; 1 \u0026amp;\u0026amp; (locb \u0026lt;= s[1] \u0026amp;\u0026amp; s[1] \u0026lt;= hicb) { // 从编码中取出编码的数据组成rune // mask2 = 00011111，maskx = 00111111 r = rune(s[0]\u0026amp;mask2)\u0026lt;\u0026lt;6 | rune(s[1]\u0026amp;maskx) pos += 2 if rune1Max \u0026lt; r { return } } // [t3, t4) --\u0026gt; [11100000, 11110000) case t3 \u0026lt;= s[0] \u0026amp;\u0026amp; s[0] \u0026lt; t4: // 该字段3字节编码 // 0800-FFFF three byte sequence if len(s) \u0026gt; 2 \u0026amp;\u0026amp; (locb \u0026lt;= s[1] \u0026amp;\u0026amp; s[1] \u0026lt;= hicb) \u0026amp;\u0026amp; (locb \u0026lt;= s[2] \u0026amp;\u0026amp; s[2] \u0026lt;= hicb) { r = rune(s[0]\u0026amp;mask3)\u0026lt;\u0026lt;12 | rune(s[1]\u0026amp;maskx)\u0026lt;\u0026lt;6 | rune(s[2]\u0026amp;maskx) pos += 3 if rune2Max \u0026lt; r \u0026amp;\u0026amp; !(surrogateMin \u0026lt;= r \u0026amp;\u0026amp; r \u0026lt;= surrogateMax) { return } } // [t4, t5) --\u0026gt; [11110000, 11111000) case t4 \u0026lt;= s[0] \u0026amp;\u0026amp; s[0] \u0026lt; t5: // 该字段4字节编码 // 10000-1FFFFF four byte sequence if len(s) \u0026gt; 3 \u0026amp;\u0026amp; (locb \u0026lt;= s[1] \u0026amp;\u0026amp; s[1] \u0026lt;= hicb) \u0026amp;\u0026amp; (locb \u0026lt;= s[2] \u0026amp;\u0026amp; s[2] \u0026lt;= hicb) \u0026amp;\u0026amp; (locb \u0026lt;= s[3] \u0026amp;\u0026amp; s[3] \u0026lt;= hicb) { r = rune(s[0]\u0026amp;mask4)\u0026lt;\u0026lt;18 | rune(s[1]\u0026amp;maskx)\u0026lt;\u0026lt;12 | rune(s[2]\u0026amp;maskx)\u0026lt;\u0026lt;6 | rune(s[3]\u0026amp;maskx) pos += 4 if rune3Max \u0026lt; r \u0026amp;\u0026amp; r \u0026lt;= maxRune { return } } } return runeError, k + 1 } for-range不能遍历*string类型。 for-range对于字符串并没有复制一份字符串进行编码，其实也不必要因为字符串的语义本来就是不可变数据。 迭代array range迭代array，key为int类型，value为数组的元素类型。 1 2 3 4 5 arr := [5]int{0,1,2,3,4} for i, v := range arr { // 【int, int】 fmt.Println(i, v) // original body } 上面迭代数组代码等效于下面代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 1) 获取数组长度 // 注意：这里支持指针数组，比如len(*[2]int) == 2 lenTemp := len(arr) // 2) 拷贝数组 // 注意：这里支持指针数组，比如arr是*[2]int // 这里也就是为什么使用数组指针和数组本身的性能差异， // 使用数组指针这里的赋值是指针赋值，而使用数组这里是值复制当数据量大时性能差别还是比较明显 rangeArr := arr // 复制一份需要遍历的数组，注意这里的副本是与原数组没有任何联系 // 3) key/value // 注意：这里的key和value，定义在for外，也是\u0026amp;i和\u0026amp;v是固定的原因 var i, v int // 定义遍历需要接收的key和value变量 // for range的编译等同代码 for indexTemp := 0; indexTemp \u0026lt; lenTemp; indexTemp++ { // 注意：这里支持指针数组赋值 valueTemp := rangeArr[indexTemp] // 数组支持语法糖 // 4) 拷贝赋值 // 注意：这里就是为什么for range中取\u0026amp;i和\u0026amp;v地址是固定的原因 i = indexTemp // 拷贝赋值 v = valueTemp // 拷贝赋值 fmt.Println(i, v) // original body } 数组遍历和切片遍历最主要的区别就是遍历副本，数组的副本与原数组没有任何关联只是值全部相同而已，而切片则是副本和原切片数共用同一个底层数组。 range能遍历【数组指针】而【不能】遍历切片指针，这得益于数值指针在赋值和len()函数上Go支持的【语法糖】转换使得range对数组指针同样适用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // range遍历指针数组时，会解引用数组指针拷贝副本遍历 package main import \u0026#34;fmt\u0026#34; func main() { var aa *[2]string = new([2]string) // 1) 语法糖1：赋值 //(*aa)[0] = \u0026#34;a\u0026#34; aa[0] = \u0026#34;a\u0026#34; // 语法糖 //(*aa)[1] = \u0026#34;bb\u0026#34; aa[1] = \u0026#34;bb\u0026#34;// 语法糖 // 2) 语法糖2：取值 // c := (*aa)[1] c := aa[1] // 语法糖 // 3) 语法糖3：求长度 // l := len(aa) // len(*aa) // 在Go中支持数组的指针相关的语法糖，所以导致使用数组和数组指针好像并没有多大的区别 // 比如数组指针aa能使用aa[0] = \u0026#34;a\u0026#34;这种形式赋值，也能使用len(aa)这种形式求长度， // 其他类型的指针则不支持 // 这些语法糖也导致了能使用range遍历数组指针 // range 拷贝 *aa 副本遍历 for i, s := range aa { // 当数组很大时，遍历数组指针是一个不错的选择 if i == 0 { aa[1] = \u0026#34;cc\u0026#34; } fmt.Println(i, s) } fmt.Println(aa) // Output: // 0 a // 1 cc // \u0026amp;[a cc] } 验证数组遍历是值拷贝。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 {\tslice1 := [4]int{0,1,2,3} // 这里拷贝的是数组的副本，因此if条件成立不会影响值 for i, v := range slice1 { // [4]int if i == 1 { slice1[3] += 10 } fmt.Println(i, v) } fmt.Println(slice1) // Output: // 0 0 // 1 1 // 2 2 // 3 3 // [0 1 2 13] } { slice1 := [4]int{0,1,2,3} // 这里拷贝的是数组的指针，因此if条件成立会影响值 for i, v := range \u0026amp;slice1 { // *[4]int if i == 1 { slice1[3] += 10 } fmt.Println(i, v) } // Output: // 0 0 // 1 1 // 2 2 // 3 13 } 迭代slice 遍历slice前会先获取slice的长度lenTemp来作为循环次数，循环体中，每次循环会先获取元素值。 如果for-range中接收index和value的话，则会对index和value进行一次赋值。 数组与数组指针的遍历过程与slice基本一致，但是也有区别，区别在于副本复制的是与原数组是一个完全不相干的数组。 for-range迭代slice，key为int，value为存储的元素类型。 1 2 3 4 5 slice1 := []int{0,1,2,3} for i, v := range slice1 { // 【int, int】 fmt.Println(i, v) // original body } 上面迭代切片代码等效于下面代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 1) 拷贝切片 // 注意：拷贝的切片与原切片共用了同一个底层数组 // 也需要注意，len和cap也拷贝元切片的值，因此for range修改不起作用， rangeSlice := slice1 // 2) 获取切片长度，也是遍历的次数 // 遍历的此时切片长度是固定的 lenTemp := len(rangeSlice) // 拿到需要遍历的切片总长度 // 3) key/value // 注意：这里的key和value，定义在for外，也是\u0026amp;i和\u0026amp;v是固定的原因 var i, v int // 定义遍历需要的key和value变量 // for range的编译等同代码 for indexTemp := 0; indexTemp \u0026lt; lenTemp; indexTemp++ { valueTemp := rangeSlice[indexTemp] // 4) 拷贝赋值 // 注意：这里就是为什么for range中取\u0026amp;i和\u0026amp;v地址是固定的原因 i = indexTemp v = valueTemp fmt.Println(i, v) // original body } 由于循环开始前循环次数就已经确定了，所以循环过程中新添加的元素是无法遍历到的。 但是循环过程中修改后面还未循环的值，则会影响，这是由于在range循环前赋值的副本与原切片共用了一个底层数组导致的，所以能相互影响。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { slice1 := []int{0,1,2,3} for i, v := range slice1 { // 【int, int】 if i == 1 { slice1[3] += 10 } fmt.Println(i, v) } // Output: // 0 0 // 1 1 // 2 2 // 3 13 } 迭代channel channel遍历是依次从channel中读取数据，读取前是不知道里面有多少个元素的。 如果channel中没有元素，则会阻塞等待，如果channel已被关闭，则会解除阻塞并退出循环。 for-range迭代channel，只能获取一个值，key为channel存储的元素类型。 1 2 3 4 5 6 c := make(chan int) // range遍历chan for v := range c { // 【int】 fmt.Println(v) // original body } 上面迭代channel代码等效于下面代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 这里是\u0026amp;v为什么都是同一个地址的原因 var v int // v其实就是固定的一个变量 for { // 注意如果不关闭channel这里会一直阻塞 // 我们知道 \u0026lt;- 符号会调用相关的函数，如果chan关闭了会返回false退出循环 value_temp, ok := \u0026lt;- c\t// 有数据则会直接返回数据，没有数据则会阻塞，通过chan的学习知道阻塞意味着 // 当前goroutine被调离调度循环等待数据到来被重新调起 // ok = false，通道已经关闭。 if !ok { break } // 2) 拷贝值 v = value_temp fmt.Println(v) // original body } 编译后的伪代码，与上面等价。关于chanrecv2()在channel中介绍。 1 2 3 4 5 6 7 8 9 10 11 12 13 var v int for { ok := chanrecv2(c, \u0026amp;value_temp) if !ok { break } v = index_temp fmt.Println(v) // original body } 注意： 使用for-range遍历channel时只能获取一个返回值。 【for-range \u0026lt;-ch】情况，该情况可以用在 【channel map、channel array|*array、channel slice、channel string】。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func chanTs2() { ch := make(chan map[int]int) // 注意：这里是 \u0026lt;-ch，前面的是 ch for k, v := range \u0026lt;-ch { println(k, v) } // --------------------------- // as 等价于下面代码 // --------------------------- // 注意：这里只会执行一次 a := \u0026lt;-ch for k, v := range a { println(k, v) } } 迭代map for-range迭代map，key为map的键，value为map的值。 1 2 3 4 5 map1 := map[string]string{\u0026#34;one\u0026#34;:\u0026#34;1\u0026#34;, \u0026#34;tow\u0026#34;:\u0026#34;2\u0026#34;} for i, v := range map1 { // 【string, string】 fmt.Println(i, v) // original body } 上面迭代map代码等效于下面代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 1) key/value // 这里也是为什么\u0026amp;i和\u0026amp;v是一个固定的地址的原因 // 定义遍历所需要的key和value变量 var i, v string // 2) map_iteration_struct // map_iteration_struct是一个hiter结构体，存储着map的遍历相关信息 var hiter map_iteration_struct\t// mapiterinit 初始化map参看runtime/map.go文件 // hiter是一个哈希迭代结构，mapiternext迭代下一个哈希 for mapiterinit(type, range, \u0026amp;hiter); hiter.key != nil; mapiternext(\u0026amp;hiter) { index_temp := *hiter.key value_temp := *hiter.val // 3) 拷贝数据 i = index_temp v = value_temp fmt.Println(i, v) // original body } 遍历map时没有指定循环次数，循环体与遍历slice类似。由于map底层实现与slice不同，map底层使用 hash表实现的。 插入数据位置是随机的，所以遍历过程中新插入的数据不能保证遍历到。 以下相关的函数在map篇中还会详细的讨论。 type hiter struct。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // A hash iteration structure. // If you modify hiter, also change cmd/compile/internal/reflectdata/reflect.go // and reflect/value.go to match the layout of this structure. type hiter struct { // 当前遍历的key地址 key unsafe.Pointer // Must be in first position. Write nil to indicate iteration end (see cmd/compile/internal/walk/range.go). // 当前遍历的elem地址 elem unsafe.Pointer // Must be in second position (see cmd/compile/internal/walk/range.go). // 当前map的类型结构 t *maptype // 当前map的内存结构 h *hmap\t// 当前map的常规桶地址 buckets unsafe.Pointer // bucket ptr at hash_iter initialization time // 当前正在遍历的桶 bptr *bmap // current bucket 当前存储桶 // h.extra.overflow overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive\t// h.extra.oldoverflow oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive // 开始遍历的桶号，随机的，用于开始遍历的起点以及结束遍历的终点 startBucket uintptr // bucket iteration started at // tophash偏移值，在[0,7]中随机生成的值，用于后续 i + offset \u0026amp; 7 用作偏移量 offset uint8 // intra-bucket offset to start from during iteration (should be big enough to hold bucketCnt-1) // 当前遍历已过最大桶(1 \u0026lt;\u0026lt; B)时被设置为true wrapped bool // already wrapped around from end of bucket array to beginning // 初始化时桶的数量 1 \u0026lt;\u0026lt; B B uint8 // 当前桶遍历的索引，默认值从0开始，该值配合offset遍历tophash，i + offset \u0026amp; 7 i uint8 // 初始化时是startBucket的值 // 1. bptr == nil时bucket存储需要遍历的桶号 // 2. bptr != nil时bucket下个桶的桶号 bucket uintptr // 存储的是当前迭代器的桶号 // noCheck.不需要检查，数据在bptr桶里面 // 其他需要检查 checkBucket uintptr // 需要检查的桶号 } mapiterinit()。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // mapiterinit initializes the hiter struct used for ranging over maps. // The hiter struct pointed to by \u0026#39;it\u0026#39; is allocated on the stack // by the compilers order pass or on the heap by reflect_mapiterinit. // Both need to have zeroed hiter since the struct contains pointers. // mapiterinit 初始化用于在map上的 hiter 结构 // \u0026#39;it\u0026#39; 指向的 hiter 结构由编译器顺序传递在堆栈上分配，或者由 reflect_mapiterinit 在堆上分配。 // 由于结构包含指针，因此两者都需要将 hiter 归零。 // // 迭代初始化 // t *maptype：当前map的元素类型 // h *hmap：当前map的内存结构 // it *hiter：迭代器结构 func mapiterinit(t *maptype, h *hmap, it *hiter) { if raceenabled \u0026amp;\u0026amp; h != nil { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, abi.FuncPCABIInternal(mapiterinit)) } it.t = t // 存储当前map的类型结构地址 if h == nil || h.count == 0 { // 如果当前map为空直接返回 return } if unsafe.Sizeof(hiter{})/goarch.PtrSize != 12 { // 判断hiter结构是否正确 throw(\u0026#34;hash_iter size incorrect\u0026#34;) // see cmd/compile/internal/reflectdata/reflect.go } it.h = h // 存储当前map的内存结构地址 // grab snapshot of bucket state it.B = h.B // 记录当前map的桶数量 it.buckets = h.buckets // 记录当前map的常规桶地址 if t.bucket.ptrdata == 0 { // 判断当前桶类型的ptrdata字段，该字段为0说明存储的都是标量数据 // 分配当前切片并记住指向当前切片和旧切片的指针。 // 即使表增长 and/or 在我们迭代时将溢出桶添加到表中，这也会保留所有相关的溢出桶。 h.createOverflow() // 创建溢出桶 it.overflow = h.extra.overflow it.oldoverflow = h.extra.oldoverflow } // decide where to start // 决定从哪里开始 r := uintptr(fastrand()) // 生成随机数决定从哪里开始 // bucketCntBits = 3 if h.B \u0026gt; 31-bucketCntBits { // 如果当前的桶数 \u0026gt; 31 - 3 r += uintptr(fastrand()) \u0026lt;\u0026lt; 31 } it.startBucket = r \u0026amp; bucketMask(h.B) // 确定开始的桶号，这里也是for range随机的原因 it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) // 开始的tophash位置处 // iterator state it.bucket = it.startBucket // 记住我们有一个迭代器。 // 可以与另一个 mapiterinit() 并发运行。\t// iterator = 1 存在桶正在在使用迭代器标志 // oldIterator = 2 存在旧桶正在使用迭代器标志 // 设置正在迭代的标志位 if old := h.flags; old\u0026amp;(iterator|oldIterator) != iterator|oldIterator { atomic.Or8(\u0026amp;h.flags, iterator|oldIterator) // 原子锁设置hmap的flags参数标志正在使用迭代器 } mapiternext(it) } mapiternext()。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 // 向下寻找下一个key func mapiternext(it *hiter) { h := it.h // 获取当前hmap内存结构 if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, abi.FuncPCABIInternal(mapiternext)) } // 当前有hashWriting操作时，比如m[k]=v或delete函数时都会报错 if h.flags\u0026amp;hashWriting != 0 { throw(\u0026#34;concurrent map iteration and map write\u0026#34;) } t := it.t // 获取map的结构 // 本次需要遍历的桶号 bucket := it.bucket // 当前的桶号 // 本次需要遍历的桶，如果为nil说明需要去bucket寻找 b := it.bptr // 当前存储桶 // 本次应该遍历的索引 i := it.i // 遍历索引默认0 checkBucket := it.checkBucket // 遍历一遍当前桶及其溢出桶直到b=nil next: // 当前桶遍历完时，切换到下一个桶去遍历 if b == nil { // 当前遍历的桶和开始的桶相等 并且 已经遍历过了最大桶数，说明遍历了一圈了 if bucket == it.startBucket \u0026amp;\u0026amp; it.wrapped { // 结束遍历的条件 // end of iteration it.key = nil it.elem = nil return } // h.growing() 当前正在扩容中 if h.growing() \u0026amp;\u0026amp; it.B == h.B { // h.growing()当前map正处于扩容状态 // 迭代器是在增长过程中启动的，但增长尚未完成。 // 如果我们查看的bucket尚未填充（即，旧bucket未被清空），那么我们需要遍历旧buckets，只返回将迁移到此bucket的buckets。 oldbucket := bucket \u0026amp; it.h.oldbucketmask() // 旧桶的桶号 b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))\t// 获取桶位置 // 当前桶的tophash[0]不是2|3|4时，说明数据没有被迁移 if !evacuated(b) {\tcheckBucket = bucket // 需要检查的桶号 } else { // 说明数据在新桶里面，数据已被迁移 b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize)))\tcheckBucket = noCheck } } else { // 1.没有扩容 2.扩容了但是it.B != h.B b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) // 新桶 checkBucket = noCheck } bucket++ // 桶号加一 // 当前桶号等于最大桶号 if bucket == bucketShift(it.B) { // bucketShift(it.B) 等于 1 \u0026gt;\u0026gt; B bucket = 0 // 标记从0号桶开始 it.wrapped = true // 标记已经过了最大桶了 } i = 0 // 新桶重置索引为0 } // 遍历当前桶的所有元素\tbucketCnt = 8 // 从当前桶遍历数据 for ; i \u0026lt; bucketCnt; i++ { offi := (i + it.offset) \u0026amp; (bucketCnt - 1) // 根据it.offset偏移量开始随机遍历元素[0,7] // b.tophash[offi] \u0026lt;= 1 或 evacuatedEmpty = 4 表示桶数据为空 if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty { // 如果当前位置为0或1或4表示桶为空 continue } k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize)) // 偏移到当前key位置 if t.indirectkey() { // 判断当前key存储是否是已指针存储而不是存储的key本身 k = *((*unsafe.Pointer)(k)) } // 偏移到当前elem位置 e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.elemsize)) // checkBucket != noCheck 数据在旧桶 并且 !h.sameSizeGrow() 翻倍扩容 // 需要验证桶时，旧桶存在数据 if checkBucket != noCheck \u0026amp;\u0026amp; !h.sameSizeGrow() { // 存在没有迁移完的旧桶时，去检查旧桶 // t.reflexivekey() 为true表示 k == k 始终成立 // t.reflexivekey() || t.key.equal(k, k) -\u0026gt; k == k 始终成立情况 if t.reflexivekey() || t.key.equal(k, k) { // 如果oldbucket中的项不是针对迭代中的当前新bucket，请跳过它 hash := t.hasher(k, uintptr(h.hash0)) if hash\u0026amp;bucketMask(it.B) != checkBucket { // 需要跳过的情况 continue } } else { // k == k 不是始终成立 // b.tophash[offi]\u0026amp;1 的最低位 参看数据迁移部分的去向 if checkBucket\u0026gt;\u0026gt;(it.B-1) != uintptr(b.tophash[offi]\u0026amp;1) { continue } } } // 将找到的k和e保存到hiter中 // evacuatedX = 2、evacuatedY = 3 // b.tophash[offi] != evacuatedX \u0026amp;\u0026amp; b.tophash[offi] != evacuatedY 存在有效数据 // !(t.reflexivekey() || t.key.equal(k, k))\t-\u0026gt; x == x 不是始终成立 if (b.tophash[offi] != evacuatedX \u0026amp;\u0026amp; b.tophash[offi] != evacuatedY) || !(t.reflexivekey() || t.key.equal(k, k)) { // 这是需要的数据，我们可以返回它 // 或 // key!=key，因此无法删除或更新条目，因此我们可以只返回它 // 这对我们来说很幸运，因为当key!=key关键是我们找不到它 it.key = k if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } it.elem = e } else { // 数据被迁移到其他地方了 // 自从迭代器启动以来，哈希表一直在增长 // 这个key的数据现在在其他地方 // 检查数据的当前哈希表 // 此代码处理以下情况： //\t已被删除、更新或删除并重新插入 //\t注意：我们需要重新标记密钥，因为它可能已更新为equal()，但不是相同的key（例如+0.0 vs-0.0） rk, re := mapaccessK(t, h, k) // 根据key去寻找相应的数据，可能是新桶也可能是旧桶 // 每寻找到，可能key已被删除 if rk == nil { continue // key has been deleted } it.key = rk it.elem = re } it.bucket = bucket // 回写桶号 // 记录当前正在遍历的桶 if it.bptr != b { // avoid unnecessary write barrier; see issue 14921 it.bptr = b\t// 避免不必要的写入障碍 } it.i = i + 1 // i加一 it.checkBucket = checkBucket return } b = b.overflow(t) // 如果上面桶遍历完接到去后面桶找 i = 0 goto next } mapaccessK()。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // returns both key and elem. Used by map iterator // 根据key找到相应的值 func mapaccessK(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, unsafe.Pointer) { if h == nil || h.count == 0 { return nil, nil } hash := t.hasher(key, uintptr(h.hash0)) // 当前key生成的hash值 m := bucketMask(h.B) // (1 \u0026lt;\u0026lt; B) - 1 b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) // key存储的当前桶 // 是否在扩容中 if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() {\t// 翻倍扩容 // There used to be half as many buckets; mask down one more power of two. m \u0026gt;\u0026gt;= 1 } // 去旧桶里面查看数据是否被迁移了 oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize)))\t// 数据没有被迁移 tophash[0] != [2,3,4] if !evacuated(oldb) { b = oldb } } top := tophash(hash) // tophash bucketloop: // 遍历当前桶及溢出桶寻找 key for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { // emptyRest = 0 break bucketloop } continue } // 找到了key // 1. 可能是hash冲突则还需要向后去查找 // 2. 确实找到了key直接返回即可 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } // key匹配成功 if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return k, e } } } return nil, nil } 总结 for-range不支持【字符串指针】、【切片指针】、【map指针】、【channel指针】，但支持【数组指针】遍历。 ","permalink":"https://heliu.site/posts/golang/process/range/","summary":"Golang for range迭代string、channel、array、slice、map解析。","title":"流程控制(range迭代)"},{"content":" 表达式型switch：包含与switch表达式的值进行比较的表达式。 类型型switch：包含与switch表达式的类型进行比较的类型。 switch 使用方式 switch var{} switch 表达式可以执行一个简单语句完成运算从而得到表达式的值。 1 2 3 4 5 6 7 8 switch var { // switch 会判断var的类型 case val1: // case 会判断val1的类型以便和var能比较 // ... case val2: // ... default: // ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package main import ( \u0026#34;fmt\u0026#34; ) const B1 = false func main() { switch B1 { case false: fmt.Println(\u0026#34;fallthrough 语句 接到执行下一个语句\u0026#34;) fallthrough case true: fmt.Println(\u0026#34;true\u0026#34;) fallthrough case false: fmt.Println(123) fallthrough case true: fmt.Println(456789) default: fmt.Println(\u0026#34;default\u0026#34;) } fmt.Println(\u0026#34;default 1234\u0026#34;) // \u0026gt; ---------------------------------------------------- var i1 = 2 switch i1 { default: fmt.Println(\u0026#34;default\u0026#34;) case 0,1,2,3: fmt.Println(\u0026#34;123456789\u0026#34;) case 4,5,6,7: fmt.Println(\u0026#34;987654321\u0026#34;) } // \u0026gt; ---------------------------------------------------- switch i1 { default: fmt.Println(\u0026#34;default\u0026#34;) case 0: case 1: case 2: case 3: fmt.Println(\u0026#34;123456789\u0026#34;) case 4,5,6,7: fmt.Println(\u0026#34;987654321\u0026#34;) } // 注意 case 0,1,2,3: 形式和 case 0: case 1: case 2: 这种形式的区别 // Output: // fallthrough 语句 接到执行下一个语句 // true // 123 // 456789 // default 1234 // 123456789 } switch{} 不提供任何被判断的值（实际上默认为判断是否为true）然后在每个case分支中检测不同的条件，当任一分支的测试结果为true时，该分支的代码会被执行，此时语句相当于switch true。 1 2 3 4 5 6 7 8 switch { // 默认推导为布尔类型 true case condition1: // condition1比较条件 // ... case condition2: // ... default: // ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var x, y, z = 2, 1, 3 // switch {} 等价于 switch true {} switch { case x \u0026lt; y: fmt.Printf(\u0026#34;x:%d,y:%d\\n\u0026#34;, x, y) case x \u0026lt; z: fmt.Printf(\u0026#34;x:%d,z:%d\\n\u0026#34;, x, z) case z == 3: fmt.Println(\u0026#34;z==4\\n\u0026#34;) } // Output: // x:2,z:3 } switch Init; var{} switch语句第三种形式，包含一个初始化语句。 1 2 3 4 5 6 7 8 switch Init; var { case val1: // ... case val2: // ... default: // ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // switch x, y, z := 2, 1, 3; {} 等价于 switch x, y, z := 2, 1, 3; true {} // 等价于 // { // x, y, z := 2, 1, 3; // switch true { // // ... ... // } // } switch x, y, z := 2, 1, 3; { case x \u0026lt; y: fmt.Printf(\u0026#34;x:%d,y:%d\\n\u0026#34;, x, y) case x \u0026lt; z: fmt.Printf(\u0026#34;x:%d,z:%d\\n\u0026#34;, x, z) case z == 3: fmt.Println(\u0026#34;z==4\\n\u0026#34;) } switch x, y, z := 2, 1, 3; false { case x \u0026lt; y: fmt.Printf(\u0026#34;x:%d,y:%d\\n\u0026#34;, x, y) case x \u0026lt; z: fmt.Printf(\u0026#34;x:%d,z:%d\\n\u0026#34;, x, z) case z == 3: fmt.Println(\u0026#34;z==4\\n\u0026#34;) } // Output: // x:2,z:3 // x:2,y:1 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 package main import \u0026#34;fmt\u0026#34; func main() { var j = 0 switch j { case 0: // 注意这种和case 0, 1:形式的区别 case 1: fmt.Println(\u0026#34;11\u0026#34;) case 2: fmt.Println(\u0026#34;22\u0026#34;) default: fmt.Println(\u0026#34;def def\u0026#34;) } var k = 0 switch k { case 0: fmt.Println(\u0026#34;fallthrough\u0026#34;) fallthrough case 1: fmt.Println(\u0026#34;111\u0026#34;) case 2: fmt.Println(\u0026#34;211\u0026#34;) default: fmt.Println(\u0026#34;def def def\u0026#34;) } var m = 0 switch m { case 0, 1: fmt.Println(\u0026#34;1111\u0026#34;) case 2: fmt.Println(\u0026#34;2111\u0026#34;) default: fmt.Println(\u0026#34;def def def def\u0026#34;) } var n = 0 switch { case n \u0026gt; 0 \u0026amp;\u0026amp; n \u0026lt; 10: fmt.Println(\u0026#34;i \u0026gt; 0 and i \u0026lt; 10\u0026#34;) case n \u0026gt; 10 \u0026amp;\u0026amp; n \u0026lt; 20: fmt.Println(\u0026#34;i \u0026gt; 10 and i \u0026lt; 20\u0026#34;) default: fmt.Println(\u0026#34;def def def def def\u0026#34;) } // Output: // fallthrough // 111 // 1111 // def def def def def } 表达式型switch 如果switch表达式求值为无类型常量，则首先将其转换为默认类型（整型默认int，浮点数默认float64，字符串默认string，复数默认complex128）。 如果是无类型的布尔值，则首先将其转换为bool类型。 预先声明的无类型值nil不能用作开关表达式（由于switch转换nil为默认类型报错）。 如果switch表达式是无类型的，则首先将其转换为switch表达式的类型。 对于每个（可能已转换的）switch表达式x和switch表达式的值t，x和t必须可以进行有效的比较。 在switch或default字句中，最后一个非空语句可以是fallthrough语句。 以指示应该从该字句的末尾流向下一个字句的第一个语句，无论下一个字句的条件是否满足。 出现fallthrough语句后，它后面只能接下一个字句。 1 2 3 4 5 6 7 8 switch expr { case v1: // pass case v2: // pass default: // pass } nil不能作为switch表达式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import \u0026#34;fmt\u0026#34; func main() { // 这里switch将nil转换成默认类型进行以下比较时报错 // 和之前的 a := nil 或 var a = nil 一样报错不能判断出a的具体类型 // 由此可见swicth需要确定变量的唯一类型 switch nil { // 报错 case nil: fmt.Println(\u0026#34;nil\u0026#34;) default: fmt.Println(\u0026#34;default\u0026#34;) } // .\\os.go:8:2: use of untyped nil // 下面这种却是可以 var m map[string]string switch m { // 这里能确认m是map类型 case nil: fmt.Println(\u0026#34;nil\u0026#34;) default: fmt.Println(\u0026#34;default\u0026#34;) } // Output: // nil } 无类型常量用作switch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import \u0026#34;fmt\u0026#34; const Sw = 12 func main() { switch Sw { // Sw被默认推导为int类型 // (untyped float constant) truncated to int // 报错，1.1被默认推导为float64类型无法与int类型比较 case 1.1:\tfmt.Println() } } switch常用示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import \u0026#34;fmt\u0026#34; func main() { // 定义局部变量 var grade string = \u0026#34;B\u0026#34; var marks int = 90 switch marks { case 90: grade = \u0026#34;A\u0026#34; case 80: grade = \u0026#34;B\u0026#34; // 这里与其他语言写法的根本原因是go默认会添加break语句，而其他语言没有这一特性的原因 case 50, 60, 70: // 这里区分其他语言 case 50: case 60: case 70: grade = \u0026#34;C\u0026#34; default: grade = \u0026#34;D\u0026#34; } // switch 省略条件 默认为 switch true {} // 和for {} 一样省略条件默认为 for true {} switch { case grade == \u0026#34;A\u0026#34;: fmt.Printf(\u0026#34;优秀\\n\u0026#34;) case grade == \u0026#34;B\u0026#34;, grade == \u0026#34;C\u0026#34;: fmt.Printf(\u0026#34;良好\\n\u0026#34;) case grade == \u0026#34;D\u0026#34;: fmt.Printf(\u0026#34;及格\\n\u0026#34;) case grade == \u0026#34;F\u0026#34;: fmt.Printf(\u0026#34;不及格\\n\u0026#34;) default: fmt.Printf(\u0026#34;差\\n\u0026#34;) } fmt.Printf(\u0026#34;你的等级是 %s\\n\u0026#34;, grade) // Output: // 优秀 // 你的等级是 A } fallthrough关键字 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // fallthrough 关键字 继续执行下一个case不判断case值 switch { case false: fmt.Println(\u0026#34;fallthrough 语句 接到执行下一个语句\u0026#34;) fallthrough case true: fmt.Println(\u0026#34;true\u0026#34;) fallthrough case false: fmt.Println(123) fallthrough case true: fmt.Println(456789) // fallthrough强制执行【紧挨着相邻】的case或default块， // 如果后面没有紧挨着的则报错 fallthrough default: fmt.Println(\u0026#34;default\u0026#34;) } // Output: // true // 123 // 456789 // default } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import \u0026#34;fmt\u0026#34; func main() { var k = 2 switch k { case 0: fmt.Println(\u0026#34;fallthrough\u0026#34;) case 2: fmt.Println(\u0026#34;211\u0026#34;) fallthrough // 可见，fallthrough 后紧挨着 default 也会执行它。 default: fmt.Println(\u0026#34;def def def\u0026#34;) case 1: fmt.Println(\u0026#34;111\u0026#34;) } // Output: // 211 // def def def } fallthrough和default一起使用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 switch { default: // 比如这里当匹配条件都不通过，则到default这里 fmt.Println(\u0026#34;1\u0026#34;) fallthrough // fallthrough后继续执行后面的case case true: fmt.Println(\u0026#34;2\u0026#34;) } // Output: // 2 switch { default: // 比如这里当匹配条件都不通过，则到default这里 fmt.Println(\u0026#34;1\u0026#34;) fallthrough // fallthrough后继续执行后面的case case false: fmt.Println(\u0026#34;2\u0026#34;) } // Output: // 1 // 2 类型型switch 比较的类型而不是值，它在其他方面类似表达式型switch，只不过分支选择的是类型而不是值。 它由一个特殊的switch表达式标记，该表达式使用类型断言的形式来进行动态类型判断。 x.(type) switch 语句还可以被用于 type-switch 来判断某个 interface 变量中实际存储的变量类型。 type switch 语句格式如下： 1 2 3 4 5 6 7 8 switch x.(type) { case type: statement(s) case type: statement(s) default: statement(s) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 定义变量t 接口类型 interface{} 可以是任何其他类型 var t interface{} t = functionOfSomeType() // switch t.(type) { ... } // t.(type) 断言t的类型 .(type)形式必须配合switch使用 switch t1 := t.(type) { default: fmt.Printf(\u0026#34;default Type %T\\n\u0026#34;, t1) case bool: fmt.Printf(\u0026#34;bool %t\\n\u0026#34;, t1) case int: fmt.Printf(\u0026#34;integer %d\\n\u0026#34;, t1) case *bool: fmt.Printf(\u0026#34;pointer bool %t\\n\u0026#34;, *t1) case *int: fmt.Printf(\u0026#34;pointer integer %d\\n\u0026#34;, *t1) } } //func functionOfSomeType () bool { // return false //} // bool false //func functionOfSomeType () uint { // return 123 //} // default Type uint //func functionOfSomeType () int { // return 123 //} // integer 123 //func functionOfSomeType () *int { // a := 123 // return \u0026amp;a //} // pointer integer 123 func functionOfSomeType () *bool { a := true return \u0026amp;a } // pointer bool true 注意 val1和val2可以是同类型的任意值，类型不局限于常数或整数，但必须是相同的类型，或最终结果为相同类型的表达式。 前花括号{必须和switch关键字在同一行。 可以同时测试多个可能符合条件的值，使用逗号分割它们。 如case val1, val2, val3而在其他语言中则是case val1: case val2: case val3:这种形式。 一旦成功地匹配到某个分支，在执行完相应代码后就会退出整个switch代码块。 也就是说，不需要特别使用break语句来表示结束，如果使用了仍然是在switch块中。 如果在执行完每个分支的代码后，还是希望继续执行后续分支的代码。 可以使用fallthrough关键字来达到目的，fallthrough强制执行后面的(紧挨着的)下一条分支代码，不管是case或default分支都会执行。 fallthrough不会判断下一条分支的表达式结果是否为真。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; ) func main() { switch a := 1; { case a == 1: fmt.Printf(\u0026#34;a == %d\\n\u0026#34;, a) fallthrough case a == 2: fmt.Println(\u0026#34;a == 2\u0026#34;) case a == 3: fmt.Println(\u0026#34;a == 3\u0026#34;) fallthrough case a == 5: fmt.Println(\u0026#34;a == 5\u0026#34;) fallthrough default: fmt.Println(\u0026#34;default\u0026#34;) case a == 4: fmt.Println(\u0026#34;a == 4\u0026#34;) } // Output: // a == 1 // a == 2 } ","permalink":"https://heliu.site/posts/golang/process/switch/","summary":"Golang 介绍switch的用法。","title":"流程控制(switch)"},{"content":" select是Go中的一个控制结构，类似switch语句。 主要作用是处理异步通道操作，所有情况都会涉及通信操作，主要用于channel操作。 因此select会监听分支语句中通道的读写操作，当分支中的通道读写操作为非阻塞状态（即能读写）时，将会触发相应的动作。 select语句会选择一组可以发送或接收操作中的一个分支继续执行，select没有条件表达式，一直等待case进入可运行状态。 总结： select中的case语句必须是对通道的操作。 select中的default子句总是可运行的。 如果有多个分支都可以运行，select会伪随机公平的选出一个执行，其他分支不会执行。 如果没有可运行的分支，且有default语句，那么就会执行default的动作。 如果没有可运行的分支，且没有default语句，select将阻塞，直到某个分支可以运行。 关于select关键字的运行原理在channel篇介绍。(如果您还不熟悉channel，参看channel后再阅读本篇文章) select(原理)。 语法格式 Go编程语言中select语句的语法如下： 1 2 3 4 5 6 7 8 select { case communication clause: statement(s) case communication clause: statement(s) default: statement(s) } 使用示例 nil channel使用select default结构。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import \u0026#34;fmt\u0026#34; func main() { var c1, c2, c3 chan int // nil var i1, i2 int // 由于selectgo函数的源代码可知，go会把所有非nil的channel组成一个send+recv集 // 然后all channel lock 伪随机的遍历case集。 // 由于这里的channel都是nil，则不存在case集，直接走default select { case i1 = \u0026lt;-c1: fmt.Printf(\u0026#34;received \u0026#34;, i1, \u0026#34; from c1\\n\u0026#34;) case c2 \u0026lt;- i2: fmt.Printf(\u0026#34;sent \u0026#34;, i2, \u0026#34; to c2\\n\u0026#34;) case i3, ok := \u0026lt;-c3: if ok {// ok 为 true，表示正常获取到值 i3 fmt.Printf(\u0026#34;received \u0026#34;, i3, \u0026#34; from c3\\n\u0026#34;) } else {// ok 为 false，表示channel因关闭而触发 fmt.Printf(\u0026#34;c3 is closed\\n\u0026#34;) } default: // 走默认分支 fmt.Printf(\u0026#34;no communication\\n\u0026#34;) } // Output: // no communication } 不存在default分支时。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var c1, c2, c3 chan int // nil var i1, i2 int // 由于selectgo函数的源代码可知，go会把所有非nil的channel组成一个send+recv集 // 然后all channel lock 伪随机的遍历case集。 // 由于这里只有Timer.C这个chan在case集中，则获取lock然后从这里读取数据，不能立刻完成则被挂起等待。 select { case i1 = \u0026lt;-c1: fmt.Printf(\u0026#34;received \u0026#34;, i1, \u0026#34;from c1\\n\u0026#34;) case c2 \u0026lt;- i2: fmt.Printf(\u0026#34;sent \u0026#34;, i2, \u0026#34;to c2\\n\u0026#34;) case i3, ok := (\u0026lt;-c3): if ok { fmt.Printf(\u0026#34;received \u0026#34;, i3, \u0026#34;from c3\\n\u0026#34;) } else { fmt.Printf(\u0026#34;c3 is closed\\n\u0026#34;) } // func After(d Duration) \u0026lt;-chan Time // After会在另一线程经过时间段d后向返回值发送当时的时间。等价于NewTimer(d).C case \u0026lt;-time.After(time.Second * 3): // 超时退出 fmt.Println(\u0026#34;request time out\u0026#34;) } // Output: // request time out } 常用用法 超时判断。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) var resChan = make(chan int) func main() { test() // request time out // Output: // request time out } func test() { // 1. case集是send+recv的集合，不包含default // 2. 获取所有 all channel lock // 3. 伪随机遍历所有的case集，寻找是否有立刻完成channel。 // 4. 如果都没有则以sudog形式封装当前goroutine挂在所有的channel上，all channel unlock 再次调度循环等待唤醒。 // 5. 当goroutine被唤醒，处理所有挂在channel上的sudog，然后返回，因为数据交换已经在唤醒前处理了。 select { case data := \u0026lt;-resChan: // 等待从resChan中读取数据 doData(data) case \u0026lt;-time.After(time.Second * 3): // 3秒后会像time.C通道中写入当前时间，这里得到选中 fmt.Println(\u0026#34;request time out\u0026#34;) } } func doData(data int) { fmt.Println(\u0026#34;doData：\u0026#34;, data) } 判断channel是否阻塞。 1 2 3 4 5 6 7 8 9 10 11 // 在某些情况下是存在不希望channel缓存满了的需求的，可以用如下方法判断 ch := make (chan int, 5) // ... data：= 0 // tryLock 形式，是否能立即完成。 select { case ch \u0026lt;- data: default: //做相应操作，比如丢弃data。视需求而定 } select作用在channel c\u0026lt;-v 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // compiler implements // // select { // case c \u0026lt;- v: // ... foo // default: // ... bar // } // // as // // if selectnbsend(c, v) { // ... foo // } else { // ... bar // } func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { // selected返回值 true.该分支被选中 false.该分支不会被选中 return chansend(c, elem, false, getcallerpc()) } v\u0026lt;-c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // compiler implements // // select { // case v = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if selectnbrecv(\u0026amp;v, c) { // ... foo // } else { // ... bar // } func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { // chanrecv函数存在两个返回值 布尔 // selected 返回值 true.该分支被选中 false.该分支不会被选中 // 第二个返回值，当前是否读取数据成功， false.读取失败 true.读取成功 selected, _ = chanrecv(c, elem, false) return } v, ok = \u0026lt;-c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // compiler implements // // select { // case v, ok = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if c != nil \u0026amp;\u0026amp; selectnbrecv2(\u0026amp;v, \u0026amp;ok, c) { // ... foo // } else { // ... bar // } func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. // chanrecv函数存在两个返回值 布尔值 // selected 返回值 true.该分支被选中 false.该分支不会被选中 // 第二个返回值，当前是否读取数据成功， false.读取失败 true.读取成功 selected, *received = chanrecv(c, elem, false) return } ","permalink":"https://heliu.site/posts/golang/process/select/","summary":"Golang select介绍。","title":"流程控制(select)"},{"content":"package 包的概念 使用包来组织管理代码，包是结构化代码的一种方式。 每个.go文件都必须归属于某一个包，每个.go文件都可能有init()函数。 包名在源文件中第一行通过关键字package指定，包名要小写。 1 package fmt 每个目录下面可以有多个.go文件，这些文件只能属于同一个包，否则编译时会报错。 同一个包下的不同.go文件相互之间可以直接引用变量和函数，所以这些文件中定义的全局变量和函数不能重名。 Go语言的可执行应用程序必须有main包，而且在main包中必须且只能有一个main()函数。 main函数是应用程序运行开始的入口，在main包中可以使用init()函数。 Go语言不强制要求包的名称和文件所在目录名称相同，但是这两者最好保持相同，否则很容易引起歧义。 因为导入包的时候会使用目录名作为包的路径，而代码中使用时，却要使用包的名称。 包的初始化 可执行应用程序的初始化和执行都起始于main包。 如果main包的源代码中没有包含main()函数，则会引发构建程序错误 undefined: main.mian。 main()函数即没有参数，也没有返回类型，init()函数和main()函数在这一点上一样。 如果main包还导入了其他的包，那么在编译时会将它们依次导入。 有时一个包会被多个包同时导入，那么它只会被导入一次（如很多包可能都会用到fmt包，但它只会被导入一次，因为没有必要导入多次） 当所有被导入的包都加载完毕 就会对main包中的包级常量和变量进行初始化 然后执行main包中的init()函数，最后执行main()函数 导入包的顺序：导入包文件，对(全局)常量和变量进行初始化，然后执行init()函数（如果函数存在的情况下） Go语言中的init()函数常用于包的初始化，该函数是Go语言的一个重要特征。 init函数是用于程序执行前进行包的初始化的函数，例如初始化包里的变量等。 每个包可以拥有多个init函数，（同一个包下不同的.go文件中都允许定义init()函数）。 同一个包中的多个init()函数的执行顺序是随机的。 不同包的init()函数按照包导入的依赖关系决定该函数的执行顺序。 init()函数不能被其他函数调用，其在main函数执行之前，自动被调用。 包的导入 Go语言程序通过导入import关键字将一组包链接在一起通过导入包为程序所使用，程序中未使用的包，不能导入进来。 导入操作会使用目录名作为包的路径而不是包名，实际应用中一般会保持两者一致。 例如标准包中定义的big包：package big;导入时语句为import \u0026quot;math/big\u0026quot;。 导入时源代码在$GOROOT目录下的src/math/big目录中。 程序代码使用big.Int时，big指的是.go文件中定义的包名称。 当导入多个包时，一般按照字母顺序排列包名称。 为避免名称冲突，同一包中所有对象的标识符必须唯一，但是相同的标识符可以在不同的包中使用，因为可以使用包名来区分它们。 1 2 3 package main import \u0026#34;context\u0026#34; // 加载context包 导入多个包的常见的方式。 1 2 3 4 import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) 1 2 // 调用导入的包函数的一般方式 fmt.Println(\u0026#34;hello world!\u0026#34;) 三种特殊的包导入 import (. \u0026quot;fmt\u0026quot;) 点操作含义是包导入之后，在调用这个包的函数时，可以省略前缀的包名。 如fmt.Println(\u0026quot;hello world\u0026quot;)可以写成Println(\u0026quot;hello world\u0026quot;)。 import (f \u0026quot;fmt\u0026quot;) 别名操作就是可以把包命名成另外一个容易记住的名字。 如fmt.Println(\u0026quot;hello world\u0026quot;)可以写成f.Println(\u0026quot;hello world\u0026quot;)。 import (_ \u0026quot;fmt\u0026quot;) _操作是引入某个包，但不直接使用包里的函数，而是调用该包里面的init函数。 有时在开发中由于某种原因某个原来导入的包现在不在使用，也可以采用这种方式处理。 1 2 3 4 import ( _ \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; ) 标准库 在Go语言的安装目录里包含标准库的各种包，在$GOROOT/src中可以看到源码，可以根据情况自行重新编译。 访问https://golang.google.cn/pkg/#stdlib了解更多详情。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 unsafe: 包含了一些打破Gp语言“类型安全”的命令，一边的程序中不会被调用，可用在C++程序的调试中 syscall-os-os/exec: os: 提供给我们一个平台无关性的操作系统功能接口，采用类似UNIX设计，隐藏了不同操作系统间的差异，让不同的文件系统和操作系统对象表现一致 os/exec: 提供运行外部操作系统命令和程序方式 syscall: 底层的外部包，提供了操作系统底层调用的基本接口 archive/tar 和 /zip-compress: 压缩(解压缩)文件功能 fmt-io-bufio-path/filepath-flag: fmt: 提供格式化输入输出的功能 io: 提供基本输入输出功能，大多数是围绕系统功能的封装 bufio: 缓冲输入输出功能的封装 path/filepath: 用来操作在当前系统中的目标文件名路径 flag: 对命令行参数的操作 strings-strconv-unicode-regexp-bytes: strings: 提供对字符的操作 strconv: 提供将字符串转换为基础类型的功能 unicode: 为unicode型的字符串提供特殊的功能 regexp: 正则表达式功能 bytes: 提供对字符型分片的操作 math-math/cmath-math/big-math/rand-sort: math: 基本的数学函数 math/cmath: 对复数的操作 math/rand: 伪随机数生成 sort: 为数组排序和自定义集合 math/big: 大数的实现和计算 container-/list-ring-heap: 实现对集合的操作 list: 双链表 ring: 环形链表 time-log: time: 日期和时间的基本操作 log: 记录程序运行时产生的日志 encoding/JSON-encoding/xml-text/template: encoding/json: 读取并解码和写入并编码json数据 encoding/xml: 简单的XML1.0解析器 text/template: 生成像HTML一样的数据与文本混合的数据驱动模板 net-net/http-html: net: 网络数据的基本操作 http: 提供了一个可扩展的HTTP服务器和客户端，解析HTTP请求和回复 html: HTML5解析器 runtime: Go程序运行时的交互操作，例如垃圾回收和协程创建 reflect: 实现通过程序运行时反射，让程序操作任意类型的变量 从github安装包 如果想安装github上的项目到本地计算机，可打开终端执行：go get -u github.com/ffhelicopter/tmm。 现在这台计算机上的其他Go引用程序也可以通过导入路径github.com/ffhelicopter/tmm来使用。 import \u0026quot;github.com/ffhelicopter/tmm\u0026quot; Go对包的版本管理不是很友好，至少在go1.10前是如此，不过现在第三方项目做得不错. 有兴趣的读者可以了解一下（glide、godep、govendor）. Gomodules是1.11版本解决“包依赖管理”的实验性技术方案，后面章节学习。 导入外部安装包 如果要在应用中使用一个或多个外部包，可以使用go install在本地计算机上安装它们。 go install是自动包安装工具，如需要将包安装到本地，它会从远端仓库下载包，完成检出、编译和安装。 包安装的先决条件是要自动处理包自身依赖关系，被依赖的包也会安装到子目录下。 如果想使用https://github.com/gocolly/colly这种托管在Google Code、GitHub和Launchpad等代码网站上的包。 也可以通过如下命令安装：go install github.com/gocolly/colly。 将一个名为github.com/gocolly/colly的包安装在$GoPATH/pkg/目录下。 go install/build用来编译包和依赖的包，区别如下： go build只对main包有效，在当前目录编译生成一个可执行的二进制文件，依赖包生成的静态库文件放在$GOOATH/pkg。 go install一般生成静态文件，放在$GOPATH/pkg目录下，文件扩展名为a。 如果为main包，运行go build则会在$GOPATH/bin生成一个可执行的二进制文件。 使用Godoc 在程序中一般都会使用注释，按照一定规则，Godoc工具会收集这些注释并产生一个技术文档。 Godoc会为每个文件生成一系列的网页。 访问Godoc文档的方法是： 命令行下进入目录并输入命令：godoc -http=:6060 -goroot=\u0026quot;.\u0026quot;。 然后在浏览器中打开地址：http://localhost:6060。 此时会看到本地的Godoc页面，从左到右一次显示出目录中的包。 或者直接在浏览器中打开地址http://localhost:6060/pkg/go42/chapter-4/4.2/1/。 Go程序的编译 在Go语言中，和编译有关的命令主要是go run、go build、go install这三个命令。 go run只能作用于main包文件。 先运行compile命令生成.a文件。 然后链接命令生成最终可执行文件并运行程序，此过程中产生的是临时文件。 在go run退出前会删除这些临时文件（含.a文件和可执行文件）。 最后直接在命令行输出程序执行结果。 go run命令在第二次执行的时候，如果发现导入的代码包没有发生变化。 则不会再次编译这个导入的代码包，而是直接进行链接生成最终可执行文件并运行程序。 go install用于编译并安装指定的代码包及它们的依赖包。 并且将编译后生成的可执行文件放到bin目录下（$GOPATH/bin）。 编译后的包文件放到当前工作区的pkg的平台相关目录下。 go build用于编译指定的代码包以及它们的依赖包。 如果用来编译非main包的源码，则只做检查性的编译，而不会输出任何结果文件。 如果是一个可执行程序的源码（即main包），过程与go run大体相同，只是会在当前目录生成一个可执行文件。 使用go build是有一个地方注意： 对外发布编译文件时如果不希望被人看到源代码，可使用go build -ldflags命令。 设置参数【-ldflags \u0026quot;-w -s\u0026quot;】再编译发布，这样使用gdb调试时无法看到源代码。 GO111MODULE Go 1.11新增了对模块的支持，希望借此解决“包依赖管理”问题。 可以通过设置环境变量GO111MODULE来开启或关闭模块支持，它有三个可选值：off、on、auto，默认值是auto。 GO111MODULE = off 无模块支持，go会从GOPATH和vendor文件夹寻找包。 GO111MODEL = on 模块支持，go会从GOPATH和vendor文件夹，值根据go.mod下载依赖。 GO111MODEL = auto 在$GOPATH/src外面且根目录有go.mod文件时，开启模块支持。 ","permalink":"https://heliu.site/posts/golang/package/bag/","summary":"Golang 包介绍。","title":"package"},{"content":" 用法：go mod \u0026lt;command\u0026gt; [arguments]。 command支持命令列表： 命令 go mod \u0026lt;command\u0026gt; 作用 go mod init 生成 go.mod 文件 go mod download 下载 go.mod 文件中指明的所有依赖 go mod tidy 整理现有的依赖 go mod graph 查看现有的依赖结构 go mod edit 编辑 go.mod 文件 go mod vendor 导出项目所有的依赖到vendor目录 go mod verify 校验一个模块是否被篡改过 go mod why 查看为什么需要依赖某模块 go mod init 用法：go mod init [module-path]。 示例： # 初始化当前目录并创建一个go.mod文件，模块路径根据其他条件推断判断 $ go mod init # 初始化当前目录并创建一个go.mod文件，模块路径为example.com/m $ go mod init example.com/m 介绍： go mod init命令在当前目录中初始化并写入一个新的go.mod文件，实际上创建了一个以当前目录为根的新模块。 go.mod文件必须不存在时执行上面命令，否则会提示go.mod文件已存在提示。 如当前存在一个空项目demo，在demo目录下执行go mod init gitee.com/bms/demo，会生成如下go.mod文件，当前go版本是go1.16.3。 module gitee.com/bms/demo go 1.16 init接受一个可选参数，即新模块的模块路径，有关选择模块路径的说明，请参阅模块路径。 如果省略了模块路径参数，init将尝试使用.go文件、vendoring工具配置文件和当前目录（如果在GOPATH中）中的导入注释来推断模块路径。 如果存在vendoring工具的配置文件，init将尝试从中导入模块需求。 init支持以下配置文件： GLOCKFILE (Glock) Godeps/Godeps.json (Godeps) Gopkg.lock (dep) dependencies.tsv (godeps) glide.lock (glide) vendor.conf (trash) vendor.yml (govend) vendor/manifest (gvt) vendor/vendor.json (govendor) Vendoring工具配置文件无法始终以完美的保真度进行翻译。 例如，同一个仓库中的多个包在不同版本中导入，而仓库中只包含一个模块，那么导入的go.mod就只能需要一个版本的模块。 您可能希望运行go list -m all以检查构建列表中的所有版本，并运行go mod tidy以添加缺少的需求并删除未使用的需求。 go mod download 将命名的模块下载到模块缓存中（模块缓存参考官方模块参考文档）。 参数可以是模块路径或模块模式，选择主模块的依赖项或表单的版本查询path@version。 不带参数，download适用于主模块的所有依赖项。 该go命令将在正常执行期间根据需要自动下载模块。 go mod download命令主要用于预填充模块缓存或加载要由模块代理服务的数据。 默认情况下，download不向标准输出写入任何内容。它将进度消息和错误打印到标准错误。 用法：go mod download [-json] [-x] [modules] -json： -json：download将一系列JSON对象打印到标准输出，描述每个下载的模块（或失败） 对应如下结构： type Module struct { Path string // 模块路径 Version string // 模块版本 Error string // 错误模板描述 Info string // 缓存的 .info 文件的绝对路径 GoMod string // 缓存 .mod 文件的绝对路径 Zip string // 缓存的 .zip 文件的绝对路径 Dir string // 缓存源根目录的绝对路径 Sum string // checksum路径，版本（比如在go.sum） GoModSum string // go.mod的checksum（比如在go.sum） -x：download打印命令download执行到标准错误 示例： $ go mod download -json -x gitee.com/phpbms/demo { \u0026#34;Path\u0026#34;: \u0026#34;gitee.com/phpbms/demo\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;v0.0.0-20211021090521-71a745ffbccb\u0026#34;, \u0026#34;Info\u0026#34;: \u0026#34;/mnt/g/Go/worker/pkg/mod/cache/download/gitee.com/phpbms/demo/@v/v0.0.0-20211021090521-71a745ffbccb.info\u0026#34;, \u0026#34;GoMod\u0026#34;: \u0026#34;/mnt/g/Go/worker/pkg/mod/cache/download/gitee.com/phpbms/demo/@v/v0.0.0-20211021090521-71a745ffbccb.mod\u0026#34;, \u0026#34;Zip\u0026#34;: \u0026#34;/mnt/g/Go/worker/pkg/mod/cache/download/gitee.com/phpbms/demo/@v/v0.0.0-20211021090521-71a745ffbccb.zip\u0026#34;, \u0026#34;Dir\u0026#34;: \u0026#34;/mnt/g/Go/worker/pkg/mod/gitee.com/phpbms/demo@v0.0.0-20211021090521-71a745ffbccb\u0026#34;, \u0026#34;Sum\u0026#34;: \u0026#34;h1:JJlXgKY8MUQtOlnSHtbIsHtRU9DNbxx9NUgpsDt3pQA=\u0026#34;, \u0026#34;GoModSum\u0026#34;: \u0026#34;h1:6H8vzSoXg8Ey2gdfFaP7ToLmbOnfc04IAcuTFDKqSV8=\u0026#34; } go mod tidy go mod tidy确保go.mod文件与模块中的源代码匹配。 它添加了构建当前模块的包和依赖项所需的任何缺失的模块要求，并删除了对不提供任何相关包的模块的要求。 它还向go.sum添加任何缺失的条目并删除不必要的条目。 go mod tidy通过递归加载主模块中的所有包以及它们导入的所有包来工作，这包括测试导入的包（包括其他模块中的测试）。 go mod tidy就像启用了所有构建标记一样，因此它会考虑特定于平台的源文件和需要自定义构建标记的文件，即使这些源文件通常不会被构建。 有一个例外：忽略构建标记未启用，因此不会考虑具有构建约束【// +build ignore】的文件。 请注意，go mod tidy不会考虑主模块中名为testdata或名称以.或_除非这些包是由其他包显式导入的。 一旦go mod tidy加载了这组包，它会确保提供一个或多个包的每个模块在主模块的go.mod文件中都有一个require指令，或者如果主模块在go 1.16或更低版本 - 是必需的另一个必需的模块。 go mod tidy将添加对每个缺失模块的最新版本的要求（有关最新版本的定义，请参阅版本查询），go mod tidy将删除不提供上述集合中任何包的模块的require指令。 go mod tidy还可以添加或删除require 指令的// indirect，// indirect间接注释表示模块不提供由主模块中的包导入的包。 用法：go mod tidy [-e] [-v] [-go=version] [-compat=version]。 介绍： -e：(在Go 1.16中添加)在加载包时遇到错误时尝试继续。 -v：将有关已删除模块的信息打印到标准错误。 -go=：将go指令更新为指定的版本，根据该版本启用或禁用模块图修剪和延迟模块加载（并根据需要添加或删除// indirect间接注释）。 -compat=：当模块图由go指令中指示的版本之前的Go版本加载时，go mod tidy将检查所选版本的模块是否不会更改。还可以通过-compat标志显式指定版本检查的兼容性。 go mod graph 以文本形式打印模块需求图。 用法：go mod graph [-go=version]。 介绍： 模块图中的每个顶点代表一个模块的特定版本，图中的每条边代表对依赖项的最低版本的要求。 go mod graph打印图形的边缘，每行一个。 每行有两个空格分隔的字段：模块版本及其依赖项之一。 每个模块版本都标识为path@version形式的字符串。 主模块没有@version后缀，因为它没有版本。 -go=：go mod graph报告给定Go版本加载的模块图，而不是go.mod文件中的go指令指示的版本。 有关如何选择版本的更多信息，请参阅最小版本选择(MVS)。 另请参阅go list -m以打印选定的版本，并查看go mod why以了解为什么需要模块。 example.com/main example.com/a@v1.1.0 example.com/main example.com/b@v1.2.0 example.com/a@v1.1.0 example.com/b@v1.1.1 example.com/a@v1.1.0 example.com/c@v1.3.0 example.com/b@v1.1.0 example.com/c@v1.1.0 example.com/b@v1.2.0 example.com/c@v1.2.0 go mod edit 该命令提供了一个用于编辑和格式化go.mod文件的命令行界面，主要供工具和脚本使用。 go mod edit只读取一个go.mod文件，它不查找有关其他模块的信息。 默认情况下，go mod edit读取和写入go.mod主模块的文件，但可以在编辑标志后指定不同的目标文件。 用法：go mod edit [editing flags] [-fmt|-print|-json] [go.mod] editing flags：指定编辑操作选项：(editing flags可以重复使用，按给定的顺序) -module：更改模块的路径(go.mod文件的module行)，修改module行模块名称。 -go=version：设置go.mod文件的Go版本。 -require=path@version：添加指定的模块路径和版本上的要求，会覆盖go.mod上的任何现有要求path。 -droprequire=path：删除指定的模块路径和版本上的要求。 -exclude=path@version：增加给定的模块路径，-exclude=path@version如果该排除已存在， 则为空操作。 -dropexclude=path@version：放弃对给定的模块路径和版本的排除。 -replace=old[@v]=new[@v]：添加了给定模块路径和版本对的替换。 如果省略old@v则添加左侧没有版本的替换，这适用于旧模块路径的所有版本。 如果省略new@v则新路径应该是本地模块根目录，而不是模块路径。 注意：-replace覆盖的任何冗余替换old[@v]，因此省略@v将删除特定版本的替换。 -dropreplace=old[@v]：丢弃给定模块路径和版本对的替换。 如果@v提供了，则删除给定版本的替换,左侧没有版本的现有替代品仍可更换模块。 如果@v省略 ，则删除没有版本的替换。 -retract=version：添加回收对于给定的版本，其可以是一个单一的版本（如v1.2.3）或间隔（等[v1.1.0,v1.2.0]）。 注意：-retract标志不能为retract指令添加基本原理注释。 -dropretract=version：删除回收对于给定的版本。 -fmt、-print、-json：额外标志来控制输出。 -fmt：重新格式化go.mod文件而不进行其他更改。 使用或重写go.mod文件的任何其他修改也暗示了这种重新格式化。 唯一需要此标志的情况是没有指定其他标志，如go mod edit -fmt。 -print：go.mod以其文本格式打印final ，而不是将其写回磁盘（就是打印go.mod文件内容）。 -json：go.mod以 JSON 格式打印最终结果，而不是以文本格式将其写回磁盘go mod edit -json。 // json打印格式 { \u0026#34;Module\u0026#34;: { \u0026#34;Path\u0026#34;: \u0026#34;mymod\u0026#34; }, \u0026#34;Go\u0026#34;: \u0026#34;1.17\u0026#34;, \u0026#34;Require\u0026#34;: [ { \u0026#34;Path\u0026#34;: \u0026#34;gitee.com/phpbms/demo\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;v0.0.0-20211021090521-71a745ffbccb\u0026#34;, \u0026#34;Indirect\u0026#34;: true } ], \u0026#34;Exclude\u0026#34;: null, \u0026#34;Replace\u0026#34;: null, \u0026#34;Retract\u0026#34;: null } // 对应相关结构体 type Module struct { Path string Version string } type GoMod struct { Module Module Go string Require []Require Exclude []Module Replace []Replace } type Require struct { Path string Version string Indirect bool } type Replace struct { Old Module New Module } type Retract struct { Low string High string Rationale string } 示例： # 添加替换指令 $ go mod edit -replace example.com/a@v1.0.0=./a # 删除替换指令 $ go mod edit -dropreplace example.com/a@v1.0.0 # 设置go版本，添加需求，打印文件而不是写入磁盘 $ go mod edit -go=1.14 -require=example.com/m@v1.0.0 -print # 格式化 go.mod 文件 $ go mod edit -fmt # 格式化并打印不同的 .mod 文件 $ go mod edit -print tools.mod # 打印 go.mod 文件的 JSON 表示 $ go mod edit -json # 所有命令使用 $ go mod edit -module=mydemo1 -go=1.16 -require=gitee.com/phpbms/demo/v3@v3.0.0 -exclude=gitee.com/phpbms/demo/v3@v3.0.1 -replace=gitee.com/phpbms/demo/v2@v2.0.1=gitee.com/phpbms/demo/v2@v2.0.0 -retract=v1.1.1 -print ./go.mod # 修改go版本，从之前的 go 1.20 修改为 go 1.21rc2 $ go mod edit -go 1.21rc2 go mod vendor 在主模块的根目录中构造一个名为vendor的目录，该目录包含支持主模块中包的构建和测试所需的所有包的副本。 不包括仅通过主模块之外的包测试导入的包。 与go mod tidy和其他模块命令一样，在构建vendor目录时不考虑除了ignore之外的构建约束。 当启用vendoring时，go命令将从vendor目录加载包，而不是将模块从其源下载到模块缓存中，并使用那些下载副本的包。 go mod vendor还会创建文件vendor/modules.txt，其中包含vendor包的列表以及从中复制它们的模块版本。 当启用vendoring时，此清单用作模块版本信息的来源，如go list -m和go version -m所报告的。 当go命令读取vendor/modules.txt时，它会检查模块版本是否与go.mod一致。 如果go.mod在vendor/modules.txt生成后发生了变化，则应再次运行go mod vendor。 请注意，go mod vendor会在重新构建之前删除vendor目录（如果它存在）。 不应对vendor的软件包进行本地更改。 go命令不会检查vendor目录中的包是否未被修改，但是可以通过运行go mod vendor并检查没有进行任何更改来验证vendor目录的完整性。 使用：go mod vendor [-e] [-v]。 -e：（在Go 1.16中添加）在加载包时遇到错误时尝试继续。 -v：将vendor模块和包的名称打印为标准错误。 go mod verify 检查存储在模块缓存中的主模块的依赖项自下载以来没有被修改。 执行此检查，对每个下载的module.zip文件和提取的目录进行散列然后将这些散列与首次下载模块时记录的散列进行比较。 go mod verify 检查构建列表中的每个模块（可以使用go list -m all打印所有模块）。 如果所有模块都未修改，则go mod verify 打印all modules verified否则，它将报告哪些模块已更改并以非零状态退出。 注意：所有模块感知命令都会验证主模块的go.sum文件中的哈希值是否与为下载到模块缓存中的模块记录的哈希值匹配。 如果go.sum中缺少哈希（例如，因为模块是第一次使用），则go命令使用校验和数据库验证其哈希。 除非模块路径与GOPRIVATE或GONOSUMDB匹配。 go mod verify不会为不在缓存中的模块下载内容，也不会使用go.sum文件来验证模块内容。 但是，go mod verify可能会下载go.mod文件以执行最少的版本选择。 它将使用go.sum来验证这些文件，并且可能会为丢失的哈希添加go.sum条目。 用法：go mod verify。 $ go mod verify all modules verified go mod why go mod why在导入图中显示从主模块到每个列出的包的最短路径。 用法：go mod why [-m] [-vendor] packages...。 -m：go mod why将其参数视为模块列表。 go mod why会打印每个模块中任何包的路径。 请注意，即使使用-m，go mod why查询包图，而不是go mod graph打印的模块图。 -vendor：go mod why忽略主模块之外的包测试中的导入（就像go mod vendor所做的那样）。 默认情况下， go mod why会考虑与all模式匹配的包图。 这个标志在Go 1.16之后在声明go 1.16或更高版本的模块中无效（使用go.mod中的go指令），因为all的含义已更改以匹配go mod供应商匹配的包集。 示例： 输出是一个节序列，每个在命令行上命名的包或模块都有一个节，用空行分隔。 每节以注释行开头，以#开头，给出目标包或模块。 后续行给出了通过导入图的路径，每行一个包。 如果包或模块不是从主模块引用的，则该节将显示一个带括号的注释，表明该事实。 $ go mod why golang.org/x/text/language golang.org/x/text/encoding # golang.org/x/text/language rsc.io/quote rsc.io/sampler golang.org/x/text/language # golang.org/x/text/encoding (main module does not need package golang.org/x/text/encoding) ","permalink":"https://heliu.site/posts/golang/package/module/","summary":"Golang go modules命令介绍。","title":"go modules"},{"content":" 用法：go work \u0026lt;command\u0026gt; [arguments] command 列表： edit：从工具或脚本编辑 go.work。 init：初始化工作区文件。 sync：将工作区构建列表同步到模块。 use：将模块添加到工作区文件。 go work init 用法：go work init [moddirs]。 init在当前目录中初始化并写入一个新的go.work文件，实际上是在当前目录中创建了一个新的工作空间。 go work init可选择接受工作区模块的路径作为参数。如果省略该参数，将创建一个没有模块的空工作区。 每个参数路径都添加到go.work文件中的use指令中。 当前的go版本也将列在go.work文件中。 示例： 1 2 # 初始化一个新的工作区，后面参数就是具体的子模块 $ go work init ./queue ./hello 1 2 3 4 5 6 7 8 9 // 项目目录构成 workspace |-- queue # 子模块 | |-- go.mod | |-- queue.go |-- hello # 子模块 | |-- go.mod | |-- main.go\t|-- go.work # 工作区 通常go.work文件不要提交到git上，因为它主要用于本地代码开发。 go work edit 用法：go work edit [editing flags] [go.work]。用于编辑go.work文件。 go work edit命令提供了一个用于编辑go.work的命令行界面，主要供工具或脚本使用。 它只读取go.work;它不查找有关所涉及模块的信息。如果没有指定文件，edit在当前目录及其父目录中查找go.work文件。 editing flags fmt：重新格式化go.work文件而不进行其他更改。使用或重写go.work文件的任何其他修改也暗示了这种重新格式化。唯一需要此标志的情况是没有指定其他标志。 示例：go work edit -fmt。用于格式化go.work文件。 $ go work edit -fmt -use=path：从go.work文件的模块目录集中添加use指令。建议使用go work use指令。 示例：go work edit -use=./queue。添加子模块。 $ go work edit -use ./ququq -dropuse=path：从go.work文件的模块目录集中删除use指令。 示例：go work edit -dropuse=./queue。删除子模块queue。 $ go work edit -dropuse ./queue -replace=old[@v]=new[@v]：添加了给定模块路径和版本对的替换。 如果old@v中的@v被省略，则添加左侧没有版本的替换，适用于旧模块路径的所有版本。 如果省略new@v中的@v，则新路径应该是本地模块根目录，而不是模块路径。 请注意，-replace会覆盖old[@v]的任何冗余替换，因此省略@v将删除特定版本的现有替换。 示例：go work edit -replace myzx.cn/helium/queue=./queue。 $ go work edit -replace myzx.cn/helium/queue=./queue -dropreplace=old[@v]：删除给定模块路径和版本对的替换。如果省略了@v，则会删除左侧没有版本的替换。 示例：go work edit -dropreplace myzx.cn/helium/queue。 $ go work edit -dropreplace myzx.cn/helium/queue -go=version：设置预期的Go语言版本。 示例：go work edit -go 1.19。 $ go work edit -go 1.19 这些editing flags可以重复使用。 更改按给定的顺序应用。 go work edit有额外的标志来控制它的输出 -print：以文本格式打印最终的go.work，而不是将其写回go.mod。 $ go work edit -print -json：以JSON格式打印最终的go.work文件，而不是将其写回go.mod。 $ go work edit -json JSON输出对应于以下Go类型： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type Module struct { Path string Version string } type GoWork struct { Go string Directory []Directory Replace []Replace } type Use struct { Path string ModulePath string } type Replace struct { Old Module New Module } go work use 用法：go work use [-r] [moddirs]。use指定使用的模块目录。 go work use命令提供了一个命令行界面，用于将目录（可选地以递归方式）添加到go.work文件中。 use指令将被添加到命令行go.work文件中列出的每个参数目录的go.work文件（如果它存在于磁盘上），或者从go.work文件中删除（如果它不存在于磁盘上）。 删除功能使用：go work edit -dropuse ./queue命令。 -r：递归搜索参数目录中的模块，并且使用命令就像每个目录都被指定为参数一样操作：即，将为存在的目录添加使用指令，为不存在的目录删除使用指令。 递归的添加子模块到当前工作区，这对于子模块引用了很多模块很用用处。 示例：go work use ./queue，添加queue子模块。 $ go work use ./queue go work sync 用法：go work sync。没有参数。 go work sync命令将工作区的构建列表同步回工作区的模块。该命令会修改go.work文件。 工作区的构建列表是用于在工作区中进行构建的所有（传递）依赖模块的版本集。go work sync使用最小版本选择(MVS)算法生成该构建列表，然后将这些版本同步回工作区中指定的每个模块（使用use指令）。 一旦计算了工作区构建列表，工作区中每个模块的go.mod文件都会被重写，并使用与该模块相关的依赖项进行升级以匹配工作区构建列表。请注意，最小版本选择保证每个模块的构建列表版本始终与每个工作区模块中的相同或更高。 $ go work sync go env GOWORK 查看环境变量，查看当前工作区文件路径。可以排查工作区文件是否设置正确。go.work路径找不到可以使用GOWORK指定。 示例： $ go env GOWORK G:\\workspace\\go.work 禁用工作区，直接把GOWORK设置为off即可。 ","permalink":"https://heliu.site/posts/golang/package/work/","summary":"Golang go work 命令介绍。","title":"go work"},{"content":"GO111MODULE Go语言提供了GO111MODULE这个环境变量来作为Go modules的开关，其允许设置以下参数： auto：只要项目包含了go.mod文件(在$GOPATH/src外面且根目录有go.mod文件时)的话启用Go modules。 on：启用Go modules，推荐设置，会忽略GOPATH和vendor文件夹，只根据go.mod下载依赖。 off：禁用Go modules，不推荐设置，会从GOPATH和vendor文件夹寻找包。 GO111MODULE相关解释： GO111MODULE这个命名代表着Go语言在1.11版本添加的，针对Module的变量。 像是在Go1.5版本的时候，也发布了一个系统环境变量GO15VENDOREXPERIMENT。 作用是用于开启vendor目录的支持，当时其默认值也不是开启，仅仅作为experimental。 其随后在Go1.6版本时也将默认值改为了开启，并且最后作为了official，GO15VENDOREXPERIMENT系统变量就退出了历史舞台。 而未来GO111MODULE这一个系统环境变量也会面临这个问题，不去除是为了兼容老版本。 $ go env -w GO111MODULE=auto GOPROXY 这个环境变量主要是用于设置Go模块代理，直接通过镜像站点来快速拉取。 GOPROXY的默认值是：https://proxy.golang.org,direct，这有一个很严重的问题，就是https://proxy.golang.org在国内是无法访问的。 在该配置下，go命令首先去Google运行的Go模块镜像，如果镜像没有模块，则回退到直接连接。 可以设置GOPRIVATE和GONOPROXY环境变量以防止使用代理下载特定模块。 中国大陆推荐使用 go env -w GOPROXY=https://goproxy.cn,direct。 其他源地址列表：https://goproxy.cn、https://goproxy.io、https://goproxy.baidu.com/。 GOPROXY的值是一个以英文逗号(,)或竖线(|)分割的Go模块代理列表，允许设置多个模块代理。 假设你不想使用，也可以将其设置为“off” ，这将会禁止Go在后续操作中使用任何Go模块代理。也就是go env -w GOPROXY=off。 direct 是什么? 是一个特殊指示符，用于指示Go回源到模块版本的源地址去抓取（比如GitHub等）。 当值列表中上一个Go模块代理返回404或410错误时，Go自动尝试列表中的下一个。 遇见“direct”时回源，也就是回到源地址去抓取，而遇见EOF时终止并抛出类似“invalid version: unknown revision...”的错误。 模块代理URL列表，以逗号 (,) 或竖线 (|) 分隔： 当go命令查找某个模块的信息时，它会依次联系列表中的每个代理，直到收到成功响应或终端错误为止。 代理可能会以404（未找到）或410（已消失）状态响应，以指示该模块在该服务器上不可用。 go命令的错误回退行为由URL之间的分隔符决定： ,：go命令会在404或410错误后回退到下一个URL，所有其他错误都被视为终端错误。 |：go命令在出现任何错误（包括超时等非HTTP错误）后回退到下一个源。 GOPROXY的URL可能具有https、http或file方案，如果URL没有方案，则假定为https。 模块缓存可以直接用作文件代理：go env -w GOPROXY=file://$(go env GOMODCACHE)/cache/download。 可以使用两个关键字代替代理URL： off：禁止从任何来源下载模块。 direct：直接从版本控制存储库下载，而不是使用模块代理。 $ go env -w GOPROXY=https://goproxy.cn,direct GOSUMDB 用于在拉取模块版本时（无论是从源站拉取还是通过Go module proxy拉取）保证拉取到的模块版本数据未经过篡改。若发现不一致，也就是可能存在篡改，将会立即中止。 GOSUMDB的默认值为：sum.golang.org，在国内也是无法访问的，但是GOSUMDB可以被Go模块代理所代理。 因此我们可以通过设置GOPROXY来解决，而先前我们所设置的模块代理goproxy.cn就能支持代理sum.golang.org。 所以这一个问题在设置GOPROXY后，你可以不需要过度关心。 另外若对GOSUMDB的值有自定义需求，其支持如下格式： 格式 1：\u0026lt;SUMDB_NAME\u0026gt;+\u0026lt;PUBLIC_KEY\u0026gt;。 格式 2：\u0026lt;SUMDB_NAME\u0026gt;+\u0026lt;PUBLIC_KEY\u0026gt; \u0026lt;SUMDB_URL\u0026gt;。 也可以将其设置为“off”，也就是禁止Go在后续操作中校验模块版本，也就是go env -w GOSUMDB=off。 如果GOSUMDB设置为off或者使用go get设置-insecure标志则不会查询校验和数据库，并接受所有无法识别的模块。 代价是放弃对所有模块进行已验证的可重复下载的安全保证。 绕过特定模块的校验和数据库的更好方法是使用GOPRIVATE或GONOSUMDB环境变量。 相关参考文档：https://goproxy.io/zh/docs/GOSUMDB-env.html。 GOPRIVATE 用于当前项目依赖了私有模块，如你公司的私有git仓库，又或是github中的私有库，都是属于私有模块，都是要进行设置的，否则会拉取失败。 就是依赖了由GOPROXY指定的Go模块代理或由GOSUMDB指定Go checksum database都无法访问到的模块时的场景。 以英文逗号“,”分割的模块路径前缀，也就是可以设置多个，例如： go env -w GOPRIVATE=\u0026quot;git.example.com,github.com/helium/bms\u0026quot;。 设置后，前缀为git.xxx.com和github.com/helium/bms的模块都会被认为是私有模块。 如果不想每次都重新设置，我们也可以利用通配符，例如： go env -w GOPRIVATE=\u0026quot;*.example.com\u0026quot;。 这样子设置的话，所有模块路径为example.com的子域名(例如：git.example.com)都将不经过Go module proxy和Go checksum database。 需要注意的是不包括example.com本身。 相关参考文档：https://goproxy.io/zh/docs/GOPRIVATE-env.html。 GONOPROXY 用于指定不使用模块代理（如proxy.golang.org）下载模块的模块路径前缀列表。 模块代理是Go 1.13及以上版本推出的功能，用于缓存公共模块，以加快模块下载速度和提高模块下载的可靠性。 该变量包含一个由逗号分隔的模块路径前缀列表。 如果你有一个私有模块存储在 git.example.com，并希望Go命令直接从该仓库下载模块而不是通过模块代理，你可以设置GONOPROXY=git.example.com。 GONOSUMDB 用于指定不检查其校验和的模块路径前缀列表。 Go modules使用校验和数据库（如sum.golang.org）来确保下载的模块版本没有被篡改。 与GONOPROXY类似，该变量也包含一个由逗号分隔的模块路径前缀列表。 假设你有私有模块并且不希望Go命令尝试验证这些模块的校验和，你可以设置GONOSUMDB=git.example.com。 GOVCS 控制go命令可以用来下载公共和私有模块，（由它们的路径是否与GOPRIVATE中的模式匹配）或其他与glob模式匹配的模块的版本控制工具集。 如果未设置GOVCS，或者模块与GOVCS中的任何模式都不匹配，则go命令可能对公共模块使用git和hg，或对私有模块使用任何已知的版本控制工具。 具体来说，go命令就像GOVCS被设置为（默认模式）：public:git|hg,private:all。 ","permalink":"https://heliu.site/posts/golang/package/env/","summary":"Golang 环境变量介绍。","title":"模块相关环境变量"},{"content":" 工作区是磁盘上模块的集合，在运行最小版本选择(MVS)时用作根模块。 工作空间可以在go.work文件中声明，该文件指定工作空间中每个模块的模块目录的相对路径。 当不存在go.work文件时，工作区由包含当前目录的单个模块组成。 大多数与模块一起使用的go子命令在由当前工作空间确定的模块集上运行。 go mod init、go mod why、go mod edit、go mod tidy、go mod vendor和go get始终在单个主模块上运行。 命令首先检查-workfile标志来确定它是否在工作区上下文中。如果-workfile设置为off，则该命令将位于单模块上下文中。 如果它为空或未提供，该命令将搜索当前工作目录，然后是后续父目录，以查找文件go.work。如果找到一个文件，该命令将在它定义的工作空间中运行； 否则，工作区将仅包含包含工作目录的模块。如果-workfile命名以.work结尾的现有文件的路径，则将启用工作区模式。任何其他值都是错误。 go.work文件一般不传到git上，只是本地一个公共区文件。 go.work文件 工作空间由名为go.work，UTF-8编码文本文件定义。 go.work文件是面向行的。每行包含一个指令，由关键字和参数组成。 例如： go 1.18 use ./my/first/thing use ./my/second/thing replace example.com/bad/thing v1.4.5 =\u0026gt; example.com/good/thing v1.4.5 与go.mod文件一样，可以从相邻行中分解出前导关键字来创建块。 use ( ./my/first/thing ./my/second/thing ) go命令提供了几个用于操作go.work文件的子命令。 go work init：创建新的go.work文件。 go work use：将模块目录添加到go.work文件中。 go work edit：执行低级编辑。 go work sync：将工作区构建列表同步到模块。 Go程序可以使用golang.org/x/mod/modfile包以编程方式进行相同的更改。 词汇元素 go.work文件中的词法元素的定义方式与go.mod文件完全相同。 语法 go.work语法在下面使用扩展巴科斯-瑙尔形式(EBNF)指定。有关EBNF语法的详细信息，请参阅Go语言规范中的符号部分。 1 2 3 4 GoWork = { Directive } . Directive = GoDirective | UseDirective | ReplaceDirective . 换行符(newline)、标识符(ident)和字符串(string)分别表示。 模块路径和版本用ModulePath和Version表示。模块路径和版本的指定方式与go.mod文件完全相同。 1 2 ModulePath = ident | string . /* see restrictions above */ Version = ident | string . /* see restrictions above */ go指令 有效的go.work文件中需要go指令。版本必须是有效的Go发行版本：一个正整数，后跟一个点和一个非负整数（例如，1.18、1.19）。 go指令指示go.work文件打算使用的go工具链版本。如果对go.work文件格式进行了更改，工具链的未来版本将根据其指示的版本解释文件。 一个go.work文件最多可以包含一个go指令。 1 2 GoDirective = \u0026#34;go\u0026#34; GoVersion newline . GoVersion = string | ident . /* valid release version; see above */ 示例： go 1.18 use指令 用户将磁盘上的模块添加到工作空间中的主要模块集。它的参数是包含模块的go.mod文件的目录的相对路径。 使用use指令不会添加包含在其参数目录的子目录中的模块。 这些模块可以通过包含其go.mod文件的目录添加到单独的使用指令中。 1 2 3 UseDirective = \u0026#34;use\u0026#34; ( UseSpec | \u0026#34;(\u0026#34; newline { UseSpec } \u0026#34;)\u0026#34; newline ) . UseSpec = FilePath newline . FilePath = /* platform-specific relative or absolute file path */ 示例： use ./mymod // example.com/mymod use ( ../othermod ./subdir/thirdmod ) replace指令 与go.mod文件中的replace指令类似，go.work文件中的replace指令将模块的特定版本或模块的所有版本的内容替换为其他地方的内容。 go.work中的通配符替换会覆盖go.mod文件中特定于版本的替换。 go.work文件中的replace指令会覆盖工作区模块中相同模块或模块版本的任何替换。 1 2 3 4 ReplaceDirective = \u0026#34;replace\u0026#34; ( ReplaceSpec | \u0026#34;(\u0026#34; newline { ReplaceSpec } \u0026#34;)\u0026#34; newline ) . ReplaceSpec = ModulePath [ Version ] \u0026#34;=\u0026gt;\u0026#34; FilePath newline | ModulePath [ Version ] \u0026#34;=\u0026gt;\u0026#34; ModulePath Version newline . FilePath = /* platform-specific relative or absolute file path */ 示例： replace golang.org/x/net v1.2.3 =\u0026gt; example.com/fork/net v1.4.5 replace ( golang.org/x/net v1.2.3 =\u0026gt; example.com/fork/net v1.4.5 golang.org/x/net =\u0026gt; example.com/fork/net v1.4.5 golang.org/x/net v1.2.3 =\u0026gt; ./fork/net golang.org/x/net =\u0026gt; ./fork/net ) 错误的go.work 同时在use和replace指定相同的本地路径。同时指定./example。 go 1.18 use ( ./hello ./example ) replace ( github.com/link1st/example =\u0026gt; ./example ) ","permalink":"https://heliu.site/posts/golang/package/go-work/","summary":"Golang go.work文件内容介绍。","title":"go.work 文件"},{"content":" 模块由其根目录中名为go.mod，UTF-8编码文本文件定义。 go.mod文件是面向行的。每行包含一个指令，由关键字后跟参数组成。例如： 1 2 3 4 5 6 7 8 9 module example.com/my/thing go 1.12 require example.com/other/thing v1.0.2 require example.com/new/thing/v2 v2.3.4 exclude example.com/old/thing v1.2.3 replace example.com/bad/thing v1.4.5 =\u0026gt; example.com/good/thing v1.4.5 retract [v1.9.0, v1.9.5] 前导关键字可以从相邻行中分解出来以创建一个块，就像在Go import中一样。 1 2 3 4 require ( example.com/new/thing/v2 v2.3.4 example.com/old/thing v1.2.3 ) go.mod文件被设计为人类可读和机器可写。go命令提供了几个更改go.mod文件的子命令。例如： go get可以升级或降级特定的依赖项。 加载模块图的命令将在需要时自动更新go.mod。 go mod edit可以执行低级编辑。 主模块以及使用本地文件路径指定的任何替换指令替换都需要一个go.mod文件。但是，缺少明确的go.mod文件的模块可能仍然需要作为依赖项，或者用作使用模块。 词汇元素 对一个go.mod文件进行分析，其内容被分成标记形式。 有几种标记：空格、注释、标点符号、关键字、标识符和字符串。 空白：由空格(U+0020)、制表符(U+0009)、回车(U+000D)和换行符(U+000A)组成。 除了换行符之外的空白字符没有任何作用，除非分隔本来与其他组合的标记。 换行符是重要的标记。 注释：以//开始到行尾。/**/注释不允许添加注释文案。 标点符号：包括（,）和=\u0026gt;。 关键字：是区分go.mod文件中不同种类的指令。 允许的关键字module，go，require，replace，exclude，retract。 标识符：非空白字符的序列，例如模块路径或语义版本。 字符串：带引号的字符序列，有两种字符串： 以引号(\u0026quot;,U+0022)开头和结尾的解释字符串。 解释的字符串可能包含由反斜杠(\\,U+005C)后跟另一个字符组成的转义序列。 转义引号(\\\u0026quot;)不会终止已解释的字符串。 解释字符串的不带引号的值是引号之间的字符序列，每个转义序列都被反斜杠后面的字符\\\u0026ldquo;替换（例如，被替换为\u0026rdquo;，\\n被替换为n）。 以重音符 (`,U+0060)开头和结尾的原始字符串。 相比之下，原始字符串的不带引号的值只是重音符之间的字符序列，反斜杠在原始字符串中没有特殊含义。 标识符和字符串在go.mod语法中是可以互换的。 模块路径和版本 go.mod文件中的大多数标识符和字符串要么是模块路径，要么是版本。 模块路径必须满足以下要求： 路径必须由一个或多个以斜线(/,U+002F)分隔的路径元素组成，它不能以斜线开头或结尾。 每个路径是由多个ASCII字母，ASCII数字或非空字符串，和有限的ASCII标点符号（-、.、_、~）。 路径元素不能以点(., U+002E)开始或结束。 直到第一个点的元素前缀不能是Windows上的保留文件名，无论大小写（CON、com1、NuL等），不能以con.或com1.或Nul.等开头。 第一个点之前的元素前缀不得以波浪号(~)后跟一个或多个数字（如EXAMPL~1.COM）结尾。 如果模块路径出现在require指令中并且没有被替换，或者模块路径出现在replace指令的右侧，则该go命令可能需要下载具有该路径的模块，并且必须满足一些附加要求。 前导路径元素（直到第一个斜杠，如果有的话），按照约定，域名必须只包含小写ASCII字母、ASCII数字、点（.,U+002E）和破折号（-,U+002D）它必须至少包含一个点，并且不能以破折号开头。 对于形式的最终路径元素/vN在那里N是数字（ASCII数字和点），N不得带前导零的开始，一定不能/v1，一定不能包含任何圆点。 对于以gopkg.in/开头的路径，此要求将替换为路径遵循gopkg.in服务约定的要求。 go.mod文件中的版本可能是规范的或非规范的，规范版本以字母v开头，后跟符合语义版本控制2.0.0规范的语义版本。 非规范版本只允许在主模块的go.mod文件中，该go命令将尝试时，它会自动用等效的规范版本替换每个非规范版本更新的go.mod文件。 在一个模块路径与版本相关的地方（如require，replace和exclude指令），最后的路径元素必须与版本是一致的，请参阅主要版本后缀。 语法 go.mod下面使用扩展巴科斯-诺尔形式(EBNF)指定语法。有关EBNF语法的详细信息，请参阅Go语言规范中的符号部分。 1 2 3 4 5 6 7 GoMod = { Directive } . Directive = ModuleDirective | GoDirective | RequireDirective | ExcludeDirective | ReplaceDirective | RetractDirective . 换行，标识符和字符串分别标注newline，ident和 string。 模块路径和版本用ModulePath和表示Version。 1 2 ModulePath = ident | string . /* see restrictions above */ Version = ident | string . /* see restrictions above */ module模块指令 一个module指令定义了主模块的路径。一个go.mod文件必须只包含一个module指令。 module指令定义了模块名称： ModuleDirective = \u0026quot;module\u0026quot; ( ModulePath | \u0026quot;(\u0026quot; newline ModulePath newline \u0026quot;)\u0026quot; ) newline . 示例： module golang.org/x/net Deprecated：弃用标志 可以在Deprecated:段落开头包含字符串（区分大小写）的注释块中将模块标记为已弃用。 弃用消息在冒号之后开始并运行到段落的末尾。注释可能出现在module指令之前或之后出现在同一行。 示例： // Deprecated: 改用 example.com/mod/v2 module example.com/mod 从Go 1.17开始，go list -m -u检查构建列表中所有弃用模块的信息。go get检查构建在命令行上命名的包所需的不推荐使用的模块。 当该go命令检索模块的弃用信息时，它会从与@latest版本查询匹配的版本加载go.mod文件，而不考虑撤回的或排除的。go命令从同一个go.mod文件加载撤回。 要弃用模块，作者可以添加// Deprecated:评论并标记新版本。作者可能会在更高版本中更改或删除弃用消息。 弃用适用于模块的所有次要版本。以v2为例，主版本高于被认为是单独的模块，因为它们的主版本后缀为它们提供了不同的模块路径。 弃用消息旨在通知用户该模块不再受支持并提供迁移说明，例如迁移到最新的主要版本。不能弃用单个次要版本和补丁版本，retract可能更适合单个版本。 go 版本指令 一个go指令表明一个模块是在假设Go的给定版本的语义的情况下编写的。 版本必须是有效的Go发布版本：一个正整数，后跟一个点和一个非负整数（例如，1.9,1.14）。示例：go 1.14。 go指令最初旨在支持Go语言的向后不兼容更改（请参阅Go 2 transition）。 自引入模块以来，没有发生不兼容的语言更改，但该go指令仍然影响新语言功能的使用： 对于模块内的包，编译器拒绝使用在go指令指定的版本之后引入的语言功能。例如，如果一个模块有指令go 1.12，它的包可能不会使用像1_000_000 Go 1.13中引入的数字文字。 如果较旧的Go版本构建模块的包之一并遇到编译错误，则该错误会指出该模块是为较新的Go版本编写的。假设一个模块有go 1.13一个包使用数字文字1_000_000。如果该包是用Go 1.12构建的，编译器会注意到代码是为Go 1.13编写的。 在go 1.17或更高版本： go.mod文件为每个模块包含一个显式的require指令，该指令提供由主模块中的包或测试传递导入的任何包。（在go 1.16及更低版本中，仅当最小版本选择会选择不同版本时才包含间接依赖项。）此额外信息启用模块图修剪和延迟模块加载。 由于可能存在// indirect比以前go版本更多的依赖项 ，因此间接依赖项记录在go.mod文件中的单独块中。 go mod vendor省略了vendor依赖的go.mod和go.sum文件。（这允许在vendor的子目录中调用go命令来识别正确的主模块。） go mod vendor将go每个依赖项go.mod文件的版本记录在vendor/modules.txt。 一个go.mod文件最多可以包含一个go指令。如果当前Go版本不存在，大多数命令会添加一个go指令。 1 2 GoDirective = \u0026#34;go\u0026#34; GoVersion newline . GoVersion = string | ident . /* valid release version; see above */ require 需求指令 一个require指令声明一个给定的模块依赖的最低版本。对于每个所需的模块版本，go命令加载该版本的go.mod文件并合并来自该文件的require。加载所有require后，go命令将使用最小版本选择 (MVS)解决它们以生成构建列表。 go命令会自动为某些require添加// indirect间接依赖注释。// indirect表示主模块中的任何包都不会直接导入所需模块中的包。 如果go指令指定go 1.16或更低版本，则当所选模块的版本高于主模块的其他依赖项已经暗示（传递）的版本时，go命令会添加一个indirect。这可能是由于显式升级（go get -u ./...）、删除了先前强加要求的其他依赖项（go mod tidy），或者导入了一个包而没有相应要求的依赖项go.mod文件（例如完全缺少go.mod文件的依赖项） 在go 1.17及更高版本中，go命令为每个模块添加了一个indirect，该模块提供由主模块中的包或测试导入（甚至indirect）的任何包，或作为参数传递给go get。 这些更全面的要求支持模块图修剪和延迟模块加载。 1 2 RequireDirective = \u0026#34;require\u0026#34; ( RequireSpec | \u0026#34;(\u0026#34; newline { RequireSpec } \u0026#34;)\u0026#34; newline ) . RequireSpec = ModulePath Version newline . 示例： 1 2 3 4 5 6 require golang.org/x/net v1.2.3 require ( golang.org/x/crypto v1.4.5 // indirect golang.org/x/text v1.6.7 ) exclude 排除指令 exclude指令防止模块版本被go命令加载。(排除指定的模块版本) 从Go 1.16开始，如果任何go.mod文件中的require指令引用的版本被主模块的go.mod文件中的exclude指令排除，则该require将被忽略。 这可能会导致像go get和go mod tidy这样的命令将更高版本的新要求添加到go.mod，如果合适，带有// indirect。 在Go 1.16之前，如果一个排除的版本被require指令引用，go命令会列出模块的可用版本（如go list -m -versions所示）并加载下一个更高的非排除版本。这可能导致不确定的版本选择，因为下一个更高的版本可能会随着时间的推移而改变。为此目的，发行版和预发行版都被考虑在内，但伪版本则不然。如果没有更高版本，go命令报错。 exclude指令仅适用于主模块的go.mod文件，在其他模块中被忽略。有关详细信息，请参阅最小版本选择。 1 2 ExcludeDirective = \u0026#34;exclude\u0026#34; ( ExcludeSpec | \u0026#34;(\u0026#34; newline { ExcludeSpec } \u0026#34;)\u0026#34; newline ) . ExcludeSpec = ModulePath Version newline . 示例： 1 2 3 4 5 6 exclude golang.org/x/net v1.2.3 exclude ( golang.org/x/crypto v1.4.5 golang.org/x/text v1.6.7 ) replace 替换指令 replace指令用在别处找到的内容替换模块的特定版本或模块的所有版本的内容。以使用另一个模块路径和版本或特定于平台的文件路径来指定替换。 如果箭头左侧(=\u0026gt;)存在某个版本，则仅替换该模块的特定版本。其他版本将正常访问。如果省略左版本，则替换模块的所有版本。 如果箭头右侧的路径是绝对或相对路径（以./或../开头），则解释为替换模块根目录的本地文件路径，必须包含一个go.mod文件。在这种情况下必须省略替换版本。 如果右侧的路径不是本地路径，则必须是有效的模块路径。在这种情况下，需要一个版本。相同的模块版本不得出现在构建列表中。 不管替换是用本地路径还是模块路径指定的，如果替换模块有go.mod文件，它的module指令必须匹配它替换的模块路径。 replace指令仅适用于主模块的go.mod文件，在其他模块中被忽略。有关详细信息，请参阅最小版本选择。 如果有多个主模块，则应用所有主模块的 go.mod 文件。 不允许跨主模块冲突的替换指令，并且必须在 go.work 文件的替换中删除或覆盖。 请注意，单独的replace指令不会将模块添加到模块图中。在主模块的go.mod文件或依赖项的go.mod文件中，还需要引用替换模块版本的require指令。如果不需要左侧的模块版本，则替换指令无效。 1 2 3 4 ReplaceDirective = \u0026#34;replace\u0026#34; ( ReplaceSpec | \u0026#34;(\u0026#34; newline { ReplaceSpec } \u0026#34;)\u0026#34; newline ) . ReplaceSpec = ModulePath [ Version ] \u0026#34;=\u0026gt;\u0026#34; FilePath newline | ModulePath [ Version ] \u0026#34;=\u0026gt;\u0026#34; ModulePath Version newline . FilePath = /* platform-specific relative or absolute file path */ 示例： 1 2 3 4 5 6 7 8 replace golang.org/x/net v1.2.3 =\u0026gt; example.com/fork/net v1.4.5 replace ( golang.org/x/net v1.2.3 =\u0026gt; example.com/fork/net v1.4.5 golang.org/x/net =\u0026gt; example.com/fork/net v1.4.5 golang.org/x/net v1.2.3 =\u0026gt; ./fork/net golang.org/x/net =\u0026gt; ./fork/net ) retract 撤回指令 retract指令指示不应依赖由go.mod定义的模块的版本或版本范围。当版本过早发布或版本发布后发现严重问题时，撤回指令很有用。撤回的版本应该在版本控制存储库和模块代理中保持可用，以确保依赖于它们的构建不会被破坏。撤回这个词是从学术文献中借来的：被撤回的研究论文仍然可用，但它有问题，不应作为未来工作的基础。 当模块版本被撤回时，用户不会使用go get、go mod tidy或其他命令自动升级到它。依赖于撤回版本的构建应该继续工作，但是当用户使用go list -m -u检查更新或使用go get更新相关模块时，会收到撤回通知。 要撤回一个版本，模块作者应该向go.mod添加一个撤回指令，然后发布一个包含该指令的新版本。新版本必须高于其他发布或预发布版本。也就是说，在考虑撤回之前，@latest版本查询应该解析为新版本。go命令从go list -m -retracted $modpath@latest（其中$modpath是模块路径）显示的版本加载并应用撤回。 除非使用-retracted标志，否则从go list -m -versions打印的版本列表中隐藏已撤回的版本。解析@\u0026gt;=v1.2.3或@latest之类的版本查询时，将排除撤回的版本。 包含撤回的版本可能会撤回自己。如果模块的最高发行版或预发行版自行收回，则在排除收回的版本后，@latest查询将解析为较低版本。 例如，考虑模块example.com/m的作者意外发布版本v1.0.0的情况。为了防止用户升级到v1.0.0，作者可以在go.mod中添加两个撤消指令，然后将撤回标记为v1.0.1。 1 2 3 4 retract ( v1.0.0 // 意外发布 v1.0.1 // 仅包含撤回 ) 当用户运行go get example.com/m@latest时，go命令从v1.0.1读取撤回，现在是最高版本。v1.0.0和v1.0.1都已撤回，因此go命令将升级（或降级！）到下一个最高版本，可能是v0.9.5。 撤回指令可以使用单个版本（如v1.0.0）或具有上下限的封闭区间版本编写，由[和]分隔（如[v1.1.0, v1.2.0]）。单个版本相当于上下限相同的区间。像其他指令一样，多个撤回指令可以组合在一个块中，由（在一行的末尾和）在它自己的行上分隔。 每个撤回指令都应该有一个注释来解释撤回的理由，尽管这不是强制性的。go命令可能会在有关撤回版本的警告和go列表输出中显示撤回注释。撤回注释可以写在撤回指令的正上方（中间没有空行），也可以写在同一行之后。如果注释出现在块上方，则它适用于块内没有自己注释的所有撤回指令。撤回注释可能跨越多行。 1 2 RetractDirective = \u0026#34;retract\u0026#34; ( RetractSpec | \u0026#34;(\u0026#34; newline { RetractSpec } \u0026#34;)\u0026#34; newline ) . RetractSpec = ( Version | \u0026#34;[\u0026#34; Version \u0026#34;,\u0026#34; Version \u0026#34;]\u0026#34; ) newline . 示例： 1 2 3 4 5 6 retract v1.0.0 retract [v1.0.0, v1.9.9] retract ( v1.0.0 [v1.0.0, v1.9.9] ) Retract指令是在Go 1.16中添加的。如果在主模块的go.mod文件中写入了撤回指令，则Go 1.15及更低版本将报告错误，并且将忽略依赖项的go.mod文件中的撤回指令。 自动更新 如果go.mod缺少信息或不能准确反映现实，大多数命令都会报告错误。go get和go mod tidy命令可用于解决大多数这些问题。 此外，-mod=mod标志可以与大多数模块感知命令（go build、go test等）一起使用，以指示go命令自动修复go.mod和go.sum中的问题。 例如，考虑这个go.mod文件： 1 2 3 4 5 6 7 8 9 10 11 12 13 module example.com/M go 1.16 require ( example.com/A v1 example.com/B v1.0.0 example.com/C v1.0.0 example.com/D v1.2.3 example.com/E dev ) exclude example.com/D v1.2.3 使用-mod=mod触发的更新将非规范版本标识符重写为规范semver形式，因此example.com/A的v1变为v1.0.0，example.com/E的dev成为dev上最新提交的伪版本分支，可能是v0.0.0-20180523231146-b3f5c0f6e5f1。 该更新修改了要求以遵守排除规则，因此对排除的example.com/D v1.2.3的require更新为使用example.com/D的下一个可用版本，可能是v1.2.4或v1.3.0。 此更新删除了多余或误导性的要求。例如，如果example.com/A v1.0.0本身需要example.com/B v1.2.0和example.com/C v1.0.0，那么 go.mod对example.com/B v1.0.0的要求具有误导性（已取代通过example.com/A需要v1.2.0），并且它对example.com/C v1.0.0的要求是多余的（暗示example.com/A需要相同版本），因此两者都将被删除。如果主模块包含直接从example.com/B或example.com/C导入包的包，那么需求将被保留但更新到正在使用的实际版本。 最后，更新以规范格式重新格式化go.mod，以便未来的机械更改将导致最小差异。 如果只需要更改格式，go命令将不会更新go.mod。 因为模块图定义了import语句的含义，所以任何加载包的命令也使用go.mod，因此可以更新它，包括go build、go get、go install、go list、go test、go mod tidy。 在Go 1.15及更低版本中，默认启用-mod=mod标志，因此会自动执行更新。从Go 1.16开始，go命令的行为就像设置了-mod=readonly一样，如果需要对go.mod进行任何更改，则go命令会报告错误并建议修复。 ","permalink":"https://heliu.site/posts/golang/package/go-mod/","summary":"Golang go.mod文件内容介绍。","title":"go.mod 文件"},{"content":" 本教程介绍Go中多模块工作区的基础知识。使用多模块工作区，您可以告诉Go命令您正在同时在多个模块中编写代码，并轻松地在这些模块中构建和运行代码。 在本教程中，您将在共享的多模块工作区中创建两个模块，对这些模块进行更改，并在构建中查看这些更改的结果。 必须条件： Go 1.18或更高版本的安装。 用于编辑代码的工具。 您拥有的任何文本编辑器都可以正常工作。 一个命令终端。Go在Linux和Mac上的任何终端以及Windows中的PowerShell或cmd上都能很好地工作。 本教程需要go1.18或更高版本。 使用go.dev/dl中的链接，确保您已在Go 1.18或更高版本中安装了Go。 创建一个模块 首先，为您要编写的代码创建一个模块。 打开命令提示符并切换到您的主目录。 在Linux或Mac上：cd。 在Windows上：C:\\\u0026gt; cd %HOMEPATH%。 本教程的其余部分将显示$作为提示。您使用的命令也可以在Windows上运行。 在命令提示符下，为您的代码创建一个名为工作区的目录。 1 2 $ mkdir workspace $ cd workspace 初始化模块 我们的示例将创建一个hello依赖于golang.org/x/example模块的新模块。 创建hello模块： 1 2 3 4 $ mkdir hello $ cd hello $ go mod init example.com/hello go: creating new go.mod: module example.com/hello 使用go get添加对golang.org/x/example模块的依赖（如果有需要）。 1 2 3 $ go get golang.org/x/example go: downloading golang.org/x/example v0.0.0-20220304235025-ad95e7f791d8 go get: added golang.org/x/example v0.0.0-20220304235025-ad95e7f791d8 在hello目录下创建hello.go，内容如下： 1 2 3 4 5 6 7 8 9 10 11 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/example/stringutil\u0026#34; ) func main() { fmt.Println(stringutil.Reverse(\u0026#34;Hello\u0026#34;)) } 现在，运行hello程序： 1 2 3 $ go mod tidy $ go run . olleH 目录结构为： 1 2 3 4 |--workspace |----hello |------hello.go |------go.mod 创建工作区 在这一步中，我们将创建一个go.work文件来指定模块的工作区。 初始化工作区 在workspace目录中，运行： 1 2 3 # go1.18beta2.exe work init ./hello ## 本地用的go1.18beta2版本 # 当前目录是 hello 的上级目录下，执行完go work init后会生成一个go.work文件 $ go work init ./hello go work init命令告诉go为包含./hello目录中的模块的工作空间创建一个go.work文件。 go命令生成一个如下所示的go.work文件： go 1.18 use ./hello go.work文件的语法与go.mod相似。 go指令告诉Go应该使用哪个版本的Go来解释文件。它类似于go.mod文件中的go指令。 use指令告诉Go在构建时hello目录中的模块应该是主模块。 因此，在工作区的任何子目录中，该模块都将处于活动状态。 目录结构为： 1 2 3 4 5 |--workspace |----hello |------hello.go |------go.mod |----go.work 运行工作区下的目录 在workspace目录中，运行： 1 2 3 # go1.18beta2.exe run example.com/hello $ go run example.com/hello olleH Go命令包括工作区中的所有模块作为主模块。这允许我们在模块中引用一个包，甚至在模块之外。 在模块或工作区之外运行go run命令会导致错误，因为go命令不知道要使用哪些模块。 接下来，我们将golang.org/x/example模块的本地副本添加到工作区。然后，我们将向stringutil包添加一个新函数，我们可以使用它来代替Reverse。 下载和修改golang.org/x/example模块 在这一步中，我们将下载包含golang.org/x/example模块的Git存储库的副本，将其添加到工作区，然后向其中添加一个我们将从hello程序中使用的新函数。 克隆存储库，在workspace目录中，运行git命令来克隆存储库： 1 2 3 4 5 6 7 8 $ git clone https://github.com/golang/example Cloning into \u0026#39;example\u0026#39;... remote: Enumerating objects: 182, done. remote: Counting objects: 100% (30/30), done. remote: Compressing objects: 100% (20/20), done. remote: Total 182 (delta 6), reused 16 (delta 4), pack-reused 152R Receiving objects: 100% (182/182), 138.39 KiB | 1.05 MiB/s, done. Resolving deltas: 100% (74/74), done. 将模块添加到工作区。 1 2 # go1.18beta2.exe work use ./example $ go work use ./example go work use命令将一个新模块添加到go.work文件中。它现在看起来像这样： go 1.18 use ( ./hello ./example ) 目录结构： 1 2 3 4 5 6 7 8 |--workspace |----hello |------hello.go |------go.mod |----example |------stringutil |--------reverse.go |----go.work 该模块现在包括example.com/hello模块和golang.org/x/example模块。 这将允许我们使用我们将在stringutil模块的副本中编写的新代码，而不是使用go get命令下载的模块缓存中的模块版本。 添加新功能： 我们将在golang.org/x/example/stringutil包中添加一个将字符串大写的新函数。 将新文件夹添加到包含以下内容的workspace/example/stringutil目录：并命令为upper.go文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package stringutil import \u0026#34;unicode\u0026#34; // ToUpper uppercases all the runes in its argument string. func ToUpper(s string) string { r := []rune(s) for i := range r { r[i] = unicode.ToUpper(r[i]) } return string(r) } 修改hello程序以使用该功能，修改workspace/hello/hello.go的内容，包含以下内容： 1 2 3 4 5 6 7 8 9 10 11 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/example/stringutil\u0026#34; ) func main() { fmt.Println(stringutil.ToUpper(\u0026#34;Hello\u0026#34;)) } 运行workspace目录下代码 从workspace目录，运行： 1 2 # go1.18beta2.exe run example.com/hello $ go run example.com/hello Go命令在go.work文件指定的hello目录中查找命令行中指定的example.com/hello模块，同样使用go.work文件解析golang.org/x/example导入。 可以使用go.work而不是添加替换指令来跨多个模块工作。 由于这两个模块位于同一个工作区中，因此很容易在一个模块中进行更改并在另一个模块中使用它。 ","permalink":"https://heliu.site/posts/golang/package/use-work/","summary":"Golang work使用介绍。","title":"工作区使用"},{"content":" 在本教程中，您将创建两个模块。第一个是旨在由其他库或应用程序导入的库。第二个是调用者应用程序，它将使用第一个。 本教程的序列包括七个简短的主题，每个主题都说明了语言的不同部分： 创建一个模块 —— 编写一个小模块，其中包含可以从另一个模块调用的函数。 从另一个模块调用您的代码 —— 导入并使用您的新模块。 返回并处理错误 —— 添加简单的错误处理。 返回一个随机的问候 —— 在切片中处理数据（Go 的动态大小的数组）。 返回多人的问候 —— 在 map 中存储 键/值 对。 添加测试 —— 使用 Go 的内置单元测试功能来测试你的代码。 编译和安装应用程序 —— 在本地编译和安装你的代码。 启动一个其他人可以使用的模块 首先创建一个Go模块。在一个模块中，您为一组离散且有用的功能收集一个或多个相关包。例如，您可能会创建一个包含具有财务分析功能的包的模块，以便其他编写财务应用程序的人可以使用您的工作。有关开发模块的更多信息，请参阅 开发和发布模块。 Go代码被分组到包中，包被分组到模块中。您的模块指定了运行代码所需的依赖项，包括 Go 版本和它所需的一组其他模块。 当您在模块中添加或改进功能时，您会发布模块的新版本。编写调用模块中函数的代码的开发人员可以导入模块的更新包并使用新版本进行测试，然后再将其投入生产使用。 打开命令提示符并cd到您的主目录： 在 Linux 或 Mac 上：cd。 在 Windows 上：cd %HOMEPATH%。 为您的Go模块源代码 创建一个demo目录。 例如，从您的主目录使用以下命令： mkdir greetings1 cd greetings1 使用go mod init命令启动您的模块。运行go mod init命令，给它你的模块路径 —— 在这里，使用gitee.com/phpbms/greetings。 运行go mod init命令，给它你的模块路径——在这里，使用gitee.com/phpbms/greetings。如果您发布一个模块，这必须是Go工具可以从中下载您的模块的路径。那将是您的代码存储库。有关使用模块路径命名模块的更多信息，请参阅 管理依赖项。 $ go mod init gitee.com/phpbms/greetings1 go: creating new go.mod: module gitee.com/phpbms/greetings1 目录结构： |--greetings1/ |----go.mod # gitee.com/phpbms/greetings1 该go mod init命令会创建一个go.mod文件来跟踪代码的依赖关系。到目前为止，该文件仅包含模块的名称和代码支持的Go版本。但是当您添加依赖项时，go.mod文件将列出您的代码所依赖的版本。这使构建保持可重复性，并使您可以直接控制要使用的模块版本。 在您的文本编辑器中，创建一个用于编写代码的文件并将其命名为greetings.go。 将以下代码粘贴到您的greetings.go文件中并保存文件 package greetings1 import \u0026#34;fmt\u0026#34; // Hello returns a greeting for the named person. func Hello(name string) string { message := fmt.Sprintf(\u0026#34;Hi, %v. Welcome!\u0026#34;, name) return message } 这是您的模块的第一个代码。它会向任何请求的呼叫者返回问候语。您将在下一步编写调用此函数的代码，在此代码中： 声明一个greetings1包来收集相关功能。 实现一个Hello函数来返回问候语。 该函数接受一个name类型为的参数string。该函数还返回一个string。在Go中，名称以大写字母开头的函数可以被不在同一个包中的函数调用。这在Go中称为导出名称。有关导出名称的更多信息，请参阅Go tour中的导出名称。 声明一个message变量来保存你的问候，在Go中，:=运算符是在一行中声明和初始化变量的快捷方式（Go使用右侧的值来确定变量的类型）。从长远来看，您可能已将其写为： var message string message = fmt.Sprintf(\u0026#34;Hi, %v. Welcome!\u0026#34;, name) 目录结构： |--greetings1/ |----go.mod\t# gitee.com/phpbms/greetings1 |----greetings.go\t# greetings1 从另一个模块调用您的代码 在(1)中，您创建了一个greetings1模块。在本节中，您将编写代码来调用Hello您刚刚编写的模块中的函数。您将编写可以作为应用程序执行的代码，并调用greetings1模块中的代码。 hello为您的Go模块源代码 创建一个目录。这是你写你的调用者的地方。 创建此目录后，您应该在层次结构的同一级别上同时拥有一个hello和一个greetings目录，如下所示： \u0026lt;home\u0026gt;/ |-- greetings1/ |-- hello2/ 例如，如果您的命令提示符位于greetings1目录中，您可以使用以下命令： cd .. mkdir hello2 cd hello2 为您要编写的代码启用依赖项跟踪，要为您的代码启用依赖项跟踪，请运行go mod init command，并为其提供您的代码所在的模块的名称。 出于本教程的目的，请使用gitee.com/phpbms/hello2模块路径。 $ go mod init gitee.com/phpbms/hello2 go: creating new go.mod: module gitee.com/phpbms/hello2 在文本编辑器的hello2目录中，创建一个用于编写代码的文件并将其命名为hello.go。 编写代码来调用Hello函数，然后打印函数的返回值 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;gitee.com/phpbms/greetings1\u0026#34; ) func main() { message := greetings1.Hello(\u0026#34;Gol\u0026#34;) fmt.Println(message) } 目录结构： |--greetings1/ |----go.mod # gitee.com/phpbms/greetings1 |----greetings.go # greetings1 |--hello2/ |----go.mod # gitee.com/phpbms/hello2 |----hello.go # main 在此代码中：\n声明一个main包。在Go中，作为应用程序执行的代码必须在main包中。 导入两个包：gitee.com/phpbms/greetings1和fmt包。这使您的代码可以访问这些包中的函数。导入gitee.com/phpbms/greetings1（包含在您之前创建的模块中的包）使您可以访问该Hello功能。您还可import fmt，具有处理输入和输出文本的功能（例如将文本打印到控制台） greetings通过调用包的 Hello函数 来获得问候。 编辑gitee.com/phpbms/greetings1模块以使用您的本地gitee.com/phpbms/greetings1模块。\n对于生产用途，您gitee.com/phpbms/greetings1将从其存储库发布模块（使用反映其发布位置的模块路径），Go 工具可以在其中找到它并下载它。目前，由于您尚未发布该模块，您需要调整该example.com/hello模块，以便它可以 gitee.com/phpbms/greetings1在您的本地文件系统上找到代码。\n为此，请使用go mod edit命令编辑example.com/hello模块以将Go工具从其模块路径（模块所在的位置）重定向到本地目录（模块所在的位置）。\n在hello目录中的命令提示符下，运行以下命令： 【go mod edit -replace gitee.com/phpbms/greetings1=../greetings1】。 该命令指定gitee.com/phpbms/greetings1应替换../greetings1为以定位依赖项。运行命令后， hello 目录中的 go.mod 文件应该包含一个replace指令： module gitee.com/phpbms/hello2 go 1.16 replace gitee.com/phpbms/greetings1 =\u0026gt; ../greetings1 在hello目录下的命令提示符下，运行【go mod tidy】命令同步gitee.com/phpbms/hello2模块的依赖，添加代码需要但模块中尚未跟踪的依赖。 $ go mod tidy -v go: found gitee.com/phpbms/greetings1 in gitee.com/phpbms/greetings1 v0.0.0-00010101000000-000000000000 命令完成后，gitee.com/phpbms/hello2模块的go.mod文件应如下所示： module gitee.com/phpbms/hello2 go 1.16 replace gitee.com/phpbms/greetings1 =\u0026gt; ../greetings1 require gitee.com/phpbms/greetings1 v0.0.0-00010101000000-000000000000 该命令在greetings1目录中找到了本地代码，然后添加了一个require指令来指定gitee.com/phpbms/hello2需要gitee.com/phpbms/greetings1。当您在hello.go中导入问候包时，您创建了此依赖项。\n模块路径后面的数字是一个伪版本号 —— 一个生成的数字用来代替语义版本号（模块还没有），要引用已发布的模块，go.mod文件通常会省略replace指令并使用 require末尾带有标记版本号的指令。require gitee.com/phpbms/greetings1 v1.1.0。有关版本号的更多信息，请参阅模块版本编号。\n在hello目录中的命令提示符处，运行您的代码以确认其工作。\n$ go run . Hi, Gol. Welcome! 返回并处理错误 处理错误是可靠代码的基本特征。在本节中，您将添加一些代码来从greetings1模块返回错误，然后在调用者中处理它。 在greetings/greetings.go中，添加下面突出显示的代码，如果您不知道该向谁打招呼，则发送问候是没有意义的。如果名称为空，则向调用者返回错误。将以下代码复制到greetings.go并保存文件。 package greetings1 import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; ) // Hello returns a greeting for the named person. func Hello(name string) (string, error) { if name == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, errors.New(\u0026#34;empty\u0026#34;) } message := fmt.Sprintf(\u0026#34;Hi, %v. Welcome!\u0026#34;, name) return message, nil } 在此代码中： 更改函数，使其返回两个值：a string和an error。您的调用者将检查第二个值以查看是否发生错误。（任何Go函数都可以返回多个值。有关更多信息，请参阅Effective Go。） 导入Go标准库errors包，以便您可以使用其errors.New功能。 添加if语句以检查无效请求（名称应为空字符串），如果请求无效则返回错误。该errors.New函数返回一个 error包含您的消息。 添加nil（意味着没有错误）作为成功返回中的第二个值。这样，调用者就可以看到函数成功了。 在hello2/hello.go文件中，处理Hello函数现在返回的错误以及非错误值。将以下代码粘贴到hello.go中。 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;gitee.com/phpbms/greetings1\u0026#34; \u0026#34;log\u0026#34; ) func main() { // Set properties of the predefined Logger, including // the log entry prefix and a flag to disable printing // the time, source file, and line number. log.SetPrefix(\u0026#34;greetings: \u0026#34;) log.SetFlags(0) // Request a greeting message. message, err := greetings1.Hello(\u0026#34;\u0026#34;) // If an error was returned, print it to the console and // exit the program. if err != nil { log.Fatal(err) } // If no error was returned, print the returned message // to the console. fmt.Println(message) } 在此代码中： 将log包配置为在其日志消息的开头打印命令名称（“greetings:”），不带时间戳或源文件信息。 将两个Hello返回值（包括 ）分配error给变量。 将Hello参数从Gladys的名称更改为空字符串，以便您可以尝试您的错误处理代码。 寻找一个非零error值。在这种情况下继续下去是没有意义的。 使用标准库中的函数log package输出错误信息。如果出现错误，则使用log包的Fatal函数打印错误并停止程序。 在hello目录中的命令行中，运行hello.go以确认代码有效。现在您传入一个空名称，您将收到错误消息。 $ go run . greetings: empty name exit status 1 返回随机问候语句 在本节中，您将更改代码，以便不是每次都返回一个问候语，而是返回多个预定义的问候语消息之一。 为此，您将使用Go切片。切片类似于数组，不同之处在于它的大小会随着您添加和删除项目而动态变化。slice是Go最有用的类型之一。 您将添加一小部分来包含三个问候消息，然后让您的代码随机返回其中一个消息。有关切片的更多信息，请参阅Go博客中的Go切片。 在greetings1/greetings.go中，更改您的代码，使其看起来如下所示。 package greetings1 import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) // Hello returns a greeting for the named person. func Hello(name string) (string, error) { if name == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, errors.New(\u0026#34;empty\u0026#34;) } message := fmt.Sprintf(randomFormat(), name) return message, nil } // init sets initial values for variables used in the function. func init() { rand.Seed(time.Now().UnixNano()) } // randomFormat returns one of a set of greeting messages. The returned // message is selected at random. func randomFormat() string { // A slice of message formats. formats := []string{ \u0026#34;Hi, %v. Welcome!\u0026#34;, \u0026#34;Great to see you, %v!\u0026#34;, \u0026#34;Hail, %v! Well met!\u0026#34;, } return formats[rand.Intn(len(formats))] } 在此代码中： 添加一个randomFormat函数，返回随机选择的问候消息格式。请注意， randomFormat以小写字母开头，使其只能由其自己的包中的代码访问（换句话说，它不会被导出）。 在中randomFormat，声明一个formats具有三种消息格式的切片。当声明一个切片，你在括号忽略它的大小，像这样：[]string。这告诉 Go 切片底层数组的大小可以动态更改。 使用math/rand 包生成一个随机数，用于从切片中选择一个项目。 添加一个init函数以rand使用当前时间为包做种子。Goinit在程序启动时自动执行函数，在全局变量初始化后。有关init函数的更多信息，请参阅 Effective Go。 在中Hello，调用该randomFormat函数以获取您将返回的消息的格式，然后一起使用该格式和name值来创建该消息。 像以前一样返回消息（或错误）。 在hello2/hello.go中，更改您的代码，使其看起来如下所示。您只是将Gladys的名字（或不同的名字，如果您喜欢）作为参数添加到Hello hello.go中的函数调用中。 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;gitee.com/phpbms/greetings1\u0026#34; \u0026#34;log\u0026#34; ) func main() { // Set properties of the predefined Logger, including // the log entry prefix and a flag to disable printing // the time, source file, and line number. log.SetPrefix(\u0026#34;greetings: \u0026#34;) log.SetFlags(0) // Request a greeting message. message, err := greetings1.Hello(\u0026#34;Gla\u0026#34;) // If an error was returned, print it to the console and // exit the program. if err != nil { log.Fatal(err) } // If no error was returned, print the returned message // to the console. fmt.Println(message) } 在命令行的hello目录中，运行hello.go以确认代码有效。多次运行它，注意到问候语发生了变化。 $ hello go run . Great to see you, Gla! $ hello go run . Great to see you, Gla! $ hello go run . Hi, Gla. Welcome! 回复多人问候 在您对模块代码所做的最后更改中，您将添加对在一个请求中为多人获取问候的支持。换句话说，您将处理多值输入，然后将该输入中的值与多值输出配对。为此，您需要将一组名称传递给一个可以为每个名称返回问候语的函数。 但有一个障碍。将Hello函数的参数从单个名称更改为一组名称会更改函数的签名。如果您已经发布了example.com/greetings 模块并且用户已经编写了调用 的代码Hello，那么这种更改会破坏他们的程序。 在这种情况下，更好的选择是编写一个具有不同名称的新函数。新函数将采用多个参数。这保留了旧功能以实现向后兼容性。 在greetings1/greetings.go中，更改您的代码，使其看起来如下所示。 package greetings1 import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) // Hello returns a greeting for the named person. func Hello(name string) (string, error) { if name == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, errors.New(\u0026#34;empty\u0026#34;) } message := fmt.Sprintf(randomFormat(), name) return message, nil } // init sets initial values for variables used in the function. func init() { rand.Seed(time.Now().UnixNano()) } // randomFormat returns one of a set of greeting messages. The returned // message is selected at random. func randomFormat() string { // A slice of message formats. formats := []string{ \u0026#34;Hi, %v. Welcome!\u0026#34;, \u0026#34;Great to see you, %v!\u0026#34;, \u0026#34;Hail, %v! Well met!\u0026#34;, } return formats[rand.Intn(len(formats))] } // Hellos returns a map that associates each of the named people // with a greeting message. func Hellos(names []string) (map[string]string, error) { // A map to associate names with messages. messages := make(map[string]string, len(names)) // Loop through the received slice of names, calling // the Hello function to get a message for each name. for _, name := range names { message, err := Hello(name) if err != nil { return nil, err } // In the map, associate the retrieved message with // the name. messages[name] = message } return messages, nil } 在此代码中： 添加一个Hellos函数，其参数是一段名称而不是单个名称。此外，您将其返回类型之一从a更改string为a，map以便您可以返回映射到问候消息的名称。 让新Hellos函数调用现有Hello函数。这有助于减少重复，同时保留两个功能。 创建messages映射以将每个接收到的名称（作为键）与生成的消息（作为值）相关联。在Go中，您使用以下语法初始化map：您让函数将此映射返回给调用者。有关地图的更多信息，请参阅Go博客上的Go map实战。make(map[*key-type*]*value-type*) 循环遍历您的函数收到的名称，检查每个名称是否具有非空值，然后将消息与每个名称关联。在此 for循环中，range返回两个值：循环中当前项目的索引和项目值的副本。您不需要索引，因此您使用 Go 空白标识符（下划线）来忽略它。有关更多信息，请参阅 Effective Go 中的空白标识符。 在你的hello2/hello.go调用代码中，传递一段名称，然后打印你返回的名称/消息映射的内容。在hello.go中，更改您的代码，使其看起来如下所示。 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;gitee.com/phpbms/greetings1\u0026#34; \u0026#34;log\u0026#34; ) func main() { // Set properties of the predefined Logger, including // the log entry prefix and a flag to disable printing // the time, source file, and line number. log.SetPrefix(\u0026#34;greetings: \u0026#34;) log.SetFlags(0) names := []string{\u0026#34;Gladys\u0026#34;, \u0026#34;Samantha\u0026#34;, \u0026#34;Darrin\u0026#34;} // Request a greeting message. message, err := greetings1.Hellos(names) // If an error was returned, print it to the console and // exit the program. if err != nil { log.Fatal(err) } // If no error was returned, print the returned message // to the console. fmt.Println(message) } 通过这些更改： 创建一个names变量作为包含三个名称的切片类型。 将names变量作为参数传递给 Hellos函数。 在命令行中，切换到包含hello/hello.go的目录，然后使用go run来确认代码是否有效。输出应该是将名称与消息相关联的地图的字符串表示形式，如下所示： $ go run . map[Darrin:Hail, Darrin! Well met! Gladys:Hail, Gladys! Well met! Samantha:Hail, Samantha! Well met!] 添加测试 既然您已经将代码放到了一个稳定的位置（顺便说一句，做得很好），请添加一个测试。在开发期间测试您的代码可以暴露在您进行更改时发现的错误。在本主题中，您将为该Hello函数添加一个测试 。 Go 对单元测试的内置支持使您可以更轻松地进行测试。具体来说，使用命名约定、Go的testing包和go test命令，您可以快速编写和执行测试。 在 greetings1 目录中，创建一个名为greetings_test.go的文件。以_test.go结尾的文件名告诉go test命令该文件包含测试函数。 在greetings_test.go中，粘贴以下代码并保存文件。 package greetings1 import ( \u0026#34;regexp\u0026#34; \u0026#34;testing\u0026#34; ) // TestHelloName calls greetings.Hello with a name, checking // for a valid return value. func TestHelloName(t *testing.T) { name := \u0026#34;Gladys\u0026#34; want := regexp.MustCompile(`\\b`+name+`\\b`) msg, err := Hello(\u0026#34;Gladys\u0026#34;) if !want.MatchString(msg) || err != nil { t.Fatalf(`Hello(\u0026#34;Gladys\u0026#34;) = %q, %v, want match for %#q, nil`, msg, err, want) } } // TestHelloEmpty calls greetings.Hello with an empty string, // checking for an error. func TestHelloEmpty(t *testing.T) { msg, err := Hello(\u0026#34;\u0026#34;) if msg != \u0026#34;\u0026#34; || err == nil { t.Fatalf(`Hello(\u0026#34;\u0026#34;) = %q, %v, want \u0026#34;\u0026#34;, error`, msg, err) } } 在此代码中： 在与您正在测试的代码相同的包中实现测试功能。 创建两个测试函数来测试greetings.Hello 函数。测试函数名称的形式为Test*Name*，其中Name表示特定测试的一些内容。此外，测试函数将指向包testing.T类型的指针作为参数。您可以使用此参数的方法来报告和记录您的测试。 实现两个测试： TestHelloName调用该Hello函数，传递一个name值，该函数应该能够使用该值返回有效的响应消息。如果调用返回错误或意外响应消息（不包含您传入的名称的消息），则使用t参数的Fatalf将消息打印到控制台并结束执行。 TestHelloEmpty``Hello用空字符串调用函数。此测试旨在确认您的错误处理工作正常。如果调用返回非空字符串或没有错误，则使用t参数的Fatalf方法将消息打印到控制台并结束执行。 在greetings目录下的命令行，运行go test命令执行测试，该go test命令执行测试Test文件（名称以_test.go结尾）中的测试函数（名称以Test_开头）。您可以添加-v标志以获取列出所有测试及其结果的详细输出。测试应该通过。 $ go test PASS ok gitee.com/phpbms/greetings1 0.024s $ go test -v === RUN TestHelloName --- PASS: TestHelloName (0.00s) === RUN TestHelloEmpty --- PASS: TestHelloEmpty (0.00s) PASS ok gitee.com/phpbms/greetings1 0.025s 中断greetings.Hello函数以查看失败的测试。该TestHelloName测试功能检查您指定为名称的返回值Hello函数的参数。要查看失败的测试结果，请更改greetings.Hello函数使其不再包含名称。在greetings/greetings.go中，粘贴以下代码代替 Hello函数。请注意，突出显示的行会更改函数返回的值，就好像name参数已被意外删除一样。 // Hello returns a greeting for the named person. func Hello(name string) (string, error) { // If no name was given, return an error with a message. if name == \u0026#34;\u0026#34; { return name, errors.New(\u0026#34;empty name\u0026#34;) } // Create a message using a random format. // message := fmt.Sprintf(randomFormat(), name)\t// 这行替换了 message := fmt.Sprint(randomFormat()) return message, nil } 在greetings目录下的命令行，运行go test执行测试。这一次，在go test没有-v标志的情况下运行。输出将仅包含失败的测试的结果，这在您进行大量测试时非常有用。该TestHelloName测试将失败-TestHelloEmpty还通过。 $ go test -v === RUN TestHelloName greetings_test.go:15: Hello(\u0026#34;Gladys\u0026#34;) = \u0026#34;Hail, %v! Well met!\u0026#34;, \u0026lt;nil\u0026gt;, want match for `\\bGladys\\b`, nil --- FAIL: TestHelloName (0.00s) === RUN TestHelloEmpty --- PASS: TestHelloEmpty (0.00s) FAIL exit status 1 FAIL gitee.com/phpbms/greetings1 0.025s 编译并安装应用程序 在最后一个主题中，您将学习几个新go命令。虽然该go run命令是在您进行频繁更改时编译和运行程序的有用快捷方式，但它不会生成二进制可执行文件。 本主题介绍了两个用于构建代码的附加命令： 该go build命令编译包及其依赖项，但不安装结果。 该go install命令编译并安装软件包。 步骤如下 从hello2目录中的命令行，运行go build 命令将代码编译为可执行文件。 从hello2目录中的命令行，运行新的hello 可执行文件以确认代码有效。请注意，根据您在测试后是否更改了greetings.go代码，您的结果可能会有所不同。 在Linux或Mac上： $ ./hello map[Darrin:Great to see you, Darrin! Gladys:Hail, Gladys! Well met! Samantha:Hail, Samantha! Well met!] 在 Windows 上： $ hello.exe map[Darrin:Great to see you, Darrin! Gladys:Hail, Gladys! Well met! Samantha:Hail, Samantha! Well met!] 您已将应用程序编译为可执行文件，以便可以运行它。但是要当前运行它，您的提示需要位于可执行文件的目录中，或者指定可执行文件的路径。接下来，您将安装可执行文件，以便无需指定其路径即可运行它。 发现 Go 安装路径，该go命令将在其中安装当前包。您可以通过运行命令来发现安装路径， 如下例所示： go list -f \u0026#39;{{.Target}}\u0026#39; 例如，命令的输出可能是/home/gopher/bin/hello，这意味着二进制文件安装到/home/gopher/bin。在下一步中您将需要此安装目录。\n将 Go 安装目录添加到系统的 shell 路径。这样，您就可以运行程序的可执行文件，而无需指定可执行文件的位置。\n在Linux或Mac上，运行以下命令： export PATH=$PATH:/path/to/your/install/directory 在Windows上，运行以下命令： set PATH=%PATH%;C:\\path\\to\\your\\install\\directory 作为替代方案，如果您$HOME/bin在 shell 路径中已经有一个目录 ，并且您想在那里安装 Go 程序，您可以通过GOBIN使用以下命令设置变量来 更改安装目标：go env\ngo env -w GOBIN=/path/to/your/bin // or go env -w GOBIN=C:\\path\\to\\your\\bin 更新 shell 路径后，运行go install命令来编译和安装包。 go install 只需键入其名称即可运行您的应用程序。为了使这变得有趣，打开一个新的命令提示符并hello在其他目录中运行可执行文件名称。 $ hello map[Darrin:Hail, Darrin! Well met! Gladys:Great to see you, Gladys! Samantha:Hail, Samantha! Well met!] ","permalink":"https://heliu.site/posts/golang/package/use-mod/","summary":"Golang 创建模块介绍。","title":"创建模块"},{"content":" 您可以将相关包收集到模块中，然后发布模块供其他开发人员使用。本主题概述了开发和发布模块。 为了支持开发、发布和使用模块，您可以使用： 您开发和发布模块的工作流程，随着时间的推移使用新版本对其进行修改。请参阅【开发和发布模块的工作流程】。 帮助模块用户理解并以稳定方式升级到新版本的设计实践。请参【阅设计和开发】。 用于发布模块和检索其代码的去中心化系统。您使您的模块可供其他开发人员从您自己的存储库中使用并使用版本号发布。请参阅 去中心化出版。 一个包搜索引擎和文档浏览器(pkg.go.dev)，开发人员可以在其中找到您的模块。请参阅包发现。 一种模块版本编号约定，用于向使用您的模块的开发人员传达对稳定性和向后兼容性的期望。请参阅 版本控制。 Go 工具使其他开发人员更容易管理依赖项，包括获取模块的源代码、升级等。请参阅管理依赖项。 也可以看看： 如果您只是对使用其他人开发的软件包感兴趣，那么这不是您的主题。相反，请参阅管理依赖项。 有关包含一些模块开发基础知识的教程，请参阅教程：创建 Go 模块。 开发和发布模块的工作流程 当您想为其他人发布您的模块时，您可以采用一些约定来简化这些模块的使用。 模块发布和版本控制工作流程中更详细地描述了以下高级步骤。 设计和编码模块将包含的包。 使用约定将代码提交到您的存储库，以确保其他人可以通过 Go 工具使用它。 发布模块以使其可被开发人员发现。 随着时间的推移，使用使用版本编号约定的版本来修改模块，以表明每个版本的稳定性和向后兼容性。 设计和开发 如果模块中的功能和包形成一个连贯的整体，您的模块将更容易被开发人员找到和使用。当你设计一个模块的公共 API 时，尽量保持它的功能集中和离散。 此外，在设计和开发模块时考虑到向后兼容性可以帮助其用户升级，同时最大限度地减少他们自己的代码的流失。您可以在代码中使用某些技术来避免发布破坏向后兼容性的版本。有关这些技术的更多信息，请参阅Go博客上的保持模块兼容。 在发布模块之前，您可以使用replace指令在本地文件系统上引用它。这使得在模块仍在开发时编写调用模块中的函数的客户端代码变得更加容易。有关详细信息，请参阅模块发布和版本控制工作流程中的“针对未发布的模块进行编码” 。 去中心化出版 在Go中，您通过在存储库中标记其代码来发布您的模块，以使其可供其他开发人员使用。 您不需要将模块推送到集中式服务，因为Go工具可以直接从您的存储库（使用模块的路径定位，这是一个省略了该方案的URL）或从代理服务器下载您的模块。 在他们的代码中导入你的包后，开发人员使用Go工具（包括go get命令）下载你的模块代码以进行编译。为了支持此模型，您遵循约定和最佳实践，使Go工具（代表其他开发人员）可以从存储库中检索模块的源代码。 例如，Go工具使用你指定的模块的模块路径，以及你用来标记模块以发布的模块版本号，为它的用户定位和下载模块。 有关源和发布约定以及最佳实践的更多信息，请参阅管理模块源。 有关发布模块的分步说明，请参阅发布模块。 包发现 在您发布了您的模块并且有人使用Go工具获取了它之后，它将在Go包发现站点pkg.go.dev上可见。在那里，开发人员可以搜索该站点以找到它并阅读其文档。 要开始使用该模块，开发人员从该模块导入包，然后运行go get命令下载其源代码以进行编译。 有关开发人员如何查找和使用模块的更多信息，请参阅管理依赖项。 版本控制 当您随着时间的推移修改和改进您的模块时，您会分配版本号（基于语义版本控制模型），旨在表明每个版本的稳定性和向后兼容性。这有助于使用您的模块的开发人员确定模块何时稳定以及升级是否可能包括行为的重大变化。您可以通过在存储库中标记模块的源代码来指示模块的版本号。 有关开发主要版本更新的更多信息，请参阅开发主要版本更新。 有关如何为Go模块使用语义版本控制模型的更多信息，请参阅模块版本编号。 模块发布和版本控制工作流程 当您开发供其他开发人员使用的模块时，您可以遵循有助于确保使用该模块的开发人员获得可靠、一致的体验的工作流程。 本主题描述了该工作流中的高级步骤。 有关模块开发的概述，请参阅开发和发布模块。 也可以看看 如果您只想在代码中使用外部包，请务必查看管理依赖项。 对于每个新版本，您都用其版本号表示对模块的更改。有关更多信息，请参阅模块版本编号。 常见的工作流程步骤 以下序列说明了示例新模块的发布和版本控制工作流程步骤。有关每个步骤的更多信息，请参阅本主题中的部分。\n开始一个模块并组织它的源代码，使开发人员更容易使用和维护。如果您是开发模块的新手，请查看教程：创建Go模块。在 Go 的去中心化模块发布系统中，如何组织代码很重要。有关更多信息，请参阅管理模块源。 设置为编写调用未发布模块中的函数的本地客户端代码。在发布模块之前，对于使用诸如go get。 在此阶段测试模块代码的一个好方法是在它位于调用代码的本地目录中时尝试它。有关本地开发的更多信息，请参阅针对未发布的模块进行编码。 当模块的代码准备好供其他开发人员试用时，开始发布v0预发布版本，例如alpha和beta。有关更多信息，请参阅发布预发布版本。 发布一个不保证稳定**的v0，但用户可以尝试。**有关更多信息，请参阅发布第一个（不稳定）版本。 在您的 v0 版本发布后，您可以（并且应该！）继续 发布它的新版本。这些新版本可能包括错误修复（补丁版本）、对模块公共 API 的添加（次要版本），甚至是重大更改。由于v0版本不保证稳定性或向后兼容性，因此您可以对其版本进行重大更改。有关更多信息，请参阅发布错误修复和发布非破坏性API更改。 当您准备好发布的稳定版本时，您可以将预发布版本发布为alphas和betas。有关更多信息，请参阅发布预发布版本。 发布 v1 作为第一个稳定版本。这是对模块稳定性做出承诺的第一个版本。有关更多信息，请参阅发布第一个稳定版本。 在 v1 版本中，继续修复错误，并在必要时对模块的公共 API 进行添加。有关更多信息，请参阅发布错误修复和发布非破坏性 API 更改。 如果无法避免，请在新的主要版本中发布重大更改。主要版本更新——例如从 v1.xx 到 v2.xx——对于模块的用户来说可能是一个非常具有破坏性的升级。这应该是最后的手段。有关更多信息，请参阅发布重大 API 更改。 ","permalink":"https://heliu.site/posts/golang/package/publish-mod/","summary":"Golang 发布模块流程介绍。","title":"开发和发布模块"},{"content":"数组的定义 🚀 数组是具有相同唯一类型的一组已编码且长度固定的数据项序列。 这是一种同构的数据结构，这种类型可以是任意的基础类型，如整型、字符串或自定义类型。 数组长度必须是一个常量表达式（编译期间能确定的值），并且是一个非负数。 数组的长度也是数组类型的一部分，[5]int和[10]int是属于不同类型。 如果想让数组元素，类型为任意类型，可以使用空接口interface{}作为类型，但使用时，必须先做一个类型判断。 访问越界，如果下标在数组合法范围之外，则触发访问越界，会panic。 数组是值类型，赋值和传参会复制整个数组，而不是指针。因此改变副本的值，不会改变本身的值。 只支持 \u0026ldquo;==\u0026quot;、\u0026rdquo;!=\u0026quot; 操作符。（不支持 \u0026ldquo;\u0026gt;\u0026quot;、\u0026quot;\u0026lt;\u0026quot;、\u0026quot;\u0026gt;=\u0026quot;、\u0026quot;\u0026lt;=\u0026quot;，原因是大于、小于对于数组来说没啥意义，我们也不会比较两个数组谁大谁小） 指针数组 [n]*T，数组指针 *[n]T。 数组元素为空接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { // 数组 a 所占内存 16 * 5 = 80 字节 var a [5]interface{} = [5]interface{}{1, \u0026#34;hello\u0026#34;, false, 0.23, 2i} // 空接口的结构构造，type eface struct {typ *_type, data uintptr} fmt.Printf(\u0026#34;数组a占用内存的大小%d\\n\u0026#34;, unsafe.Sizeof(a))\t// 数组a占用内存的大小80 5*(8+8) // [5]interface {}{1, \u0026#34;hello\u0026#34;, false, 0.23, (0+2i)} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, a) // 这里遍历可以改成遍历 \u0026amp;a，这样避免了大数组的复制 // 变量指针数组是Go的语法糖 for i, v := range a { // 【int, any】 fmt.Printf(\u0026#34;i:%d v:%#v t:%T\\n\u0026#34;, i , v, v) // 必须要做断言才能使用，空接口.(具体类型) if ii, ok := v.(int); ok { fmt.Println(ii + 10) } } // Output: // 数组a占用内存的大小80 // [5]interface {}{1, \u0026#34;hello\u0026#34;, false, 0.23, (0+2i)} // i:0 v:1 t:int // 11 // i:1 v:\u0026#34;hello\u0026#34; t:string // i:2 v:false t:bool // i:3 v:0.23 t:float64 // i:4 v:(0+2i) t:complex128 } 指针数组和数组指针 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import \u0026#34;fmt\u0026#34; func main() { // 1. 指针数组，数组的元素是指针类型 var p1 [2]*int = [2]*int{} // [2]*int{nil, nil} fmt.Println(p1) var a int = 5 p1[1] = \u0026amp;a fmt.Println(p1) // Output: // [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] // [\u0026lt;nil\u0026gt; 0xc00000e0b8] // 2. 数组指针 var p2 *[2]int fmt.Println(p2) a1 := [2]int{1, 2} p2 = \u0026amp;a1 fmt.Printf(\u0026#34;%#v\u0026#34;, p2) // Output // \u0026lt;nil\u0026gt; // \u0026amp;[2]int{1, 2} } 数组和数组指针 在Go中数组和数组指针的用法基本一致，能遍历（range）、赋值、取值、求长度等，这是由于数组指针操作时存在语法糖支持。 切片(slice)则不允许这样操作，只有数组是特有的，为啥数组支持遍历数组地址，很大原因是大数据数组遍历的拷贝开销比较大，采用指针形式则不需要拷贝。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { // *[5]int a1 := new([5]int) // 1) 语法糖： (*a1)[0] = 12 a1[0] = 12\t// 2) 语法糖： c := (*a1)[1] c := a1[1]\t// 3) 语法糖： l := len(*a1) l := len(a1)\t// 遍历a1，这是由于上面两个语法糖(2)(3)的支持 for i := range a1 { // 【int, int】 } } 数组的声明与使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 1) 指定索引 var a = [5]string{3:\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} // [5]string{\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, a) // 2) ... 只能用在最外层数组 // ... 的用法 // 1. 用于数组声明的最外层数组，自动统计数组长度。 // 2. 用作函数的最后一个参数，...T 表示可变参数 []T 切片形式。 // 3. 用作切片后 []T... 表示解引用。【append([]int{1,2}, []int{3,4,5}...)】 // 4. 只有在【append([]byte(\u0026#34;hello \u0026#34;), \u0026#34;world\u0026#34;...)】时可以使用 【string...】 形式其他地方不被允许。 // slice = append(slice, elem1, elem2) // slice = append(slice, anotherSlice...) // slice = append([]byte(\u0026#34;hello \u0026#34;), \u0026#34;world\u0026#34;...) // ... 作为解引用时，只能用在Slice和string中 var b = [...]string{3:\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} // [5]string{\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, b) // 3) 默认值，注意不是空数组，数组不存在空数组概念，数组中一定是存在值的即使是默认值 var c [2]uint8\t// [2]uint8{0, 0} // Output: // [5]string{\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} // [5]string{\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} 一维数组或多维数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 1. 常用初始化 var arrAge = [5]int{15,16,15,18,17}\t// [5]int{15,16,15,18,17}\t// 2. 指定索引位置的初始化 var arrName = [5]string{3:\u0026#34;Chris\u0026#34;, 4:\u0026#34;Ron\u0026#34;}\t// [5]string{\u0026#34;\u0026#34;,\u0026#34;\u0026#34;,\u0026#34;\u0026#34;,\u0026#34;Chris\u0026#34;, \u0026#34;Ron\u0026#34;} var arrCount = [4]int{500, 2:100}\t// [4]int{500,0,100,0} // 3. 数组长度初始化根据元素多少决定 var arrLazy = [...]int{5,6,7,8,23}\t// [5]int{5,6,7,8,23}\tvar arrPack = [...]int{10,5:100}\t// [6]int{10,0,0,0,0,100} // 4. 不指定默认值 var arrRoom [20]int\t// [20]int{0,0,0,...} // 5. 使用new函数 var arrBed = new([20]int)\t// *[20]int{0,0,0,...} // 6. 数组类型是结构体 d := [...]struct{ name string\t// 占16字节 age uint8\t// 占1字节 内存对齐后 占8字节 }{ {\u0026#34;user1\u0026#34;, 10}, {\u0026#34;user2\u0026#34;, 20},\t// 别忘了最后一行的逗号，这是由于GO语法解析 } fmt.Println(unsafe.Sizeof(d))\t// 48 = (16+8) * 2 fmt.Printf(\u0026#34;arrAge:%#v arrAge:Type:%T\\n\u0026#34;, arrAge, arrAge) fmt.Printf(\u0026#34;arrName:%#v arrName:Type:%T\\n\u0026#34;, arrName, arrName) fmt.Printf(\u0026#34;arrCount:%#v arrCount:Type:%T\\n\u0026#34;, arrCount, arrCount) fmt.Printf(\u0026#34;arrLazy:%#v arrLazy:Type:%T\\n\u0026#34;, arrLazy, arrLazy) fmt.Printf(\u0026#34;arrPack:%#v arrPack:Type:%T\\n\u0026#34;, arrPack, arrPack) fmt.Printf(\u0026#34;arrRoom:%#v arrRoom:Type:%T\\n\u0026#34;, arrRoom, arrRoom) fmt.Printf(\u0026#34;arrBed:%#v arrBed:Type:%T\\n\u0026#34;, arrBed, arrBed) fmt.Printf(\u0026#34;d:%#v d:Type:%T\\n\u0026#34;, d, d) } /* * arrAge:[5]int{15, 16, 15, 18, 17} arrAge:Type:[5]int * arrName:[5]string{\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Chris\u0026#34;, \u0026#34;Ron\u0026#34;} arrName:Type:[5]string * arrCount:[4]int{500, 0, 100, 0} arrCount:Type:[4]int * arrLazy:[5]int{5, 6, 7, 8, 23} arrLazy:Type:[5]int * arrPack:[6]int{10, 0, 0, 0, 0, 100} arrPack:Type:[6]int * arrRoom:[20]int{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0} arrRoom:Type:[20]int * arrBed:\u0026amp;[20]int{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0} arrBed:Type:*[20]int * d: * [2]struct { name string; age uint8 } * { * struct { name string; age uint8 }{name:\u0026#34;user1\u0026#34;, age:0xa}, * struct { name string; age uint8 }{name:\u0026#34;user2\u0026#34;, age:0x14} * } * d:Type: * [2]struct { name string; age uint8 } */ Go语言中数组是一种值类型（不像C/C++中是指向首元素的指针），所以可以通过new()来创建。 // 申请 5 * 8 byte内存 var arr1 = new([5]int)\t// *[5]int 使用new([5]int)创建和var arr2 [5]int的区别，arr1的类型是 *[5]int，而arr2的类型是[5]int。 数组长度不同算作不同类型 在Go语言中，数组的长度都算在类型里，由于在数组的类型描述结构中记录着数组的长度。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 1) new([5]int) 创建的是数组指针 var arr1 = new([5]int) // *[5]int // 把数组 [5]int 看做如下构成： // a: struct { // a1 int // a2 int // a3 int // a4 int // a5 int // } // 则 arr1 = \u0026amp;a // arr1类型:*[5]int, \u0026amp;arr1:0xc00000a028, arr1:0xc000012420, \u0026amp;arr1[0]:0xc000012420 fmt.Printf(\u0026#34;arr1类型:%T, \u0026amp;arr1:%p, arr1:%p, \u0026amp;arr1[0]:%p\\n\u0026#34;, arr1, \u0026amp;arr1, arr1, \u0026amp;arr1[0]) // arr1:\u0026amp;[5]int{0, 0, 0, 0, 0} fmt.Printf(\u0026#34;arr1:%#v\\n\u0026#34;, arr1) // arr和arr1指向同一地址，因而修改arr1和arr同样也生效 arr := arr1 // arr类型:*[5]int, \u0026amp;arr:0xc00000a038, arr:0xc000012420, \u0026amp;arr[0]:0xc000012420 fmt.Printf(\u0026#34;arr类型:%T, \u0026amp;arr:%p, arr:%p, \u0026amp;arr[0]:%p\\n\u0026#34;, arr, \u0026amp;arr, arr, \u0026amp;arr[0]) // arr:\u0026amp;[5]int{0, 0, 0, 0, 0} fmt.Printf(\u0026#34;arr:%#v\\n\u0026#34;, arr) arr1[2] = 100 // (*arr1)[2] = 100 fmt.Println(arr1[2], arr[2]) // 100 100 // 2) 非指针形式 [5]int var arr2 [5]int // newArr是arr2的副本，因此修改任何一个值都不会改变另外一个值 newArr := arr2 arr2[2] = 100 fmt.Println(arr2[2], newArr[2]) // 100 0 } 函数或方法时，如果参数是数组，需要注意参数不能过大。 由于把一个大数组传递给函数会消耗很多内存（值传递），可以使用其他方式传递。 传递数组的指针。 使用切片（常用选择）。 多维数组 1 2 3 [...][5]int{ {10,20},{30,40} } // len() 长度根据实际初始化时数组的长度来定，这里是 2 [3][2]int // len() 长度这里是 3 [2][2][2]float64 // 可以这样理解[2]([2]([2]float64)) 定义多维数组是，仅第一维允许使用 \u0026ldquo;...\u0026quot;。 内置函数len()和cap()都返回第一维度长度。 len()获取的是数组的长度。 cap()获取的是数组的容量，这里也就是返回数组的长度。 定义数组时 \u0026ldquo;...\u0026rdquo; 表示长度不定，初始化时根据实际长度来确定数组的长度。 1 2 b := [...][5]int{ {10,20},{30,40,50,60} } fmt.Println(b[1][3], len(b)) // 60 2 数组元素可以通过索引（下标）来读取或者修改，所以从0开始。 遍历数组的方法可以使用for或者for-range。这两种对于切片一样适用。多维数组的遍历需要使用多层的嵌套。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var arrAge = [5]int{18,20,15,22,16} for i := 0; i \u0026lt; len(arrAge) ; i++ { // 【int, int】 fmt.Println(arrAge[i]) } fmt.Println(\u0026#34;-------------------------\u0026#34;) for key, val := range arrAge { // 【int, int】 fmt.Println(key, val) } // Output: // 18 // 20 // 15 // 22 // 16 // ------------------------- // 0 18 // 1 20 // 2 15 // 3 22 // 4 16 } 数组之间比较 数组元素类型支持 == 或 != 操作符，那么数组也支持此操作。 但如果数组类型不一样则不支持（需要数组长度和数组类型一致，否则编译不通过）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var arrRoom [20]int var arrBed [20]int fmt.Println(arrRoom == arrBed) // true var a [2]int = [2]int{0, 1} var b [2]int = [2]int{0, 1} var c [2]int = [2]int{0, 2} fmt.Println(a == b) // true fmt.Println(a == c) // false // Output: // true // true // false } 数组比较的核心代码示例：以下代码抄自src/reflect/type.go文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // typ表示数组的元类型_type，etyp则是数组元素的元类型_type // 举例如 [5]string 数组，这里的typ就是[5]string数组类型，etyp就是string类型 etyp := typ.common() // esize表示数组元素所在内存大小，这里的esize就是string类型的大小16字节 esize := etyp.Size() // 标记数组比较字段为nil，nil表示当前类型不可比较 array.equal = nil // 这里先标记默认值 // 判断etyp.equal也就是数组的元素类型(string)是否可以比较，如果该类型不可比较则当前数组也不可比较 if eequal := etyp.equal; eequal != nil { // 数组元素可以比较时，初始化数组的比较字段闭包形式 // p和q分表表示需要比较的两个数组地址 array.equal = func(p, q unsafe.Pointer) bool { // array.equal数组的比较方法 for i := 0; i \u0026lt; count; i++ { // 遍历数组的所有元素，count记录数组元素的大小 pi := arrayAt(p, i, esize, \u0026#34;i \u0026lt; count\u0026#34;) // arrayAt偏移到p的每个元素位置，得到数组元素值 qi := arrayAt(q, i, esize, \u0026#34;i \u0026lt; count\u0026#34;) // arrayAt偏移到q的每个元素位置，得到数组元素值 // eequal则是数组元素类型的比较函数，这里举例是string比较函数 if !eequal(pi, qi) { // eequal数组元素类型的比较方法，比较pi和qi return false // 两个数组不相等时 } } return true // 两个数组一致时 } } 值拷贝行为会造成性能问题，通常会建议使用 slice，或数组指针。 多维数组遍历 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 二维数组，2X3 var f [2][3]int = [...][3]int{{1, 2, 3}, {7, 8, 9}} for k1, v1 := range f { // 【int, [3]int】 for k2, v2 := range v1 { // 【int, int】 fmt.Printf(\u0026#34;(%d,%d)=%d \u0026#34;, k1, k2, v2) } fmt.Println() } // Output: // (0,0)=1 (0,1)=2 (0,2)=3 // (1,0)=7 (1,1)=8 (1,2)=9 } 数组拷贝和传参 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import \u0026#34;fmt\u0026#34; func printArr(arr *[5]int) { arr[0] = 10 // (*arr)[0] // for i, v := range *arr for i, v := range arr { // 【int, int】 fmt.Println(i, v) } } func main() { var arr1 [5]int printArr(\u0026amp;arr1) fmt.Println(arr1) arr2 := [...]int{2, 4, 6, 8, 10} printArr(\u0026amp;arr2) fmt.Println(arr2) } /* * 0 10 * 1 0 * 2 0 * 3 0 * 4 0 * [10 0 0 0 0] * 0 10 * 1 4 * 2 6 * 3 8 * 4 10 * [10 4 6 8 10] */ 求数组所有元素之和 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) // 求元素和 func sumArr(a *[10]int) int { var sum int = 0 for i := 0; i \u0026lt; len(a); i++ { // 语法糖 len(*a) sum += a[i] // 语法糖 (*a)[i] } //for _, v := range a { //\tsum += v //} return sum } func main() { // 若想做一个真正的随机数，一般使用时间纳秒播种随机数 // seed()种子默认是1，rand.Seed(1) rand.Seed(time.Now().UnixNano()) var b [10]int for i := 0; i \u0026lt; len(b); i++ { // 产生一个0到1000随机数 b[i] = rand.Intn(1000) } sum := sumArr(\u0026amp;b) fmt.Printf(\u0026#34;sum=%d\\n\u0026#34;, sum) // Output: // sum=3171 } 找出数组中和为给定值的两个元素的下标 例如数组[1,3,5,8,7]，找出两个元素之和等于8的下标分别是(0, 4)和(1, 2)。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import \u0026#34;fmt\u0026#34; // 找出数组中和为给定值的两个元素的下标，例如数组[1,3,5,8,7]， // 找出两个元素之和等于8的下标分别是（0，4）和（1，2） // 求元素和，是给定的值 func myTest(a []int, target int) { for i := 0; i \u0026lt; len(a); i++ { other := target - a[i] for j := i + 1; j \u0026lt; len(a); j++ { if a[j] == other { fmt.Printf(\u0026#34;(%d,%d)\\n\u0026#34;, i, j) } } } } func main() { b := [5]int{1, 3, 5, 8, 7} // b[:] 会引用数组b的地址，如果myTest函数修改参数a则会影响到b。 myTest(b[:], 8) } 随机打乱一个数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 随机打乱一个数组 // 1) 给 [12]int 赋值 var ar [12]int = [12]int{} for i := range \u0026amp;ar { ar[i] = i + 1 } fmt.Println(ar) rand.Seed(time.Now().UnixNano()) // 2) 打乱 [12]int n := len(ar) // 12 for i := 1; i \u0026lt; n; i++ { // 根据随机数打乱ar j := rand.Int() % (i+1) ar[i], ar[j] = ar[j], ar[i] } fmt.Println(ar) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) func shuffleArray(arr []int) { // 获取随机数种子 rand.Seed(time.Now().UnixNano()) // 遍历数组，随机交换元素 for i := len(arr) - 1; i \u0026gt; 0; i-- { j := rand.Intn(i + 1) arr[i], arr[j] = arr[j], arr[i] } } func main() { arr := []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20} shuffleArray(arr) fmt.Println(arr) } ... 的使用 用于数组时，...只能用在最外层数组。 用于数组申明的最外层数组，自动统计数组长度。 用作函数的最后一个参数，...T表示可变参数[]T切片形式。 用作切片后[]T...表示解引用。【append([]int{1,2}, []int{3,4,5}\u0026hellip;)】 只有在【append([]byte(\u0026ldquo;hello \u0026ldquo;), \u0026ldquo;world\u0026rdquo;\u0026hellip;)】时可以使用【string...】形式其他地方不被允许。 ...作为解引用时，只能用在Slice和string中。 append()相关用法。 slice = append(slice, elem1, elem2) slice = append(slice, anotherSlice...) slice = append([]byte(\u0026quot;hello \u0026quot;), \u0026quot;world\u0026quot;...) 注意 在Go语言中只有数组和数组指针能相互混用，其他类型则不能，比如切片和切片指针等。 1 2 3 4 5 6 7 8 9 10 11 12 { sl := [4]int{1,2,3,4} str3 := \u0026amp;sl // str3[1]、range str3、len(str3) 等操作 _ = str3[1] // (*str3)[1] 语法糖 for range str3 {\t} _ = len(str3) // len(*str3) 语法糖 _ = cap(str3) // cap(*str3) 语法糖 } ","permalink":"https://heliu.site/posts/golang/array/use/","summary":"数组的定义及基础使用。","title":"数组使用"},{"content":" 数组在内存中是连续分配的，数组的大小保存在数组类型元数据中的。 [3]int 的内存布局 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 示例[3]int 数组布局 内存中连续分配 // 地址 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // |\u0026lt;---a[0]----\u0026gt;| |\u0026lt;-------a[1]------\u0026gt;| |\u0026lt;--------a[2]------\u0026gt;| a := [3]int{0, 1, 2} // a的地址\u0026amp;a也就是当前示例的0即内存的首地址 // 查看a的内存占用大小 int 在64位系统下占8字节 3*8 = 24字节 fmt.Println(unsafe.Sizeof(a)) // 24 // 数组的长度保存在类型元数据中 type arrayType struct { _type // 数组类型结构 elem *_type // 数组元素类型结构 slice *_type // 切片类型结构 len uintptr // 数组长度 } [3]string 的内存布局 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 示例[5]string 字符串数组内存布局 // 字符串结构我们是如下 64位操作系统下 // string struct // 字段 类型 大小 示例 // data uintptr 8byte 指向底层数组 如x[0] -\u0026gt; [\u0026#39;h\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;] // len int 8byte 记录字符的长度 如x[0] 7 // // | // 0 1 ... 6 7 8 9 ... 14 15 16 17 .. 22 23 24 25 ... 30 31 32 33 .. 39 40 41 42 ... 内存地址byte // | | | | | | | | | | ... // |x[0].data| | x[0].len | | x[1].data | | x[1].len | | x2[2].data | ... // | 8B | | 8B | | 8B | | 8B | | 8B | ... // // 数组的长度记录在数组的类型元数据中 x := [5]string{\u0026#34;hello21\u0026#34;, \u0026#34;word\u0026#34;, \u0026#34;! 1\u0026#34;, \u0026#34;! 2\u0026#34;, \u0026#34;! 3\u0026#34;} // 数组x占用内存大小(字节) 5*16 fmt.Println(unsafe.Sizeof(x))\t// 80 验证[2]string的内存布局。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) // array2Str 类 [2]string 内存结构布局 // 因此 数组 直接看成相应的结构体 type array2Str struct { a0Data unsafe.Pointer a0Len int a1Data unsafe.Pointer a1Len int } func main() { a := [2]string{\u0026#34;hello\u0026#34;, \u0026#34;world!\u0026#34;} // 16 * 2 = 32 // 把 a 看成 array2Str 结构体 s := **(**[5]byte)(unsafe.Pointer(\u0026amp;a)) // a[0]; array2Str.p1 fmt.Println(string(s[:]), unsafe.Sizeof(a)) // hello 32 // \u0026amp;array2Str.l1 // 把 a 看成 array2Str 这里比较好理解 a0l := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;a)) + unsafe.Sizeof(uintptr(0)))) // len(a[0]) //a0l := (*(*[2]int)(unsafe.Pointer(\u0026amp;a)))[1] // 5 fmt.Println(*a0l) // 5 ss := (*array2Str)(unsafe.Pointer(\u0026amp;a)) fmt.Println(*ss) // {4807271 5 4807756 6} } 数组的按值传参 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { a := [2]int{10, 20} // 数组a占用内存大小：16 fmt.Printf(\u0026#34;数组a占用内存大小：%d\\n\u0026#34;, unsafe.Sizeof(a)) fmt.Printf(\u0026#34;数组a地址：%p\\n\u0026#34;, \u0026amp;a) x(a) // Output: // 数组a占用内存大小：16 // 数组a地址：0xc00000e0b0 // 数组a占用内存大小：16 // 数组a地址：0xc00000e0d0 // 从数组a的地址可以看出，main函数的栈分配是经挨着的 } func x(a [2]int) { // 数组a占用内存大小：16 fmt.Printf(\u0026#34;数组a占用内存大小：%d\\n\u0026#34;, unsafe.Sizeof(a)) fmt.Printf(\u0026#34;数组a地址：%p\u0026#34;, \u0026amp;a) } ","permalink":"https://heliu.site/posts/golang/array/memory/","summary":"Golang 数组的内存布局介绍。","title":"数组的内存布局"},{"content":" Golang 的元类型在interface章节才会介绍，如果不熟悉略过。 数组元类型结构 数组元类型：构成数组类型的结构。（数组类型和自定义数组类型） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // 数组类型 type arrayType struct { _type // 数组元类型，也就是数组类型相关信息 elem *_type // 数组元素元类型，比如[2]string中的string类型相关信息 slice *_type // 切片元类型，为什么数组类型结构中有一个切片的元类型。在反射的方法中被用到用于快速找到切片 len uintptr // 数组长度，数组的长度是保存在元类型中的 } // 自定义数组类型 type u struct { arrayType u uncommonType } // uncommonType 是自定义方法集 type uncommonType struct { pkgPath int32 // 4B 偏移到包名称路径 mcount uint16 // 2B 方法总数量 xcount uint16 // 2B 可导出方法数量 moff uint32 // 4B 偏移到首方法的偏移量，方法是按照方法名正序排序的，因此导出方法在最前面 _ uint32 // 4B 占位内存补齐，补齐4B，该uncommonType正好是16B无论是32位下还是64位下都兼容 } // 方法类型 type method struct { name nameOff // 偏移量 方法名 mtyp typeOff // 偏移量 方法类型 ifn textOff // 偏移量 方法地址 用于接口 编译器生成的包装方法 tfn textOff // 偏移量 方法地址 } 查看数组的_type信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) // sType 不论在32位下还是64位下刚好是8的倍数都兼容 type sType struct { size uintptr // 当前类型占用字节大小，字节B ptrData uintptr // 类型中也可包含指针的字节数B，在当前大小范围后都是标量数据 hash uint32 // 类型唯一哈希值，用于快速区分元素类型 tFlag uint8 // 记录着当前类型的额外信息，比如名称、方法集、名称*前缀、包路径、tag标签等 align uint8 // 类型的对齐量 fieldAlign uint8 // 结构体字段的对齐量 kind uint8 // 类型枚举，也就是当前类型值 equal func(uintptr, uintptr) // 类型比较函数，不为nil表示可比较 gcData *byte // 垃圾回收相关，记录当前类型引用的回收状态等 str int32 // 当前类型name的偏移量，到当前类型名称路径的偏移量，也就是tFlag信息对应的内容处 ptrToThis int32 // 当前类型的指针类型的偏移量，也就是[2]int偏移到*[2]int的偏移量 } //type AA [2]string func main() { var s = [2]string{\u0026#34;hello\u0026#34;, \u0026#34;world!\u0026#34;} //var s AA = [2]string{\u0026#34;hello\u0026#34;, \u0026#34;world!\u0026#34;} // type eface interface {typ *_type, data uintptr} var ss interface{} = s at := **(**sType)(unsafe.Pointer(\u0026amp;ss)) // main.sType{ // size:0x20, // 2 * 16 = 32 // ptrData:0x18, // 16 + 8 = 3 * 8 = 24，在24字节后全部都是标量数据 // hash:0xe9e55850, // tFlag:0x2, // 0000 0010 // align:0x8, // fieldAlign:0x8, // kind:0x11, // 16 + 1 = 17 // equal:(func(uintptr, uintptr))(0x45dee0), // 可比较 // gcData:(*uint8)(0x49d780), // str:5888, // ptrToThis:0 // 数组该值都为0 // } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, at) } 查看数组全部信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type sType struct { size uintptr // 当前类型占用字节大小 B ptrData uintptr // 类型中也可包含指针的字节数 B 在当前大小范围后都是标量数据 hash uint32 // 类型唯一哈希值 tFlag uint8 // 记录着当前类型的额外信息，比如名称、方法集、名称*前缀、包路径、tag标签等 align uint8 // 类型的对齐量 fieldAlign uint8 // 结构体字段的对齐量 kind uint8 // 类型枚举 equal func(uintptr, uintptr) // 类型比较函数 gcData *byte // 垃圾回收相关 str int32 // 当前类型name的偏移量 ptrToThis int32 // 当前类型的指针类型的偏移量 } type arrayType struct { sType elem *sType slice *sType len uintptr } func main() { var s = [2]string{\u0026#34;hello\u0026#34;, \u0026#34;world!\u0026#34;} // type eface interface {typ *_type, data uintptr} var ss interface{} = s at := **(**arrayType)(unsafe.Pointer(\u0026amp;ss)) // main.arrayType{ // sType:main.sType{ // size:0x20, // ptrData:0x18, // hash:0xe9e55850, // tFlag:0x2, // align:0x8, // fieldAlign:0x8, // kind:0x11, // equal:(func(uintptr, uintptr))(0x45dee0), // gcData:(*uint8)(0x49d880), // str:5896, // ptrToThis:0 // }, // elem:(*main.sType)(0x486fa0), // slice:(*main.sType)(0x486120), // len:0x2 // } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, at) fmt.Println(*at.elem) // {16 8 3774831796 7 8 8 24 0x402d20 0x4b4268 3135 21952} fmt.Println(*at.slice) // {24 8 183740627 2 8 8 23 \u0026lt;nil\u0026gt; 0x4b4268 5068 0} } 自定义数组类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type sType struct { size uintptr // 当前类型占用字节大小 B ptrData uintptr // 类型中也可包含指针的字节数 B 在当前大小范围后都是标量数据 hash uint32 // 类型唯一哈希值 tFlag uint8 // 记录着当前类型的额外信息，比如名称、方法集、名称*前缀、包路径、tag标签等 align uint8 // 类型的对齐量 fieldAlign uint8 // 结构体字段的对齐量 kind uint8 // 类型枚举 equal func(uintptr, uintptr) // 类型比较函数 gcData *byte // 垃圾回收相关 str int32 // 当前类型name的偏移量 ptrToThis int32 // 当前类型的指针类型的偏移量 } // 数组元类型 type arrayType struct { sType elem *sType slice *sType len uintptr } // 自定义数组类型，包含自定义方法 type u struct { arrayType uncommonType } // 自定义方法集 type uncommonType struct { pkgPath int32 // 4B 偏移到表名称路径 mCount uint16 // 2B 总方法数量 xCount uint16 // 2B 可导出方法数量 mOff uint32 // 4B 偏移到首方法的偏移量，方法是按照方法名正序排序的，因此导出方法在最前面 _ uint32 // 4B 占位内存补齐 } // AA 定义自定义类型 type AA [2]uint8 func (a AA) String() string { return \u0026#34;可导出方法\u0026#34; } func (a *AA) setName(i uint8) { a[0] = i // 这里是语法糖 (*a)[0] = 1 } // ptrType represents a pointer type. 指针类型 type ptrType struct { sType elem *sType // pointer element (pointed at) type } type up struct { ptrType uncommonType } func main() { // 验证自定义类型 var a AA a.setName(12) // AA类型 var inter any = a // 该类型只实现了String方法 s := **(**u)(unsafe.Pointer(\u0026amp;inter)) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, s) // *AA类型 是指针类型 var inter1 any = \u0026amp;a // 该类型只实现了setName方法,但是还有编译包装的*AA String()方法 s1 := **(**up)(unsafe.Pointer(\u0026amp;inter1)) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, s1) } // kind: 0x11 是 17 array类型 // AA类型 // main.u{ // arrayType:main.arrayType{ // sType:main.sType{ // size:0x2, // ptrData:0x0, // hash:0xeb895ab, // tFlag:0xf, // align:0x1, // fieldAlign:0x1, // kind:0x11, // equal:(func(uintptr, uintptr))(0xb02c40), // gcData:(*uint8)(0xbc8010), // str:4503, // ptrToThis:45344 // }, // elem:(*main.sType)(0xb94e20), // slice:(*main.sType)(0xb93f20), // len:0x2 // }, // uncommonType:main.uncommonType{ // pkgPath:522, // mCount:0x1, // 方法总数1 // xCount:0x1, // mOff:0x10, // _:0x0 // } // } // kind: 0x36 是 54 = 32(类型间接存在接口值中) + 22(指针类型) // *AA类型 // main.up{ // ptrType:main.ptrType{ // sType:main.sType{ // size:0x8, // ptrData:0x8, // hash:0xae85f2d0, // tFlag:0x9, // 1001 // align:0x8, // fieldAlign:0x8, // kind:0x36, // 0x36 = 54 = 32 + 22 // equal:(func(uintptr, uintptr))(0x9f2c80), // gcData:(*uint8)(0xab8330), // str:4512, // ptrToThis:0 // }, // elem:(*main.sType)(0xa88fc0) // }, // uncommonType:main.uncommonType{ // pkgPath:522, // mCount:0x2, // 方法总数2 // xCount:0x1, // mOff:0x10, // _:0x0 // } // } ","permalink":"https://heliu.site/posts/golang/array/meta/","summary":"Golang 数组的元类型介绍。","title":"数组的元类型"},{"content":" 切片：对底层数组的一个连续片段的引用，所以切片是一个引用类型（和数组不一样）该数组称为相关数组，通常是匿名的。 切片提供对该数组中编号的元素序列的访问。 未初始化切片的值为nil（注意：nil切片和空切片[]的区别）。 与数组一样切片是可索引的并且具有长度。 切片s的长度可以通过内置的len()函数获取，与数组不同切片的长度可能在执行期间发生变化。 元素可以通过整数索引0到len(s)-1来寻址，切片相当一个长度可变的数组。 计算容器的函数cap()。可以计算切片最大长度。 切片的长度永远不会超过它的容量，所以对于s切片来说，0 \u0026lt;= len(s) \u0026lt;= cap(s)。 一旦初始化，切片始终与保存其元素的基础数据相关联。 因此，切片会和其拥有同一基础数据的其他切片共享存储。 相比之下，不同的数组总是拥有不同的存储。 使用make()函数可以给切片初始化，该函数指定切片类型、长度和可选容量的参数。 因为切片是引用，所以他们不需要使用额外的内存，并且比数组更高效，因此切片比数组常用。 声明切片 声明切片格式。不需要指定长度，切片在未初始化之前默认为nil，长度为0。 1 var identifer []type 切片初始化格式。 slice1是由数组arr1从start索引到end-1索引之间的元素构成的子集。 start:end 称为slice表达式。 1 2 3 4 // [start,end) // len = end - start // cap = end - start var slice1 []type = arr1[strat:end] 切片初始化格式。 1 var x = []int{2,3,5,7,11,13} // 这样创建一个长度和容量为6的切片 使用make()函数来创建一个切片。 1 2 3 var slice1 []type = make([]type, len, cap) // 简写形式如下 slice1 := make([]type, len, cap) make函数的len是数组的长度也是slice的初始长度，cap是容量，是可选参数。 1 2 3 // 创建一个有50个int值得数组，并且创建长度为10，容量为50的切片 // 该切片指向数组的前10个元素 v := make([]int, 10 , 50) 从数组或者切片中生成一个新的切片。 1 2 3 4 5 6 7 // cap = max - low 的结果表示容量 // len = high - low 的结果表示长度 a[low:high:max] // high和max不能大于a.cap的值 // low的默认值0 // high的默认值 len(a) // max的默认值 cap(a) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main import ( \u0026#34;fmt\u0026#34; ) func main() { a := [5]int{1,2,3,4,5} // len = 3-1 = 2 // cap = 5-1 = 4 t := a[1:3:5] // 可以看出此处变量t引用了变量a的部分数据 fmt.Println(a, t) // [1 2 3 4 5] [2 3] a[1] += 1 fmt.Println(a, t) // [1 3 3 4 5] [3 3] fmt.Println(t, len(t), cap(t)) // [3,3] 2 4 } 切片取值时索引大于长度会导致异常发生，即使容量远远大于长度也没有用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package main import ( \u0026#34;fmt\u0026#34; ) func main() { sli := make([]int, 5, 10) fmt.Printf(\u0026#34;切片sli长度和容量：%d, %d\\n\u0026#34;, len(sli), cap(sli)) fmt.Println(sli) // len = 10, cap = 10 newSli := sli[:cap(sli)] // 可以看出此处变量newSli复用了sli的底层数组，导致修改一个全部都变 fmt.Println(sli, newSli) // [0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] newSli[0] += 10 fmt.Println(sli, newSli) // [10 0 0 0 0] [10 0 0 0 0 0 0 0 0 0] var x = []int{2,3,5,7,11} fmt.Printf(\u0026#34;切片x长度和容量：%d, %d\\n\u0026#34;, len(x), cap(x)) a := [5]int{1,2,3,4,5} // len = 2, cap = 4 t := a[1:3:5] // 可以看出变量t复用了a的数据，导致修改一个全部都变 fmt.Println(t, a) // [2 3] [1 2 3 4 5] t[0] += 10 fmt.Println(t, a) // [12 3] [1 12 3 4 5] fmt.Printf(\u0026#34;切片t长度和容量：%d, %d\\n\u0026#34;, len(t), cap(t)) // fmt.Println(t[2]) // panic 索引不能超过切片的长度 } /** * 切片sli长度和容量：5, 10 * [0 0 0 0 0] * [0 0 0 0 0] [0 0 0 0 0 0 0 0 0 0] * [10 0 0 0 0] [10 0 0 0 0 0 0 0 0 0] * 切片x长度和容量：5, 5 * [2 3] [1 2 3 4 5] * [12 3] [1 12 3 4 5] * 切片t长度和容量：2, 4 */ 创建切片汇总。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import \u0026#34;fmt\u0026#34; func main() { // 1. 声明切片，nil切片，也就是没有分配底层关联数组的切片 var s1 []int // 默认值为 nil 格式如 type slice struct {nil, 0, 0} if s1 == nil { fmt.Println(\u0026#34;是nil\u0026#34;) // 是nil } else { fmt.Println(\u0026#34;不是nil\u0026#34;) } // Output: // 是nil // 2. := []切片，也就是初始化了底层关联数组的切片 s2 := []int{} // 默认值为 struct {0xxxxxx, 0, 0} if s2 != nil { fmt.Println(\u0026#34;不是nil\u0026#34;) // 不是nil } else { fmt.Println(\u0026#34;是nil\u0026#34;) } // Output: // 不是nil // 3. make() var s3 []int = make([]int, 0) // 空切片 fmt.Printf(\u0026#34;s1:%#v s2:%#v s3:%#v\\n\u0026#34;, s1, s2, s3) // s1:[]int(nil) s2:[]int{} s3:[]int{} fmt.Println(s1, s2, s3)\t// [] [] [] // 4. 初始化赋值 var s4 []int = make([]int, 0, 0) // 空切片 fmt.Printf(\u0026#34;s4:%#v\\n\u0026#34;, s4) // s4:[]int{} fmt.Println(s4) // [] s5 := []int{1, 2, 3} fmt.Println(s5) // [1 2 3] // 5. 从数组切片 arr := [5]int{1, 2, 3, 4, 5} var s6 []int // [1,4)，该语法的意思是引用数组地址，注意返回的是对应的切片 // len = 3, cap = 4 s6 = arr[1:4] // 这种情况会共用数组的作为底层关联数组 fmt.Println(s6, len(s6), cap(s6)) // [2 3 4] 3 4 } 切片初始化 array、string、slice 使用 [:] 数组使用[:]返回的是对应的【切片】类型，数组使用 [low:high:max] 时，low和high、max必须是满足[0, len(array)]范围。 字符串使用[:]返回的还是【字符串】类型，字符串使用 [low:high] 时，low和high必须是满足[0, len(string)]范围。字符串不支持第三个参数max也没任何意义。 切片使用[:]返回的还是【切片】类型，切片使用 [low:high:max] 时，low和high、max必须满足[0, cap(slice)]范围。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) // 切片内存结构 type sliceStruct struct { data uintptr len int cap int } // 字符内存结构 type stringStruct1 struct { data uintptr len int } func main() { fmt.Println(\u0026#34;array -------\u0026#34;) // 1. 数组使用[low:high:max]情况时 var a [3]int = [3]int{1, 2, 3} // \u0026amp;a:0xc000014138, \u0026amp;a[0]0xc000014138 fmt.Printf(\u0026#34;\u0026amp;a:%p, \u0026amp;a[0]%p\\n\u0026#34;, \u0026amp;a, \u0026amp;a[0])\t// len = 2-0 = 2 // cap = 3-0 = 3 a1 := a[:2:3] // 这种形式确实共用了同一个底层关联数组 u1 := *(**byte)(unsafe.Pointer(\u0026amp;a1)) u2 := *(*sliceStruct)(unsafe.Pointer(\u0026amp;a1)) // u1:0xc000014138, u2:main.sliceStruct{data:0xc000014138, len:2, cap:3} fmt.Printf(\u0026#34;u1:%p, u2:%#v\\n\u0026#34;, u1, u2)\tfmt.Printf(\u0026#34;a.Type: %T\\n\u0026#34;, a1) // a.Type: []int // \u0026gt; ----------------------------------------------------------------------- fmt.Println(\u0026#34;string -------\u0026#34;) // 2. 字符串使用[low:high]情况时，感觉字符串中max参数没用 var ss string = \u0026#34;hello,world!\u0026#34; // 12 // \u0026amp;ss[0]:0x436cf1 fmt.Printf(\u0026#34;\u0026amp;ss[0]:%p\\n\u0026#34;, *(**byte)(unsafe.Pointer(\u0026amp;ss)))\t// \u0026amp;ss-struct: main.stringStruct1{data:0x436cf1, len:12} fmt.Printf(\u0026#34;\u0026amp;ss-struct: %#v\\n\u0026#34;, *(*stringStruct1)(unsafe.Pointer(\u0026amp;ss)))\tss1 := ss[:10] // len = 10 // \u0026amp;ss1[0]:0x436cf1 fmt.Printf(\u0026#34;\u0026amp;ss1[0]:%p\\n\u0026#34;, *(**byte)(unsafe.Pointer(\u0026amp;ss1)))\t// \u0026amp;ss1-struct: main.stringStruct1{data:0x436cf1, len:10} fmt.Printf(\u0026#34;\u0026amp;ss1-struct: %#v\\n\u0026#34;, *(*stringStruct1)(unsafe.Pointer(\u0026amp;ss1)))\tfmt.Printf(\u0026#34;ss1.Type: %T\\n\u0026#34;, ss1)\t// ss1.Type: string // \u0026gt; ----------------------------------------------------------------------- // 3. 切片 fmt.Println(\u0026#34;slice -------\u0026#34;) var sl []int = []int{1,2,3,4,5,6,7,8} // len=8,cap=8 // 为什么下面的地址没有替换翻倍扩容？原因使sl被覆盖了 // 如果在这一行打印sl地址，与下面坑定不同。fmt.Printf(\u0026#34;\u0026amp;sl[0]:%p\\n\u0026#34;, \u0026amp;sl[0]) sl = append(sl, 9) // 这里翻倍扩容了 // \u0026amp;sl[0]:0xc00000c340 fmt.Printf(\u0026#34;\u0026amp;sl[0]:%p\\n\u0026#34;, \u0026amp;sl[0])\t// \u0026amp;sl[0]:0xc00000c340 fmt.Printf(\u0026#34;\u0026amp;sl[0]:%p\\n\u0026#34;, *(**byte)(unsafe.Pointer(\u0026amp;sl)))\t// sl-struct:main.sliceStruct{data:0xc00000c340, len:9, cap:16} fmt.Printf(\u0026#34;sl-struct:%#v\\n\u0026#34;, *(*sliceStruct)(unsafe.Pointer(\u0026amp;sl)))\tsl1 := sl[:] // \u0026amp;sl1[0]:0xc00000c340 fmt.Printf(\u0026#34;\u0026amp;sl1[0]:%p\\n\u0026#34;, \u0026amp;sl1[0])\tsl2 := sl[:10:16] // 正是由于前面sl翻倍扩容了，这里能取到16 // \u0026amp;sl1[0]:0xc00000c340 fmt.Printf(\u0026#34;\u0026amp;sl1[0]:%p\\n\u0026#34;, \u0026amp;sl2[0])\t} [:]初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 全局： var arr = [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} // len=10 // len=9,cap=10 var slice0 []int = arr[0:9] // [0,9) // len=9,cap=10 var slice1 []int = arr[:9] // [0,9) // len=10,cap=10 var slice2 []int = arr[0:] // [0,10] // len=10,cap=10 var slice3 []int = arr[:] // [0,10] // len=9,cap=10 // arr[:9] var slice4 = arr[:len(arr)-1] // 去掉切片的最后一个元素 // 局部： arr2 := [...]int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} slice5 := arr[0:9] slice6 := arr[:9] slice7 := arr[0:] slice8 := arr[:] slice9 := arr[:len(arr)-1] //去掉切片的最后一个元素 操作 含义 s[n] 切片s中索引位置为n的项 s[:] 从切片s的索引位置0到len(s)-1处所获得的切片 s[low:] 从切片s的索引位置low到len(s)-1处所获得的切片 s[:high] 从切片s的索引位置0到high处所获得的切片，len == high s[low:high] 从切片s的索引位置low到high处所获得的切片，len == high-low s[low:high:max] 从切片s的索引位置low到high处所获得的切片，len == high-low，cap == max-low len(s) 切片s的长度，总是 \u0026lt;= cap(s) cap(s) 切片s的容量，总是 \u0026gt;= len(s) s[low:high:max]： 省略low默认为0。 省略high默认为len(s)。 省略max默认为cap(s)。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 package main import ( \u0026#34;fmt\u0026#34; ) var arr = [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} // main.init // main.init.0 var slice0 []int = arr[2:8] var slice1 []int = arr[0:6] // 可以简写为 var slice []int = arr[:end] var slice2 []int = arr[5:10] // 可以简写为 var slice[]int = arr[start:] var slice3 []int = arr[0:len(arr)] // var slice []int = arr[:] var slice4 = arr[:len(arr)-1] // 去掉切片的最后一个元素 func main() { fmt.Printf(\u0026#34;全局变量：arr %v\\n\u0026#34;, arr) fmt.Printf(\u0026#34;全局变量：slice0 %v\\n\u0026#34;, slice0) fmt.Printf(\u0026#34;全局变量：slice1 %v\\n\u0026#34;, slice1) fmt.Printf(\u0026#34;全局变量：slice2 %v\\n\u0026#34;, slice2) fmt.Printf(\u0026#34;全局变量：slice3 %v\\n\u0026#34;, slice3) fmt.Printf(\u0026#34;全局变量：slice4 %v\\n\u0026#34;, slice4) fmt.Printf(\u0026#34;-----------------------------------\\n\u0026#34;) arr2 := [...]int{9, 8, 7, 6, 5, 4, 3, 2, 1, 0} slice5 := arr[2:8] slice6 := arr[0:6] //可以简写为 slice := arr[:end] slice7 := arr[5:10] //可以简写为 slice := arr[start:] slice8 := arr[0:len(arr)] //slice := arr[:] slice9 := arr[:len(arr)-1] //去掉切片的最后一个元素 fmt.Printf(\u0026#34;局部变量： arr2 %v\\n\u0026#34;, arr2) fmt.Printf(\u0026#34;局部变量： slice5 %v\\n\u0026#34;, slice5) fmt.Printf(\u0026#34;局部变量： slice6 %v\\n\u0026#34;, slice6) fmt.Printf(\u0026#34;局部变量： slice7 %v\\n\u0026#34;, slice7) fmt.Printf(\u0026#34;局部变量： slice8 %v\\n\u0026#34;, slice8) fmt.Printf(\u0026#34;局部变量： slice9 %v\\n\u0026#34;, slice9) // Output: // 全局变量：arr [0 1 2 3 4 5 6 7 8 9] // 全局变量：slice0 [2 3 4 5 6 7] // 全局变量：slice1 [0 1 2 3 4 5] // 全局变量：slice2 [5 6 7 8 9] // 全局变量：slice3 [0 1 2 3 4 5 6 7 8 9] // 全局变量：slice4 [0 1 2 3 4 5 6 7 8] // ----------------------------------- // 局部变量： arr2 [9 8 7 6 5 4 3 2 1 0] // 局部变量： slice5 [2 3 4 5 6 7] // 局部变量： slice6 [0 1 2 3 4 5] // 局部变量： slice7 [5 6 7 8 9] // 局部变量： slice8 [0 1 2 3 4 5 6 7 8 9] // 局部变量： slice9 [0 1 2 3 4 5 6 7 8] } make()创建切片 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package main import ( \u0026#34;fmt\u0026#34; ) var slice0 []int = make([]int, 10) var slice1 = make([]int, 10) var slice2 = make([]int, 10, 10) func main() { fmt.Printf(\u0026#34;make全局slice0 ：%v\\n\u0026#34;, slice0) fmt.Printf(\u0026#34;make全局slice1 ：%v\\n\u0026#34;, slice1) fmt.Printf(\u0026#34;make全局slice2 ：%v\\n\u0026#34;, slice2) fmt.Println(\u0026#34;--------------------------------------\u0026#34;) slice3 := make([]int, 10) slice4 := make([]int, 10) slice5 := make([]int, 10, 10) fmt.Printf(\u0026#34;make局部slice3 ：%v\\n\u0026#34;, slice3) fmt.Printf(\u0026#34;make局部slice4 ：%v\\n\u0026#34;, slice4) fmt.Printf(\u0026#34;make局部slice5 ：%v\\n\u0026#34;, slice5) // Output: // make全局slice0 ：[0 0 0 0 0 0 0 0 0 0] // make全局slice1 ：[0 0 0 0 0 0 0 0 0 0] // make全局slice2 ：[0 0 0 0 0 0 0 0 0 0] // -------------------------------------- // make局部slice3 ：[0 0 0 0 0 0 0 0 0 0] // make局部slice4 ：[0 0 0 0 0 0 0 0 0 0] // make局部slice5 ：[0 0 0 0 0 0 0 0 0 0] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import ( \u0026#34;fmt\u0026#34; ) func main() { data := [...]int{0, 1, 2, 3, 4, 5} s := data[2:4] // 切割数组是引用数组地址 s[0] += 100 s[1] += 200 fmt.Println(s) fmt.Println(data) // Output: // [102 203] // [0 1 102 203 4 5] } 可直接创建 slice 对象，自动分配底层数组。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;fmt\u0026#34; func main() { s1 := []int{0, 1, 2, 3, 8: 100} // 通过初始化表达式构造，可使用索引号。 fmt.Println(s1, len(s1), cap(s1)) s2 := make([]int, 6, 8) // 使用 make 创建，指定 len 和 cap 值。 fmt.Println(s2, len(s2), cap(s2)) s3 := make([]int, 6) // 省略 cap，相当于 cap = len。 fmt.Println(s3, len(s3), cap(s3)) // Output: // [0 1 2 3 0 0 0 0 100] 9 9 // [0 0 0 0 0 0] 6 8 // [0 0 0 0 0 0] 6 6 } 使用 make 动态创建slice，避免了数组必须用常量做长度的麻烦。 还可用指针直接访问底层数组，退化成普通数组操作。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import \u0026#34;fmt\u0026#34; func main() { s := []int{0, 1, 2, 3} p := \u0026amp;s[2] // *int, 获取底层数组元素指针。 *p += 100 fmt.Println(s) // [0 1 102 3] // Output: // [0 1 102 3] } 二维切片 至于 [][]T，是指元素类型为 []T，该结构为二维切片。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { // make函数只能初始化最外层内存，也就是24 * 16，最里层不能 // 会创建24 * 16 大小内存，也就是[]int * cap会分配内存，但是最里一层并没有初始化这点需要注意 s := make([][]int, 8, 16)\t// [][]int{[]int(nil), []int(nil), []int(nil), []int(nil), []int(nil), []int(nil), []int(nil), []int(nil)} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, s)\ts[0] = make([]int, 2, 4) // [][]int{[]int{0, 0}, []int(nil), []int(nil), []int(nil), []int(nil), []int(nil), []int(nil), []int(nil)} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, s)\t// 注意s还是切片结构，因此这里依然占用24字节大小 fmt.Printf(\u0026#34;s占用内存大小%d\\n\u0026#34;, unsafe.Sizeof(s))\t} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import ( \u0026#34;fmt\u0026#34; ) func main() { data := [][]int{ []int{1, 2, 3}, []int{100, 200}, []int{11, 22, 33, 44}, } fmt.Println(data)\tfmt.Printf(\u0026#34;%#v\\n\u0026#34;, data)\t// Output: // [[1 2 3] [100 200] [11 22 33 44]] // [][]int{[]int{1, 2, 3}, []int{100, 200}, []int{11, 22, 33, 44}} } 可直接修改 struct array/slice 成员。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;fmt\u0026#34; ) func main() { d := [5]struct { x int }{} // 使用d[:]数组d称为s的底层关联数组 s := d[:] // 修改d的数据相当于直接修改s的底层关联数组 d[1].x = 10 // 修改s的数据也相当于直接修改s的底层关联数组d的数据 s[2].x = 20 fmt.Println(d) // [{0} {10} {20} {0} {0}] fmt.Println(s) // [{0} {10} {20} {0} {0}] // 0xc00000c3f0, 0xc00000c3f0, 0xc000004078, 0xc00000c3f0 fmt.Printf(\u0026#34;%p, %p, %p, %p\\n\u0026#34;, \u0026amp;d, \u0026amp;d[0], \u0026amp;s, \u0026amp;s[0]) } append()追加元素 append(s S, x ...T) S 向s切片中追加数据T（T的类型为s切片的元素类型）S = []T。返回追加后的切片S。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var a = []int{1, 2, 3} // len 3 cap 3 fmt.Printf(\u0026#34;slice a : %v\\n\u0026#34;, a) var b = []int{4, 5, 6} // len 3 cap 3 fmt.Printf(\u0026#34;slice b : %v\\n\u0026#34;, b) c := append(a, b...) // len 6 cap 6 fmt.Printf(\u0026#34;slice c : %v\\n\u0026#34;, c) d := append(c, 7) // len 7 cap 12 fmt.Printf(\u0026#34;slice d : %v\\n\u0026#34;, d) e := append(d, 8, 9, 10)// len 10 cap 12 fmt.Printf(\u0026#34;slice e : %v, %d, %d\\n\u0026#34;, e, len(e), cap(e)) // Output: // slice a : [1 2 3] // slice b : [4 5 6] // slice c : [1 2 3 4 5 6] // slice d : [1 2 3 4 5 6 7] // slice e : [1 2 3 4 5 6 7 8 9 10], 10, 12 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import \u0026#34;fmt\u0026#34; func main() { var c []byte = make([]byte, 0, 20) // slice = append([]byte(\u0026#34;hello \u0026#34;), \u0026#34;world\u0026#34;...) c = append(c, \u0026#34;Go语言001\u0026#34;...) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, c) fmt.Println(string(c)) // Output: // []byte{0x47, 0x6f, 0xe8, 0xaf, 0xad, 0xe8, 0xa8, 0x80, 0x30, 0x30, 0x31} // Go语言001 } append：向slice尾部添加数据，返回新的slice对象。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { s1 := make([]int, 0, 5) // %p 这里是 打印s1第一个指针地址，所以这里显示的是第一个8B存储的值 fmt.Printf(\u0026#34;s1关联数组地址：%p\\n\u0026#34;, s1) s2 := append(s1, 2012, 5) fmt.Printf(\u0026#34;s2关联数组地址：%p\\n\u0026#34;, s2) fmt.Println(s1, s2, len(s1), cap(s1), len(s2), cap(s2)) // [] [2012 5] 0 5 2 5 // Output: // s1关联数组地址：0xc0000c2060 // s2关联数组地址：0xc0000c2060 // [] [2012 5] 0 5 2 5 // 切片结构 slice struct { data pointer, len int, cap int } // a1拿到的是结构体中data的值也就是底层关联数组的首地址值 a1 := *(*uintptr)(unsafe.Pointer(\u0026amp;s2)) fmt.Printf(\u0026#34;a1:type:%T a1存储的值:%#x\\n\u0026#34;, a1, a1) // a1:type:uintptr a1存储的值:0xc0000c2060 // s2[0]的值 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(nil)) + *(*uintptr)(unsafe.Pointer(\u0026amp;s2))))) // s2[1]的值 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(nil)) + *(*uintptr)(unsafe.Pointer(\u0026amp;s2)) + unsafe.Sizeof(int(0))))) // s2[2]的值 直接访问s2[2]会出现下标越界 fmt.Println(*(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(nil)) + *(*uintptr)(unsafe.Pointer(\u0026amp;s2)) + 2 * unsafe.Sizeof(int(0))))) // Output: // s1关联数组地址：0xc0000c6060 // s2关联数组地址：0xc0000c6060 // [] [2012 5] 0 5 2 5 // a1:type:uintptr a1存储的值:oxc0000c6060 // 2012 // 5 // 0 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type SliceHeader struct { Data uintptr Len int Cap int } func main() { s1 := make([]int, 0, 5) fmt.Println(s1) // [] fmt.Printf(\u0026#34;%p\\n\u0026#34;, s1) // 0xc00001a0c0 // main.SliceHeader{Data:0xc00001a0c0, Len:0, Cap:5} fmt.Printf(\u0026#34;%#v\\n\u0026#34;, *(*SliceHeader)(unsafe.Pointer(\u0026amp;s1)))\ts2 := append(s1, 1, 2) fmt.Printf(\u0026#34;%p\\n\u0026#34;, s2) // 0xc00001a0c0 s3 := append(s2, 1, 2, 3, 4) fmt.Printf(\u0026#34;%p\\n\u0026#34;, s3) // 0xc0000c4000 } slice.cap 限制 会重新分配底层数组，即便原数组并未填满。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;fmt\u0026#34; ) func main() { data := [...]int{0, 1, 2, 3, 4, 10: 0} s := data[:2:3] s = append(s, 100, 200) // 一次 append 两个值，超出 s.cap 限制。 fmt.Println(s, data) // 重新分配底层数组，与原数组无关。 fmt.Println(\u0026amp;s[0], \u0026amp;data[0]) // 比对底层数组起始指针。 // Output: // [0 1 100 200] [0 1 2 3 4 0 0 0 0 0 0] // 0xc00000c3f0 0xc00005c060 } 从输出结果可以看出： append 后的 s 重新分配了底层数组，并复制数据。 如果只追加一个值，则不会超过 s.cap 限制，也就不会重新分配。 通常以 2 倍容量重新分配底层数组。 在大批量添加数据时，建议一次性分配足够大的空间，以减少内存分配和数据复制开销。 或初始化足够长的 len 属性，改用索引号进行操作。 及时释放不再使用的 slice 对象，避免持有过期数组，造成 GC 无法回收。 copy() 使用 copy(to, fm slice) int 与 copy(to []byte, fm string) int。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;fmt\u0026#34; ) func main() { s1 := []int{1, 2, 3, 4, 5} fmt.Printf(\u0026#34;slice s1 : %v\\n\u0026#34;, s1) // slice s1 : [1 2 3 4 5] s2 := make([]int, 10) fmt.Printf(\u0026#34;slice s2 : %v\\n\u0026#34;, s2) // slice s2 : [0 0 0 0 0 0 0 0 0 0] // copy(to, fm slice) int fm -\u0026gt; to copy(s2, s1) fmt.Printf(\u0026#34;copied slice s1 : %v\\n\u0026#34;, s1) // copied slice s1 : [1 2 3 4 5] fmt.Printf(\u0026#34;copied slice s2 : %v\\n\u0026#34;, s2) // copied slice s2 : [1 2 3 4 5 0 0 0 0 0] s3 := []int{1, 2, 3} fmt.Printf(\u0026#34;slice s3 : %v\\n\u0026#34;, s3) // slice s3 : [1 2 3] s3 = append(s3, s2...) fmt.Printf(\u0026#34;appended slice s3 : %v\\n\u0026#34;, s3) // appended slice s3 : [1 2 3 1 2 3 4 5 0 0 0 0 0] s3 = append(s3, 4, 5, 6) fmt.Printf(\u0026#34;last slice s3 : %v\\n\u0026#34;, s3) // last slice s3 : [1 2 3 1 2 3 4 5 0 0 0 0 0 4 5 6] } 函数copy在两个slice间复制数据，复制长度以 len小的为准。 两个slice可指向同一底层数组，允许元素区间重叠（两个切片都指向同一底层数组时需要注意覆盖问题）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import ( \u0026#34;fmt\u0026#34; ) func main() { data := [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} fmt.Println(\u0026#34;array data : \u0026#34;, data) // array data : [0 1 2 3 4 5 6 7 8 9] s1 := data[8:] s2 := data[:5] fmt.Printf(\u0026#34;slice s1 : %v\\n\u0026#34;, s1) // slice s1 : [8 9] fmt.Printf(\u0026#34;slice s2 : %v\\n\u0026#34;, s2) // slice s2 : [0 1 2 3 4] // copy(to, fm slice) int copy(s2, s1) fmt.Printf(\u0026#34;copied slice s1 : %v\\n\u0026#34;, s1) // copied slice s1 : [8 9] fmt.Printf(\u0026#34;copied slice s2 : %v\\n\u0026#34;, s2) // copied slice s2 : [8 9 2 3 4] // 注意这里索引0 索引1的值 在copy函数时发生了变化，因为都是同一个底层数组的原因 fmt.Println(\u0026#34;last array data : \u0026#34;, data)\t// last array data : [8 9 2 3 4 5 6 7 8 9] } 应及时将所需数据copy到较小的slice，以便释放超大号底层数组内存。 遍历切片 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package main import ( \u0026#34;fmt\u0026#34; ) func main() { data := [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} slice := data[:] for index, value := range slice { fmt.Printf(\u0026#34;inde : %v , value : %v\\n\u0026#34;, index, value) } } /* * inde : 0 , value : 0 * inde : 1 , value : 1 * inde : 2 , value : 2 * inde : 3 , value : 3 * inde : 4 , value : 4 * inde : 5 , value : 5 * inde : 6 , value : 6 * inde : 7 , value : 7 * inde : 8 , value : 8 * inde : 9 , value : 9 */ 字符串和切片 string：底层就是一个的数组，因此，也可以进行切片操作。 string数据结构：type string struct {data uintptr; len int}。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import \u0026#34;fmt\u0026#34; func main() { str := \u0026#34;hello world\u0026#34; s1 := str[0:5] // string fmt.Println(s1) s2 := str[6:] // string fmt.Println(s2) // Output: // hello // world } string本身是不可变的，因此要改变string中字符。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import \u0026#34;fmt\u0026#34; func main() { str := \u0026#34;Hello world\u0026#34; // []byte(str) 会重新分配内存并拷贝str数据 s := []byte(str) // 中文字符需要用[]rune(str) s[6] = \u0026#39;G\u0026#39; // 可以看出使用[]byte强制转换【并没】用共用一个底层数组 fmt.Println(str, string(s)) // Hello world Hello Gorld s = s[:8] s = append(s, \u0026#39;!\u0026#39;) // string(s) 也会重新分配一块内存，然后拷贝s数据 // 原因是slice是可变的，而string是不可变的 str = string(s) // 切片转字符串 fmt.Println(str)// Hello Go! } nil切片和空切片区别 nil切片表示切片没有初始化，也就是没有分配存储地址。 空切片则是切片已经初始化，并分配了存储地址。 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import ( \u0026#34;fmt\u0026#34; ) func main() { var sl []string // nil切片 sl并没有分配底层内存地址 if sl == nil { fmt.Println(\u0026#34;aaaa\u0026#34;) } } // 看下相关汇编 string.go:7 0x496680 493b6610 cmp rsp, qword ptr [r14+0x10] string.go:7 0x496684 767d jbe 0x496703 string.go:7 0x496686 4883ec68 sub rsp, 0x68 string.go:7 0x49668a 48896c2460 mov qword ptr [rsp+0x60], rbp string.go:7 0x49668f 488d6c2460 lea rbp, ptr [rsp+0x60] // 这是设置 slice.data = 0 可以看出并没有分配存储内存 string.go:8 0x496694 48c744243000000000 mov qword ptr [rsp+0x30], 0x0 // 这里是 slice.len = slice.cap = 0 设置了长度和容量 string.go:8 0x49669d 440f117c2438 movups xmmword ptr [rsp+0x38], xmm15 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import ( \u0026#34;fmt\u0026#34; ) func main() { sl := []string{} // 空切片 sl此时已经初始化过，分配了底层内存地址 if sl == nil { fmt.Println(\u0026#34;aaaa\u0026#34;) } } // 看下相关汇编 string.go:7\t0x46d240 4883ec30 sub rsp, 0x30 string.go:7\t0x46d244 48896c2428 mov qword ptr [rsp+0x28], rbp string.go:7\t0x46d249 488d6c2428 lea rbp, ptr [rsp+0x28] // []string的底层数组被编译器直接分配在了栈上，因为rsp存储的是栈上的值 string.go:8\t0x46d24e 488d0424 lea rax, ptr [rsp] // rax = rsp 存储的值 // [rsp+0x8] = rax 这里是存储的变量sl的地址空间指向slice.data string.go:8\t0x46d252 4889442408 mov qword ptr [rsp+0x8], rax string.go:8\t0x46d257 8400 test byte ptr [rax], al string.go:8\t0x46d259 eb00 jmp 0x46d25b // [rsp+0x10] = rax slice.data = rax 可以看出是分配了地址空间 string.go:8\t0x46d25b 4889442410\tmov qword ptr [rsp+0x10], rax // 这里是 slice.len = slice.cap = 0 设置了长度和容量 string.go:8\t0x46d260 440f117c2418 movups xmmword ptr [rsp+0x18], xmm15 string.go:10 0x46d266 eb00 jmp 0x46d268 string.go:13 0x46d268 488b6c2428 mov rbp, qword ptr [rsp+0x28] .:0 0x46d26d 4883c430 add rsp, 0x30 .:0 0x46d271 c3 ret 切片重组 通过改变切片长度得到新切片的过程称为切片重组。 如slice1 = slice1[0:end] 取值范围len = end - 0; cap = cap - 0; 其中end是新的末尾索引（即长度）。 在一个切片基础上重新划分一个切片时，新的切片会继续引用原有切片的相关数组。 如果忘记这个行为，在程序内存内分配占用大量的内存的临时切片。 然后在这个临时切片基础上创建只引用一小部分原有数据的新切片时。 会导致难以预期的内存使用结果。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;fmt\u0026#34; ) func get() []byte { raw := make([]byte, 10000) fmt.Println(len(raw), cap(raw), \u0026amp;raw[0]) // 10000 10000 0xc000090000 // 此处返回值引用变量raw的底层部分数组数据，导致返回时raw从栈逃逸到堆里 // return raw[:3:3] // 这种也会逃逸到堆 // 返回切片底层数组引用了raw导致raw不会被释放，占用很多不必要内存空间 // len = 3, cap = 10000 return raw[:3] // raw变量逃逸到堆了 } func main() { data := get() fmt.Println(len(data), cap(data), \u0026amp;data[0]) // 3 10000 0xc000090000 // \u0026amp;raw[0] == $data[0] 表明切片被引用了 } 为了避免这个陷阱，需要在临时的切片中使用内置函数copy()，复制数据（而不是重新引用划分切片）到新切片。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package main import ( \u0026#34;fmt\u0026#34; ) func get() []byte { raw := make([]byte, 10000) fmt.Println(len(raw), cap(raw), \u0026amp;raw[0]) // 10000 10000 0xc000080000 // len = 3, cap = 3 res := make([]byte, 3) // 利用copy函数复制, raw可被GC释放 // res从raw复制部分数据 copy(to, fm slice) int // 使用copy能有效防止变量逃逸 copy(res, raw[:3]) return res } func main() { data := get() fmt.Println(len(data), cap(data), \u0026amp;data[0]) // 3 3 0xc00000a0c8 } 需要向切片末尾追加数据时，可以使用内置函数append()。 1 func append(s S,x ...T) S // T是S元素类型 S = []T append函数将0个或多个具有相同类型S的元素追加到切片s后面并且返回新的切片。 追加的元素必须和原切片的元素同类型，如果s的容量不足以存储新增元素，append会分配新的切片来保证已有切片元素和新增元素的存储。 因此append函数返回的切片可能已经指向一个不同的相关数组了，即使修改了数据也不会同步。 append()函数总是返回成功，除非系统内存耗尽了。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 切片容量不足 append() 返回的是新的切片 指向不同的关联数组 s0 := []int{0,0} fmt.Println(s0, \u0026amp;s0[0], len(s0), cap(s0))// [0 0] 0xc00000a0b0 2 2 // 由于s0的容量只有2，此时添加元素导致扩容，从新分配内存，并把之前数据复制过来 s1 := append(s0,2) fmt.Println(s1, \u0026amp;s1[0], len(s1), cap(s1))// [0 0 2] 0xc00000e340 3 4 s1[0] += 1 fmt.Println(s0, s1) // [0 0] [1 0 2] // 此时添加元素 又会导致扩容 从新分配内存 并把之前数据复制过来 s2 := append(s1, 3, 5, 7) fmt.Println(s2, \u0026amp;s2[0], len(s2), cap(s2))// [1 0 2 3 5 7] 0xc00000c300 6 8 // 此时刚好达到最大容量，不会扩容 变量s3引用变量s2底层数组，修改其中元素会引起其他修改 s3 := append(s2, s0...) fmt.Println(s3, len(s3), cap(s3)) // [1 0 2 3 5 7 0 0] 8 8 s2[1] += 1 fmt.Println(s2, s3) // [1 1 2 3 5 7] [1 1 2 3 5 7 0 0] // s3[3:6] len=3 cap=5 // s3[2:] len=6 cap=6 // 导致s4从新分配内存存储数据 s4 := append(s3[3:6], s3[2:]...) fmt.Println(s4) // [3 5 7 2 3 5 7 0 0] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 如果切片容量足够 append()后不会生成新的切片 s0 := make([]int, 10, 20) fmt.Println(s0, \u0026amp;s0[0], len(s0), cap(s0)) // [0 0 0 0 0 0 0 0 0 0] 0xc00007c000 10 20 s1 := append(s0,2) fmt.Println(s1, \u0026amp;s1[0], len(s1), cap(s1)) // [0 0 0 0 0 0 0 0 0 0 2] 0xc00007c000 11 20 s2 := append(s1, 3, 5, 7) fmt.Println(s2, \u0026amp;s2[0], len(s2), cap(s2)) // [0 0 0 0 0 0 0 0 0 0 2 3 5 7] 0xc00007c000 14 20 // 此时扩容，从新开辟内存，复制原来数据 s3 := append(s2, s0...) fmt.Println(s3, len(s3), cap(s3)) // [0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] 24 40 // 这里s4容量为37 是由于s3[3:6] 这里40-3=37容量 // 此时容量足够，并没有扩容 s4 := append(s3[3:6], s3[2:]...) fmt.Println(s4, len(s4), cap(s4)) // [0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] 25 37 fmt.Println(s0) // [0 0 0 0 0 0 0 0 0 0] fmt.Println(s1) // [0 0 0 0 0 0 0 0 0 0 2] fmt.Println(s2) // [0 0 0 0 0 0 0 0 0 0 2 3 5 7] fmt.Println(s3) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0] fmt.Println(s4) // [0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] s0[1] += 1 fmt.Println(s0) // [0 1 0 0 0 0 0 0 0 0] fmt.Println(s1) // [0 1 0 0 0 0 0 0 0 0 2] fmt.Println(s2) // [0 1 0 0 0 0 0 0 0 0 2 3 5 7] fmt.Println(s3) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0] fmt.Println(s4) // [0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] s4[0] += 1 fmt.Println(s3) // [0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0] fmt.Println(s4) // [1 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] } 陈旧的切片 多个切片可以引用同一个底层相关数组。 某些情况下在一个切片中添加新的数据，在原有数组无法保持更多新的数据时，将导致分配一个新的数组。 而其他的切片还指向老的数组（和老的数据）。 append()函数操作后，有没有生成新的切片需要看原有的切片的容量是否足够。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;fmt\u0026#34; ) func main() { s1 := []int{1,2,3} fmt.Println(len(s1), cap(s1), s1) // 3 3 [1 2 3] // len = 3-1 = 2 // cap = 3-1 = 2 s2 := s1[1:] fmt.Println(len(s2), cap(s2), s2) // 2 2 [2 3] for i := range s2{ s2[i] += 20 } // s2的修改会音响到数组数据，s1输出新数据 fmt.Println(s1) // [1 22 23] fmt.Println(s2) // [22 23] // append s2容量为2 导致slice s2扩容，会生成新的底层数组 s2 = append(s2, 4) for i := range s2{ s2[i] += 10 } // s1数据现在是来数据 s2扩容了，复制到新数组，他们底层数组已经不是同一个数组了 fmt.Println(len(s1), cap(s1), s1) // 3 3 [1 22 23] fmt.Println(len(s2), cap(s2), s2) // 3 4 [32 33 14] } ","permalink":"https://heliu.site/posts/golang/slice/use/","summary":"Golang slice的使用介绍。","title":"Slice(使用)"},{"content":" 本篇文章都是slice的源码走读。 注意：slice 不是并发安全的数据结构，大家在使用时请务必注意并发安全问题。 type slice struct 切片的内存布局。 array：指向一个[cap]T大小的数组地址。就是指向一个cap容量大小的数组首地址。 len：记录切片已存储元素的长度，也是可访问的最大下标len - 1。 cap：记录切片的容量，也就是当前切片存储的最大元素数量（未扩容前）。 type slice struct { array unsafe.Pointer len int cap int } type notInHeapSlice struct notInHeapSlice是go:notinheap内存支持的slice。 也就是该类型的对象不是在堆中创建的，也就是GC不会扫描，多用于内存管理模块中。 1 2 3 4 5 6 // A notInHeapSlice is a slice backed by go:notinheap memory. type notInHeapSlice struct { array *notInHeap // 指向一个起始地址 len int cap int } type notInHeap struct notInHeap是由sysAlloc或persistentAlloc等底层分配器分配的堆外内存。 一般来说，最好使用标记为go:notinheap的真实类型，但在无法这样做的情况下(比如在分配器中)，它用作通用类型。 TODO：使用它作为sysAlloc,persistentAlloc等的返回类型? 1 2 3 4 5 6 7 8 9 10 11 // notInHeap is off-heap memory allocated by a lower-level allocator // like sysAlloc or persistentAlloc. // // In general, it\u0026#39;s better to use real types marked as go:notinheap, // but this serves as a generic type for situations where that isn\u0026#39;t // possible (like in the allocators). // // TODO: Use this as the return type of sysAlloc, persistentAlloc, etc? // //go:notinheap type notInHeap struct{} add() 1 2 3 4 func (p *notInHeap) add(bytes uintptr) *notInHeap { // p + bytes return (*notInHeap)(unsafe.Pointer(uintptr(unsafe.Pointer(p)) + bytes)) } make() make内置函数分配并初始化一个类型为slice、map或chan的对象(only)。 和new一样，第一个参数是类型，而不是值。与new不同，make的返回值类型与其参数的类型相同，而不是指向参数的指针。 具体的结果取决于类型： Slice： size指定了长度。切片的容量等于它的长度。 以提供第二个整数参数来指定不同的容量;它必须不小于长度。 例如，make([]int, 0, 10)会分配一个长度为10的底层数组，并返回一个长度为0、容量为10的切片。 Map：一个空的map分配了足够的空间来保存指定数量的元素。在这种情况下，可以省略长度，分配一个较小的起始长度。 Channel：channel缓冲区使用指定的缓冲区容量初始化。如果为0，或者size被省略，则channel是无缓冲的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // The make built-in function allocates and initializes an object of type // slice, map, or chan (only). Like new, the first argument is a type, not a // value. Unlike new, make\u0026#39;s return type is the same as the type of its // argument, not a pointer to it. The specification of the result depends on // the type: //\tSlice: The size specifies the length. The capacity of the slice is //\tequal to its length. A second integer argument may be provided to //\tspecify a different capacity; it must be no smaller than the //\tlength. For example, make([]int, 0, 10) allocates an underlying array //\tof size 10 and returns a slice of length 0 and capacity 10 that is //\tbacked by this underlying array. //\tMap: An empty map is allocated with enough space to hold the //\tspecified number of elements. The size may be omitted, in which case //\ta small starting size is allocated. //\tChannel: The channel\u0026#39;s buffer is initialized with the specified //\tbuffer capacity. If zero, or the size is omitted, the channel is //\tunbuffered. func make(t Type, size ...IntegerType) Type makeslice() make([]T *_type, len, cap int) *_type：记录着切片元素类型，比如[]string切片这里是string的元类型。 len：切片的长度，该参数是必传。 cap：切片的容量，该参数是可传，默认会传len大小。 makeslice()函数是切片申请内存的make()函数原型，主要负责申请slice.array字段指向的内存大小。 那么切片的24字节大小内存是在什么时候分配的？（64位系统下为24字节内存，32系统下为12字节内存） 可能在函数栈上直接分配24字节大小内存。 也可能在堆上分配24字节大小内存。 调用了makeslice()函数，其slice.array指向的内存块一定是在堆上。没有调该函数时可能内存分配在栈上。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func makeslice(et *_type, len, cap int) unsafe.Pointer { // 1）判断et.size * uintptr(cap)是否造成内存溢出 mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 按照cap计算的 // 1. 【overflow == true】：溢出 // 2. 【mem \u0026gt; maxAlloc】：超过操作系统最大内存 // 3. 【len \u0026lt; 0】：错误的len参数 // 4. 【len \u0026gt; cap】：长度大于容量 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a \u0026#39;len out of range\u0026#39; error instead of a // \u0026#39;cap out of range\u0026#39; error when someone does make([]T, bignumber). // \u0026#39;cap out of range\u0026#39; is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. // // 当有人 make([]T, bignumber) 时，产生一个 \u0026#39;len out of range\u0026#39; 错误而不是 \u0026#39;cap out of range\u0026#39; 错误提示 // 当 \u0026#39;cap out of range\u0026#39; 也是太长了，由于cap只是隐式地提供，所以说len更清楚的提示。 mem, overflow := math.MulUintptr(et.size, uintptr(len))\t// 根据len计算 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() // painc \u0026#39;len out of range\u0026#39; } panicmakeslicecap() // panic \u0026#39;cap out of range\u0026#39; } // 2）向操作系统申请mem大小的内存块，返回申请到内存块的首地址 return mallocgc(mem, et, true) } makeslice64() int64版本，如果当前是在32位系统中时，int其实是int32大小。 1 2 3 4 5 6 7 8 9 10 11 12 13 func makeslice64(et *_type, len64, cap64 int64) unsafe.Pointer { len := int(len64) // 32位系统下转换会丢失部分数据 if int64(len) != len64 { panicmakeslicelen() // painc \u0026#39;len out of range\u0026#39; } cap := int(cap64) if int64(cap) != cap64 { panicmakeslicecap() // panic \u0026#39;cap out of range\u0026#39; } return makeslice(et, len, cap) } len() 以下伪代码获取切片的长度。 len函数的原型：func len(array []T) int。 1 2 3 4 // 伪代码示例 func len(array []T) int { return array.len } cap() 以下伪代码获取切片的容量。 cap函数的原型：func cap(array []T) int。 1 2 3 4 // 伪代码示例 func cap(array []T) int { return array.cap } copy() copy内置函数将元素从源片复制到目标片。(作为特殊情况，它也会将bytes从string复制到byte切片。) 源和目标可能重叠。 copy返回复制的元素数量，这将是len(src)和len(dst)的最小值。src-\u0026gt;dst。 1 2 3 4 5 6 // The copy built-in function copies elements from a source slice into a // destination slice. (As a special case, it also will copy bytes from a // string to a slice of bytes.) The source and destination may overlap. Copy // returns the number of elements copied, which will be the minimum of // len(src) and len(dst). func copy(dst, src []Type) int slicecopy() slicecopy用于将pointerless元素的字符串或切片复制到切片中。 注意：copy()的函数原型中没有可变参数（... T）的形式参数。 slicecopy 适用以下两种情况：fm -\u0026gt; to 【copy(to, fm []T) int】 【copy(to []byte, fm string) int】 注意以下slicecopy函数可能在go1.18+版本中不是这样的，这一版采用的是go1.22左右版本的源码，但是只是发生了变化具体逻辑没变。 参数：fromPtr -\u0026gt; toPtr toPtr unsafe.Pointer：目标地址，也就是上面的to.array值。 toLen int：目标长度，也就是上面的to.len值。 fromPtr unsafe.Pointer：来源地址，也就是上面的fm.array值。 fromLen int：来源长度，也就是上面的fm.len值。 width uintptr：切片类型占用内存大小，也就是[]T的T类型的大小。 返回值： int：拷贝的元素数量。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // slicecopy is used to copy from a string or slice of pointerless elements into a slice. func slicecopy(toPtr unsafe.Pointer, toLen int, fromPtr unsafe.Pointer, fromLen int, width uintptr) int { // 1) 拷贝或被拷贝长度为0直接返回 if fromLen == 0 || toLen == 0 { return 0 } // 2) 拷贝元素的个数取决于拷贝或被拷贝的最小长度 n := fromLen if toLen \u0026lt; n { n = toLen } // 3) 拷贝的元素大小为0，直接返回n if width == 0 {\t// []struct{} return n } // 4) size 需要拷贝的总内存大小/字节。 size := uintptr(n) * width if raceenabled { callerpc := getcallerpc() pc := abi.FuncPCABIInternal(slicecopy) racereadrangepc(fromPtr, size, callerpc, pc) racewriterangepc(toPtr, size, callerpc, pc) } if msanenabled { msanread(fromPtr, size) msanwrite(toPtr, size) } if asanenabled { asanread(fromPtr, size) asanwrite(toPtr, size) } // 一般情况下，这里的值大约是2x（只有1字节需要拷贝） // to := make([]byte, 1); copy(to, \u0026#34;hello\u0026#34;) // 【[]byte】 OR 【[]uint8】 OR 【[]int8】 OR 【[]bool】 if size == 1 { // common case worth about 2x to do here // TODO: is this still worth it with new memmove impl? // // TODO: 使用新的memmove impl，这仍然值得吗? // 已知fromPtr和toPtr是 byte 指针 *(*byte)(toPtr) = *(*byte)(fromPtr) // known to be a byte pointer } else { memmove(toPtr, fromPtr, size) // 拷贝数据 } return n } memmove() memmove从from复制n个字节到to。 memmove确保任何位于from中的指针都以不可分割的写入方式写入到to中，因此，动态读取无法观察到一个只写了一半的指针。 这是必要的，以防止垃圾收集器发现无效指针，这与非托管语言中的memmove不同。 不过，只有当from和to可能包含指针时，memmove()才需要这么做，只有当from、to和n都是 word-aligned时才会这样做。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // memmove copies n bytes from \u0026#34;from\u0026#34; to \u0026#34;to\u0026#34;. // // memmove ensures that any pointer in \u0026#34;from\u0026#34; is written to \u0026#34;to\u0026#34; with // an indivisible write, so that racy reads cannot observe a // half-written pointer. This is necessary to prevent the garbage // collector from observing invalid pointers, and differs from memmove // in unmanaged languages. However, memmove is only required to do // this if \u0026#34;from\u0026#34; and \u0026#34;to\u0026#34; may contain pointers, which can only be the // case if \u0026#34;from\u0026#34;, \u0026#34;to\u0026#34;, and \u0026#34;n\u0026#34; are all be word-aligned. // // Implementations are in memmove_*.s. // //go:noescape func memmove(to, from unsafe.Pointer, n uintptr) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 TEXT runtime·memmove\u0026lt;ABIInternal\u0026gt;(SB), NOSPLIT, $0-24 // AX = to // BX = from // CX = n MOVQ AX, DI MOVQ BX, SI MOVQ CX, BX tail: // TEST指令用于对BX寄存器的内容和自身进行按位与操作，但是不改变寄存器的内容。 TESTQ BX, BX # 检查BX是否为0 // 检查上一条指令（TEST）执行后是否设置了零标志（ZF） JEQ move_0 # Jump if Equal // 这是一个比较指令，用于比较BX寄存器中的值和立即数2。 // 具体来说，它会将BX寄存器的值和2相减，但不改变任何寄存器的值，只是根据结果设置状态标志。 CMPQ BX, $2 // BX \u0026lt;= 2 成立 JBE move_1or2 # Jump if Below or Equal CMPQ BX, $4 # \u0026lt;= 4 JB move_3 JBE move_4 CMPQ BX, $8 # \u0026lt;= 8 JB move_5through7 JE move_8 CMPQ BX, $16 JBE move_9through16 CMPQ BX, $32 JBE move_17through32 CMPQ BX, $64 JBE move_33through64 CMPQ BX, $128 JBE move_65through128 CMPQ BX, $256 JBE move_129through256 TESTB $1, runtime·useAVXmemmove(SB) JNZ avxUnaligned //... ... append() 内置函数append()将元素添加到切片的末尾。 如果它有足够的容量，目的地将被重新划分以容纳新的元素。如果没有，将分配一个新的底层数组。 注意：append()函数存在可变参数（... T）的形式的参数。 append()返回更新后的slice。因此，有必要将append()的结果存储在保存切片本身的变量中： 【slice = append(slice, elem1, elem2)】 【slice = append(slice, anotherSlice...)】 作为一种特殊情况，可以将字符串添加到字节切片中，如下所示： 【slice = append([]byte(\u0026quot;hello \u0026quot;), \u0026quot;world\u0026quot;...)】 1 2 3 4 5 6 7 8 9 10 11 12 13 // The append built-in function appends elements to the end of a slice. If // it has sufficient capacity, the destination is resliced to accommodate the // new elements. If it does not, a new underlying array will be allocated. // Append returns the updated slice. It is therefore necessary to store the // result of append, often in the variable holding the slice itself: // //\tslice = append(slice, elem1, elem2) //\tslice = append(slice, anotherSlice...) // // As a special case, it is legal to append a string to a byte slice, like this: // //\tslice = append([]byte(\u0026#34;hello \u0026#34;), \u0026#34;world\u0026#34;...) func append(slice []Type, elems ...Type) []Type append 执行步骤： 如果当前append()函数执行完后切片不会\u0026ldquo;翻倍扩容\u0026quot;那么，直接是把append()后追加的数据拷贝到切片的后续空间即可。 如果当前append()函数执行完后需要\u0026ldquo;翻倍扩容\u0026rdquo;，那么先调用runtime.growslice()扩容函数，然后在拷贝数据追加到新的内存空间。 growslice() growslice()在append()函数期间处理切片增长。 它将slice元素类型、旧的slice和所需的新最小容量传递给它，然后返回一个至少具有该容量的新slice，并将旧数据复制到其中。 新slice的长度被设置为旧slice的长度，而不是新请求的容量。 这是为了方便codegen。旧片的长度立即用于计算在追加期间在何处写入新值。 TODO：当旧的后端消失时，重新考虑这个决定。 SSA后端可能更喜欢新的长度，或者只返回ptr/cap以节省栈空间。 参数： et *_type：切片元素的元类型。 old slice：未翻倍扩容前切片。 cap int：append()函数后需要的长度 old.len + n = cap。也就是append(s S, x ...T) S函数中len(S) + len(x) = cap后的长度。 返回值：slice slice.data：新申请的地址。 slice.len：old.len的值。注意这里是旧切片的长度。 slice.cap：扩容后的容量。 该函数在append()函数调用时根据条件触发。如old = append(old, 1, 2, 1), len(old) + 3 \u0026gt; cap(old)时就需要扩容了。 注意，关于slice的扩容规则在go1.18前是根据len的一套规则，而在以后版本又是根据cap的一套规则，本篇采用的是go1.22左右版本的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 // growslice handles slice growth during append. // It is passed the slice element type, the old slice, and the desired new minimum capacity, // and it returns a new slice with at least that capacity, with the old data // copied into it. // The new slice\u0026#39;s length is set to the old slice\u0026#39;s length, // NOT to the new requested capacity. // This is for codegen convenience. The old slice\u0026#39;s length is used immediately // to calculate where to write new values during an append. // TODO: When the old backend is gone, reconsider this decision. // The SSA backend might prefer the new length or to return only ptr/cap and save stack space. func growslice(et *_type, old slice, cap int) slice { if raceenabled { callerpc := getcallerpc() racereadrangepc(old.array, uintptr(old.len*int(et.size)), callerpc, abi.FuncPCABIInternal(growslice)) } if msanenabled { msanread(old.array, uintptr(old.len*int(et.size))) } if asanenabled { asanread(old.array, uintptr(old.len*int(et.size))) } // 1) 切片长度溢出判断 if cap \u0026lt; old.cap { panic(errorString(\u0026#34;growslice: cap out of range\u0026#34;)) } // 2) 切片元素类型 占用内存为零 情况 // 这种情况出现在： // var s []struct{} // s = append(s, struct{}{}, struct{}{}) if et.size == 0 { // append should not create a slice with nil pointer but non-zero len. // We assume that append doesn\u0026#39;t need to preserve old.array in this case. // // Append不应该创建一个指针为nil的切片，而是一个len为non-zero的切片。 // 在这种情况下，我们假设append不需要保存old.array。 // 赋值slice.array指定地址，为了确保slice不是nil // slice为nil的判断条件是，只要slice.array==0x00,不管len和cap的值为多少都为nil return slice{unsafe.Pointer(\u0026amp;zerobase), old.len, cap} } // 3) 评估扩容后的容量 // ---+-------+----------------------------------------------------------------------------------- // 预 | if | oldCap * 2 \u0026lt; cap ------\u0026gt; newCap = cap 使用cap值 // 估 |-------+----------------------------------------------------------------------------------- // 规 | else | oldCap \u0026lt; 256 ------\u0026gt; newCap = oldCap * 2 翻倍扩容 // 则 | | oldCap \u0026gt;= 256 ------\u0026gt; newCap = oldCap * 5/4 + 256 * 3/4 在原容量上扩容1/4在扩容192 // ---+-------+----------------------------------------------------------------------------------- newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { // 2倍旧容量 \u0026lt; cap时，则按照cap算。 newcap = cap } else { const threshold = 256 if old.cap \u0026lt; threshold { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. // // 检查 0 \u0026lt; newcap 以检测溢出并防止无限循环。 for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. newcap += (newcap + 3*threshold) / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } // 4) 内存规格匹配 // 内存是否溢出 true.溢出 false.没有溢出 var overflow bool\t// lenmem 旧切片元素占用的内存大小 // 该值用于迁移旧数据的依据/字节 // newlenmem 翻倍后切片元素占用的内存大小 // 该值是当前扩容后实际占用的大小/字节 // 因此capmem-newlenmem这部分内存是多余的，不会被用到。 // capmem 翻倍后新容量占用的内存大小， // 用于向操作系统申请的内存大小/字节 // 这部分内存可能大于newlenmem的值，因为Go的内存申请是有规格的。 var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don\u0026#39;t need any division/multiplication. // For goarch.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. // // 专门用于 et.size 的共同值。 // 对于1，我们不需要任何除法/乘法 // 对于 goarch.PtrSize，编译器将除法/乘法 优化为一个常量的位移 // 对于2的幂次方，使用可变位移 switch { // 倘若数组元素的大小为 1，则新容量大小为 1 * newcap. // 同时会针对 span class 进行取整 case et.size == 1: // 1字节 lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) // 匹配最近接的内存块规格 overflow = uintptr(newcap) \u0026gt; maxAlloc // 是否内存溢出 newcap = int(capmem) // 从新调整翻倍后新容量 // 倘若数组元素为指针类型，则根据指针占用空间结合元素个数计算空间大小 // 并会针对 span class 进行取整 case et.size == goarch.PtrSize: // 4或8字节 lenmem = uintptr(old.len) * goarch.PtrSize newlenmem = uintptr(cap) * goarch.PtrSize capmem = roundupsize(uintptr(newcap) * goarch.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/goarch.PtrSize newcap = int(capmem / goarch.PtrSize) // 倘若元素大小为 2 的指数，则直接通过位运算进行空间大小的计算 case isPowerOfTwo(et.size): // 2的幂次方 var shift uintptr if goarch.PtrSize == 8 { // Mask shift for better code generation. // // 掩码移位以更好地生成代码。 // sys.Ctz64函数计数尾部(低阶)零，如果全部为零，则为64。 // 比如 et.size 是2^8也就是 1_0000_0000，也就是8个零 shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026amp; 63 // 64位 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026amp; 31 // 32位 } lenmem = uintptr(old.len) \u0026lt;\u0026lt; shift newlenmem = uintptr(cap) \u0026lt;\u0026lt; shift capmem = roundupsize(uintptr(newcap) \u0026lt;\u0026lt; shift) overflow = uintptr(newcap) \u0026gt; (maxAlloc \u0026gt;\u0026gt; shift) newcap = int(capmem \u0026gt;\u0026gt; shift) // 兜底分支：根据元素大小乘以元素个数 // 再针对 span class 进行取整 default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size // math.MulUintptr 返回 capmem = et.size * uintptr(newcap); overflow 是否溢出 capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } // 以上代码因为会去匹配内存规格，所以会从新计算newcap这个翻倍后的值 // The check of overflow in addition to capmem \u0026gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // 除了capmem \u0026gt; maxAlloc之外，还需要检查溢出，以防止溢出， // 该溢出可用于在32位体系结构上触发段故障，示例程序如下: // // type T [1\u0026lt;\u0026lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d)\t// print(len(s), \u0026#34;\\n\u0026#34;) // } // 4*(1\u0026lt;\u0026lt;27 + 1)*8 if overflow || capmem \u0026gt; maxAlloc { panic(errorString(\u0026#34;growslice: cap out of range\u0026#34;)) } // 申请到的内存首地址 var p unsafe.Pointer if et.ptrdata == 0 { // 切片元素类型不包含指针 // capmem 申请的内存; nil 类型元类型用于判断是否为指针类型; false 是否重置内存为零值; p = mallocgc(capmem, nil, false) // 向操作系统申请内存块 // The append() that calls growslice is going to overwrite from // old.len to cap (which will be the new length). // Only clear the part that will not be overwritten. // // 调用 growslice 的 append() 方法会将 old.len 覆盖到 cap(这将是新的长度)。 // 只清除不会被覆盖的部分。 // 清零capmem-newlenmem这块内存，这快内存是多余的，不会被用到。 memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem)\t} else { // 切片元素类型包含指针 // Note: can\u0026#39;t use rawmem (which avoids zeroing of memory), // because then GC can scan uninitialized memory. // // Note: 不能使用rawmem(它可以避免内存归零)，因为这样GC会扫描未初始化的内存。 p = mallocgc(capmem, et, true) // 向操作系统申请内存块 if lenmem \u0026gt; 0 \u0026amp;\u0026amp; writeBarrier.enabled { // 开启了写屏障 // Only shade the pointers in old.array since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. // // 在 old.array 中只对指针进行 shade 处理，因为我们知道目标切片 p 只包含nil指针， // 因为它在alloc期间已被清除。 // lenmem-et.size+et.ptrdata 刚好是old.array存在的都是指针 // -et.size：减去最后一个元素的内存 // +et.ptrdata：再加上最后一个元素的指针 // 刚好处理完最后一个元素后面不是指针的部分内存。 // [dst, dst+size] bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem-et.size+et.ptrdata)\t} } // 从old.array中迁移lenmem大小内存数据到p中 memmove(p, old.array, lenmem) // 注意：这里返回的是 old.len，因为此时还是之前的旧数据 return slice{p, old.len, newcap} } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // bulkBarrierPreWriteSrcOnly is like bulkBarrierPreWrite but // does not execute write barriers for [dst, dst+size). // // In addition to the requirements of bulkBarrierPreWrite // callers need to ensure [dst, dst+size) is zeroed. // // This is used for special cases where e.g. dst was just // created and zeroed with malloc. // // The type of the space can be provided purely as an optimization, // however it is not used with GOEXPERIMENT=noallocheaders. // //go:nosplit func bulkBarrierPreWriteSrcOnly(dst, src, size uintptr, _ *abi.Type) { // GC并发标记阶段，这里需要处理混合写屏障相关事项，因为在拷贝指针数据 if (dst|src|size)\u0026amp;(goarch.PtrSize-1) != 0 { throw(\u0026#34;bulkBarrierPreWrite: unaligned arguments\u0026#34;) } if !writeBarrier.enabled { return // 并发标记已结束 } buf := \u0026amp;getg().m.p.ptr().wbBuf // 写屏障缓冲区 h := heapBitsForAddr(dst, size) for { var addr uintptr if h, addr = h.next(); addr == 0 { break } srcx := (*uintptr)(unsafe.Pointer(addr - dst + src)) p := buf.get1() p[0] = *srcx } } 所有0字节分配的基地址。 1 2 // base address for all 0-byte allocations var zerobase uintptr roundupsize() mallocgc返回将分配的内存块的大小，如果您要求该大小。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // Returns size of the memory block that mallocgc will allocate if you ask for the size. func roundupsize(size uintptr) uintptr { // _MaxSmallSize = 32768 if size \u0026lt; _MaxSmallSize { // smallSizeMax = 1024 if size \u0026lt;= smallSizeMax-8 { // 以最下8B倍数对齐 // smallSizeDiv = 8，divRoundUp 等价于 ceil(size/8) // size_to_class8和class_to_size 记录着 size 的映射关系 return uintptr(class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]]) } else { // 以最小128B倍数对齐 // largeSizeDiv = 128 return uintptr(class_to_size[size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]]) } } // _PageSize = 8192 if size+_PageSize \u0026lt; size { return size } return alignUp(size, _PageSize) // 对齐8KB } alignUp() alignUp将n取整为a的倍数。a必须是2的幂。 1 2 3 4 // alignUp rounds n up to a multiple of a. a must be a power of 2. func alignUp(n, a uintptr) uintptr { return (n + a - 1) \u0026amp;^ (a - 1) } MulUintptr() MulUintptr返回a * b以及乘法运算是否溢出。 在受支持的平台上，这是由编译器降低的固有特性。 1 2 3 4 5 6 7 8 9 10 11 // MulUintptr returns a * b and whether the multiplication overflowed. // On supported platforms this is an intrinsic lowered by the compiler. func MulUintptr(a, b uintptr) (uintptr, bool) { // a|b \u0026lt; 1\u0026lt;\u0026lt;16 || a|b \u0026lt; 1\u0026lt;\u0026lt;32 if a|b \u0026lt; 1\u0026lt;\u0026lt;(4*goarch.PtrSize) || a == 0 { return a * b, false } // const MaxUintptr = ^uintptr(0) overflow := b \u0026gt; MaxUintptr/a return a * b, overflow } ","permalink":"https://heliu.site/posts/golang/slice/theory/","summary":"slice的内存结构、make、copy、append函数及扩容介绍。","title":"Slice(原理)"},{"content":"什么是边界检查 边界检查，英文名Bounds Check Elimination，简称为 BCE。 它是Go语言中防止数组、切片越界而导致内存不安全的检查手段。如果检查下标已经越界了，就会产生Panic。 边界检查使得我们的代码能够安全地运行，但是另一方面，也使得我们的代码运行效率略微降低。 比如下面这段代码，会进行三次的边界检查。 1 2 3 4 5 6 7 8 9 package main func f(s []int) { _ = s[0] // 检查第一次 _ = s[1] // 检查第二次 _ = s[2] // 检查第三次 } func main() {} 你可能会好奇了，三次？我是怎么知道它要检查三次的。 实际上，你只要在编译的时候，加上参数-gcflags=\u0026quot;-d=ssa/check_bce/debug=1\u0026quot;即可，命令如下： 1 2 3 4 5 $ go build -gcflags=\u0026#34;-d=ssa/check_bce/debug=1\u0026#34; main.go # command-line-arguments ./main.go:4:7: Found IsInBounds ./main.go:5:7: Found IsInBounds ./main.go:6:7: Found IsInBounds 边界检查的条件 并不是所有的对数组、切片进行索引操作都需要边界检查。 比如下面这个示例，就不需要进行边界检查，因为编译器根据上下文已经得知，s这个切片的长度是多少，你的终止索引是多少，立马就能判断到底有没有越界，因此是不需要再进行边界检查，因为在编译的时候就已经知道这个地方会不会 panic。 1 2 3 4 5 6 7 8 9 package main func f() { s := []int{1,2,3,4} // panic: runtime error: slice bounds out of range [:9] with capacity 4 _ = s[:9] // 不需要边界检查 } func main() {} 因此可以得出结论，对于在编译阶段无法判断是否会越界的索引操作才会需要边界检查，比如这样子： 1 2 3 4 5 6 7 package main func f(s []int) { _ = s[:9] // 需要边界检查 } func main() {} 边界检查的特殊案例 案例一 在如下示例代码中，由于索引2在最前面已经检查过会不会越界，因此聪明的编译器可以推断出后面的索引0和1不用再检查。 1 2 3 4 5 6 7 8 9 package main func f(s []int) { _ = s[2] // 检查一次 _ = s[1] // 不会检查 _ = s[0] // 不会检查 } func main() {} 案例二 在下面这个示例中，可以在逻辑上保证不会越界的代码，同样是不会进行越界检查的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main // [low:high:max] // len = high - low // cap = max - low // s =\u0026gt; len = 10, cap = 20 func f(s []int) { for index, _ := range s { // 以下操作都是在有效的索引范围 _ = s[index] _ = s[:index+1] // index [0,9] _ = s[index:len(s)] // len(s) = 10 } } func main() {} 案例三 在如下示例代码中，虽然数组的长度和容量可以确定，但是索引是通过rand.Intn()函数取得的随机数，在编译器看来这个索引值是不确定的，它有可能大于数组的长度，也有可能小于数组的长度。 因此第一次是需要进行检查的，有了第一次检查后，第二次索引从逻辑上就能推断，所以不会再进行边界检查。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import ( \u0026#34;math/rand\u0026#34; ) func f() { s := make([]int, 3, 5) index := rand.Intn(3) // [0,1,2,3] _ = s[:index] // 第一次检查 _ = s[index:] // 第二次检查 } func main() {} 我们只有当数组的长度和容量相等时，:index成立，才能一定能推出index:也成立，这样的话，只要做一次检查即可。 一旦数组的长度和容量不相等，那么index在编译器看来是有可能大于数组长度的，甚至大于数组的容量。 我们假设index取得的随机数为4，那么它大于数组长度，此时s[:index]虽然可以成功，但是s[index:]是要失败的，因此第二次边界的检查是有必要的。 你可能会说，index不是最大值为3吗？怎么可能是4呢？要知道编译器在编译的时候，并不知道index的最大值是3呢。 总结： 当数组的长度和容量相等时，s[:index]成立能够保证s[index:]也成立，因为只要检查一次即可。 当数组的长度和容量不等时，s[:index]成立不能保证s[index:]也成立，因为要检查两次才可以。 案例四 由于数组是调用者传入的参数，所以编译器编译的时候无法得知数组的长度和容量是否相等，因此只能保险一点，两个都检查。 1 2 3 4 5 6 7 8 9 10 11 12 package main import ( \u0026#34;math/rand\u0026#34; ) func f(s []int, index int) { _ = s[:index] // 第一次检查 _ = s[index:] // 第二次检查 } func main() {} 但是如果把两个表达式的顺序反过来，就只要做一次检查就行了。 1 2 3 4 5 6 7 8 9 10 11 12 package main import ( \u0026#34;math/rand\u0026#34; ) func f(s []int, index int) { _ = s[index:] // 第一次检查 _ = s[:index] // 不用检查 } func main() {} 主动消除边界检查 虽然编译器已经非常努力去消除一些应该消除的边界检查，但难免会有一些遗漏。 这就需要”警民合作”，对于那些编译器还未考虑到的场景，但开发者又极力追求程序的运行效率的，可以使用一些小技巧给出一些暗示，告诉编译器哪些地方可以不用做边界检查。 比如下面这个示例，从代码的逻辑上来说，是完全没有必要做边界检查的，但是编译器并没有那么智能，实际上每个for循环，它都要做一次边界的检查，非常的浪费性能。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package main func f0(is []int, bs []byte) { if len(is) \u0026gt;= 256 { //is=is[:256] for _, n := range bs { // 每个循环都要边界检查， // 因为编译器并不知道is[n]这里的is的长度是否会超过byte大小 _ = is[n] } } } func main() {} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 TEXT main.f0(SB) /mnt/hgfs/g/hello1/struct.go func f0(is []int, bs []byte) { 0x4552e0 4883ec50 SUBQ $0x50, SP 0x4552e4 48896c2448 MOVQ BP, 0x48(SP) 0x4552e9 488d6c2448 LEAQ 0x48(SP), BP 0x4552ee 4889442458 MOVQ AX, 0x58(SP) # is.data 0x4552f3 48895c2460 MOVQ BX, 0x60(SP) # is.len 0x4552f8 48894c2468 MOVQ CX, 0x68(SP) # is.cap 0x4552fd 48897c2470 MOVQ DI, 0x70(SP) # bs.data 0x455302 4889742478 MOVQ SI, 0x78(SP) # bs.len 0x455307 4c89842480000000 MOVQ R8, 0x80(SP) # bs.cap if len(is) \u0026gt;= 256 { 0x45530f 48895c2428 MOVQ BX, 0x28(SP) # BX=is.len 0x455314 4881fb00010000 CMPQ $0x100, BX # is.len 与 256比较 0x45531b 7d02 JGE 0x45531f 0x45531d eb36 JMP 0x455355 for _, n := range bs { 0x45531f 488b542470 MOVQ 0x70(SP), DX # DX=bs.data 0x455324 488b5c2478 MOVQ 0x78(SP), BX # BX=bs.len 0x455329 488bb42480000000 MOVQ 0x80(SP), SI # SI=bs.cap 0x455331 4889542430 MOVQ DX, 0x30(SP) 0x455336 48895c2438 MOVQ BX, 0x38(SP) 0x45533b 4889742440 MOVQ SI, 0x40(SP) 0x455340 48c744242000000000 MOVQ $0x0, 0x20(SP) 0x455349 488b542438 MOVQ 0x38(SP), DX\t# DX=bs.len 0x45534e 4889542418 MOVQ DX, 0x18(SP) 0x455353 eb0c JMP 0x455361 } 0x455355 eb00 JMP 0x455357 0x455357 488b6c2448 MOVQ 0x48(SP), BP 0x45535c 4883c450 ADDQ $0x50, SP 0x455360 c3 RET for _, n := range bs { 0x455361 488b542420 MOVQ 0x20(SP), DX # DX=0 0x455366 4839542418 CMPQ DX, 0x18(SP) # DX 与 bs.len 循环判断条件 0x45536b 7f02 JG 0x45536f 0x45536d eb2e JMP 0x45539d 0x45536f 488b542430 MOVQ 0x30(SP), DX 0x455374 4803542420 ADDQ 0x20(SP), DX 0x455379 0fb602 MOVZX 0(DX), AX 0x45537c 88442417 MOVB AL, 0x17(SP) _ = is[n] 0x455380 488b4c2460 MOVQ 0x60(SP), CX 0x455385 4839c1 CMPQ AX, CX # 越界判断 0x455388 7702 JA 0x45538c 0x45538a eb13 JMP 0x45539f 0x45538c eb00 JMP 0x45538e for _, n := range bs { 0x45538e 488b542420 MOVQ 0x20(SP), DX 0x455393 48ffc2 INCQ DX 0x455396 4889542420 MOVQ DX, 0x20(SP) 0x45539b ebc4 JMP 0x455361 } 0x45539d ebb8 JMP 0x455357 _ = is[n] 0x45539f 90 NOPL 0x4553a0 e81bd3ffff CALL runtime.panicIndex(SB) 0x4553a5 90 NOPL 可以试着在for循环前加上这么一句is = is[:256]来告诉编译器新is的长度为256，最大索引值为255，不会超过byte的最大值，因为is[n]从逻辑上来说是一定不会越界的。 1 2 3 4 5 6 7 8 9 10 11 package main func f00(is []int, bs []byte) { if len(is) \u0026gt;= 256 { is = is[:256] for _, n := range bs { _ = is[n] // 不需要做边界检查 } } } func main() {} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 TEXT main.f00(SB) /mnt/hgfs/g/hello1/t1.go func f00(is []int, bs []byte) { 0x4552e0 4883ec50 SUBQ $0x50, SP 0x4552e4 48896c2448 MOVQ BP, 0x48(SP) 0x4552e9 488d6c2448 LEAQ 0x48(SP), BP 0x4552ee 4889442458 MOVQ AX, 0x58(SP) 0x4552f3 48895c2460 MOVQ BX, 0x60(SP) 0x4552f8 48894c2468 MOVQ CX, 0x68(SP) 0x4552fd 48897c2470 MOVQ DI, 0x70(SP) 0x455302 4889742478 MOVQ SI, 0x78(SP) 0x455307 4c89842480000000 MOVQ R8, 0x80(SP) if len(is) \u0026gt;= 256 { 0x45530f 48895c2428 MOVQ BX, 0x28(SP) 0x455314 4881fb00010000 CMPQ $0x100, BX # 256 与 is.len 比较 0x45531b 7d02 JGE 0x45531f 0x45531d eb54 JMP 0x455373 is = is[:256] // 消除边界检查 0x45531f 488b542468 MOVQ 0x68(SP), DX # DX=is.cap 0x455324 4881fa00010000 CMPQ $0x100, DX # 256 与 is.cap 比较 0x45532b 7305 JAE 0x455332 0x45532d e993000000 JMP 0x4553c5 0x455332 eb00 JMP 0x455334 0x455334 48c744246000010000 MOVQ $0x100, 0x60(SP) # is.len=256 for _, n := range bs { 0x45533d 488b542470 MOVQ 0x70(SP), DX # DX=bs.data 0x455342 488b5c2478 MOVQ 0x78(SP), BX # BX=bs.len 0x455347 488bb42480000000 MOVQ 0x80(SP), SI # SI=bs.cap 0x45534f 4889542430 MOVQ DX, 0x30(SP) 0x455354 48895c2438 MOVQ BX, 0x38(SP) 0x455359 4889742440 MOVQ SI, 0x40(SP) 0x45535e 48c744242000000000 MOVQ $0x0, 0x20(SP) 0x455367 488b542438 MOVQ 0x38(SP), DX # DX=bs.len 0x45536c 4889542418 MOVQ DX, 0x18(SP) 0x455371 eb0c JMP 0x45537f } 0x455373 eb00 JMP 0x455375 0x455375 488b6c2448 MOVQ 0x48(SP), BP 0x45537a 4883c450 ADDQ $0x50, SP 0x45537e c3 RET for _, n := range bs { 0x45537f 488b542420 MOVQ 0x20(SP), DX # DX=0 0x455384 4839542418 CMPQ DX, 0x18(SP) # 0 与 bs.len 比较 0x455389 7f02 JG 0x45538d 0x45538b eb2e JMP 0x4553bb 0x45538d 488b542430 MOVQ 0x30(SP), DX # DX=bs.data 0x455392 4803542420 ADDQ 0x20(SP), DX # DX=0+DX 0x455397 0fb602 MOVZX 0(DX), AX # AX=*bs.data 0x45539a 88442417 MOVB AL, 0x17(SP) _ = is[n] 0x45539e 488b4c2460 MOVQ 0x60(SP), CX # CX=256 0x4553a3 4839c1 CMPQ AX, CX # 越界判断 0x4553a6 7702 JA 0x4553aa 0x4553a8 eb13 JMP 0x4553bd 0x4553aa eb00 JMP 0x4553ac for _, n := range bs { 0x4553ac 488b542420 MOVQ 0x20(SP), DX 0x4553b1 48ffc2 INCQ DX 0x4553b4 4889542420 MOVQ DX, 0x20(SP) 0x4553b9 ebc4 JMP 0x45537f } 0x4553bb ebb8 JMP 0x455375 _ = is[n] 0x4553bd 0f1f00 NOPL 0(AX) 0x4553c0 e8fbd2ffff CALL runtime.panicIndex(SB) is = is[:256] // 消除边界检查 0x4553c5 b900010000 MOVL $0x100, CX 0x4553ca e871d3ffff CALL runtime.panicSliceAcap(SB) 0x4553cf 90 NOPL ","permalink":"https://heliu.site/posts/golang/slice/check/","summary":"Golang slice边界检查。","title":"边界检查"},{"content":" 本篇文章中涉及到汇编，不熟悉请忽略。 使用介绍 append() 函数用于附加连接切片。 T是类型S的元素类型，比如S = []T。 append(s S, x ...T) S append函数将0个或多个具有相同类型S的元素追加到切片s后面并且返回新的切片。 追加的元素必须和原切片的元素同类型。 它的可变参数必须是切片的类型，并返回结果切片，也就是S类型。 值x传递给类型为 ... 的参数T，其中T是S的元素类型。 如果s的容量不足以存储新增元素，append会分配新的切片来保证已有切片元素和新增元素的存储。 因此append()函数返回的切片可能已经指向一个不同的相关数组了，即使修改了数据也不会同步，具体需要根据S的容量进行判断。 append()函数总是返回成功，除非系统内存耗尽了。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 s0 := []int{0, 0} // len 2 cap 2 // append 附加连接单个元素 s1 == []int{0, 0, 2} len 3 cap 4 s1 := append(s0, 2) // append 附加连接多个元素 s2 == []int{0, 0, 2, 3, 5, 7} len 6 cap 8 s2 := append(s1, 3, 5, 7) // append 附加连接切片s0 s3 == []int{0, 0, 2, 3, 5, 7, 0, 0} len 8 cap 8 s3 := append(s2, s0...) // append 附加切片指定值 s4 == []int{3, 5, 7, 2, 3, 5, 7, 0, 0} len 9 cap 10 s4 := append(s3[3:6], s3[2:]...) fmt.Println(\u0026#34;s0\u0026#34;, len(s0), cap(s0)) fmt.Println(\u0026#34;s1\u0026#34;, len(s1), cap(s1)) fmt.Println(\u0026#34;s2\u0026#34;, len(s2), cap(s2)) fmt.Println(\u0026#34;s3\u0026#34;, len(s3), cap(s3)) fmt.Println(\u0026#34;s4\u0026#34;, len(s4), cap(s4)) // s0 len:2 cap:2 // s1 len:3 cap:4 翻倍扩容 // s2 len:6 cap:8 翻倍扩容 // s3 len:8 cap:8 // s4 len:9 cap:10 翻倍扩容 这里翻倍扩容到10原因在于s3[3:6]的容量为5 切片的元素是空接口。 1 2 var t []interface{} t = append(t, 42, 3.1415, \u0026#34;foo\u0026#34;) // t == []interfase{}{42, 3.1415, \u0026#34;foo\u0026#34;} 切片的元素是字节。 1 2 var b []byte b = append(b, \u0026#34;bar\u0026#34;...) // append附加连接字符串内容 b == []byte{\u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;r\u0026#39;} append() 使用示例。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 func ExampleAppend() { // 切片容量不足 append() 返回的是新的切片 指向不同的关联数组 s0 := []int{0,0} // len 2 cap 2 fmt.Println(s0, \u0026amp;s0[0], len(s0), cap(s0))// [0 0] 0xc00000a0b0 2 2 // 由于s0的容量只有2，此时添加元素导致扩容，从新分配内存，并把之前数据复制过来 s1 := append(s0, 2) fmt.Println(s1, \u0026amp;s1[0], len(s1), cap(s1))// [0 0 2] 0xc00000e340 3 4 这里显示扩容后地址变了 s1[0] += 1 fmt.Println(s0, s1) // [0 0] [1 0 2] // 此时添加元素 又会导致扩容 从新分配内存 并把之前数据复制过来 s2 := append(s1, 3, 5, 7) fmt.Println(s2, \u0026amp;s2[0], len(s2), cap(s2))// [1 0 2 3 5 7] 0xc00000c300 6 8 这里显示扩容后地址又变了 // 此时刚好达到最大容量，不会扩容 变量s3引用变量s2底层数组，修改其中元素会引起其他修改 s3 := append(s2, s0...) fmt.Println(s3, len(s3), cap(s3)) // [1 0 2 3 5 7 0 0] 8 8 s2[1] += 1 fmt.Println(s2, s3) // [1 1 2 3 5 7] [1 1 2 3 5 7 0 0] // s3[3:6] len=3 cap=5 // s3[2:] len=6 cap=6 // 导致s4从新分配内存存储数据，s4 这里 len 9 cap 10 s4 := append(s3[3:6], s3[2:]...) fmt.Println(s4) // [3 5 7 2 3 5 7 0 0] // Output: // [0 0] 0xc00000a0b0 2 2 // [0 0 2] 0xc00000e340 3 4 // [0 0] [1 0 2] // [1 0 2 3 5 7] 0xc00000c300 6 8 // [1 0 2 3 5 7 0 0] 8 8 // [1 1 2 3 5 7] [1 1 2 3 5 7 0 0] // [3 5 7 2 3 5 7 0 0] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 func ExampleAppend() { // 如果切片容量足够 append()后不会生成新的切片 s0 := make([]int, 10, 20) // len.10 cap.20 fmt.Println(s0, \u0026amp;s0[0], len(s0), cap(s0)) // [0 0 0 0 0 0 0 0 0 0] 0xc00007c000 10 20 s1 := append(s0,2) // len.11 cap.20 fmt.Println(s1, \u0026amp;s1[0], len(s1), cap(s1)) // [0 0 0 0 0 0 0 0 0 0 2] 0xc00007c000 11 20 s2 := append(s1, 3, 5, 7) // len.14 cap.20 fmt.Println(s2, \u0026amp;s2[0], len(s2), cap(s2)) // [0 0 0 0 0 0 0 0 0 0 2 3 5 7] 0xc00007c000 14 20 // 此时扩容，从新开辟内存，复制原来数据 s3 := append(s2, s0...) // len.24 cap.40 fmt.Println(s3, len(s3), cap(s3)) // [0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] 24 40 // 这里s4容量为37 是由于s3[3:6] 这里40-3=37容量 // 此时容量足够，并没有扩容 // s3[3:6] -\u0026gt; len = 6-3=3 cap = 40-3 = 37 // s3[2:] -\u0026gt; len = 24-2=22 cap = 40-2 = 38 s4 := append(s3[3:6], s3[2:]...) fmt.Println(s4, len(s4), cap(s4)) // [0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] 25 37 fmt.Println(s0) // [0 0 0 0 0 0 0 0 0 0] fmt.Println(s1) // [0 0 0 0 0 0 0 0 0 0 2] fmt.Println(s2) // [0 0 0 0 0 0 0 0 0 0 2 3 5 7] fmt.Println(s3) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0] fmt.Println(s4) // [0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] s0[1] += 1 fmt.Println(s0) // [0 1 0 0 0 0 0 0 0 0] fmt.Println(s1) // [0 1 0 0 0 0 0 0 0 0 2] fmt.Println(s2) // [0 1 0 0 0 0 0 0 0 0 2 3 5 7] fmt.Println(s3) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0] fmt.Println(s4) // [0 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] s4[0] += 1 fmt.Println(s3) // [0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0] fmt.Println(s4) // [1 0 0 0 0 0 0 0 0 0 0 2 3 5 7 0 0 0 0 0 0 0 0 0 0] } Go中append的描述 append 内置函数将元素附加到切片的末尾。如果它有足够的容量，目标将被重新切片以容纳新元素。如果没有，将分配一个新的底层数组。 Append 返回更新后的切片。因此有必要将 append 的结果存储在保存切片本身的变量中： slice = append(slice, elem1, elem2)： elem1，elem2 切片元素。 slice = append(slice, anotherSlice...)：anotherSlice 其他切片。 作为一种特殊情况，将字符串附加到字节切片是合法的，如下所示： slice = append([]byte(\u0026quot;hello \u0026quot;), \u0026quot;world\u0026quot;...) 【append([]T, ...T) []T】 或 【append([]byte, string...) []byte】 1 2 3 4 5 6 7 8 9 10 // The append built-in function appends elements to the end of a slice. If // it has sufficient capacity, the destination is resliced to accommodate the // new elements. If it does not, a new underlying array will be allocated. // Append returns the updated slice. It is therefore necessary to store the // result of append, often in the variable holding the slice itself: //\tslice = append(slice, elem1, elem2)\t//\tslice = append(slice, anotherSlice...)\t// As a special case, it is legal to append a string to a byte slice, like this: //\tslice = append([]byte(\u0026#34;hello \u0026#34;), \u0026#34;world\u0026#34;...) func append(slice []Type, elems ...Type) []Type append() 不扩容时。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 func main() { s := make([]int, 0, 8) // 不存在扩容的情况 s = append(s, 1, 2) _ = s } /* TEXT main.main(SB) /mnt/hgfs/g/hello1/slice1.go func main() { 0x4551e0 4883ec60 SUBQ $0x60, SP 0x4551e4 48896c2458 MOVQ BP, 0x58(SP) 0x4551e9 488d6c2458 LEAQ 0x58(SP), BP s := make([]int, 0, 8) 0x4551ee 440f113c24 MOVUPS X15, 0(SP) 0x4551f3 440f117c2410 MOVUPS X15, 0x10(SP) 0x4551f9 440f117c2420 MOVUPS X15, 0x20(SP) 0x4551ff 440f117c2430 MOVUPS X15, 0x30(SP) 0x455205 488d0424 LEAQ 0(SP), AX # AX=0(SP) 0x455209 8400 TESTB AL, 0(AX) 0x45520b eb00 JMP 0x45520d 0x45520d eb00 JMP 0x45520f 0x45520f 4889442440 MOVQ AX, 0x40(SP) 0x455214 48c744244800000000 MOVQ $0x0, 0x48(SP) 0x45521d 48c744245008000000 MOVQ $0x8, 0x50(SP) s = append(s, 1, 2) 0x455226 eb00 JMP 0x455228 0x455228 48c7042401000000 MOVQ $0x1, 0(SP) 0x455230 48c744240802000000 MOVQ $0x2, 0x8(SP) 0x455239 4889442440 MOVQ AX, 0x40(SP) 0x45523e 48c744244802000000 MOVQ $0x2, 0x48(SP) 0x455247 48c744245008000000 MOVQ $0x8, 0x50(SP) } 0x455250 488b6c2458 MOVQ 0x58(SP), BP 0x455255 4883c460 ADDQ $0x60, SP 0x455259 c3 RET */ // +60 | address of runtime.main // ---------------------------------------- // +58 | BP of runtime.main // ---------------------------------------- BP // +50 | 8 s.cap // ---------------------------------------- // +48 | 2 s.len // ---------------------------------------- // +40 | 0(SP) s.data // ---------------------------------------- // +38 | 0 *s.data.7 // ---------------------------------------- // +30 | 0 *s.data.6 // ---------------------------------------- // +28 | 0 *s.data.5 // ---------------------------------------- // +20 | 0 *s.data.4 // ---------------------------------------- // +18 | 0 *s.data.3 // ---------------------------------------- // +10 | 0 *s.data.2 // ---------------------------------------- // +08 | 2 *s.data.1 // ---------------------------------------- // +00 | 1 *s.data.0 // ---------------------------------------- SP append() 翻倍扩容时。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 func main() { s := make([]int, 0, 1) // 翻倍扩容情况 s = append(s, 1, 2) _ = s } /* TEXT main.main(SB) /mnt/hgfs/g/hello1/slice1.go func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 0f8681000000 JBE 0x45526b 0x4551ea 4883ec68 SUBQ $0x68, SP 0x4551ee 48896c2460 MOVQ BP, 0x60(SP) 0x4551f3 488d6c2460 LEAQ 0x60(SP), BP s := make([]int, 0, 1) 0x4551f8 48c744244000000000 MOVQ $0x0, 0x40(SP) 0x455201 488d5c2440 LEAQ 0x40(SP), BX # BX=0x40(SP) 0x455206 8403 TESTB AL, 0(BX) 0x455208 eb00 JMP 0x45520a 0x45520a eb00 JMP 0x45520c 0x45520c 48895c2448 MOVQ BX, 0x48(SP) 0x455211 48c744245000000000 MOVQ $0x0, 0x50(SP) 0x45521a 48c744245801000000 MOVQ $0x1, 0x58(SP) s = append(s, 1, 2) 0x455223 eb00 JMP 0x455225 0x455225 488d05f44a0000 LEAQ 0x4af4(IP), AX # AX=0x4af4(IP) \u0026amp;type.int 0x45522c 31c9 XORL CX, CX # CX=0 0x45522e bf01000000 MOVL $0x1, DI # DI=1 0x455233 be02000000 MOVL $0x2, SI # SI=2 翻倍扩容后 cap=2 # runtime.growslice -\u0026gt; func growslice(et *_type, old slice, cap int) slice 扩容函数 # 返回值 AX=r.data; BX=r.len; CX=r.cap 0x455238 e8c3b2feff CALL runtime.growslice(SB)\t# DX=r.len+2 原因是runtime.growslice返回的r.len是old.len 0x45523d 488d5302 LEAQ 0x2(BX), DX\t0x455241 eb00 JMP 0x455243 0x455243 48c70001000000 MOVQ $0x1, 0(AX)\t0x45524a 48c7400802000000 MOVQ $0x2, 0x8(AX) 0x455252 4889442448 MOVQ AX, 0x48(SP) 0x455257 4889542450 MOVQ DX, 0x50(SP) 0x45525c 48894c2458 MOVQ CX, 0x58(SP) } 0x455261 488b6c2460 MOVQ 0x60(SP), BP 0x455266 4883c468 ADDQ $0x68, SP 0x45526a c3 RET func main() { 0x45526b e8f0ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x455270 e96bffffff JMP main.main(SB) */ // +68 |\taddress of runtime.main // ------------------------------------ // +60 |\tBP of runtime.main // ------------------------------------ BP // +58 | 1 s.cap // ------------------------------------ // +50 | 0 s.len // ------------------------------------ // +48 | 0x40(SP) s.data // ------------------------------------ // +40 | 0 *s.data.0 // ------------------------------------ // +38 | // ------------------------------------ // +30 | // ------------------------------------ // +28 | // ------------------------------------ // +20 | // ------------------------------------ // +18 | // ------------------------------------ // +10 | // ------------------------------------ // +08 | // ------------------------------------ // +00 | // ------------------------------------ SP nil切片调用append函数 1 2 3 4 5 6 7 8 9 package main import \u0026#34;fmt\u0026#34; func main() { var s []int // {nil, 0, 0} s = append(s, 1, 2) fmt.Println(s) } TEXT main.main(SB) /mnt/hgfs/g/hello1/slice1.go func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7665 JBE 0x45524b 0x4551e6 4883ec60 SUBQ $0x60, SP 0x4551ea 48896c2458 MOVQ BP, 0x58(SP) 0x4551ef 488d6c2458 LEAQ 0x58(SP), BP var s []int // {nil, 0, 0} 0x4551f4 48c744244000000000 MOVQ $0x0, 0x40(SP) 0x4551fd 440f117c2448 MOVUPS X15, 0x48(SP) s = append(s, 1, 2) 0x455203 eb00 JMP 0x455205 0x455205 488d05144b0000 LEAQ 0x4b14(IP), AX # AX=0x4b14(IP) et=\u0026amp;type.int 0x45520c 31db XORL BX, BX # BX=0 old.data 0x45520e 31c9 XORL CX, CX # CX=0 old.len 0x455210 4889cf MOVQ CX, DI # DI=0 old.cap 0x455213 be02000000 MOVL $0x2, SI # SI=2 cap=2 # runtime.growslice -\u0026gt; func growslice(et *_type, old slice, cap int) slice 扩容函数 # 这里就是nil切片能使用append新增元素的原因 0x455218 e8e3b2feff CALL runtime.growslice(SB) 0x45521d 488d5302 LEAQ 0x2(BX), DX 0x455221 eb00 JMP 0x455223 0x455223 48c70001000000 MOVQ $0x1, 0(AX) 0x45522a 48c7400802000000 MOVQ $0x2, 0x8(AX) 0x455232 4889442440 MOVQ AX, 0x40(SP) 0x455237 4889542448 MOVQ DX, 0x48(SP) 0x45523c 48894c2450 MOVQ CX, 0x50(SP) } 0x455241 488b6c2458 MOVQ 0x58(SP), BP 0x455246 4883c460 ADDQ $0x60, SP 0x45524a c3 RET func main() { 0x45524b e810cdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455250 eb8e JMP main.main(SB) // +60 | address of runtime.main // ----------------------------------- // +58 | BP of runtime.main // ----------------------------------- BP // +50 | 0 s.cap // ----------------------------------- // +48 | 0 s.len // ----------------------------------- // +40 | 0 s.data // ----------------------------------- // +38 | // ----------------------------------- // +30 | // ----------------------------------- // +28 | // ----------------------------------- // +20 | // ----------------------------------- // +18 | // ----------------------------------- // +10 | // ----------------------------------- // +08 | // ----------------------------------- // +00 | // ----------------------------------- SP append 执行步骤 如果当前append()函数执行完后切片不会\u0026quot;翻倍扩容\u0026quot;那么，直接是把append后追加的数据拷贝到切片的后续空间即可。 如果当前append()函数执行完后需要\u0026quot;翻倍扩容\u0026quot;，那么先调用runtime.growslice()扩容函数，然后在拷贝数据追加到新的内存空间。 append 函数总结 append() 函数原型 func append(slice []Type, elems ...Type) []Type 支持两种形式。 1 2 3 4 // 形式一 slice = append(slice, elem1, elem2)\t// 形式二 anotherSlice... 这种形式只支持anotherSlice是切片 slice = append(slice, anotherSlice...)\t1 2 // 形式三 只有在这种形式下函数内才能使用 \u0026#34;world\u0026#34;... 形式解引用字符串 slice = append([]byte(\u0026#34;hello \u0026#34;), \u0026#34;world\u0026#34;...) append() 函数是由编译器支持的没有函数原型只存在函数声明。 func append(slice []Type, elems ...Type) []Type 如果添加过程中需要扩容，编译器会调用 runtime.growslice 函数，该函数原型。 1 2 3 4 5 6 7 8 9 10 11 // 函数参数 // et *_type：切片元素元类型 // old slice：未扩容前切片 // cap int：添加元素后的容量 old.len + n = cap // 返回值 slice // slice.data：新分配的内存地址 // slice.len：old.len 旧切片长度 // slice.cap：翻倍扩容后的容量 func growslice(et *_type, old slice, cap int) slice ","permalink":"https://heliu.site/posts/golang/slice/append/","summary":"Golang append()函数介绍。","title":"append()"},{"content":"copy(dst, src []Type) int copy 内置函数将元素从 src 源切片复制到 dst 目标切片。(作为一种特殊情况，它还将字节从一个 string 复制到一个 []byte) src 和 dst 可能会重叠。copy 返回赋值的元素数量，它将是 len(src) 和 len(dst) 的最小值。 常常将切片元素从源src复制到目标dst，并返回复制的元素数 两个参数必须具有相同得元素类型Type，并且可以分配给类型为[]Type的切片 src和dst切片的底层元素可能会重叠 复制的元素数量是len(src)和len(dst)的最小值 1 2 3 4 5 6 // The copy built-in function copies elements from a source slice into a // destination slice. (As a special case, it also will copy bytes from a // string to a slice of bytes.) The source and destination may overlap. Copy // returns the number of elements copied, which will be the minimum of // len(src) and len(dst). copy(dst, src []Type) int // src -\u0026gt; dst 使用示例。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func ExampleCopy() { var a = [...]int{0,1,2,3,4,5,6,7} var s = make([]int, 6) n1 := copy(s, a[0:]) fmt.Println(n1, s) // 6 [0 1 2 3 4 5] // 从s中赋值数据到s中 n2 := copy(s, s[2:]) fmt.Println(n2, s) // 4 [2 3 4 5 4 5] fmt.Println(a) // [0 1 2 3 4 5 6 7] // Output: // 6 [0 1 2 3 4 5] // 4 [2 3 4 5 4 5] // [0 1 2 3 4 5 6 7] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func ExampleCopy() { var a = [...]int{0,1,2,3,4,5,6,7} var s = make([]int, 4) n1 := copy(s, a[0:]) fmt.Println(n1, s) // 4 [0 1 2 3] // 从s中赋值数据到s中 n2 := copy(s, s[2:]) fmt.Println(n2, s) // 2 [2 3 2 3] fmt.Println(a) // [0 1 2 3 4 5 6 7] // Output: // 4 [0 1 2 3] // 2 [2 3 2 3] // [0 1 2 3 4 5 6 7] } copy(to []byte, fm string) int copy(to []byte, fm string) int\t// fm -\u0026gt; to copy() 函数还接收可分配给[]byte类型的目标参数，其中fm参数为字符串类型 1 2 3 4 5 6 7 8 9 10 func ExampleCopy() { var b = make([]byte, 5) n3 := copy(b, \u0026#34;Hello，World!\u0026#34;) fmt.Println(n3, b) // 5 [72 101 108 108 111] // Output: // 5 [72 101 108 108 111] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func ExampleCopy() { var s string = \u0026#34;hello Go语言\u0026#34; // 8 + 2*3 = 14 var slice1 []byte // 创建切片 默认长度为0 num1 := copy(slice1, s) fmt.Println(num1, slice1) // 0 [] var slice2 []byte = []byte{0} // 创建切片 并初始化一个容量 num2 := copy(slice2, s) fmt.Println(num2, slice2) // 1 [104] slice3 := make([]byte, 20) // 创建切片 初始化长度为20 num3 := copy(slice3, s) fmt.Println(num3, slice3) // 14 [104 101 108 108 111 32 71 111 232 175 173 232 168 128 0 0 0 0 0 0] slice4 := make([]byte, 20, 40) // 创建切片 初始化长度为20 容量为40 num4 := copy(slice4, s) fmt.Println(num4, slice4) // 14 [104 101 108 108 111 32 71 111 232 175 173 232 168 128 0 0 0 0 0 0] // 由此可以看出 copy()函数 复制多少跟接受变量长度有关 // Output: // 0 [] // 1 [104] // 14 [104 101 108 108 111 32 71 111 232 175 173 232 168 128 0 0 0 0 0 0] // 14 [104 101 108 108 111 32 71 111 232 175 173 232 168 128 0 0 0 0 0 0] } 1 2 3 4 5 6 7 8 func ExampleCopy() { slice := make([]byte, 3) n := copy(slice, \u0026#34;append\u0026#34;) fmt.Println(n ,slice) // 3 [97 112 112] // Output: // 3 [97 112 112] } copy 源码 参考本章节的原理篇。 ","permalink":"https://heliu.site/posts/golang/slice/copy/","summary":"Golang copy()函数介绍。","title":"copy()"},{"content":"map 介绍 map是一种无序的基于key-value的数据结构，Go语言中的map是引用类型，必须初始化才能使用。 字典(map)是一种键-值对(key-value)的无序集合。 一组称为值元素 value。 另外一组称为唯一键索引key。 未初始化字典的值nil。 字典是引用类型：声明如下 [keytype]和valuetype之间允许有空格，但是Gofmt移除了空格。 var map1 map[keytype]valuetype 声明的时候不需要知道字典的长度，字典是可以动态增长的，但最好指定容量。 key可以是任意能使用**==或者!=**操作符比较的类型，这是由于在使用map中很多都需要比较key是否相等，比如获取key存储的value值，需要比较key是否一致。 如string、int、float。 所以字典、切片、函数不能作为key。 含有切片的结构体不能作为key，只能包含内建类型的struct是可以作为key的。 指针和接口类型可以，尽量不使用接口，接口作为key在hash时有可能会panic，接口中存在不可比较类型时。 value可以是任意类型，通过使用空接口类型，可以存储任意值。但是使用这种类型作为值时需要先做一次类型断言。 字典传递给函数的代价很小，虽然通过key在字典中查找值很快。但是仍然比从数组和切片的索引中读取要慢，一般建议使用切片。 字典可以用{key1:val1, key2:val2}的描述方式来初始化，就像数组和结构体一样。字典是引用类型的，内存用make函数来分配。 var map1 = make(map[keytype]valtype) 和数组不同，字典可以根据新增的键-值(key-value)对动态的伸缩，因此它不存在固定长度或者最大限制。 也可以选择标明map的初始容量capacity，make(map[keytype]valtype, cap)。 // cap 表示 map 的容量，该参数虽然不是必须的 // 应该在初始化map的时候就为其指定一个合适的容量 make(map[keyType]ValueType, [cap]) map2 := make(map[string]float32, 100) // 支持100个key/elem不扩容 当字典增长到容量上限的时候，如果在增加新的键-值对，字典的大小会自动加1。所以对于大的字典或者会快速扩张的字典，即使只是大概知道容量，也最好先标明。 在一个nil的切片中添加元素是没有问题的，但是对于一个字典做同样的事情将会生成一个运行时异常。由于nil还未分配内存，所以不能使用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 声明变量s，并未分配内存 默认值为 nil // slice切片结构 struct slice {data, len, cap} var s []int // append函数会初始化s变量并分配内存 s = append(s, 1) fmt.Println(s) // [1] //var m map[string]int //m[\u0026#34;one\u0026#34;] = 1 // panic: assignment to entry in nil map //fmt.Println(m) // 但是使用make()创建的者不会出现类似情况 // make函数会初始化map，并分配内存 m2 := make(map[string]int, 0) m2[\u0026#34;a\u0026#34;] = 12 fmt.Println(m2) // map[a:12] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;fmt\u0026#34; ) var m3 = make(map[string]int, 8) var m4 map[string]float64 func main() { var m = make(map[string]int, 8) m[\u0026#34;a\u0026#34;] = 12 fmt.Println(m) // map[a:12] var m1 map[string]string m1[\u0026#34;a\u0026#34;] = \u0026#34;as\u0026#34; // panic: assignment to entry in nil map fmt.Println(m1) m2 := make(map[string]int, 8) m2[\u0026#34;a\u0026#34;] = 12 fmt.Println(m2) // map[a:12] m3[\u0026#34;a\u0026#34;] = 12 fmt.Println(m3) // map[a:12] m4[\u0026#34;a\u0026#34;] = 12.3 // panic: assignment to entry in nil map fmt.Println(m4) i, v := m3[\u0026#34;a\u0026#34;] fmt.Println(i, v) // 12 true } 可以通过val1 = map1[key1]的方法获取key1对应的值val1。 value, ok = map[key] 1 2 3 if _, ok := x[\u0026#34;two\u0026#34;]; !ok { fmt.Println(\u0026#34;值不存在\u0026#34;) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import \u0026#34;fmt\u0026#34; func main() { scoreMap := make(map[string]int) scoreMap[\u0026#34;one\u0026#34;] = 90 scoreMap[\u0026#34;two\u0026#34;] = 100 // 如果key存在 ok为true，v为对应的值 // key不存在 ok为false，v为值类型的零值 v, ok := scoreMap[\u0026#34;two\u0026#34;] if ok { fmt.Println(v) } else { fmt.Println(\u0026#34;不存在\u0026#34;) } } 定义字典的例子。 1 2 3 4 5 6 7 8 9 10 // 指定容量 map1 := make(map[string]string, 5) map2 := make(map[string]string) // 创建并初始化一个空的字典，这时没有任何元素 map3 := map[string]string{} // 字典中有三个值 map4 := map[string]string{\u0026#34;a\u0026#34;:\u0026#34;1\u0026#34;, \u0026#34;b\u0026#34;:\u0026#34;2\u0026#34;, \u0026#34;c\u0026#34;:\u0026#34;3\u0026#34;} 从map1中删除key1，直接使用delete(map1, key1)就可以。 map1：表示要删除键值对的map key1：表示要删除的键值对的键 如果key1不存在，该操作不会产生错误 // 从字典map4中删除键\u0026#34;a\u0026#34; delete(map4, \u0026#34;a\u0026#34;) 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;fmt\u0026#34; func main() { scoreMap := make(map[string]int) scoreMap[\u0026#34;one\u0026#34;] = 90 scoreMap[\u0026#34;two\u0026#34;] = 100 // 从scoreMap中删除键one delete(scoreMap, \u0026#34;one\u0026#34;) fmt.Println(scoreMap) // map[two:100] } 字典默认是无序的，无论是按照key还是value默认都不排序。 如果想为字典排序，需要将key（或者value）复制到一个切片，再对切片排序（使用sort包）。 按照指定顺序遍历map 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;sort\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 初始化随机数种子 rand.Seed(time.Now().UnixNano()) var scoreMap = make(map[string]int, 200) // 生成数据 for i := 0; i \u0026lt; 100; i++ { // 生成 0~99 的随机整数 key := \u0026#34;\u0026#34; if i \u0026lt; 10 { key = \u0026#34;0\u0026#34; + strconv.Itoa(i) } else { key = strconv.Itoa(i) } scoreMap[key] = rand.Intn(100) } // 取出map中的所有key存入切片keys var keys = make([]string, 0, 200) for key := range scoreMap { // 把map的key存入[]string切片 keys = append(keys, key) } // 对切片进行排序 sort.Strings(keys) // 按照排序后的key遍历map for _, key := range keys { fmt.Println(key, scoreMap[key]) } } 元素为map类型的切片 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import \u0026#34;fmt\u0026#34; func main() { var mapSlice = make([]map[string]string, 3) // 元素map为nil，需要初始化 for index, value := range mapSlice { fmt.Printf(\u0026#34;index:%d value:%#v\\n\u0026#34;, index, value) } /* * index:0 value:map[string]string(nil) * index:1 value:map[string]string(nil) * index:2 value:map[string]string(nil) */ fmt.Println(\u0026#34;after init\u0026#34;) // 对切片中的map元素进行初始化 并指定容量为10 mapSlice[0] = make(map[string]string, 10)\tfmt.Println(mapSlice, mapSlice[0]) // [map[] map[] map[]] map[] mapSlice[0][\u0026#34;name\u0026#34;] = \u0026#34;name\u0026#34; mapSlice[0][\u0026#34;password\u0026#34;] = \u0026#34;password\u0026#34; mapSlice[0][\u0026#34;address\u0026#34;] = \u0026#34;address\u0026#34; fmt.Println(mapSlice) // [map[address:address name:name password:password] map[] map[]] for index, value := range mapSlice { fmt.Printf(\u0026#34;index:%d value:%#v\\n\u0026#34;, index, value) } /* * index:0 value:map[address:address name:name password:password] * index:1 value:map[string]string(nil) * index:2 value:map[string]string(nil) */ } 值为切片类型的map 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main import \u0026#34;fmt\u0026#34; func main() { var sliceMap = make(map[string][]string, 3) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, sliceMap) // map[string][]string{} fmt.Println(\u0026#34;after init\u0026#34;) // after init key := \u0026#34;中国\u0026#34; value, ok := sliceMap[key] fmt.Printf(\u0026#34;%#v, %#v\\n\u0026#34;, value, ok) // []string(nil), false if !ok { // 初始化 切片[]string 长度0 容量2 value = make([]string, 0, 2) } // 切片添加元素 value = append(value, \u0026#34;北京\u0026#34;, \u0026#34;上海\u0026#34;) sliceMap[key] = value fmt.Println(sliceMap) // map[中国:[北京 上海]] } range语句中的值 在range语句中生成的数据的值是真实集合元素的副本，他们不是原有元素的引用。 意味着更新这些值将不会修改原来的数据，同时也意味着使用这些值的地址将不会得到原有数据的指针。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;fmt\u0026#34; ) func main() { data := []int{1, 2, 3} for _, v := range data { v *= 10 } fmt.Println(\u0026#34;data:\u0026#34;, data) // data: [1 2 3] scoreMap := make(map[string]int) scoreMap[\u0026#34;one\u0026#34;] = 90 scoreMap[\u0026#34;two\u0026#34;] = 100 for k := range scoreMap { fmt.Println(k) } for k, v := range scoreMap { fmt.Println(k, v) } } /* data: [1 2 3] one two one 90 two 100 */ 修改更新原有集合中的数据。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import ( \u0026#34;fmt\u0026#34; ) func main() { data := []int{1, 2, 3} for i := range data { data[i] *= 10 } fmt.Println(\u0026#34;data:\u0026#34;, data) // data: [10 20 30] } ","permalink":"https://heliu.site/posts/golang/map/use/","summary":"Golang map的使用介绍。","title":"Map(使用)"},{"content":" 本篇介绍map的golang源码，全篇代码较多比较枯燥。 map 包说明： map 只是一个 hash 表。数据被安排在桶数组中。每个桶最多包含8个 key/elem 对。 hash 的low-order bits(hash\u0026amp;1\u0026lt;\u0026lt;B - 1)用于选择桶。每个桶包含 high-order bits（高8位）用于区分每个桶中的 entries（就是tophash）。 如果有超过 8 个 keys，hash 到一个桶中，我们将额外的 extra 桶链接起来。 当 hashtable 增长时，我们分配一个两倍大小的新桶数组。桶会从旧的桶数组渐进式复制到新的桶数组中。 Map 迭代器遍历桶数组，并按遍历顺序返回keys。（常规桶后是按照溢出桶的顺序返回桶索引） 为了维护迭代语义，我们从不将 keys 移动到桶中(如果移动，键可能会返回0或2次)。 在增长 table 时，迭代器仍然在迭代旧表，并且必须检查新表是否已经移动(“evacuated”)到新表。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 // This file contains the implementation of Go\u0026#39;s map type. // // A map is just a hash table. The data is arranged // into an array of buckets. Each bucket contains up to // 8 key/elem pairs. The low-order bits of the hash are // used to select a bucket. Each bucket contains a few // high-order bits of each hash to distinguish the entries // within a single bucket. // // If more than 8 keys hash to a bucket, we chain on // extra buckets. // // When the hashtable grows, we allocate a new array // of buckets twice as big. Buckets are incrementally // copied from the old bucket array to the new bucket array. // // Map iterators walk through the array of buckets and // return the keys in walk order (bucket #, then overflow // chain order, then bucket index). To maintain iteration // semantics, we never move keys within their bucket (if // we did, keys might be returned 0 or 2 times). When // growing the table, iterators remain iterating through the // old table and must check the new table if the bucket // they are iterating through has been moved (\u0026#34;evacuated\u0026#34;) // to the new table. // Picking loadFactor: too large and we have lots of overflow // buckets, too small and we waste a lot of space. I wrote // a simple program to check some stats for different loads: // (64-bit, 8 byte keys and elems) // // Picking loadFactor: 太大会有很多溢出的桶，太小会浪费很多空间。 // 我写了一个简单的程序来检查不同加载的一些统计信息:(64-bit, 8 byte keys and elems) // loadFactor %overflow bytes/entry hitprobe missprobe // 4.00 2.13 20.77 3.00 4.00 // 4.50 4.05 17.30 3.25 4.50 // 5.00 6.85 14.77 3.50 5.00 // 5.50 10.55 12.94 3.75 5.50 // 6.00 15.27 11.67 4.00 6.00 // 6.50 20.90 10.79 4.25 6.50 -- loadFactor = 13/2 // 7.00 27.14 10.15 4.50 7.00 // 7.50 34.03 9.73 4.75 7.50 // 8.00 41.10 9.40 5.00 8.00 // // %overflow = percentage of buckets which have an overflow bucket # 有溢出桶的桶的百分比 // bytes/entry = overhead bytes used per key/elem pair # 每个 key/elem 对使用的开销字节数 // hitprobe = # of entries to check when looking up a present key # 在查找当前键时要检查的条目 // missprobe = # of entries to check when looking up an absent key # 在查找缺失键时要检查的条目 // // Keep in mind this data is for maximally loaded tables, i.e. just // before the table grows. Typical tables will be somewhat less loaded. hmap 🚀 type hmap struct 结构说明：go的map中存储的是hmap的指针。map分配的是一块连续的内存，包括常规桶和溢出桶的内存。\ncount：记录map中存储的键值对数量。该值也是len(map)返回值。cap()函数对map没有实际作用。 flags：扩容、迭代相关标志位。 B：常规桶个数2^B，此处的B是幂次方。注意这里并没有包括溢出桶数量。 noverflow：已使用的溢出桶数量，该值用于等量扩容的判断值。 hash0：生成的随机值，扩容时候该值不会被刷新。但是在删除时map为空时会刷新。 buckets：常规桶起始地址。 oldbuckets：扩容时用于存储旧常规桶的起始地址也就是buckets的值，当oldbuckets != nil时也是扩容正在进行的条件。 nevacuate：扩容正在进行中下一个要被迁移的旧桶编号。 extra：溢出桶相关信息。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler\u0026#39;s definition. // 1. 已经存储的键值对个数，len(map) == count // 2. map不能使用cap()函数，cap()函数是计算容量，对于map来说意义不大 count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 // 当前hmap的状态，比如正处于写入数据中等，参看下面的常量 // 【常规桶】个数等于 2^B，make()初始化时该值会被设置，注意这里并【没用】包含溢出桶的数量 B uint8 // log_2 of # of buckets (最多可以容纳 loadFactor * 2^B items) // 已使用的溢出桶数量，用于是否等量扩容判断，在make初始化和扩容初始化时被重置为0 // 已使用溢出桶的计数规则： // 1. 常规桶 h.B \u0026lt;= 15 时，每使用了一个溢出桶 h.noverflow++ // 2. 常规桶 h.B \u0026gt; 16 时，按照一定概率增加溢出桶 1/((1 \u0026lt;\u0026lt; (h.B-15))-1) 的概率 h.noverflow++ noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details // 在make初始化时根据随机数生成 // hash随机数，用于生成key的hash值，make初始化时该值会被设置 hash0 uint32 // hash seed\t// 常规桶起始地址，make初始化时该值会被设置 // 该值也许为nil，当count==0时，在【[key] = elem】时会初始化分配内存 buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. // 当存在扩容时会把hmap.buckets值拷贝到hmap.oldbuckets // 这也是判断扩容的条件 hmap.oldbuckets != nil oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing // 记录下一个要被迁移的旧桶编号，在扩容初始化时被重置为0，被分摊到到每次map操作中渐进迁移 nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) // make初始化时extra.nextOverflow改值会被设置，记录溢出桶的首地址 // 溢出桶分配规则常规桶 【h.B \u0026gt;= 4】，就会预分配 【h.B-4】 个溢出桶备用 // extra 主要是记录分配的备用空闲溢出桶地址 extra.nextOverflow，以及分配过的无指针溢出桶记录在extra.overflow extra *mapextra // optional fields\t溢出桶信息 以及 扩容信息 } createOverflow() 创建一个 extra 或 extra.overflow。 1 2 3 4 5 6 7 8 9 10 11 12 func (h *hmap) createOverflow() { if h.extra == nil {\th.extra = new(mapextra) } if h.extra.overflow == nil { // slice多采用make()创建，这里采用new创建 // 也就是只是创建24B大小内存，\u0026amp;slice{0,0,0} // 后续overflow字段会通过append()函数添加元素 // 当bmap是指针类型时，用于存储溢出bmap，以免被GC给回收了 h.extra.overflow = new([]*bmap) } } growing() 判断当前map是否处于扩容状态，可能是翻倍扩容或等量扩容。 1 2 3 4 // growing reports whether h is growing. The growth may be to the same size or bigger. func (h *hmap) growing() bool { return h.oldbuckets != nil // true.处于扩容状态 } sameSizeGrow() sameSizeGrow 表示当前正在处于等量扩容状态。 1 2 3 4 // sameSizeGrow reports whether the current growth is to a map of the same size. func (h *hmap) sameSizeGrow() bool { return h.flags\u0026amp;sameSizeGrow != 0 // true.等量扩容 } noldbuckets() noldbuckets 计算当前 map 扩容之前的常规桶数。 1 2 3 4 5 6 7 8 // noldbuckets calculates the number of buckets prior to the current map growth. func (h *hmap) noldbuckets() uintptr { oldB := h.B if !h.sameSizeGrow() { oldB-- } return bucketShift(oldB) // 1 \u0026lt;\u0026lt; B } oldbucketmask() 常规桶扩容之前的掩码数。 1 2 3 4 // oldbucketmask provides a mask that can be applied to calculate n % noldbuckets(). func (h *hmap) oldbucketmask() uintptr { return h.noldbuckets() - 1 // 桶增长之前的掩码 } incrnoverflow() Incrnoverflow 增加 h.noverflow。noverflow 统计溢出桶的数量。 这用于触发等量扩容大小的map增长。等量扩容条件参看 tooManyOverflowBuckets 方法。 为了保持hmap较小，noverflow是uint16类型。 当桶很少时，noverflow是一个精确的计数。当有很多桶时，noverflow是一个近似的计数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // incrnoverflow increments h.noverflow. // noverflow counts the number of overflow buckets. // This is used to trigger same-size map growth. // See also tooManyOverflowBuckets. // To keep hmap small, noverflow is a uint16. // When there are few buckets, noverflow is an exact count. // When there are many buckets, noverflow is an approximate count. func (h *hmap) incrnoverflow() {\t// 增加使用的溢出桶计数器 // We trigger same-size map growth if there are // as many overflow buckets as buckets. // We need to be able to count to 1\u0026lt;\u0026lt;h.B. // // 如果溢出桶和常规桶一样多，我们就会触发等量扩容map。我们需要能够数到 1\u0026lt;\u0026lt;h.B。 if h.B \u0026lt; 16 { // 当桶的数量 \u0026lt;= 2^15 溢出桶加一 h.noverflow++ return } // Increment with probability 1/(1\u0026lt;\u0026lt;(h.B-15)). // When we reach 1\u0026lt;\u0026lt;15 - 1, we will have approximately // as many overflow buckets as buckets. // // 以1/(1\u0026lt;\u0026lt;(h.B-15))概率递增加一 mask := uint32(1)\u0026lt;\u0026lt;(h.B-15) - 1\t// Example: if h.B == 18, then mask == 7, // and fastrand \u0026amp; 7 == 0 with probability 1/8. if fastrand()\u0026amp;mask == 0 { h.noverflow++ } } newoverflow() 分配新的溢出桶，如果当前桶满了则需要分配溢出桶调用此方法返回溢出桶。 该方法有备用的溢出桶已用完重新分配溢出桶情况。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 func (h *hmap) newoverflow(t *maptype, b *bmap) *bmap { var ovf *bmap // 分配的溢出桶 *bmap // 当前溢出桶信息不为空 并且 下一个溢出桶不为空 直接从后面获取 if h.extra != nil \u0026amp;\u0026amp; h.extra.nextOverflow != nil {\t// We have preallocated overflow buckets available. // See makeBucketArray for more details. // // 我们有预先分配的溢出桶可用。更多细节请参见makeBucketArray方法。 ovf = h.extra.nextOverflow // 判断溢出桶的overflow字段是否为nil，用于判断分配的备用溢出桶使用已用完 // 参看makeBucketArray方法中把最后一个溢出桶overflow指向了第一个常规桶地址 if ovf.overflow(t) == nil { // We\u0026#39;re not at the end of the preallocated overflow buckets. Bump the pointer. // // 我们还没有到达预分配的溢出桶的末尾。碰一下指针。 h.extra.nextOverflow = (*bmap)(add(unsafe.Pointer(ovf), uintptr(t.bucketsize)))\t// 下一个空闲的溢出桶 } else { // 已经是最后一个备用的溢出桶了（最后一个溢出桶指向了第一个常规桶，其他溢出桶都应该未nil） // This is the last preallocated overflow bucket. // Reset the overflow pointer on this bucket, // which was set to a non-nil sentinel value. // // 这是最后一个预分配的溢出桶。 // 重置此桶上的溢出指针，该指针被设置为非nil哨兵值。 ovf.setoverflow(t, nil) // ovf.overflow = nil h.extra.nextOverflow = nil } } else { // 溢出桶以分配完了 或者 没有分配溢出桶时 // 注意：这里直接调用new()函数分配的 ovf = (*bmap)(newobject(t.bucket))\t} // 已使用溢出桶计数器 h.incrnoverflow()\t// 桶不包含指针 if t.bucket.ptrdata == 0 { h.createOverflow()\t// 防止 h.extra 或 h.extra.overflow 没有初始化 // 将分配的溢出桶保存在h.extra.overflow中，主要是防止这部分内存不该被GC清理，结果被清除了 *h.extra.overflow = append(*h.extra.overflow, ovf) } b.setoverflow(t, ovf) // b.overflow = ovf return ovf } type bmap struct bmap 用来装 map 的桶。 bmap 前8字节是 tophash 值，后面分别是8个连续的 key 和8个连续的 value 然后是一个溢出桶指针。 之所以桶按照这个结构设计是为了内存紧凑。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // A bucket for a Go map. type bmap struct { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] \u0026lt; minTopHash, // tophash[0] is a bucket evacuation state instead. // // Tophash通常包含该桶中每个键的散列值的顶部字节。 // 如果tophash[0] \u0026lt; minTopHash，则tophash[0]为桶疏散状态。 // const minTopHash = 5 // const bucketCnt = 8; tophash [bucketCnt]uint8 // [8]uint8 // Followed by bucketCnt keys and then bucketCnt elems. // NOTE: packing all the keys together and then all the elems together makes the // code a bit more complicated than alternating key/elem/key/elem/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer. // // 接下来是bucketCnt的keys，然后是bucketCnt的elems。 // 注意: 将所有key打包在一起，然后将所有elem打包在一起 // 这比交替使用key/elem/key/elem/…但它允许我们消除所需的内边距，例如 map[int64]int8。 // 后跟一个溢出指针。 } bmap 结构： h1 - h8：8个hash值分别是key的hash高八位，主要用于快速查找key和bmap桶的相关迁移状态标记。 k1 - k8：8个key的值。 v1 - v8：8个value的值。 overflow：指向后面溢出桶的指针。 evacuated() 该 bmap 桶是否是疏散的，1 \u0026lt; tophash[0] \u0026lt; 5，表明该 bmap 桶数据已被迁移。 1 2 3 4 5 6 7 8 func evacuated(b *bmap) bool { h := b.tophash[0] // 参看后面 consts 中相关常量定义 // const emptyOne = 1 // const minTopHash = 5 // return h IN (2,3,4) return h \u0026gt; emptyOne \u0026amp;\u0026amp; h \u0026lt; minTopHash } overflow() 该 bmap 桶的 overflow 字段指向的溢出桶 *bmap。 1 2 3 4 func (b *bmap) overflow(t *maptype) *bmap { // b + bucketsize - goarch.PtrSize return *(**bmap)(add(unsafe.Pointer(b), uintptr(t.bucketsize)-goarch.PtrSize)) } setoverflow() 该 bmap 桶的 overflow 字段指向 ovf *bmap 这个桶。 等价于 bmap.overflow = ovf 。 1 2 3 4 func (b *bmap) setoverflow(t *maptype, ovf *bmap) { // bmap.overflow = ovf *(**bmap)(add(unsafe.Pointer(b), uintptr(t.bucketsize)-goarch.PtrSize)) = ovf } keys() 返回该 bmap 桶的 key 开始地址。 1 2 3 4 5 func (b *bmap) keys() unsafe.Pointer { // dataOffset 参看后面 consts 中的常量定义 // dataOffset -\u0026gt; [8]uint8 return add(unsafe.Pointer(b), dataOffset) } type mapextra struct Mapextra 持有一些在所有map中都不存在的字段。主要是溢出桶相关。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // mapextra holds fields that are not present on all maps. type mapextra struct { // If both key and elem do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and elem do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. // // 如果 key 和 elem 都不包含指针并且是允许内联(inline)的，那么我们将bucket类型标记为【不包含指针】。这样避免了扫描这样的map。 // 然而 bmap.overflow 是一个指针。 // 为了保持overflow桶是alive(活跃的不被GC回收)，我们将指向所有overflow桶的指针存储在hmap.extra.overflow和hmap.extra.oldoverflow中 // 【仅当 key 和 elem 不包含指针时，才使用 overflow 和 oldoverflow。】因为不包含指针才容易被GC回收，因此需要保存。 // overflow 包含用于 hmap.buckets 的overflow桶集 // oldoverflow 包含用于 hmap.oldbuckets 的overflow桶集 // 间接允许在hiter中存储一个指向切片的指针。(hiter是遍历相关结构) overflow *[]*bmap // 在 key 和 elem 不包含指针时，把已经用到的溢出桶存储起来，主要是保存 alive oldoverflow *[]*bmap // 扩容正在进行时，把 overflow 数据拷贝到这里 // nextOverflow holds a pointer to a free overflow bucket. // // nextOverflow保存了一个指向空闲溢出桶的指针。 // 下一个尚未使用的溢出桶，这里桶之间是一个链表链接所有的溢出桶。 // 该值在make函数中被设置成申请的首个溢出桶 nextOverflow *bmap\t} constant 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 const ( // Maximum number of key/elem pairs a bucket can hold. // // 一个桶可以容纳的最大 key/elem 对数量 bucketCntBits = 3 bucketCnt = 1 \u0026lt;\u0026lt; bucketCntBits // 2^3 = 8 // Maximum average load of a bucket that triggers growth is 6.5. // Represent as loadFactorNum/loadFactorDen, to allow integer math. // // 触发增长的桶的最大平均负载为13/2 = 6.5。 // 表示为 loadFactorNum/loadFactorDen ，允许进行整数运算。 loadFactorNum = 13 // loadFactorNum/loadFactorDen = 6.5 loadFactorDen = 2 // Maximum key or elem size to keep inline (instead of mallocing per element). // Must fit in a uint8. // Fast versions cannot handle big elems - the cutoff size for // fast versions in cmd/compile/internal/gc/walk.go must be at most this elem. // // 保存inline的最大 key 或 elem 大小(而不是为每个元素分配内存) // 必须适配在uint8中。快速版本不能处理大元素-在cmd/compile/internal/gc/walk中快速版本的截止大小。Go最多只能是这个elem。 maxKeySize = 128 // map键最大内存值 128B，超过该值则是桶的key是间接存储的，也就是只是存储的是指针 maxElemSize = 128 // map值最大内存值 128B，超过该值则是桶的elem是间接存储的，也就是只是存储的是指针 // data offset should be the size of the bmap struct, but needs to be // aligned correctly. For amd64p32 this means 64-bit alignment // even though pointers are 32 bit. // // dataOffset 是bmap结构体的长度，但需要正确对齐 // 对于amd64p32，这意味着即使指针是32位，也会进行64位对齐。 dataOffset = unsafe.Offsetof(struct { b bmap // 8B v int64 // 8B }{}.v) // dataOffset = 8B bmap桶的第一个key偏移量 // Possible tophash values. We reserve a few possibilities for special marks. // Each bucket (including its overflow buckets, if any) will have either all or none of its // entries in the evacuated* states (except during the evacuate() method, which only happens // during map writes and thus no one else can observe the map during that time). // // 可能的 tophash 值。我们保留一些特殊标记的可能性。 // 每个桶(包括它的溢出桶，如果有的话)的所有条目都将处于 evacuated* 状态(除非在使用evacuate()方法时，这种情况只发生在map写操作期间， // 因此，在这段时间内，没有其他人可以观察map)。 // 当前格为空的默认状态，后面格都为空不存在其他数据 emptyRest = 0 // this cell is empty, and there are no more non-empty cells at higher indexes or overflows. // 当前格为空，后面格还存在其他数据。在当前格被删除时会被标记为1 emptyOne = 1 // this cell is empty // key/elem是有效的，entry已被疏散到翻倍后的新桶里，原来的桶号处 evacuatedX = 2 // key/elem is valid. Entry has been evacuated to first half of larger table. // key/elem是有效的，entry已被疏散到翻倍后的新桶里，原来桶号的2倍处 evacuatedY = 3 // same as above, but evacuated to second half of larger table. // 单元格是空的。在扩容进行中被标记从 0或1标记为4 evacuatedEmpty = 4 // cell is empty, bucket is evacuated. // 正常填充单元格的最小值，比如某个key计算后的hash值为0则填充为5。 minTopHash = 5 // minimum tophash for a normal filled cell. // flags // 可能有一个使用buckets的迭代器 iterator = 1 // there may be an iterator using buckets // 可能有一个使用oldbuckets的迭代器 oldIterator = 2 // there may be an iterator using oldbuckets // 一个goroutine正在向map写入数据，用于判断map是否在读写删除并发操作 // 在m[key] = elem时被设置或在delete删除key时被设置 hashWriting = 4 // a goroutine is writing to the map // 等量扩容标志位 sameSizeGrow = 8 // the current map growth is to a new map of the same size // sentinel bucket ID for iterator checks // 迭代器检查的哨兵桶ID，如果桶号为该值不需要检查 // 迭代器相关，在扩容进行中迭代器用于检查的桶号 noCheck = 1\u0026lt;\u0026lt;(8*goarch.PtrSize) - 1\t) type maptype struct map 元类型，runtime/type.go。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 type maptype struct { typ _type // map类型 key *_type // key类型 elem *_type // elem类型 // 桶的类型，桶包含tophashs、keys、elems、overflow这四块 // 由于key/elem是不确定的类型，所以bucket也是不同的类型 // bucket是否包含指针类型，是取决于该结构中是否存在指针 //\t1. tophashs 是非指针 // 2. keys、elems 是根据具体情况的 // 3. overflow 是个指针，那么是否意味则bucket是否包含指针类型? // 其实bucket是否包含指针类型是根据keys、elems决定的，原因是overflow是用户操作不到的 // 因此处理这个特殊情况时，采用了非指针形式采用mapextra结构保存溢出桶数据，以便不被GC回收 bucket *_type // internal type representing a hash bucket // function for hashing keys (ptr to key, seed) -\u0026gt; hash // hash函数，用于(key, h.hash0) hasher func(unsafe.Pointer, uintptr) uintptr\t// size of key slot keysize uint8 // key值大小 // size of elem slot elemsize uint8 // value值大小 // size of bucket bucketsize uint16 // 桶大小 flags uint32 // map的标志位 } indirectkey() 当 key 大于128B时key存的是它的指针，key 是否是间接存储的。采用这种间接存储是为了满足GC的位图。 一个桶最多支持 bucketSize*(1+maxKeySize+maxValSize)+ptrSize 字节，即2064字节，或258个指针大小的字，或33字节的指针位图。 因为键和值都小于128字节，所以可以保证它们有位图而不是GC程序。 1 2 3 4 5 6 // Note: flag values must match those used in the TMAP case // in ../cmd/compile/internal/reflectdata/reflect.go:writeType. func (mt *maptype) indirectkey() bool { // store ptr to key instead of key itself // flags = 1：key占用内存大于 128B return mt.flags\u0026amp;1 != 0\t} indirectelem() 当elem大于128B时key存的是它的指针，elem是否是间接存储的。 1 2 3 4 func (mt *maptype) indirectelem() bool { // store ptr to elem instead of elem itself // flags = 2：elem占用内存大于 128B return mt.flags\u0026amp;2 != 0\t} reflexivekey() map key是NaN时，判断 key 满足 x == x 成立? x != x 成立情况： float32、float64、complex64、complex128（当为NaN时）。 any：存储的是 NaN 时。 Array 时判断数组的元素类型。切片不能作为map的key因此排除。 String 时，判断字段类型。 根据 IEEE754 标准，当浮点数的指数位全为1时，该数处于非正常是标准多用于表示正无穷大或负无穷大及NaN，因此其他位可能是不同的数值。 x != x 情况是会影响hash，因此NaN的位值不一定全部相等。 1 2 3 4 func (mt *maptype) reflexivekey() bool { // true if k==k for all keys // flags = 4：说明 x == x始终是成立的 return mt.flags\u0026amp;4 != 0\t} needkeyupdate() map key的值需要更新，这种情况出现在 key == key，但是 key 生成的 hash 可能不相同，这会影响到 tophash 存储值。 需要更新的类型： float32、float64、complex64、complex128（floats and complex can be +0/-0）。 浮点数和复数可以是+0/-0，浮点数中这两个数保存的符号位是不同得，但是比较这两个数确实是相等的。 any 由于 any 能存储任何类型，所有可以存储浮点数等因此也需要更新。 string：（strings might have smaller backing stores） 字符串可能有较小的后备存储器 Array 类型时判断数组元素，可能是上面类型。 Struct 时判断结构体的元素，可能是上面类型。 1 2 3 4 func (mt *maptype) needkeyupdate() bool { // true if we need to update key on an overwrite // flags = 8：需要更新slot的key return mt.flags\u0026amp;8 != 0\t} hashMightPanic() key 生成 hash 可能发生 panic，这是由于slice、map、function不能作为map key，而any可以存储任何类型。 存在可能的类型： any、slice、map、function; 当any存储的slice或map或function时就会panic。 Array 类型时判断数组的元素，该元素时slice或map或包含它们都会panic。Slice 不能作为key。 Struct 类型时判断结构体的元素，该元素时slice或map或包含它们都会panic。 但是如果是它们类型的指针则不会发生panic。 1 2 3 4 func (mt *maptype) hashMightPanic() bool { // true if hash function might panic // flags = 16：key生成hash可能panic的 return mt.flags\u0026amp;16 != 0\t} make() 🚀 makemap() 实现为 make(map[k]v, hint) 创建 Go map。 如果编译器已经确定可以在栈上创建map或第一个bucket，h and/or bucket 可能是 non-nil。 如果 h != nil，则可以直接在h中创建map。 如果 h.buckets != nil，则指向的桶可以用作第一个桶。 参数： t *maptype：map 的元类型。 hint int：key/elem对的数量，不是桶的数量。hint能保证一定能存储key/elem对数据而不扩容。 h *hmap：map 指针，可能是 nil 或 non-nil。 返回值： *hmap：生成的 map 的值，也就是 *hmap。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // makemap implements Go map creation for make(map[k]v, hint). // If the compiler has determined that the map or the first bucket // can be created on the stack, h and/or bucket may be non-nil. // If h != nil, the map can be created directly in h. // If h.buckets != nil, bucket pointed to can be used as the first bucket. func makemap(t *maptype, hint int, h *hmap) *hmap { // MulUintptr 返回 a * b 以及乘法是否溢出 // mem = uintptr(hint) * t.bucket.size // 这里使用 key/elem 对乘上 桶大小 显示是在扩大计算内存，因为 hint 一定是大于 桶的数量的 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } // initialize Hmap if h == nil { // 初始化 hmap // 注意这里使用了new函数创建的 h = new(hmap)\t} // 生成一个随机数用于后续key的hash，该值在桶每次清空时该值会从新生成随机值 h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint \u0026lt; 0 overLoadFactor returns false since hint \u0026lt; bucketCnt. // // 找到参数B的大小，它将保存请求的元素 // 对于 hint \u0026lt; 0 overLoadFactor 返回 false，因为 hint \u0026lt; bucketCnt。 B := uint8(0) // 计算保存hint个key/elem对不扩容最小需要的B的数量 for overLoadFactor(hint, B) { B++ } h.B = B // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. // // 分配初始hash表，如果B == 0，则稍后(在mapassign中，也就是存储数据过程中)延迟分配buckets字段， // 如果hint很大，则清空该内存可能需要一段时间。 if h.B != 0 { var nextOverflow *bmap // 用于记录 makeBucketArray 是否分配了溢出桶 // makeBucketArray 根据B分配常规桶和溢出桶，如果分配了溢出桶则将最后一个溢出桶地址指向第一个常规桶地址 // 溢出桶分配规则 B \u0026gt;= 4 分配最少 B-4 个溢出桶备用，溢出桶数量 \u0026gt;= 1 \u0026lt;\u0026lt; (B-4) h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) // 记录下一个可使用的溢出桶 h.extra.nextOverflow = nextOverflow } } return h } overLoadFactor() overLoadFactor 报告放置在 1\u0026laquo;B 桶中的项目数量是否超过 loadFactor。 1 2 3 4 5 6 7 8 9 10 11 12 13 // overLoadFactor reports whether count items placed in 1\u0026lt;\u0026lt;B buckets is over loadFactor. func overLoadFactor(count int, B uint8) bool { // const ( // bucketCnt = 8 // loadFactorNum = 13 // loadFactorDen = 2 // ) // bucketShift(B) == 1 \u0026lt;\u0026lt; B // uintptr(count)/bucketShift(B) \u0026lt; loadFactorNum/loadFactorDen // // return count \u0026gt; 8 \u0026amp;\u0026amp; count \u0026gt; 6.5 * (1 \u0026lt;\u0026lt; B) return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } bucketShift() bucketShift 返回 1\u0026lt;\u0026lt;b，为代码生成做了优化。 1 2 3 4 5 6 7 8 // bucketShift returns 1\u0026lt;\u0026lt;b, optimized for code generation. func bucketShift(b uint8) uintptr { // Masking the shift amount allows overflow checks to be elided. // // 屏蔽移位量可以省略溢出检查。 // goarch.PtrSize 64位下为8，32位下为4; goarch.PtrSize*8 - 1 掩码为了防止溢出 return uintptr(1) \u0026lt;\u0026lt; (b \u0026amp; (goarch.PtrSize*8 - 1)) // 1 \u0026lt;\u0026lt; b } makeBucketArray() makeBucketArray() 为 map 桶初始化一个后备数组。 1\u0026lt;\u0026lt;b是要分配的最小桶数。 dirtyalloc要么是nil，要么是makeBucketArray之前分配的具有相同t和b参数的桶数组。 如果dirtyalloc为nil，将分配一个新的后备数组，否则将清除dirtyalloc并作为后备数组重用。 参数： t *maptype：map的类型结构。 b uint8：h.B的值。 dirtyalloc unsafe.Pointer：nil时重新申请块内存，不是nil时，继续使用dirtyalloc 指向的内存地址。 返回值： buckets unsafe.Pointer：分配的常规桶首地址。 nextOverflow *bmap：分配的溢出桶首地址。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 // makeBucketArray initializes a backing array for map buckets. // 1\u0026lt;\u0026lt;b is the minimum number of buckets to allocate. // dirtyalloc should either be nil or a bucket array previously // allocated by makeBucketArray with the same t and b parameters. // If dirtyalloc is nil a new backing array will be alloced and // otherwise dirtyalloc will be cleared and reused as backing array. func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) { // base := 1 \u0026lt;\u0026lt; b base := bucketShift(b) // 常规桶数量 nbuckets := base // 存储(常规桶 + 溢出桶)的总数量 // For small b, overflow buckets are unlikely. // Avoid the overhead of the calculation. // // 对于小值b来说，溢出桶不太可能出现。避免计算的开销。 // 溢出桶分配规则 B \u0026gt;= 4 分配最少 B-4 个溢出桶备用。 if b \u0026gt;= 4 { // Add on the estimated number of overflow buckets // required to insert the median number of elements // used with this value of b. // // 再加上用该值b插入元素的中位数所需的溢出桶的估计数量。 // nbuckets += 1 \u0026lt;\u0026lt; (b - 4) nbuckets += bucketShift(b - 4) // 常规桶 + 溢出桶 sz := t.bucket.size * nbuckets // 计算全部桶(常规桶 + 溢出桶)所需内存大小 up := roundupsize(sz) // 匹配最接近sz的内存大小规格 if up != sz { // 匹配的内存规格偏大\t// 调整 nbuckets 数量，这里应该是偏大设置 // 因为不能能匹配后出现偏小的情况 nbuckets = up / t.bucket.size } } if dirtyalloc == nil { // 没有可重新利用的内存块，重新向内存管理系统申请内存 // buckets 申请的桶首地址 包含常规桶和溢出桶，因此常规桶和溢出桶是一整块连续的内存 buckets = newarray(t.bucket, int(nbuckets))\t} else { // dirtyalloc was previously generated by // the above newarray(t.bucket, int(nbuckets)) // but may not be empty. // // dirtyalloc是由上述 newarray(t.bucket, int(nbuckets)) 生成的，但不能为空。 buckets = dirtyalloc // 桶内存块地址 size := t.bucket.size * nbuckets // 内存块大小 if t.bucket.ptrdata != 0 { // 当前桶中存在指针数据时 // 重置从buckets地址开始长度为size大小的内存 memclrHasPointers(buckets, size) } else { // 当前桶中不存在指针数据时 // 重置从buckets地址开始长度为size大小的内存 memclrNoHeapPointers(buckets, size) } } // 分配了溢出桶 if base != nbuckets { // We preallocated some overflow buckets. // To keep the overhead of tracking these overflow buckets to a minimum, // we use the convention that if a preallocated overflow bucket\u0026#39;s overflow // pointer is nil, then there are more available by bumping the pointer. // We need a safe non-nil pointer for the last overflow bucket; just use buckets. // // 我们预先分配了一些溢出桶。 // 为了将跟踪这些溢出桶的开销降到最低，我们使用约定:如果预分配的溢出桶的overflow指针为nil，则通过碰撞指针来提供更多可用的内存。 // 我们需要为最后一个溢出桶提供一个安全的 non-nil 指针; 就用常规桶吧。用于在分配溢出桶时判断溢出桶以分配完 nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize))) // 首个溢出桶 *bmap last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize)))// 最后一个溢出桶 *bmap // 之所以将最后一个溢出桶overflow指向第一个常规桶地址是用于分配溢出桶是判断是否分配完参看(*hmap).newoverflow()方法 last.setoverflow(t, (*bmap)(buckets)) // 最后一个溢出桶指针指向首个常规桶 } return buckets, nextOverflow } newarray() newarray() 分配一个包含 n 个类型为 typ 的元素的数组。 参数： typ *_type：桶的类型结构。 n int：桶的个数（常规桶 + 溢出桶）总数。 返回值： unsafe.Pointer：申请到的内存首地址。 1 2 3 4 5 6 7 8 9 10 11 12 13 // newarray allocates an array of n elements of type typ. func newarray(typ *_type, n int) unsafe.Pointer { if n == 1 { // 只有一个桶，直接申请 return mallocgc(typ.size, typ, true) } // 溢出判断，typ.size * uintptr(n) 为桶总共占用的内存 mem, overflow := math.MulUintptr(typ.size, uintptr(n)) if overflow || mem \u0026gt; maxAlloc || n \u0026lt; 0 { panic(plainError(\u0026#34;runtime: allocation size out of range\u0026#34;)) } return mallocgc(mem, typ, true) } makemap_small() makemap_small() 实现了 make(map[k]v) 和 make(map[k]v, hint) 的Go map创建。 当hint(\u0026lt;= 8)在编译时已知最多为 bucketCnt (8)，并且需要在堆上分配map时。 1 2 3 4 5 6 7 8 9 10 // makemap_small implements Go map creation for make(map[k]v) and // make(map[k]v, hint) when hint is known to be at most bucketCnt // at compile time and the map needs to be allocated on the heap. func makemap_small() *hmap { // 当 hint \u0026lt;= 8 时 // 初始化 map h := new(hmap) h.hash0 = fastrand() return h } map Get 🚀 获取 map 中指定 key 的值 v := h[key] mapaccess1_fat() 可以指定默认值 zero，当分0内存是返回zero值。 该函数返回一个地址，地址指向的值就是要取得v值。 参数： t *maptype：map的类型结构。 h *hmap：map的内存结构。 key unsafe.Pointer：key的地址。 zero unsafe.Pointer：零值地址，用于返回值。 返回值： unsafe.Pointer：获取到的elem地址。 1 2 3 4 5 6 7 func mapaccess1_fat(t *maptype, h *hmap, key, zero unsafe.Pointer) unsafe.Pointer { e := mapaccess1(t, h, key) if e == unsafe.Pointer(\u0026amp;zeroVal[0]) { return zero } return e } mapaccess1() mapaccess1() 返回一个指向h[key]的指针。 永远不要返回nil，相反，如果key不在map中，它会返回一个指向elem类型的zero对象的引用。 zero对象就是全局变量\u0026amp;zeroVal[0]地址值。 注意：返回的指针可能会使整个map保持活动状态，所以不要占用它太长时间。 go map 是不支持多线程的写，但是多线程的读是没有问题的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 // mapaccess1 returns a pointer to h[key]. Never returns nil, instead // it will return a reference to the zero object for the elem type if // the key is not in the map. // NOTE: The returned pointer may keep the whole map live, so don\u0026#39;t // hold onto it for very long. func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if raceenabled \u0026amp;\u0026amp; h != nil { callerpc := getcallerpc() pc := abi.FuncPCABIInternal(mapaccess1) racereadpc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled \u0026amp;\u0026amp; h != nil { msanread(key, t.key.size) } if asanenabled \u0026amp;\u0026amp; h != nil { asanread(key, t.key.size) } // 1) map未初始化 或 没有key/elem对 if h == nil || h.count == 0 { // 当key为any类型时，在key经过hash时可能会发生panic // t.hashMightPanic()判断当前hash函数是否可能发生panic // 这是因为 any 存储的值可能不适合作为 map 的 key if t.hashMightPanic() { // 尝试hash panic t.hasher(key, 0) // see issue 23734 } // 直接返回 \u0026amp;zeroVal[0]，返回默认值 return unsafe.Pointer(\u0026amp;zeroVal[0]) } // 2) 当前map存在其他goroutine正在写操作，直接报错不支持并发 // hashWriting 标志在写map或delete map时被设置 if h.flags\u0026amp;hashWriting != 0 { fatal(\u0026#34;concurrent map read and map write\u0026#34;) // 并发的map读写操作 } // 3) key根据h.hash0生成hash值，根据上面key为any时这里hash可能会panic hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) // map常规桶数量; m = (1 \u0026lt;\u0026lt; B) - 1 // 4) 偏移到当前key对应的常规桶处 *bmap b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) // 5) c != nil 当前map正在扩容中，需要判断当前旧桶数据是否迁移，没迁移数据还在旧桶中 if c := h.oldbuckets; c != nil { // !h.sameSizeGrow() == true; // 翻倍扩容时 if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. // // 过去桶的数量只有现在的一半;再除一个2的倍数。 m \u0026gt;\u0026gt;= 1 // 需要把m缩小两倍 } oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) // 判断旧桶是否已经迁移了，没有迁移则从旧桶里面取数据 // 不是2|3|4时表示数据还在旧桶里面，tophash[0] NOT IN (2,3,4) if !evacuated(oldb) { b = oldb // 替换为旧桶 *bmap } } // 6) top 是 hash 的高八位值，用于快速比对 key // hash \u0026gt;\u0026gt; (8*8 - 8) top := tophash(hash) // uint8 bucketloop: // 7) 遍历当前桶以及后面的溢出桶 for ; b != nil; b = b.overflow(t) { // 遍历当前桶; bucketCnt = 8 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 7.1) 当前 tophash 不相等 if b.tophash[i] != top { // const emptyRest = 0 // 当前桶包括溢出桶后面没有数据了 if b.tophash[i] == emptyRest { break bucketloop // 结束遍历 } continue } // 7.2) b.tophash[i] == top; 并不代表一定找到key，可能出现tophash冲突情况 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) // 找到当前key的地址 // key的数据是间接存储的，关于常量maxKeySize的相关情况 if t.indirectkey() { k = *((*unsafe.Pointer)(k)) // 拿到key地址 } // 7.3) 调用key的比较函数，比较key和k是否相等。 // 这里也是key必须是可比较类型的原因 // 不可比较的类型： // 1. map，以及包含map的结构 // 2. slice，以及包含slice的结构 // 这里key如果是 NaN 的话比对不通过。 if t.key.equal(key, k) { // 比对成功。偏移到elem元素地址处 e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) // elem的数据是间接存储的，关于常量maxElemSize的相关情况 if t.indirectelem() { e = *((*unsafe.Pointer)(e)) // 拿到elem地址 } return e // 成功返回找到的elem地址指针 } // 未匹配成功出现tophash【冲突】情况 } } // map 中没有 key，返回默认值 return unsafe.Pointer(\u0026amp;zeroVal[0]) } bucketMask() bucketMask 返回1\u0026lt;\u0026lt;b - 1，为代码生成做了优化。 1 2 3 4 // bucketMask returns 1\u0026lt;\u0026lt;b - 1, optimized for code generation. func bucketMask(b uint8) uintptr { return bucketShift(b) - 1 // (1\u0026lt;\u0026lt;b) - 1 } tophash() tophash 计算 hash 的 Tophash 值。 1 2 3 4 5 6 7 8 9 10 11 // tophash calculates the tophash value for hash. func tophash(hash uintptr) uint8 { // hash \u0026gt;\u0026gt; (8*8 - 8) // hash高八位 top := uint8(hash \u0026gt;\u0026gt; (goarch.PtrSize*8 - 8))\t// top \u0026lt; 5 if top \u0026lt; minTopHash { top += minTopHash } return top } evacuated() 桶数据是否已迁移。 1 2 3 4 5 func evacuated(b *bmap) bool { h := b.tophash[0] // b.tophash[0] IN (2,3,4) return h \u0026gt; emptyOne \u0026amp;\u0026amp; h \u0026lt; minTopHash } v, b := h[key] mapaccess2_fat() 可以指定默认值 zero。当分0内存是返回 zero 值。 1 2 3 4 5 6 7 8 9 func mapaccess2_fat(t *maptype, h *hmap, key, zero unsafe.Pointer) (unsafe.Pointer, bool) { // 没看错，这里依然是调用的 mapaccess1() 函数 // 因为如果没找到key会返回\u0026amp;zeroVal[0]，根据该值能判断bool。 e := mapaccess1(t, h, key) if e == unsafe.Pointer(\u0026amp;zeroVal[0]) { return zero, false } return e, true } mapaccess2() mapaccess2() 和 mapaccess1() 代码基本一样，只多返回个获取成失败的值。 该函数在反射相关中被调用，正常map这里不会调用该函数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) { if raceenabled \u0026amp;\u0026amp; h != nil { callerpc := getcallerpc() pc := abi.FuncPCABIInternal(mapaccess2) racereadpc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled \u0026amp;\u0026amp; h != nil { msanread(key, t.key.size) } if asanenabled \u0026amp;\u0026amp; h != nil { asanread(key, t.key.size) } if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026amp;zeroVal[0]), false // 这里获取失败返回 false } if h.flags\u0026amp;hashWriting != 0 { fatal(\u0026#34;concurrent map read and map write\u0026#34;) } hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. m \u0026gt;\u0026gt;= 1 } oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) if !evacuated(oldb) { b = oldb } } top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return e, true // 这里获取成功返回 true } } } return unsafe.Pointer(\u0026amp;zeroVal[0]), false // 这里获取失败返回 false } map Set 🚀 h[k] = v reflect_mapassign() key和elem分别代表的是各自的地址。 当 key != key 时，存入的数据for range情况是取不出来的。 参数： t *maptype：map类型结构。 h *hmap：map内存结构。 key unsafe.Pointer：map的key地址。 elem unsafe.Pointer：map要写入的v地址。 1 2 3 4 5 6 7 //go:linkname reflect_mapassign reflect.mapassign func reflect_mapassign(t *maptype, h *hmap, key unsafe.Pointer, elem unsafe.Pointer) { // 从map中找到elem应该放入插槽的地址 p := mapassign(t, h, key)\t// 拷贝数据，也就四把\u0026amp;v复制给map插槽 typedmemmove(t.elem, p, elem)\t} mapassign() 类似于mapaccess，但如果key在map中不存在，则会为键分配一个位置。 存在两种情况： 新增：可能k是从来没存在map中。 修改：可能k已经存储在map中。 map 是并发不安全的。 map 必须要经过make()函数初始化才能使用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 // Like mapaccess, but allocates a slot for the key if it is not present in the map. func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // 1) 未初始化的map不允许写操作 // 这里就是为什么向nil的map写入数据会panic原因 if h == nil { panic(plainError(\u0026#34;assignment to entry in nil map\u0026#34;)) } if raceenabled { callerpc := getcallerpc() pc := abi.FuncPCABIInternal(mapassign) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled { msanread(key, t.key.size) } if asanenabled { asanread(key, t.key.size) } // 2) 检查map是否存在并发的写操作，删除也是写操作。 if h.flags\u0026amp;hashWriting != 0 { fatal(\u0026#34;concurrent map writes\u0026#34;) } // 3) key根据h.hash0生成hash值，根据上面key为any时这里hash可能会panic。 hash := t.hasher(key, uintptr(h.hash0)) // Set hashWriting after calling t.hasher, since t.hasher may panic, // in which case we have not actually done a write. // // 在调用t.hasher之后设置hashWriting，因为t.hasher可能会出错，在这种情况下我们实际上并没有写入。 // 这里使用 ^= 有点小窍门，因为在并发写的情况下可能存在上面的h.flags\u0026amp;hashWriting != 0检查时被跳过了， // 所以这个函数最后还需要判断并是否已经发生 ^ 异或 相同得0，不同得1; hashWriting = 4 = 0b100 // 按照正常逻辑 h.flags 的3bit位应该是0，那么0^1=1。在函数的最后 h.flags\u0026amp;hashWriting == 0 判断时 1\u0026amp;1=1。 // 异常逻辑 h.flags 的3bit位是1，那么 1^1=0。在函数的最后 h.flags\u0026amp;hashWriting == 0 判断时 0\u0026amp;1=0。因此判断并发发生 h.flags ^= hashWriting // 写状态标记 // 4) 没有分配常规桶，这种情况来自makemap_small()函数，hint\u0026lt;=8 时 if h.buckets == nil { // 申请一个常规桶内存块 h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: // 5) 根据 hash 映射到指定桶号 bucket := hash \u0026amp; bucketMask(h.B) // bucket = hash \u0026amp; ((1 \u0026lt;\u0026lt; B) - 1) // 6) 是否正处于扩容中：【等量扩容】 或 【翻倍扩容】 if h.growing() { // h.oldbuckets != nil // 迁移当前key对应的桶数据到新桶完成部分扩容任务 // 迁移后会把旧桶数据迁移到新桶，因此以下代码处理新桶即可 // growWork() 函数在delete(map)和map[k]=v时被调用，渐进式迁移数据 growWork(t, h, bucket)\t} // 7) 寻找对应的桶(*bmap)，key对应的桶 *bmap b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) // top = uint8( hash \u0026amp; (1\u0026gt;\u0026gt;8*8-8) ) top := tophash(hash) // hash 高八位，用于快速判断 key // inserti 对应key应该放入tophash的slot位置地址 var inserti *uint8\t// insertk 对应key应该放入keys的slot位置地址 var insertk unsafe.Pointer // elem 对应key应该放入elems的slot位置地址 var elem unsafe.Pointer\tbucketloop: // 8) 遍历常规桶和溢出桶，寻找slot位置 // 被删除的slot会被优先使用来存储数据 for { // 8.1) 遍历单个桶; const bucketCnt = 8 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // 8.1.1) tophash 比对失败 if b.tophash[i] != top { // isEmpty(b.tophash[i]) --\u0026gt; b.tophash[i] \u0026lt;= 1 // inserti == nil; 寻找到slot后不会再进入这里 // 这里也是判断当前可能是新增的情况，当前位可以插入数据如果是新增的话。 if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { // 记录当前插槽位置 inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) } // b.tophash[i] == 0; 后面没有数据了 if b.tophash[i] == emptyRest { break bucketloop } // b.tophash[i] == 1 // 后面有数据需要继续遍历判断是否当前key已经存在在map中了 continue // continue的作用就是继续遍历map寻找key } // tophash匹配成功 // 1. 可能是hash冲突，继续向后寻找 // 2. 可能是匹配到了key，则是更新 // 8.1.2) 当前key的slot地址 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { // key 间接存储 k = *((*unsafe.Pointer)(k)) } // 8.1.3) 比较key和k是否相等，不相等说明 tophash冲突了 // 如果存储的 key 是 NaN 这里比对不通过。 if !t.key.equal(key, k) { continue // key != k 继续向后寻找 } // key == k; 匹配成功则本次是更新操作 // already have a mapping for key. Update it. // // 已经有一个key的映射。【更新它】。 // key == key成立，但是可能生成的hash值不同，比如+0和-0 if t.needkeyupdate() { typedmemmove(t.key, k, key) // 把k更新为key } // 8.1.4) 找到elem地址 elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } ovf := b.overflow(t) // b后面链接的溢出桶 // 没有溢出桶了 if ovf == nil { break } b = ovf } // Did not find mapping for key. Allocate new cell \u0026amp; add entry. // // 9) 没有找到key的映射。分配新的单元格并添加entry。新增 key/elem // If we hit the max load factor or we have too many overflow buckets, // and we\u0026#39;re not already in the middle of growing, start growing. // // 10) 如果我们达到了最大负载系数，或者我们有太多溢出桶，而我们还没有达到增长的一半，就开始增长。 // h.growing() -\u0026gt; (h.oldbuckets != nil); 是否正在扩容中 if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) // 扩容初始化 // 扩容hash table会使上面的所有操作失效，所以再试一次 goto again // Growing the table invalidates everything, so try again } // 11) 常规桶和溢出桶(如果存在)都没找到slot，这时候需要分配新的溢出桶 if inserti == nil { // The current bucket and all the overflow buckets connected to it are full, allocate a new one. // // 当前桶和连接到它的所有溢出桶已满，分配一个新的桶。 newb := h.newoverflow(t, b) // 分配一个溢出桶 *bmap inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position // // 12) 将新的键/elem存储在插入位置 if t.indirectkey() { // key 间接存储 kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { // elem 间接存储 vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem // 由于done后面有 t.indirectelem() 判断所有这里没有 elem = vmem 这行代码 } // 13) 拷贝数据 typedmemmove(t.key, insertk, key) // 保存key的值 *inserti = top // tophash 保存 h.count++ // key/elem 对加一 done: // 14) 再次判断是否有其他goroutine正在对map进行写操作 if h.flags\u0026amp;hashWriting == 0 { fatal(\u0026#34;concurrent map writes\u0026#34;) } h.flags \u0026amp;^= hashWriting // 清除hashWriting标志位 if t.indirectelem() { // elem 间接存储 elem = *((*unsafe.Pointer)(elem)) } return elem // 返回当前slot的地址 } isEmpty() isEmpty报告给定的tophash数组项是否表示空桶项。 1 2 3 4 // isEmpty reports whether the given tophash array entry represents an empty bucket entry. func isEmpty(x uint8) bool { return x \u0026lt;= emptyOne // x \u0026lt;= 1 } overLoadFactor() 翻倍扩容判断条件。 1 2 3 4 5 // overLoadFactor reports whether count items placed in 1\u0026lt;\u0026lt;B buckets is over loadFactor. func overLoadFactor(count int, B uint8) bool { // count \u0026gt; 8 \u0026amp;\u0026amp; count \u0026gt; 13*((1\u0026lt;\u0026lt;B) / 2) return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } tooManyOverflowBuckets() 等量扩容判断条件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // tooManyOverflowBuckets reports whether noverflow buckets is too many for a map with 1\u0026lt;\u0026lt;B buckets. // Note that most of these overflow buckets must be in sparse use; // if use was dense, then we\u0026#39;d have already triggered regular map growth. func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026#34;too many\u0026#34; means (approximately) as many overflow buckets as regular buckets. // See incrnoverflow for more details. if B \u0026gt; 15 { B = 15 } // The compiler doesn\u0026#39;t see here that B \u0026lt; 16; mask B to generate shorter shift code. return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } 扩容 🚀 翻倍扩容条件 h.oldbuckets == nil; 未处于扩容过程中。 存储的key/elem对数量大于常规桶数量的 6.5 倍。 key/elem对数量大于8 1 2 3 // 1) h.oldbuckets != nil; 处于扩容中。!h.growing()：没有处于扩容中 // 2) overLoadFactor(h.count+1, h.B)：新增一个元素是否需要扩容判断 if !h.growing() \u0026amp;\u0026amp; overLoadFactor(h.count+1, h.B) {} overLoadFactor() overLoadFactor 报告放置在 1\u0026lt;\u0026lt;B 桶中的项目数量是否超过 loadFactor。 1 2 3 4 5 6 // overLoadFactor reports whether count items placed in 1\u0026lt;\u0026lt;B buckets is over loadFactor. func overLoadFactor(count int, B uint8) bool { // count \u0026gt; 8 \u0026amp;\u0026amp; count \u0026gt; 13*( (1\u0026lt;\u0026lt;B) / 2) // count \u0026gt; 8 \u0026amp;\u0026amp; count \u0026gt; 6.5 * (1\u0026lt;\u0026lt;B) return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } 等量扩容条件 当常规桶(h.B)小于等于15时，溢出桶数量 大于等于 常规桶数量(1 \u0026lt;\u0026lt; h.B) 就要扩容。 当常规桶(h.B)大于15时，溢出桶数量 大于等于 (1 \u0026lt;\u0026lt; 15) 就要扩容了。 溢出桶的分配规则：当B\u0026gt;=4时则分配(B-4)个溢出桶备用，因此常规桶数量大于溢出桶数量。等量扩容时备用的溢出桶一定是被用完了。 1 2 3 // 1) !h.growing()：没有处于扩容中 // 2) tooManyOverflowBuckets(h.noverflow, h.B)：满足等量扩容条件 if !h.growing() \u0026amp;\u0026amp; tooManyOverflowBuckets(h.noverflow, h.B) {} tooManyOverflowBuckets() tooManyOverflowBuckets 报告 noverflow 桶对于一个包含 1\u0026lt;\u0026lt;B 桶的 map 来说是否太多。 请注意，大多数溢出桶必须稀疏使用; 如果使用是密集的，那么我们就已经触发了常规的 map 增长。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // tooManyOverflowBuckets reports whether noverflow buckets is too many for a map with 1\u0026lt;\u0026lt;B buckets. // Note that most of these overflow buckets must be in sparse use; // if use was dense, then we\u0026#39;d have already triggered regular map growth. func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026#34;too many\u0026#34; means (approximately) as many overflow buckets as regular buckets. // See incrnoverflow for more details. // // 如果阈值太低，我们做多余的工作。 // 如果阈值过高，则增大和缩小的映射会占用大量未使用的内存。 // \u0026#34;too many\u0026#34;是指溢出桶的数量(大约)与普通桶相同。更多细节请参见h.incnoverflow()。 if B \u0026gt; 15 { B = 15 } // The compiler doesn\u0026#39;t see here that B \u0026lt; 16; mask B to generate shorter shift code. // // 编译器没有看到B \u0026lt; 16;掩码B以生成更短的移位码。 // noverflow：表示已使用的溢出桶数量 return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } 扩容初始化 hashGrow() 扩容初始化开始。 参数： t *maptype：当前 map 的类型结构。 h *hmap：当前 map 的内存结构。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 func hashGrow(t *maptype, h *hmap) { // If we\u0026#39;ve hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \u0026#34;grow\u0026#34; laterally. // // 1) 如果我们达到了满载系数，就会变大。否则，溢出桶太多，所以保持相同数量的桶，横向“增长”。 bigger := uint8(1)\t// bigger是翻倍扩容还是等量扩容 1.【翻倍扩容】 0.【等量扩容】\tif !overLoadFactor(h.count+1, h.B) { bigger = 0 // 标记等量扩容 h.flags |= sameSizeGrow\t// 设置等量扩容标志位 } oldbuckets := h.buckets // 记录旧桶地址 // 2) 申请一块新内存，当做新桶地址 newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)\t// 3) 清除iterator 和 oldIterator标志的flags flags := h.flags \u0026amp;^ (iterator | oldIterator) // 迭代器在扩容的前面时 if h.flags\u0026amp;iterator != 0 {\t// 迭代器正在运行 flags |= oldIterator // 标记迭代旧数据 } // 4) 设置 hmap 相关参数 // commit the grow (atomic wrt gc) h.B += bigger // 扩容后的B h.flags = flags // 最新的flags状态 h.oldbuckets = oldbuckets // 旧桶地址 h.buckets = newbuckets // 新桶地址 h.nevacuate = 0\t// 下一个需要迁移的旧桶号 h.noverflow = 0 // 已使用的溢出桶 // h.extra.overflow 和 h.extra.oldoverflow // 5) 溢出桶相关设置（主要是GC相关），作用在前面已经介绍了 if h.extra != nil \u0026amp;\u0026amp; h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\u0026#34;oldoverflow is not nil\u0026#34;) } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } // 6) 分配了备用溢出桶 if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). // // 实际的哈希表数据复制是通过growWork()和evacuate()完成的。 // 渐进式扩容分配到【写】和【删除】中调用growWork()和evacuate()完成的。 // 注意：读操作【并没有】渐进式迁移部分数据。 } 渐进式迁移 growWork() 渐进式迁移桶数据。先迁移当前传入的桶号，再去迁移下次需要迁移的桶号。 因为当前传入的桶号一定是当前正在写或删除的key对应的桶号，因此先迁移该桶，然后迁移固定增长的桶号。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 func growWork(t *maptype, h *hmap, bucket uintptr) { // make sure we evacuate the oldbucket corresponding // to the bucket we\u0026#39;re about to use // // 确保我们清空了将要使用的桶对应的oldbucket evacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // evacuate one more oldbucket to make progress on growing // // 疏散更多的旧桶，以取得进展的增长 if h.growing() { evacuate(t, h, h.nevacuate)\t// 注意这里传的桶号是h.nevacuate } } evacuate() 执行一次桶迁移，在疏散旧桶时只修改了topHash，并且在没有迭代器情况下才清除key/elem。 参数： t *maptype：map 类型结构。 h *hmap：map 内存结构。 oldbucket uintptr：当前需要迁移桶的编号。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 func evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 1) oldbucket 桶号对应的 *bmap b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) // *bmap newbit := h.noldbuckets() // 旧桶数量，等量扩容就是 1\u0026lt;\u0026lt;h.B，翻倍扩容为 1\u0026lt;\u0026lt;(h.B-1) // 2) 当前桶没有被迁移，tophash[0] not in (2,3,4) if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // // TODO: 如果没有迭代器使用旧的桶，则重用溢出的桶，而不是使用新的桶。(If !oldIterator) // xy contains the x and y (low and high) evacuation destinations. // // xy包含x和y(low and high)疏散目的地。 // 2.1) 记录迁移后桶的去向，x与旧桶，y则是新桶 var xy [2]evacDst\tx := \u0026amp;xy[0] // 流向旧桶时的桶信息。 x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) // 2.2) 翻倍扩容 if !h.sameSizeGrow() {\t// Only calculate y pointers if we\u0026#39;re growing bigger. // Otherwise GC can see bad pointers. // // 只有当y指针翻倍扩容时才计算。否则GC会看到坏指针。 y := \u0026amp;xy[1] // 流向新桶时的桶信息。 y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } // 2.3) 遍历【常规桶】和后面的【溢出桶】 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) // key开始首地址 e := add(k, bucketCnt*uintptr(t.keysize)) // elem开始首地址 // 2.4) 遍历当前桶 i、k、e 分别对应当前桶 index、key、elem // const bucketCnt = 8 for i := 0; i \u0026lt; bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] // 2.4.1) 当前i处为空，top \u0026lt;= 1 if isEmpty(top) { // const evacuatedEmpty = 4 // 0或1 标记为 4 b.tophash[i] = evacuatedEmpty\tcontinue } // const minTopHash = 5 if top \u0026lt; minTopHash { throw(\u0026#34;bad map state\u0026#34;) } // 2.4.2) 有数据需要迁移 k2 := k\t// k是当前遍历桶\u0026amp;key\tunsafe.Pointer if t.indirectkey() { // 间接存储 k2 = *((*unsafe.Pointer)(k2)) } // 由于记录桶的流向 0.旧桶 1.新桶 var useY uint8\tif !h.sameSizeGrow() { // 翻倍扩容 // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). // // 计算哈希值以做出疏散决策(我们需要将这个键/elem发送到桶x还是桶y)。 hash := t.hasher(k2, uintptr(h.hash0)) // !t.reflexivekey() == true 说明 k2 != k2 成立，比如 NaN // h.flags\u0026amp;iterator != 0 迭代器在扩容后 if h.flags\u0026amp;iterator != 0 \u0026amp;\u0026amp; !t.reflexivekey() \u0026amp;\u0026amp; !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn\u0026#39;t reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. // // 如果 key != key (NaNs)，那么这个hash值可能(也可能会)与旧的hash值完全不同。此外，它是不可复制的。 // 在迭代器存在的情况下，需要重现性，因为我们的疏散决策必须匹配迭代器所做的任何决策。 // 幸运的是，我们可以自由地以任何方式发送这些keys。而且，tophash对于这种类型的键没有意义。(因为无法取出来) // 我们让低bit位的tophash来决定疏散。 // 我们为下一层重新计算一个新的随机tophash值，这样这些键在增长多次后将均匀分布到所有桶中。 // 注意这里的top是旧桶的tophash在计算疏散方向 useY = top \u0026amp; 1 // top的最低位用来随机计算，以便均匀的分布这些key到存储桶中去 top = tophash(hash) // 从新计算tophash，该top存储在新桶 } else { // 没有迭代器在运行 或 k == k成立 // 流向新桶，newbit是旧桶数量为2的幂次方 if hash\u0026amp;newbit != 0 {\tuseY = 1 } } } // const evacuatedX = 2 // const evacuatedY = 3 if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\u0026#34;bad evacuatedN\u0026#34;) } // tophash = 2 或 3，数据流向; // 注意上面的 useY = top \u0026amp; 1; // 即使这里修改了旧桶的topHash也能知道疏散方向，因为2和3代表疏散方向 b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY // dst目标桶 dst := \u0026amp;xy[useY] // evacuation destination // 当前桶已经存满了 // const bucketCnt = 8 if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b)\t// 关联桶并分配新的溢出桶 dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } // tophash 迁移 dst.b.tophash[dst.i\u0026amp;(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { // 间接存储 *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { // 间接存储 *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That\u0026#39;s ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } // Unlink the overflow buckets \u0026amp; clear key/elem to help GC. // // 当前桶及溢出桶都被疏散完成后；断开溢出桶 并 清除key/elem以帮助GC // h.flags\u0026amp;oldIterator == 0：遍历器没有在遍历旧数据 // t.bucket.ptrdata != 0：桶类型中存在指针，也就是 key/elem 类型中存在指针 if h.flags\u0026amp;oldIterator == 0 \u0026amp;\u0026amp; t.bucket.ptrdata != 0 { // 当前清除旧桶所在桶地址 b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) // Preserve b.tophash because the evacuation // state is maintained there. // // 保留b.tophash，因为疏散状态在那里保持。 ptr := add(b, dataOffset) // key开始地址 n := uintptr(t.bucketsize) - dataOffset // 需要清除的字节长度 // 清除keys、elems、overflow帮助GC memclrHasPointers(ptr, n) } } // growWork方法在迁移了本次桶后会再迁移一次h.nevacuate，因此这里得到执行 if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } evacuated() 判断当前桶是否已被迁移。 1 2 3 4 5 6 7 func evacuated(b *bmap) bool { h := b.tophash[0] // const emptyOne = 1 // const minTopHash = 5 // b.tophash[0] IN (2,3,4) return h \u0026gt; emptyOne \u0026amp;\u0026amp; h \u0026lt; minTopHash } type evacDst struct evacDst 是桶数据迁移流转的一个存储器。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // evacDst is an evacuation destination. type evacDst struct { // 当前流转的目地桶 *bmap // 也就是迁移后的新桶的桶地址，比如从A桶迁移到B桶，这里就是B桶的桶地址。 b *bmap // current destination bucket // key/elem 索引到b // 该值默认为0，表示第一个索引下标 i int // key/elem index into b // 指向当前key存储的指针 // 该值默认指向第一个key的地址 k unsafe.Pointer // pointer to current key storage // 指向当前elem存储的指针 // 该值默认指向第一个elem的地址 e unsafe.Pointer // pointer to current elem storage } isEmpty() 判断当前 slot 处是否为空。 1 2 3 4 5 // isEmpty reports whether the given tophash array entry represents an empty bucket entry. func isEmpty(x uint8) bool { // const emptyOne = 1 return x \u0026lt;= emptyOne } advanceEvacuationMark() h.nevacuate 桶号得到迁移后相关判断迁移完毕代码。 参数： h *hmap：map 的内存结构。 t *maptype：map 的类型结构。 newbit uintptr：扩容后的总数量，翻倍扩容是之前容量的两倍，等量扩容就是之前的容量。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func advanceEvacuationMark(h *hmap, t *maptype, newbit uintptr) {\th.nevacuate++ // 下一个需要迁移的桶号 // Experiments suggest that 1024 is overkill by at least an order of magnitude. // Put it in there as a safeguard anyway, to ensure O(1) behavior. // // 实验表明，1024是多余的，至少是一个数量级。把它放在那里作为一种保护措施，以确保O(1)行为。 stop := h.nevacuate + 1024 // stop是一个循环次数最大1024次 // newbit 未扩容前桶数量，stop \u0026gt; newbit 剩余扩容数量在[0,1024]间 if stop \u0026gt; newbit { stop = newbit } // 循环一定的次数，判断后面的桶是否已经迁移了 for h.nevacuate != stop \u0026amp;\u0026amp; bucketEvacuated(t, h, h.nevacuate) { h.nevacuate++ } // 桶已经迁移完 if h.nevacuate == newbit { // newbit == # of oldbuckets // Growing is all done. Free old main bucket array. h.oldbuckets = nil // 释放oldbuckets // Can discard old overflow buckets as well. // If they are still referenced by an iterator, // then the iterator holds a pointers to the slice. // // 可以丢弃旧的溢出桶。如果它们仍然被迭代器引用，则迭代器保存一个指向片的指针。 if h.extra != nil { h.extra.oldoverflow = nil } h.flags \u0026amp;^= sameSizeGrow // 清除sameSizeGrow标志位，如果设置了的话 } } bucketEvacuated() 判断 bucket 桶是否已经迁移了。 1 2 3 4 func bucketEvacuated(t *maptype, h *hmap, bucket uintptr) bool { b := (*bmap)(add(h.oldbuckets, bucket*uintptr(t.bucketsize))) return evacuated(b) } 删除 🚀 delete() 内置函数delete()将指定键值(m[key])的元素从map中删除。 如果m为nil或不存在这样的元素，则delete()为空操作。 1 2 3 4 // The delete built-in function deletes the element with the specified key // (m[key]) from the map. If m is nil or there is no such element, delete // is a no-op. func delete(m map[Type]Type1, key Type) mapdelete() delete删除map。 如果删除的是中间数据直接标记并清除key和elem即可。 如果删除的是最后一个则需要向前判断前面是否已被删除依次标记tophash为0。 参数： t *maptype：map类型结构。 h *hmap：map内存结构。 key unsafe.Pointer：需要删除的key地址。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { if raceenabled \u0026amp;\u0026amp; h != nil { callerpc := getcallerpc() pc := abi.FuncPCABIInternal(mapdelete) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled \u0026amp;\u0026amp; h != nil { msanread(key, t.key.size) } if asanenabled \u0026amp;\u0026amp; h != nil { asanread(key, t.key.size) } // 1) 未初始的map 或 map没有key/elem对 if h == nil || h.count == 0 { // 当key为any类型时，在key经过hash时可能会发生panic // t.hashMightPanic()判断当前hash函数是否可能发生panic if t.hashMightPanic() { // 尝试hash panic t.hasher(key, 0) // see issue 23734 } return } // 2) 当前map正在并发写操作 if h.flags\u0026amp;hashWriting != 0 { fatal(\u0026#34;concurrent map writes\u0026#34;) } // 3) key根据h.hash0生成hash值，根据上面key为any时这里hash可能会panic hash := t.hasher(key, uintptr(h.hash0)) // Set hashWriting after calling t.hasher, since t.hasher may panic, // in which case we have not actually done a write (delete). // // 在调用t.hasher之后设置hashWriting，因为t.hasher可能会发生错误， // 在这种情况下我们实际上并没有执行写入(delete)操作。 h.flags ^= hashWriting bucket := hash \u0026amp; bucketMask(h.B) // 当前key对应桶号 // 4) 正在扩容进行中，去迁移该桶的数据 if h.growing() { growWork(t, h, bucket) } b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) // *bmap bOrig := b\t// 当前变量开始桶，用于向前遍历时判断结束点 top := tophash(hash) search: // 5) 变量当前常规桶以及后面溢出桶(如果存在) for ; b != nil; b = b.overflow(t) { // 遍历当前桶 // const bucketCnt = 8 for i := uintptr(0); i \u0026lt; bucketCnt; i++ { // tophash比对失败 if b.tophash[i] != top { // const emptyRest = 0 // 后面slot都没有数据 if b.tophash[i] == emptyRest { break search } continue } // tophash比对成功; // 可能是【tophash冲突】 或 【匹配到了key】 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) // key k2 := k if t.indirectkey() {\t// 间接存储 k2 = *((*unsafe.Pointer)(k2)) } // 比对失败 tophash冲突 // NaN 的 key 无法被删除 if !t.key.equal(key, k2) {\tcontinue } // key 比对成功 // Only clear key if there are pointers in it. // // 只有在 key 中有指针时才清除 key。 if t.indirectkey() { // 间接存储时 *(*unsafe.Pointer)(k) = nil // 清空key } else if t.key.ptrdata != 0 { // key 中存在指针类型数据时 memclrHasPointers(k, t.key.size) // 清空key } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) // elem if t.indirectelem() { // 简介存储时 *(*unsafe.Pointer)(e) = nil // 清空elem } else if t.elem.ptrdata != 0 { // elem 中存在指针类型数据时 memclrHasPointers(e, t.elem.size) // 清空elem } else { // elem 中不存在指针类型数据时 memclrNoHeapPointers(e, t.elem.size) // 清空elem } // 标记 tophash 位为 1 b.tophash[i] = emptyOne // emptyOne == 1 // If the bucket now ends in a bunch of emptyOne states, // change those to emptyRest states. // It would be nice to make this a separate function, but // for loops are not currently inlineable. // // 当前桶最后一个 key if i == bucketCnt-1 { if b.overflow(t) != nil \u0026amp;\u0026amp; b.overflow(t).tophash[0] != emptyRest { // 存在溢出桶并且后面还有数据，处理后续后直接返回。 // 因为后面有数据不需要清楚已被删除的其他slot。 goto notLast } } else { // 后面一个tophash != 0; 后面还有数据 // const emptyRest = 0 if b.tophash[i+1] != emptyRest { goto notLast } } // 后面没有数据了，需要向前遍历处理已经删除的slot for { // const emptyRest = 0 // 标记当前tophash为0 b.tophash[i] = emptyRest\t// 当前桶的第一个slot if i == 0 { if b == bOrig { // 已经到最前的常规桶了 break // beginning of initial bucket, we\u0026#39;re done. } // Find previous bucket, continue at its last entry. c := b for b = bOrig; b.overflow(t) != c; b = b.overflow(t) { } i = bucketCnt - 1 } else { // 向前回溯 i-- } // const emptyOne = 1 // 因为删除的空格全部标记为了1，因此!=1说明存在数据了直接退出 if b.tophash[i] != emptyOne { break } } notLast: // key/elem对数量减一 h.count--\t// Reset the hash seed to make it more difficult for attackers to // repeatedly trigger hash collisions. See issue 25237. // // 重置hash值，使攻击者更难触发hash碰撞。 if h.count == 0 { h.hash0 = fastrand() // 重置hash0 } break search } } // 并发判断 if h.flags\u0026amp;hashWriting == 0 {\tfatal(\u0026#34;concurrent map writes\u0026#34;) } h.flags \u0026amp;^= hashWriting // 清除hashWriting标志位 } len() 🚀 reflect_maplen() len() 函数实现。 1 2 3 4 5 6 7 8 9 10 11 12 //go:linkname reflect_maplen reflect.maplen func reflect_maplen(h *hmap) int { if h == nil { return 0 } if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, abi.FuncPCABIInternal(reflect_maplen)) } // 直接取值 hmap.count return h.count } 迭代器 🚀 type hiter struct hash 迭代器。 如果你修改了hiter，也要修改 cmd/compile/internal/reflectdata/reflect.go 和 reflect/value.go 来匹配这个结构的布局。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // A hash iteration structure. // If you modify hiter, also change cmd/compile/internal/reflectdata/reflect.go // and reflect/value.go to match the layout of this structure. type hiter struct { // 必须在第一位置。写入nil来表示迭代结束(参见cmd/compile/internal/walk/range.go)。 key unsafe.Pointer // Must be in first position. Write nil to indicate iteration end (see cmd/compile/internal/walk/range.go). // 必须在第二位置(参见cmd/compile/internal/walk/range.go)。 elem unsafe.Pointer // Must be in second position (see cmd/compile/internal/walk/range.go). // map类型结构 t *maptype\t// map内存结构 h *hmap\t// 常规桶地址 buckets unsafe.Pointer // bucket ptr at hash_iter initialization time // 正在迭代的桶，如果bptr == nil则从bucket获取桶号迭代 bptr *bmap // current bucket overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive // 开始遍历的桶号，随机的，用于开始遍历的起点以及结束遍历的终点 startBucket uintptr // bucket iteration started at // tophash偏移值，在[0,7]中随机生成的值，用于后续 i + offset \u0026amp; 7 用作偏移量 offset uint8 // intra-bucket offset to start from during iteration (should be big enough to hold bucketCnt-1) // 当前遍历已过最大桶(1 \u0026lt;\u0026lt; B)时被设置为true wrapped bool // already wrapped around from end of bucket array to beginning B uint8 // 初始化时桶的数量 1 \u0026lt;\u0026lt; B // 当前桶遍历的索引，默认值从0开始，该值配合offset遍历tophash，i + offset \u0026amp; 7 i uint8 // 初始化时是startBucket的值 // 1. bptr == nil时bucket存储需要遍历的桶号 // 2. bptr != nil时bucket下个桶的桶号 bucket uintptr // 下个迭代器迭代的桶号 checkBucket uintptr // 需要检查的桶号 } 初始化迭代器 mapiterinit() mapiterinit() 初始化用于在 map 上进行范围搜索的 hiter 结构体。 'it'指向的hiter结构体由编译器order pass分配到栈上，或由reflect_mapiterinit分配到堆上。 两者都需要将hiter置零，因为该结构体包含指针。 参数： t *maptype：map 类型结构。 h *hmap：map 内存结构。 it *hiter：遍历器存储的结构。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 // mapiterinit initializes the hiter struct used for ranging over maps. // The hiter struct pointed to by \u0026#39;it\u0026#39; is allocated on the stack // by the compilers order pass or on the heap by reflect_mapiterinit. // Both need to have zeroed hiter since the struct contains pointers. func mapiterinit(t *maptype, h *hmap, it *hiter) { if raceenabled \u0026amp;\u0026amp; h != nil { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, abi.FuncPCABIInternal(mapiterinit)) } it.t = t // 1) 未初始化的map 或 key/elem对为空的map if h == nil || h.count == 0 { return } if unsafe.Sizeof(hiter{})/goarch.PtrSize != 12 { throw(\u0026#34;hash_iter size incorrect\u0026#34;) // see cmd/compile/internal/reflectdata/reflect.go } it.h = h // grab snapshot of bucket state // // 2) 抓取桶状态快照 it.B = h.B it.buckets = h.buckets if t.bucket.ptrdata == 0 { // Allocate the current slice and remember pointers to both current and old. // This preserves all relevant overflow buckets alive even if // the table grows and/or overflow buckets are added to the table // while we are iterating. // // 分配当前切片并记住指向当前和旧切片的指针。 // 这使得所有相关的溢出桶都保持活跃，即使表增长，and/or 在迭代时溢出桶被添加到表中。 h.createOverflow()\t// 判断h.extra是否初始化 it.overflow = h.extra.overflow it.oldoverflow = h.extra.oldoverflow } // decide where to start // // 3) 决定从哪里开始 var r uintptr if h.B \u0026gt; 31-bucketCntBits {\t// h.B \u0026gt; 31 - 3 r = uintptr(fastrand64()) // uint64 } else { r = uintptr(fastrand()) // uint32 } // 4) 用于确定从那个桶开始遍历 it.startBucket = r \u0026amp; bucketMask(h.B) // 随机数确定开始的桶号 // 5) 用于确定在每个桶的随机偏移量 it.offset = uint8(r \u0026gt;\u0026gt; h.B \u0026amp; (bucketCnt - 1)) // 随机的偏移量[0,7]中随机数 // iterator state it.bucket = it.startBucket\t// 当前迭代桶号 // Remember we have an iterator. // Can run concurrently with another mapiterinit(). // // 6) 记住我们有一个迭代器。可以与另一个mapiterinit()并发运行。 if old := h.flags; old\u0026amp;(iterator|oldIterator) != iterator|oldIterator { atomic.Or8(\u0026amp;h.flags, iterator|oldIterator) // 设置迭代标志 iterator和oldIterator } mapiternext(it) } 迭代 mapiternext() 扩容发生在迭代器之前，此时应该去变量扩容后的所有桶，都是从旧桶出发。这种情况旧桶里面可能没key/elem以及overflow信息。 扩容发生在迭代器之后，此时应该遍历所有的旧桶数量，从旧桶出发。这种情况旧桶保留了所有的key/elem以及overflow信息。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 func mapiternext(it *hiter) { h := it.h\t// *hmap if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, abi.FuncPCABIInternal(mapiternext)) } if h.flags\u0026amp;hashWriting != 0 { fatal(\u0026#34;concurrent map iteration and map write\u0026#34;) } t := it.t // *maptype bucket := it.bucket\t// 需要迭代桶号 b := it.bptr // 当前正在迭代的桶 *bmap i := it.i // 当前遍历bptr桶的索引 checkBucket := it.checkBucket // 需要检查的桶 next:\t// 根据bucket获取*bmap if b == nil {\t// map遍历完了 if bucket == it.startBucket \u0026amp;\u0026amp; it.wrapped { // end of iteration // 结束迭代器 it.key = nil it.elem = nil return } // h.growing()：正在扩容中 // it.B == h.B：扩容发生在迭代器之前，迭代器开始时已经在进行扩容了 // 1. 这种情况可能发生部分数据还在旧桶里面，也可能在新桶里面 // 2. 随着扩容在进行中，可能出现部分数据在旧桶部分数据在新桶 if h.growing() \u0026amp;\u0026amp; it.B == h.B {\t// 数据可能在旧桶里面，可能在新桶里 // Iterator was started in the middle of a grow, and the grow isn\u0026#39;t done yet. // If the bucket we\u0026#39;re looking at hasn\u0026#39;t been filled in yet (i.e. the old // bucket hasn\u0026#39;t been evacuated) then we need to iterate through the old // bucket and only return the ones that will be migrated to this bucket. // // 迭代器是在扩容过程进行中启动的，而且扩容还没有完成 // 如果我们查看的桶还没有被填充（即旧桶还没有被清空），那么我们需要迭代旧桶，并只返回将要迁移到此桶的那些。 oldbucket := bucket \u0026amp; it.h.oldbucketmask() // 旧桶编号 b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))\t// 旧桶 *bmap // 其实这种情况一直是在检查旧桶，旧桶数据有没被迁移迁移到哪里了 if !evacuated(b) { // 旧桶有数据，可能下面数据被迁移到新桶了 // 需要检查新桶的桶好，因此新桶旧桶都要查看 checkBucket = bucket\t} else { // 如果旧桶没有数据则说明数据一定在新桶 b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) // 新桶 *bmap // 因此不需要再检查其他的桶了 checkBucket = noCheck } } else { // !h.growing() || h.growing() \u0026amp;\u0026amp; it.B != h.B // 1. !h.growing(): (没有扩容)数据在b桶里，遍历b桶即可。 // 2. h.growing() \u0026amp;\u0026amp; it.B != h.B; (扩容发生在迭代之后)可能b桶被迁移了但是b桶仍然保持着key/elem; // (2)这种情况我们为什么不能直接拿去b桶的elem，因为可能key又被删除或更新了需要查看新数据 // 这里可以看出迭代数据时是按照保存快照的数据为准的。 b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } bucket++ // 迭代过了最大桶号 // 1. 扩容发生在迭代之前，需要遍历所有扩容后的桶数量，被疏散的key/elem不管 // 2. 扩容发生在迭代之后，则只会迭代旧桶数量，被疏散的key/elem去新桶里面找 if bucket == bucketShift(it.B) { // bucket == 1 \u0026lt;\u0026lt; B bucket = 0\t// 桶号重置为0 it.wrapped = true // 标记wrapped已过最大桶号 } i = 0 } // 迭代桶 for ; i \u0026lt; bucketCnt; i++ { offi := (i + it.offset) \u0026amp; (bucketCnt - 1) // tophash[offi] \u0026lt;= 1 || tophash[offi] == 4 // 当前slot处没有数据，因为一直遍历的是旧桶b，如果是下面这两种条件直接跳过即可 if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty { // TODO: emptyRest is hard to use here, as we start iterating // in the middle of a bucket. It\u0026#39;s feasible, just tricky. continue } k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize)) if t.indirectkey() { // 间接存储 k = *((*unsafe.Pointer)(k)) } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.elemsize)) // 扩容发生在迭代器之前; 翻倍扩容才需要检查旧桶 // checkBucket != noCheck：有需要特殊检查的桶 // !h.sameSizeGrow()：当前是翻倍扩容 if checkBucket != noCheck \u0026amp;\u0026amp; !h.sameSizeGrow() {\t// Special case: iterator was started during a grow to a larger size // and the grow is not done yet. We\u0026#39;re working on a bucket whose // oldbucket has not been evacuated yet. Or at least, it wasn\u0026#39;t // evacuated when we started the bucket. So we\u0026#39;re iterating // through the oldbucket, skipping any keys that will go // to the other new bucket (each oldbucket expands to two // buckets during a grow). // // 特殊情况:迭代器在增长到更大的尺寸期间启动，但增长还没有完成。 // 我们正在处理一个桶，它的旧桶还没有被清空。 // 至少，我们启动水桶时还没人撤离。因此，我们遍历oldbucket，跳过所有将进入另一个新桶的键(每个oldbucket在增长过程中会扩展到两个桶)。 // k == k 成立，这种请款出现在 +0和-0虽然相等但是生成的hash确实不相同 if t.reflexivekey() || t.key.equal(k, k) {\t// If the item in the oldbucket is not destined for // the current new bucket in the iteration, skip it. // // 如果旧桶中的项在迭代中不是为当前的新桶指定的，则跳过它。 hash := t.hasher(k, uintptr(h.hash0)) // hash\u0026amp;bucketMask(it.B) != checkBucket; 表示当前key/elem不应该在checkBucket桶中 // 则跳过后续到，后续会去找这种情况 if hash\u0026amp;bucketMask(it.B) != checkBucket { continue } } else { // Hash isn\u0026#39;t repeatable if k != k (NaNs). We need a // repeatable and randomish choice of which direction // to send NaNs during evacuation. We\u0026#39;ll use the low // bit of tophash to decide which way NaNs go. // NOTE: this case is why we need two evacuate tophash // values, evacuatedX and evacuatedY, that differ in // their low bit. // // 如果 k != k (NaNs)，则 hash 是不可重复的。 // 在疏散过程中，我们需要一个可重复且随机的选择将NaNs派往哪个方向。 // 我们将使用tophash的低位来决定NaNs的方向。 // 注意:在这种情况下，我们需要两个疏散tophash值evacuatedX和evacuatedY，它们的低位不同。 if checkBucket\u0026gt;\u0026gt;(it.B-1) != uintptr(b.tophash[offi]\u0026amp;1) { continue\t// 疏散的不是当前桶则跳过后续会去查找 } } } // const evacuatedX = 2 // const evacuatedY = 3 // // tophash[offi] != 2或3 || k != k // tophash[offi] != 2或3; 存在数据 // k != k：NaN 情况 if (b.tophash[offi] != evacuatedX \u0026amp;\u0026amp; b.tophash[offi] != evacuatedY) || !(t.reflexivekey() || t.key.equal(k, k)) { // This is the golden data, we can return it. // OR // key!=key, so the entry can\u0026#39;t be deleted or updated, so we can just return it. // That\u0026#39;s lucky for us because when key!=key we can\u0026#39;t look it up successfully. // // 这是黄金数据，我们可以返回它。或 key!=key，因此entry不能被删除或更新，因此我们可以直接返回它。 // 这对我们来说是幸运的，因为当 key!=key 无法成功查找时。 it.key = k if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } it.elem = e } else {\t// tophash[offi] == 2或3；数据被迁移了 // The hash table has grown since the iterator was started. // The golden data for this key is now somewhere else. // Check the current hash table for the data. // This code handles the case where the key // has been deleted, updated, or deleted and reinserted. // NOTE: we need to regrab the key as it has potentially been // updated to an equal() but not identical key (e.g. +0.0 vs -0.0). // // 自迭代器启动以来，散列表一直在增长。 // 这个密钥的黄金数据现在在其他地方。 // 检查当前散列表中的数据。 // 这段代码处理键被删除、更新或删除并重新插入的情况。 // 注意:我们需要重新获取密钥，因为它可能已经更新到equal()，但key不相同(例如+0.0 vs -0.0)。 rk, re := mapaccessK(t, h, k) // 根据k查找数据 if rk == nil { continue // key has been deleted } it.key = rk it.elem = re } it.bucket = bucket // 记录当前正在迭代的桶号 if it.bptr != b { // avoid unnecessary write barrier; see issue 14921 it.bptr = b } it.i = i + 1 // 下次需要迭代的tophash索引 it.checkBucket = checkBucket // 需要检查的桶号 return } // 迭代b桶的溢出桶 b = b.overflow(t) i = 0 goto next } mapaccessK() 同时返回key和elem。由map迭代器使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // returns both key and elem. Used by map iterator func mapaccessK(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, unsafe.Pointer) { if h == nil || h.count == 0 { return nil, nil } hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) // *bmap if c := h.oldbuckets; c != nil { // 正处于扩容状态 if !h.sameSizeGrow() { // 翻倍扩容 // There used to be half as many buckets; mask down one more power of two. m \u0026gt;\u0026gt;= 1 } oldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) if !evacuated(oldb) { // 查看旧桶是否有数据 b = oldb } } top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return k, e } } } return nil, nil } 不能作为map key类型 官方解释 map的键可以是任何可比较的类型。 语言规范精确地定义了这一点，简而言之，可比类型是boolean, numeric, string, pointer, channel, and interface类型，以及只包含这些类型的结构体或数组。 值得注意的是，列表中没有【slices】,【 maps】, and 【functions】; 这些类型不能使用==进行比较，也不能用作映射键。 但是slice、map、function能与nil作为比较。 slice不能作为map key slice 不能比较，因此也不能作为map key。更深层的原因应该是 Slice 不能作为map key因此Slice定义为不可比较类型。 根本原因是 slice 是不可比较类型，在Go中Slice作为只是底层数组的连续的描述符，如果按照元素的比较方式Slice可以像Array一样进行比较，但是当Slice作为map key值则会出现这种情况当一个slice作为key保存在map中，我们修改当前slice的元素值会修改map中的slice的key值，这与map的存储意义相违背。因此Go干脆不支持Slice的比较，比较函数为nil。另外一方面slice的cap在比较中又显得不是很重要，比如 make([]int64, 0, 10) 和 make([]int64, 0, 9) 是否相等呢，因此Slice作为可比较类型是有歧义的。 如果Array作为由于Array是固定长度的因此比较元素即可，另外array作为map key是副本的形式不存在slice的情况。 map不能作为key map 不能比较，因此也不能作为map key。更深层的原因应该是 map 不能作为map key因此map定义为不可比较类型。 如果map能比较，那么比较 map 的所有 key/elem 对即可，但是当map作为map key时key中保存的是*hmap，因此当我们修改这个作为map key的map值也会修改到map中相应的key值，这种问题和slice类似这与map的存储意义相违背。因此Go干脆不支持Map的比较，比较函数为nil。 function不能作为key function 不能比较，因此不能作为map key。更深层的原因应该是 function 不能作为map key因此function定义为不可比较类型。 function类型的组成由funcval{fn uintptr}结构体以及一系列捕获列表。如果直接判断函数的签名可能存在不同的签名函数实现的函数体不同，因此函数签名不能作为判断函数相等依据，如果使用\u0026amp;funcval作为map key，会出现如果相同的\u0026amp;funcval不同的捕获列表其实并没有成功匹配到key。 for range range map只是此时map的一个快照。 对于key为NaN的，for range能遍历出来。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 map1 := map[string]string{\u0026#34;one\u0026#34;:\u0026#34;1\u0026#34;, \u0026#34;tow\u0026#34;:\u0026#34;2\u0026#34;} for i, v := range map1 { fmt.Println(i, v) // original body } // ------------------------------- // 下面是上面编译后代码 // ------------------------------- // 定义遍历所需要的key和value变量 var i, v string\t// map_iteration_struct是一个hiter结构体，存储着map的遍历相关信息 var hiter map_iteration_struct\t// mapiterinit 初始化map参看runtime/map.go文件 // hiter是一个哈希迭代结构，mapiternext迭代下一个哈希 for mapiterinit(type, range, \u0026amp;hiter); hiter.key != nil; mapiternext(\u0026amp;hiter) { index_temp := *hiter.key value_temp := *hiter.val i = index_temp v = value_temp fmt.Println(i, v) // original body } map相关练习题 示例一 map[string]map[string]string类型遍历。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import \u0026#34;fmt\u0026#34; var mm map[string]map[string]string func init() { mm = make(map[string]map[string]string, 1024) } func main() { // 测试验证 modifyUser(mm, \u0026#34;one\u0026#34;) modifyUser(mm, \u0026#34;two\u0026#34;) modifyUser(mm, \u0026#34;three\u0026#34;) fmt.Println(mm) modifyUser(mm, \u0026#34;one\u0026#34;) fmt.Println(mm) } // 1. 使用map[string]map[string]string类型 // 2. key：表示用户名，是唯一的，不可以重复 // 3. 如果某个用户名存在，就将其密码修改\u0026#34;888888\u0026#34;，如果不存在就增加这个用户信息（包括昵称nickname和密码pwd） // 4. 编写一个函数modifyUser(users map[string]map[string]string, name string)完成上述功能 func modifyUser(user map[string]map[string]string, name string) { if v, ok := user[name]; ok { // 因为v存储的时*hmap指针 // 因此直接修改v[\u0026#34;pwd\u0026#34;]时可行的 v[\u0026#34;pwd\u0026#34;] = \u0026#34;888888\u0026#34; return } user[name] = map[string]string{\u0026#34;pwd\u0026#34;: name, \u0026#34;nickname\u0026#34;: \u0026#34;nickname\u0026#34;} } 示例二 map作为集合使用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import \u0026#34;fmt\u0026#34; // 1. map作为集合使用 var mm map[string]struct{} func init() { mm = make(map[string]struct{}, 8) mm[\u0026#34;redis\u0026#34;] = struct{}{} mm[\u0026#34;mysql\u0026#34;] = struct{}{} mm[\u0026#34;nginx\u0026#34;] = struct{}{} } func main() { if _, ok := mm[\u0026#34;php\u0026#34;]; ok { // 指定元素存在 } for k := range mm { fmt.Println(k) } } ","permalink":"https://heliu.site/posts/golang/map/theory/","summary":"Golang map源码介绍。","title":"Map(原理)"},{"content":"type maptype struct maptype 是 map 的元类型结构体。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type maptype struct { typ _type // map类型 key *_type // key类型 elem *_type // elem类型 // 桶的类型，桶包含tophashs、keys、elems、overflow这四块 // 由于key/elem是不确定的类型，所以bucket也是不同的类型 // bucket是否包含指针类型，是取决于该结构中是否存在指针 //\t1. tophashs 是非指针 // 2. keys、elems 是根据具体情况的 // 3. overflow 是个指针，那么是否意味则bucket是否包含指针类型? // 其实bucket是否包含指针类型是根据keys、elems决定的 // bucket 的组成由 tophash、keys、elems、overflow bucket *_type // internal type representing a hash bucket // function for hashing keys (ptr to key, seed) -\u0026gt; hash // hash函数，用于(key, h.hash0) hasher func(unsafe.Pointer, uintptr) uintptr\tkeysize uint8 // size of key slot // key值大小 elemsize uint8 // size of elem slot // value值大小 bucketsize uint16 // size of bucket // 桶大小 flags uint32 // map的标志位 } 自定义map类型 1 2 3 4 type u struct { maptype u uncommontype } maptype的组成，以及maptype.bucket的组成。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type tpe struct { size uintptr ptrdata uintptr // size of memory prefix holding all pointers hash uint32 tflag uint8 align uint8 fieldAlign uint8 kind uint8 // function for comparing objects of this type // (ptr to object A, ptr to object B) -\u0026gt; ==? equal func(unsafe.Pointer, unsafe.Pointer) bool // gcdata stores the GC type data for the garbage collector. // If the KindGCProg bit is set in kind, gcdata is a GC program. // Otherwise it is a ptrmask bitmap. See mbitmap.go for details. gcdata *byte str int32 ptrToThis int32 } type maptype struct { typ tpe // map类型 key *tpe // key类型 elem *tpe // elem类型 // 桶的类型，桶包含tophashs、keys、elems、overflow这四块 // 由于key/elem是不确定的类型，所以bucket也是不同的类型 // bucket是否包含指针类型，是取决于该结构中是否存在指针 //\t1. tophashs 是非指针 // 2. keys、elems 是根据具体情况的 // 3. overflow 是个指针，那么是否意味则bucket是否包含指针类型? // 其实bucket是否包含指针类型是根据keys、elems决定的 bucket *tpe // internal type representing a hash bucket // function for hashing keys (ptr to key, seed) -\u0026gt; hash // hash函数，用于(key, h.hash0) hasher func(unsafe.Pointer, uintptr) uintptr keysize uint8 // size of key slot\t// key值大小 elemsize uint8 // size of elem slot\t// value值大小 bucketsize uint16 // size of bucket\t// 桶大小 flags uint32 // map的标志位 } type e struct { i *tpe d uintptr } func main() { m := make(map[string]uint8, 8) var d any = m dd1 := **(**maptype)(unsafe.Pointer(\u0026amp;d)) dd := *(**(**maptype)(unsafe.Pointer(\u0026amp;d))).bucket // 8 + 16*8 + 8 + 8 // 8 + 128 + 8 + 8 // 98 -\u0026gt; 152 fmt.Printf(\u0026#34;%#v\\n\u0026#34;, dd1) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, dd) // Output: // main.maptype{ // typ:main.tpe{ // size:0x8, // ptrdata:0x8, // hash:0xfc5c9caf, // tflag:0x2, // align:0x8, // fieldAlign:0x8, // kind:0x35, // 0x35 = 53 = 32 + 21 // equal:(func(unsafe.Pointer, unsafe.Pointer) bool)(nil), // gcdata:(*uint8)(0x71b448), // str:13639, // ptrToThis:0 // }, // key:(*main.tpe)(0x6e8140), // elem:(*main.tpe)(0x6e82c0), // bucket:(*main.tpe)(0x6f1d40), // hasher:(func(unsafe.Pointer, uintptr) uintptr)(0x6adf40), // keysize:0x10, // string 大小 16 byte // elemsize:0x1, // uint8 大小 1 byte // bucketsize:0x98, // 桶大小 tophash + 8key + 8elem + 1overflow // flags:0xc //} // // kind:0x35：32.间接存储在接口中; 21.map类型 //main.tpe{ // size:0x98, // ptrdata:0x98, // hash:0x9f98cd28, // tflag:0x2, // align:0x8, // fieldAlign:0x8, // kind:0x19, // equal:(func(unsafe.Pointer, unsafe.Pointer) bool)(nil), // gcdata:(*uint8)(0x71b5f8), // str:17051, // ptrToThis:0 //} } ","permalink":"https://heliu.site/posts/golang/map/meta/","summary":"Golang map元类型结构。","title":"Map 元类型"},{"content":"函数定义 函数基本组成：关键字func、函数名、参数列表、返回值列表、函数体、返回语句。 1 2 3 4 func 函数名(参数列表) (返回值列表) { // 函数体 return // 返回语句 } 除了main()、init()函数外，其他所有类型的函数都可以有【参数】与【返回值】。 函数一般也可以这么写：func FunctionName Signature [FunctionBody] func定义函数关键字。FunctionName函数名。 Signature函数签名，包括函数参数和函数返回值，函数签名是识别一个函数的依据。 FunctionBody函数体。 func FunctionName (a typea, b typed) (t1 type1, t2 type2) 函数签名由函数参数、返回值以及它们的类型组成。 (a typea, b typed) (t1 type1, t2 type2) 如果两个函数的参数列表和返回值列表的变量类型能一一对应，那么这两个函数就有相同得签名。 下面testa与testb具有相同得函数签名。 func testa (a, b int, z float32) bool func testb (a, b int, z float32) (bool) 函数调用传入的参数必须按照参数声明的顺序。Go语言【没有默认参数值】。 函数签名中的最后传入参数可以具有前缀为...的类型(...int)，这样的参数称为【可变参数】。 在接收这种(...)参数的时候，当做【切片】处理即可。 注意(s…)这种形式的s只能是切片或者是字符串（只能在append()函数或可变参数函数中使用）【不能是数组】。 可以使用零个或多个参数来调用该函数，这样的函数称为【变参函数】。 // 其实values就是 []int 切片 func doFix(prefix string, values ...int) 使用 函数的参数和返回值列表始终带括号，但只有一个未命名的参数值，可以将其写为未加括号的类型。 一个函数也可以拥有多个返回值，返回类型之间需要使用逗号分隔，并使用小括号（）将它们括起来。 func testa (a, b int, z float32) bool func swap (a int, b int) (t1 int, t2 int) 在函数体中，参数是局部变量，被初始化为调用者传入的值。 函数的参数和命名返回值是函数最外层的局部变量，它们的作用域就是整个函数。 如果函数的签名声明了返回值，则函数体的语句列表必须以终止语句结束。 但是如果函数没有声明返回值也是可以使用return结束函数后面代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func IndexRune(s string,r rune) int { for i, c := range s { if c == r { return i } } //必须有终止语句return， // 否则会发生编译错误 missing return at end of function return } // 没有指定返回值的函数，也是可以使用return结束整个函数运行的 func Show() { fmt.Println(123) return } Go语言函数重载是不被允许的。\n函数重载：可以编写多个同名函数，只要它们拥有不同的形参或者不同的返回值。 官方不支持重载原因，让Go保存简单。 函数可以作为函数类型被使用。函数类型就是函数签名。函数类型的未初始化变量的值为nil（函数是引用类型）。\n函数作为参数被使用，这种是回调。其实就是funcval指针。\n函数作为返回值被使用，这种是闭包。其实就是funcval指针。\n1 2 3 4 5 // 通过type关键字，定义一个新的函数类型 funcType type funcType func(int, int) int // 通过var关键字，创建函数变量 var f func() int 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type funcType func(int, int) int func main() { var f funcType = func(a, b int) int { return a + b } fmt.Println(unsafe.Sizeof(f)) // Output: // 8 } 函数可以在表达式中赋值给变量，这样作为表达式中的右值出现，称为函数值字面量。 函数值字面量是一种表达式，它的值被称为匿名函数。 1 2 3 f := func() int { return 7 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 定义函数类型 funcType type funcType func(time.Time) func main() { // 直接赋值给变量 f := func(t time.Time) time.Time { return t } fmt.Println(\u0026#34;一：\u0026#34;, f( time.Now() )) // 定义函数类型 funcType 变量 timer var timer funcType = CurrentTime timer( time.Now() ) // 先把CurrentTime函数转为funcType类型，然后传入参数调用 // funcType(CurrentTime) CurrentTime转换为funcType类型 funcType(CurrentTime)(time.Now()) // Output: // 一： 2021-04-11 12:25:15.8479173 +0800 CST m=+0.001997401 // 二： 2021-04-11 12:25:15.8589326 +0800 CST m=+0.013013701 // 二： 2021-04-11 12:25:15.8599231 +0800 CST m=+0.014004301 } func CurrentTime (start time.Time) { fmt.Println(\u0026#34;二：\u0026#34;, start) } ...int 函数只能是最后一个参数是 ...int 形式。 1 2 3 4 5 6 7 8 9 10 11 12 package main func main() { show(\u0026#34;aaa\u0026#34;) } //go:noinline func show(name string, params ...int) { // params默认值[]int(nil) // params == nil println(name, params) } main.main相关汇编： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP # 1. 栈增长判断 0x4551e4 7630 JBE 0x455216 0x4551e6 4883ec30 SUBQ $0x30, SP # 2. 设置栈大小 0x4551ea 48896c2428 MOVQ BP, 0x28(SP) # 3. 保存rbp寄存器值 0x4551ef 488d6c2428 LEAQ 0x28(SP), BP # 4. 设置rbp新值 show(\u0026#34;aaa\u0026#34;) # AX和BX寄存器用于传递参数 【name string】 0x4551f4 488d05fdc70000 LEAQ 0xc7fd(IP), AX # name.data = 0xc7fd(IP) 0x4551fb bb03000000 MOVL $0x3, BX # name.len = 0x3 # params == nil 【params ...int】 # CX、DI、SI 用于传递 ..int 参数，是 []int 0x455200 31c9 XORL CX, CX # params.data = 0 0x455202 31ff XORL DI, DI # params.len = 0 0x455204 4889fe MOVQ DI, SI # params.cap = 0 0x455207 e814000000 ALL main.show(SB) # 调用 main.show 函数 } 0x45520c 488b6c2428 MOVQ 0x28(SP), BP 0x455211 4883c430 ADDQ $0x30, SP 0x455215 c3 RET func main() { 0x455216 e845cdffff CALL runtime.morestack_noctxt.abi0(SB) 0x45521b ebc3 JMP main.main(SB) ...int传递参数： 1 2 3 4 5 6 7 8 9 10 11 package main func main() { //var s []int = []int{1, 2} X(1, 2, 3, 4) // []int 24字节 } func X(ss ...int) int { // 可能ss==nil，因此编译器要做检查 return ss[0] } main.main相关汇编： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 $ go build -gcflags=\u0026#34;-N -l\u0026#34; -o ./h1 heliu.site/helium $ go tool objdump -S -s \u0026#39;^main.main$\u0026#39; ./h1 TEXT main.main(SB) /mnt/hgfs/workspace/helium/main.go func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x4551e4 0f8687000000 JBE 0x455271 0x4551ea 4883ec60 SUBQ $0x60, SP 0x4551ee 48896c2458 MOVQ BP, 0x58(SP) 0x4551f3 488d6c2458 LEAQ 0x58(SP), BP X(1, 2, 3, 4) # []int 24字节 # 0x18-0x38 分别作为参数1,2,3,4 0x4551f8 440f117c2418 MOVUPS X15, 0x18(SP) # 0x18-0x28 清零 0x4551fe 440f117c2428 MOVUPS X15, 0x28(SP) # 0x28-0x38 清零 0x455204 488d542418 LEAQ 0x18(SP), DX # DX=0x18(SP) 0x455209 4889542438 MOVQ DX, 0x38(SP) # 0x38(SP)=0x18(SP) 0x45520e 8402 TESTB AL, 0(DX) 0x455210 48c744241801000000 MOVQ $0x1, 0x18(SP) # 1 0x455219 8402 TESTB AL, 0(DX) 0x45521b 48c744242002000000 MOVQ $0x2, 0x20(SP) # 2 0x455224 8402 TESTB AL, 0(DX) 0x455226 48c744242803000000 MOVQ $0x3, 0x28(SP) # 3 0x45522f 8402 TESTB AL, 0(DX) 0x455231 48c744243004000000 MOVQ $0x4, 0x30(SP) # 4 0x45523a 488b442438 MOVQ 0x38(SP), AX # AX=0x38(SP) 0x45523f 8400 TESTB AL, 0(AX) 0x455241 eb00 JMP 0x455243 0x455243 4889442440 MOVQ AX, 0x40(SP) # ss.data=0x38(SP) 0x455248 48c744244804000000 MOVQ $0x4, 0x48(SP) # ss.len=4 0x455251 48c744245004000000 MOVQ $0x4, 0x50(SP) # ss.cap=4 0x45525a bb04000000 MOVL $0x4, BX # BX=4 0x45525f 4889d9 MOVQ BX, CX # CX=4 # AX=0x38(SP), BX=4, CX=4; 作为 main.X(SB) 的调用参数 0x455262 e819000000 CALL main.X(SB) } 0x455267 488b6c2458 MOVQ 0x58(SP), BP 0x45526c 4883c460 ADDQ $0x60, SP 0x455270 c3 RET func main() { 0x455271 e8eaccffff CALL runtime.morestack_noctxt.abi0(SB) 0x455276 e965ffffff JMP main.main(SB) main.X相关汇编： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 $ go tool objdump -S -s \u0026#39;^main.X$\u0026#39; ./h1 TEXT main.X(SB) /mnt/hgfs/workspace/helium/main.go func X(ss ...int) int { 0x455280 4883ec20 SUBQ $0x20, SP 0x455284 48896c2418 MOVQ BP, 0x18(SP) 0x455289 488d6c2418 LEAQ 0x18(SP), BP # ss ...int 0x45528e 4889442428 MOVQ AX, 0x28(SP) # slice.data 0x455293 48895c2430 MOVQ BX, 0x30(SP) # slice.len 0x455298 48894c2438 MOVQ CX, 0x38(SP) # slice.cap 0x45529d 48c744241000000000 MOVQ $0x0, 0x10(SP) # main.X 返回值 0 return ss[0] 0x4552a6 488b4c2430 MOVQ 0x30(SP), CX # CX=4 0x4552ab 488b542428 MOVQ 0x28(SP), DX # DX=slice.data # TEST 逻辑与运算，因为ss[0]取第一个下标，因此CX=0是不能满足的，直接panic 0x4552b0 4885c9 TESTQ CX, CX # CX \u0026amp; CX; 这里做了一次越界检查 0x4552b3 7702 JA 0x4552b7 0x4552b5 eb12 JMP 0x4552c9 0x4552b7 488b02 MOVQ 0(DX), AX # AX=ss[0] 0x4552ba 4889442410 MOVQ AX, 0x10(SP) # main.X 返回值 1 0x4552bf 488b6c2418 MOVQ 0x18(SP), BP 0x4552c4 4883c420 ADDQ $0x20, SP 0x4552c8 c3 RET 0x4552c9 31c0 XORL AX, AX 0x4552cb e8f0d3ffff CALL runtime.panicIndex(SB) # panic，无效的索引 0x4552d0 90 NOPL main.main和main.X 函数的栈布局情况： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // +88 runtime.main back // -------------------------------- --------------------------------------- // +80 BP of runtime.main +58 // -------------------------------- rbp \u0026lt;------- ------------------ // +78 4 +50 sliceStruct.cap // -------------------------------- \u0026lt;------- // +70 4 +48 sliceStruct.len []int切片传参前 // -------------------------------- \u0026lt;------- // +68 0x18(rsp) +40 sliceStruct.data // -------------------------------- \u0026lt;------- ------------------ // +60 0x18(rsp) +38 关联数组开始位置 // -------------------------------- \u0026lt;------- ------------------ // +58 4 +30 // -------------------------------- // +50 3 +28 // -------------------------------- 传参变量 // +48 2 +20 // -------------------------------- // +40 1 +18 // -------------------------------- \u0026lt;------- ------------------ // +38 4 +10 // -------------------------------- // +30 4 +08 X函数的参数 []int // -------------------------------- // +28 0x18(rsp) +00 // -------------------------------- rsp \u0026lt;------- ------------------ // +20 main.main back // -------------------------------- --------------------------------------- // +18 BP of main.main // -------------------------------- rbp // +10 1 X函数的返回值 // -------------------------------- X函数栈 // +08 // -------------------------------- // +00 // -------------------------------- rsp ----------------------------------- s...形式传参： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main func main() { var s []int = []int{1, 2} X(s...) // []int 24字节 } func X(ss ...int) int { // if len(ss) \u0026gt;= 2 { // return ss[1] // } else { // return 0 // } return ss[1] // 这里会进行一次越界检查 } main.main相关汇编代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 $ go tool objdump -S -s \u0026#39;^main.main$\u0026#39; ./h1 TEXT main.main(SB) /mnt/hgfs/workspace/helium/main.go func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x4551e4 7669 JBE 0x45524f 0x4551e6 4883ec50 SUBQ $0x50, SP 0x4551ea 48896c2448 MOVQ BP, 0x48(SP) 0x4551ef 488d6c2448 LEAQ 0x48(SP), BP var s []int = []int{1, 2} # 0x18(SP)-0x28(SP) 用于 1,2 参数的存放 0x4551f4 440f117c2418 MOVUPS X15, 0x18(SP) # 0x18(SP)-0x28(SP) 清零 0x4551fa 488d442418 LEAQ 0x18(SP), AX # AX=0x18(SP) 0x4551ff 4889442428 MOVQ AX, 0x28(SP) # 0x28(SP)=AX=0x18(SP) 0x455204 8400 TESTB AL, 0(AX) 0x455206 48c744241801000000 MOVQ $0x1, 0x18(SP) # 0x18(SP)=1 0x45520f 8400 TESTB AL, 0(AX) 0x455211 48c744242002000000 MOVQ $0x2, 0x20(SP) # 0x20(SP)=2 0x45521a 8400 TESTB AL, 0(AX) 0x45521c eb00 JMP 0x45521e 0x45521e 4889442430 MOVQ AX, 0x30(SP) # ss.data=0x18(SP) 0x455223 48c744243802000000 MOVQ $0x2, 0x38(SP) # ss.len=2 0x45522c 48c744244002000000 MOVQ $0x2, 0x40(SP) # ss.cap=2 X(s...) # []int 24字节 0x455235 bb02000000 MOVL $0x2, BX # BX=2 0x45523a 4889d9 MOVQ BX, CX # CX=2 0x45523d 0f1f00 NOPL 0(AX) # AX=0x18(SP); BX=2; CX=2; 用作 main.X 函数的传参 0x455240 e81b000000 CALL main.X(SB) } 0x455245 488b6c2448 MOVQ 0x48(SP), BP 0x45524a 4883c450 ADDQ $0x50, SP 0x45524e c3 RET func main() { 0x45524f e80ccdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455254 eb8a JMP main.main(SB) main.X函数相关汇编： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ go tool objdump -S -s \u0026#39;^main.X$\u0026#39; ./h1 TEXT main.X(SB) /mnt/hgfs/workspace/helium/main.go func X(ss ...int) int { 0x455260 4883ec20 SUBQ $0x20, SP 0x455264 48896c2418 MOVQ BP, 0x18(SP) 0x455269 488d6c2418 LEAQ 0x18(SP), BP 0x45526e 4889442428 MOVQ AX, 0x28(SP) # ss.data 0x455273 48895c2430 MOVQ BX, 0x30(SP) # ss.len 0x455278 48894c2438 MOVQ CX, 0x38(SP) # ss.cap 0x45527d 48c744241000000000 MOVQ $0x0, 0x10(SP) # 返回值临时内存 0 return ss[1] # 这里会进行一次越界检查 0x455286 488b4c2430 MOVQ 0x30(SP), CX # CX=2 0x45528b 488b542428 MOVQ 0x28(SP), DX # DX=2 0x455290 4883f901 CMPQ $0x1, CX # 这里进行越界检查 0x455294 7702 JA 0x455298 0x455296 eb13 JMP 0x4552ab 0x455298 488b4208 MOVQ 0x8(DX), AX # AX=ss[1] 0x45529c 4889442410 MOVQ AX, 0x10(SP) # 返回值临时内存 ss[1] 0x4552a1 488b6c2418 MOVQ 0x18(SP), BP 0x4552a6 4883c420 ADDQ $0x20, SP 0x4552aa c3 RET 0x4552ab b801000000 MOVL $0x1, AX 0x4552b0 e80bd4ffff CALL runtime.panicIndex(SB) 0x4552b5 90 NOPL main.main和main.X函数的栈布局情况： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // +50 runtime.main back // ------------------------------------- ---------------------------------------------- // +48 BP of runtime.main // ------------------------------------- rbp \u0026lt;---------------- ------- --------- // +40 2 sliceStruct.cap // ------------------------------------- \u0026lt;---------------- // +38 2 sliceStruct.len []int // ------------------------------------- \u0026lt;---------------- // +30 0x18(rsp) sliceStruct.data // ------------------------------------- \u0026lt;---------------- ------- 初始化s变量 // +28 0x18(rsp) 底层数组首地址 // ------------------------------------- // +20 2 // ------------------------------------- // +18 1 // ------------------------------------- \u0026lt;---------------- ------- --------- // +10 // ------------------------------------- \u0026lt;---------------- // +08 X函数参数[]int // ------------------------------------- \u0026lt;---------------- // +00 // ------------------------------------- rsp \u0026lt;---------------- ------- --------- 函数调用 Go语言中函数默认使用按值传递来传递参数，也就是传递参数的副本。函数接收参数副本之后，在使用变量的过程中可能对副本的值进行更改，但不会影响原来的变量。 如果希望函数可以直接修改参数的值，而不是对参数的副本进行操作。需要将参数的地址传递给函数，这就是按引用传值。如Function(\u0026amp;arg1)，此时传递给函数的是一个指针。如果传递给函数的是一个指针，则可以通过这个指针来修改对应地址上的变量值。 在进行函数调用时，像切片(slice)、字典(map)、函数(func)、通道(channel)等这样的引用类型都是默认使用引用传递。 命名返回值被初始化为相应类型的零值，当需要返回的时候，只需要一条简单的不带参数的return语句。即使只有一个命名返回值，也需要使用()括起来。如type funcType func() (b bool)、type funcType1 func() bool。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func main() { // 常规调用，参数可以是多个 list(1, 2, 3, 4, 5, 6) // []int{1, 2, 3, 4, 5, 6} []int // 在参数同类型时，可以组成slice使用 params... 进行参数传递 numbers := []int{1, 2, 3, 4, 5, 6, 7} // numbers... 语法只对slice和string使用。 list(numbers...) // []int{1, 2, 3, 4, 5, 6, 7} []int fmt.Println(numbers) // [2 2 3 4 5 6 7] // Output: // []int{1, 2, 3, 4, 5, 6} []int // []int{1, 2, 3, 4, 5, 6, 7} []int // [2 2 3 4 5 6 7] } // 变长参数，参数不定长 func list(nums ...int) { if nums == nil { painc(\u0026#34;切片未初始化 nil\u0026#34;) } fmt.Printf(\u0026#34;%#v %T\\n\u0026#34;, nums, nums) nums[0] += 1 } 内置函数 内置函数是预先声明的，它们像任何其他函数一样被调用。 内置函数没有标准的类型，因此只能出现在调用表达式中，不能用作函数值。 它们有时候可以针对不同的类型进行操作。 内置函数make()和new()都和内存分配相关，但也有差异。 内置函数 说明 make(T) make只用于slice、map以及channel这三种引用数据的内存分配和初始化，make(T)返回类型T的值（不是*T） new(T) new用于值类型的内存分配，并且置为零值，new(T)分配类型T的零值并返回其地址，也就是指向类型T的指针 内置函数make()用作于slice、map和channel三种数据类型时，参数及作用有些区别。 make 函数原型：func make(t Type, size ...IntegerType) Type new 函数原型：func new(Type) *Type T 的类型 参数 说明 slice make(T, n) T为切片类型，长度和容量都为n slice make(T, n, m) T为切片类型，长度n，容量m（n \u0026lt;=m，否则错误 ） map make(T) T为字典类型 map make(T, n) T为字典类型，分配n个元素的空间 channel make(T) T为通道类型，无缓冲区 channel make(T, n) T为通道类型，缓冲区容量为n 内置函数make()的实际使用举例 1 2 3 4 5 6 s := make([]int, 10, 100) // 切片，len(s) == 10, cap(s) == 100 s := make([]int, 1e3) // 切片，len(s) == cap(s) == 1000 s := make([]int, 1 \u0026lt;\u0026lt; 63) // 非法，int类型的大小*len(s) 以造成内存不足，所以导致非法 int*cap(s)如果溢出也是一样的 s := make([]int, 10, 0) // 非法，len(s) \u0026gt; cap(s) c := make(chan int, 10) // 通道缓冲区有10个元素 m := make(map[string]int, 100) // map的初始空间有大约100个元素 new(T) 内置函数在运行时为该类型的变量分配内存，返回指向它的类型 *T 的值，并对变量初始化 1 2 3 4 5 type S struct { a int b float64 } new(S) // \u0026amp;S{0,0.0} new(S) 为S类型的变量分配内存，并初始化（a = 0, b = 0.0），返回包含该位置地址的类型 *S 的值。 slice、map和channel这三种数据类型声明时，可设置长度或容量，所以通过内置函数len()和cap()得到对应长度与容量。 len 函数原型：func len(v Type) int cap 函数原型：func cap(v Type) int 内置函数 参数s的类型 结果说明 len(s) string string类型s的长度（按照字节计算） len(s) [n]T，*[n]T 数组类型s的长度（[n]T、[n]*T、*[n]T）数组指针*[n]T支持语法糖 len(s) []T 切片类型s的长度 len(s) map[K]T 字典类型s的长度 len(s) chan T 通道类型s的缓冲区排队的元素数量 cap(s) []T 切片类型s的容量 cap(s) chan T 通道类型s的缓冲区容量 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;fmt\u0026#34; func main() { var a = new([2]int) // *[2]int // len(a) 语法糖 fmt.Printf(\u0026#34;%#v %T %d\u0026#34;, a, a, len(a)) // Output: // \u0026amp;[2]int{0, 0} *[2]int 2 } 对于len(s)和cap(s)，如果s为nil值，则两个函数的取值都是0，此外： 1 0 \u0026lt;= len(s) \u0026lt;= cap(s) Go语言中，常量在某些计算条件下也可以通过表达式计算得到。 假如s是字符串常量，则表达式len(s)是常量。 如s的类型是数组或指向数组的指针而表达式不包含通道接收或（非常量）函数调用，则表达式len(s)和cap(s)是常量，否则len和cap的调用不是常量。 1 2 3 4 5 6 7 8 9 const ( c1 = imag(2i) // 2.0 imag(2i) == 2.0 是常量 c2 = len([10]float64{2}) // 10 [10]float64{2} 无函数调用 c3 = len([10]float64{c1}) // 10 [10]float64{c1} 无函数调用 c4 = len([10]float64{imag(2i)}) // 10 imag(2i)常量无函数调用 c5 = len([10]float64{imag(z)}) // 无效 imag(z) 非常量函数调用 ) var z complex128 递归与回调 递归函数：函数直接或间接调用函数本身。使用递归函数时经常会遇到栈溢出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func main() { var i uint64 = 7 fmt.Printf(\u0026#34;%d 的阶乘是 %d\\n\u0026#34;, i, Factorial(i)) // 7 的阶乘是 5040 fmt.Printf(\u0026#34;%d 的阶乘是 %d\\n\u0026#34;, i, Fac2(i)) // 7 的阶乘是 5040 // Output: // 7 的阶乘是 5040 // 7 的阶乘是 5040 } // Factorial 函数递归调用 n! = n*(n-1)...*1 func Factorial(n uint64) (result uint64) { if n \u0026gt; 0 { result = n * Factorial(n - 1) return result } return 1 } // Fac2 循环形式实现 n! = n*(n-1)...*1 func Fac2(n uint64) (result uint64) { result = 1 var un uint64 = 1 for i := un; i \u0026lt;= n; i++ { result *= i } return } Go语言中也可以使用相互调用的递归函数，多个函数之间相互调用形成闭环。 回调：Go语言函数可以作为其他函数的参数进行传递，然后在其他函数内调用执行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 func main() { callback(1, Add) // Output: // 1 + 2 = 3 } func Add(a, b int) { fmt.Printf(\u0026#34;%d + %d = %d\u0026#34;, a, b, a + b) // 1 + 2 = 3 } func callback(y int, f func(int, int)) { f(y, 2) // 回调函数f } 匿名函数 匿名函数：函数值字面量是一种表达式。不给函数起名字的时候，可以使用匿名函数。 这样的函数不能独立存在，但是可以被赋值于某个变量，即保存函数的地址到变量中。 1 2 3 4 5 6 fplus := func(x, y int) int { return x + y } // 然后通过变量名对函数进行调用 fplus(3, 4) 当然，也可以直接对匿名函数进行调用。注意匿名函数的最后加上括号并填入参数值，如果没有参数，也需要加上括号，代表直接调用。 1 2 3 func(x, y int) int { return x + y }(3, 4) 计算0 ~ 100万整数的总和的匿名函数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func main() { fn := func() { fmt.Println(\u0026#34;hello\u0026#34;) } fn() fmt.Println(\u0026#34;匿名函数加法求集：\u0026#34;, func(x, y int) int {return x + y}(3,4)) func() { sum := 0 for i := 1; i \u0026lt;= 1e6; i++ { sum += i } fmt.Println(\u0026#34;匿名函数加法循环求和：\u0026#34;, sum) }() // Output: // hello // 匿名函数加法求集： 7 // 匿名函数加法循环求和： 500000500000 } 变参函数 可变参数就是不定长参数，支持可变参数列表的函数可以支持任意个传入参数。如：fmt.Println 函数就是一个支持可变长参数列表的函数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package main import \u0026#34;fmt\u0026#34; func main() { s := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} // 注意这里的切片 s... 把切片打撒传入，与s具有相同底层数组的值 Greeting(s...) fmt.Println(s) // Output: // 0 hello // 1 world // [hello 123456] } // 这里的who参数其实就是切片[]string类型，也就是所谓的可变参数 func Greeting(who ...string){ for k, v := range who{ fmt.Println(k, v) } who[1] = \u0026#34;123456\u0026#34; } ","permalink":"https://heliu.site/posts/golang/func/use/","summary":"Golang 函数使用介绍。","title":"函数使用"},{"content":" CPU在执行程序时，IP寄存器会指向下一条即将被执行的指令，而SP寄存器会指向栈顶。 CALL指令会先把下一条指令的地址压入栈中，这就是所谓的返回地址。然后跳转到被调用函数去执行。当被调用函数执行完成后会返回到CALL指令压栈的返回地址继续执行。由于CALL指令引发了入栈和指令跳转，所以SP和IP寄存器的值都发生了改变。 RET指令会从栈上弹出返回地址，然后跳转到该地址处继续执行。 栈帧布局 编译器生成的指令负责栈帧的而分配与释放。栈帧的布局也是由编译器在编译阶段确定的，其依据就是函数代码，所以也可以说函数栈帧是由编译器管理的。\n参照函数栈帧布局图，函数栈帧包含以下几部分：\nreturn address：函数返回地址，占用一个指针大小空间。实际上是在函数被调用时由CALL指令自动压栈的，并非由被调用函数分配。 caller's BP：调用者的栈帧基址，占用一个指针大小空间。用来将调用路径上所有的栈帧连成一个链表，方便栈回溯，只在部分平台架构上存在。函数通过将栈指针SP直接向下移动指定大小，一次性分配caller's BP、locals和args to callee所占用的空间，在x86架构上就是使用SUB指令将SP减去指定大小的。 locals：局部变量区间，占用若干机器字节。用来存放函数的局部变量，根据函数的局部变量占用空间大小来分配，没有局部变量的函数不分配。 args to callee：调用传参区域，占用若干机器字节。这一区域所占空间大小，会按照当前函数调用的所有函数中返回值加上参数所占用的空间来分配。当没有调用任何函数时，不需要分配该区间。 综上，只有 return address 是一定存在的，其他三个区间都要根据实际情况分析。 按照一般代码的逻辑，函数的栈帧应该包含返回值、参数、返回地址和局部变量这四部分。 传参 交换两个变量的值(值传递)。 1 2 3 4 5 6 7 8 9 10 11 package main func main() { a,b := 1,2 swap(a,b) } //go:noinline func swap(a,b int) { a,b = b,a } 相关汇编代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP # 比较栈是否溢出 0x4551e4 7639 JBE 0x45521f 0x4551e6 4883ec28 SUBQ $0x28, SP # main.main函数预分配栈帧大小 0x4551ea 48896c2420 MOVQ BP, 0x20(SP) # 存储被调用函数runtime.main的BP 0x4551ef 488d6c2420 LEAQ 0x20(SP), BP # 调整当前main.main的BP a,b := 1,2 0x4551f4 48c744241801000000 MOVQ $0x1, 0x18(SP) # 变量a 0x4551fd 48c744241002000000 MOVQ $0x2, 0x10(SP) # 变量b swap(a,b) 0x455206 488b442418 MOVQ 0x18(SP), AX # main.swap的a参数 AX = a = 1 0x45520b bb02000000 MOVL $0x2, BX # main.swap的b参数 BX = 2 0x455210 e82b000000 CALL main.swap(SB) # 调用swap函数 } 0x455215 488b6c2420 MOVQ 0x20(SP), BP # 恢复runtime.main的BP 0x45521a 4883c428 ADDQ $0x28, SP # 调整栈 0x45521e c3 RET # 函数返回 ，弹出runtime.main的下一条IP地址，SP减8 func main() { 0x45521f 90 NOPL 0x455220 e83bcdffff CALL runtime.morestack_noctxt.abi0(SB) # 栈溢出时会跳转到这里来，从新分配栈空间 0x455225 ebb9 JMP main.main(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func swap(a,b int) { 0x455240 4883ec10 SUBQ $0x10, SP # 预分配栈大小 0x455244 48896c2408 MOVQ BP, 0x8(SP) # 存储main.main的BP 0x455249 488d6c2408 LEAQ 0x8(SP), BP # 调整BP寄存器 0x45524e 4889442418 MOVQ AX, 0x18(SP) # 把参数a放入栈上，在main.main的栈上 0x455253 48895c2420 MOVQ BX, 0x20(SP) # 把参数b放入栈上，在main.main的栈上 a,b = b,a 0x455258 48890424 MOVQ AX, 0(SP) # 把参数a得值临时放入(rsp) 0x45525c 488b442420 MOVQ 0x20(SP), AX # 把参数b的值放入 AX=2 0x455261 4889442418 MOVQ AX, 0x18(SP) # 把参数b的值和参数a交换a=2 0x455266 488b0424 MOVQ 0(SP), AX # 取出临时存放的a的值1 0x45526a 4889442420 MOVQ AX, 0x20(SP) # 把临时存放a的值复制给b=1 } 0x45526f 488b6c2408 MOVQ 0x8(SP), BP # 恢复main.main的BP 0x455274 4883c410 ADDQ $0x10, SP # 调整栈大小 0x455278 c3 RET # 函数返回 图片备注：图片+08处的runtime.main BP应该是main.main BP。\n交换两个变量的值(引用传递)。 1 2 3 4 5 6 7 8 9 10 11 package main func main() { a,b := 1,2 swap(\u0026amp;a,\u0026amp;b) } //go:noinline func swap(a,b *int) { *a,*b = *b,*a } 相关汇编代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7639 JBE 0x45521f 0x4551e6 4883ec28 SUBQ $0x28, SP 0x4551ea 48896c2420 MOVQ BP, 0x20(SP) 0x4551ef 488d6c2420 LEAQ 0x20(SP), BP a,b := 1,2 0x4551f4 48c744241801000000 MOVQ $0x1, 0x18(SP) 0x4551fd 48c744241002000000 MOVQ $0x2, 0x10(SP) swap(\u0026amp;a,\u0026amp;b) 0x455206 488d442418 LEAQ 0x18(SP), AX # AX=0x18(SP) -\u0026gt; 0x1 注意这里的0x18偏移量是变量a的地址 0x45520b 488d5c2410 LEAQ 0x10(SP), BX # BX=0x10(SP) -\u0026gt; 0x2 注意这里的0x10偏移量是变量a的地址 0x455210 e82b000000 CALL main.swap(SB) # 调用main.swap函数 } 0x455215 488b6c2420 MOVQ 0x20(SP), BP 0x45521a 4883c428 ADDQ $0x28, SP 0x45521e c3 RET func main() { 0x45521f 90 NOPL 0x455220 e83bcdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455225 ebb9 JMP main.main(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func swap(a,b *int) { 0x455240 4883ec10 SUBQ $0x10, SP 0x455244 48896c2408 MOVQ BP, 0x8(SP) 0x455249 488d6c2408 LEAQ 0x8(SP), BP 0x45524e 4889442418 MOVQ AX, 0x18(SP) 0x455253 48895c2420 MOVQ BX, 0x20(SP) *a,*b = *b,*a 0x455258 8400 TESTB AL, 0(AX) 0x45525a 488b00 MOVQ 0(AX), AX # 取AX=0x1 0x45525d 48890424 MOVQ AX, 0(SP) 0x455261 488b442418 MOVQ 0x18(SP), AX # AX=0x30(SP) 0x455266 8400 TESTB AL, 0(AX) 0x455268 488b4c2420 MOVQ 0x20(SP), CX # CX=0x28(SP) 0x45526d 8401 TESTB AL, 0(CX) 0x45526f 488b09 MOVQ 0(CX), CX # CX=0x2 0x455272 488908 MOVQ CX, 0(AX) # AX=0x30(SP) -\u0026gt; 0x2 0x455275 488b442420 MOVQ 0x20(SP), AX # AX=0x28(SP) 0x45527a 8400 TESTB AL, 0(AX) 0x45527c 488b0c24 MOVQ 0(SP), CX # CX=0x1 0x455280 488908 MOVQ CX, 0(AX) # AX=0x28(SP) -\u0026gt; 0x1 } 0x455283 488b6c2408 MOVQ 0x8(SP), BP 0x455288 4883c410 ADDQ $0x10, SP 0x45528c c3 RET 图片备注：图片+08处的runtime.main BP应该是main.main BP。\n交换两个变量的值(引用传递)。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main func main() { a,b := 1,2 swap(\u0026amp;a,\u0026amp;b) //println(a, b)\t// 1,2 } //go:noinline func swap(a,b *int) { // temp = a // a = b // b = temp // 变量a、b是函数内的局部变量， // 因此交换不会影响外部指针数据 a,b = b,a\t// 这种情况和第一种副本传参交换一致 //println(*a, *b)\t// 2,1 } 相关汇编代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7639 JBE 0x45521f 0x4551e6 4883ec28 SUBQ $0x28, SP 0x4551ea 48896c2420 MOVQ BP, 0x20(SP) 0x4551ef 488d6c2420 LEAQ 0x20(SP), BP a,b := 1,2 0x4551f4 48c744241801000000 MOVQ $0x1, 0x18(SP) # 变量a 0x4551fd 48c744241002000000 MOVQ $0x2, 0x10(SP) # 变量b swap(\u0026amp;a,\u0026amp;b) 0x455206 488d442418 LEAQ 0x18(SP), AX # 参数a 0x45520b 488d5c2410 LEAQ 0x10(SP), BX # 参数b 0x455210 e82b000000 CALL main.swap(SB) # 函数调用 } 0x455215 488b6c2420 MOVQ 0x20(SP), BP 0x45521a 4883c428 ADDQ $0x28, SP 0x45521e c3 RET func main() { 0x45521f 90 NOPL 0x455220 e83bcdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455225 ebb9 JMP main.main(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func swap(a,b *int) { 0x455240 4883ec10 SUBQ $0x10, SP 0x455244 48896c2408 MOVQ BP, 0x8(SP) 0x455249 488d6c2408 LEAQ 0x8(SP), BP 0x45524e 4889442418 MOVQ AX, 0x18(SP) 0x455253 48895c2420 MOVQ BX, 0x20(SP) a,b = b,a 0x455258 48890424 MOVQ AX, 0(SP) # AX寄存器参数a保存在临时容器里 0x45525c 488b442420 MOVQ 0x20(SP), AX # AX=0x28(SP) S.b 0x455261 4889442418 MOVQ AX, 0x18(SP) # 交换 0x455266 488b0424 MOVQ 0(SP), AX 0x45526a 4889442420 MOVQ AX, 0x20(SP) } 0x45526f 488b6c2408 MOVQ 0x8(SP), BP 0x455274 4883c410 ADDQ $0x10, SP 0x455278 c3 RET 图片备注：图片+08处的runtime.main BP应该是main.main BP。\n返回值 匿名返回值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main func main() { var a int = 1 b := incr(a) _ = b } //go:noinline func incr(a int) int { var b int = 2 // defer 闭包捕获的是incr局部变量 defer func() { a++ b++ }() a++ b = a return b // 由于b在incr栈空间创建defer影响不到 } 相关汇编代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main() { 0x4552a0 493b6610 CMPQ 0x10(R14), SP 0x4552a4 7630 JBE 0x4552d6 0x4552a6 4883ec20 SUBQ $0x20, SP 0x4552aa 48896c2418 MOVQ BP, 0x18(SP) 0x4552af 488d6c2418 LEAQ 0x18(SP), BP var a int = 1 0x4552b4 48c744241001000000 MOVQ $0x1, 0x10(SP) b := incr(a) 0x4552bd b801000000 MOVL $0x1, AX # AX=1 0x4552c2 e819000000 CALL main.incr(SB) 0x4552c7 4889442408 MOVQ AX, 0x8(SP) } 0x4552cc 488b6c2418 MOVQ 0x18(SP), BP 0x4552d1 4883c420 ADDQ $0x20, SP 0x4552d5 c3 RET func main() { 0x4552d6 e825cdffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552db ebc3 JMP main.main(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 func incr(a int) int { 0x4552e0 4c8d6424f8 LEAQ -0x8(SP), R12 0x4552e5 4d3b6610 CMPQ 0x10(R14), R12 0x4552e9 0f86d9000000 JBE 0x4553c8 0x4552ef 4881ec88000000 SUBQ $0x88, SP 0x4552f6 4889ac2480000000 MOVQ BP, 0x80(SP) 0x4552fe 488dac2480000000 LEAQ 0x80(SP), BP 0x455306 4889842490000000 MOVQ AX, 0x90(SP) 0x45530e 48c744240800000000 MOVQ $0x0, 0x8(SP) var b int = 2 0x455317 48c744241002000000 MOVQ $0x2, 0x10(SP) defer func() { 0x455320 48c744246800000000 MOVQ $0x0, 0x68(SP) 0x455329 440f117c2470 MOVUPS X15, 0x70(SP) 0x45532f 488d4c2468 LEAQ 0x68(SP), CX # CX=0x68(SP) 0x455334 48894c2460 MOVQ CX, 0x60(SP) 0x455339 8401 TESTB AL, 0(CX) 0x45533b 488d159e000000 LEAQ main.incr.func1(SB), DX # DX=main.incr.func1 0x455342 4889542468 MOVQ DX, 0x68(SP) 0x455347 8401 TESTB AL, 0(CX) 0x455349 488d942490000000 LEAQ 0x90(SP), DX # DX=0x90(SP) 0x455351 4889542470 MOVQ DX, 0x70(SP) 0x455356 8401 TESTB AL, 0(CX) 0x455358 488d542410 LEAQ 0x10(SP), DX # DX=0x10(SP) 0x45535d 4889542478 MOVQ DX, 0x78(SP) 0x455362 48894c2430 MOVQ CX, 0x30(SP) 0x455367 488d442418 LEAQ 0x18(SP), AX # AX=0x18(SP) 0x45536c e88f50fdff CALL runtime.deferprocStack(SB) # 注册defer链表 0x455371 85c0 TESTL AX, AX 0x455373 7539 JNE 0x4553ae 0x455375 eb00 JMP 0x455377 a++ 0x455377 488b842490000000 MOVQ 0x90(SP), AX # AX=1 0x45537f 48ffc0 INCQ AX # AX=2 0x455382 4889842490000000 MOVQ AX, 0x90(SP) b = a 0x45538a 4889442410 MOVQ AX, 0x10(SP) return b // 由于b在incr栈空间创建defer影响不到 0x45538f 4889442408 MOVQ AX, 0x8(SP) # return先把值复制给I.o然后在去defer的 0x455394 e88756fdff CALL runtime.deferreturn(SB) # 执行defer，defer捕获的是a和b与I.o无关 0x455399 488b442408 MOVQ 0x8(SP), AX # defer完之后在从I.o取值到AX 0x45539e 488bac2480000000 MOVQ 0x80(SP), BP 0x4553a6 4881c488000000 ADDQ $0x88, SP 0x4553ad c3 RET defer func() { 0x4553ae e86d56fdff CALL runtime.deferreturn(SB) 0x4553b3 488b442408 MOVQ 0x8(SP), AX 0x4553b8 488bac2480000000 MOVQ 0x80(SP), BP 0x4553c0 4881c488000000 ADDQ $0x88, SP 0x4553c7 c3 RET func incr(a int) int { 0x4553c8 4889442408 MOVQ AX, 0x8(SP) 0x4553cd e82eccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4553d2 488b442408 MOVQ 0x8(SP), AX 0x4553d7 e904ffffff JMP main.incr(SB) 图片备注：图片+80处的runtime.main BP应该是main.main BP。\n实名返回值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main func main() { var a int = 1 b := incr(a) _ = b } //go:noinline func incr(a int) (b int) { // defer 闭包捕获的是incr局部变量 defer func() { a++ b++ }() a++ b = a return b // 由于b在incr栈空间创建defer影响不到 } 相关汇编代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main() { 0x4552a0 493b6610 CMPQ 0x10(R14), SP 0x4552a4 7630 JBE 0x4552d6 0x4552a6 4883ec20 SUBQ $0x20, SP 0x4552aa 48896c2418 MOVQ BP, 0x18(SP) 0x4552af 488d6c2418 LEAQ 0x18(SP), BP var a int = 1 0x4552b4 48c744241001000000 MOVQ $0x1, 0x10(SP) b := incr(a) 0x4552bd b801000000 MOVL $0x1, AX # AX=1 0x4552c2 e819000000 CALL main.incr(SB) 0x4552c7 4889442408 MOVQ AX, 0x8(SP) } 0x4552cc 488b6c2418 MOVQ 0x18(SP), BP 0x4552d1 4883c420 ADDQ $0x20, SP 0x4552d5 c3 RET func main() { 0x4552d6 e825cdffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552db ebc3 JMP main.main(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 func incr(a int) (b int) { 0x4552e0 493b6610 CMPQ 0x10(R14), SP 0x4552e4 0f86b8000000 JBE 0x4553a2 0x4552ea 4883c480 ADDQ $-0x80, SP 0x4552ee 48896c2478 MOVQ BP, 0x78(SP) 0x4552f3 488d6c2478 LEAQ 0x78(SP), BP 0x4552f8 4889842488000000 MOVQ AX, 0x88(SP) 0x455300 48c744240800000000 MOVQ $0x0, 0x8(SP) defer func() { 0x455309 48c744246000000000 MOVQ $0x0, 0x60(SP) 0x455312 440f117c2468 MOVUPS X15, 0x68(SP) # 清空0x68(SP)后16B 0x455318 488d4c2460 LEAQ 0x60(SP), CX # CX=0x60(SP) 0x45531d 48894c2458 MOVQ CX, 0x58(SP) 0x455322 8401 TESTB AL, 0(CX) 0x455324 488d1595000000 LEAQ main.incr.func1(SB), DX # DX=main.incr.func1 0x45532b 4889542460 MOVQ DX, 0x60(SP) 0x455330 8401 TESTB AL, 0(CX) 0x455332 488d942488000000 LEAQ 0x88(SP), DX # DX=0x88(SP) 0x45533a 4889542468 MOVQ DX, 0x68(SP) 0x45533f 8401 TESTB AL, 0(CX) 0x455341 488d542408 LEAQ 0x8(SP), DX # DX=0x8(SP) 0x455346 4889542470 MOVQ DX, 0x70(SP) 0x45534b 48894c2428 MOVQ CX, 0x28(SP) 0x455350 488d442410 LEAQ 0x10(SP), AX # AX=0x10(SP)，defer结构体起始地址 0x455355 e8a650fdff CALL runtime.deferprocStack(SB) # 注册defer 0x45535a 85c0 TESTL AX, AX 0x45535c 7530 JNE 0x45538e 0x45535e 6690 NOPW 0x455360 eb00 JMP 0x455362 a++ 0x455362 488b842488000000 MOVQ 0x88(SP), AX # AX=1 0x45536a 48ffc0 INCQ AX # AX=2 0x45536d 4889842488000000 MOVQ AX, 0x88(SP) b = a 0x455375 4889442408 MOVQ AX, 0x8(SP) return b // 由于b在incr栈空间创建defer影响不到 0x45537a e8a156fdff CALL runtime.deferreturn(SB) # 执行defer链表 0x45537f 488b442408 MOVQ 0x8(SP), AX # 从I.o中取出返回值放入AX 0x455384 488b6c2478 MOVQ 0x78(SP), BP 0x455389 4883ec80 SUBQ $-0x80, SP 0x45538d c3 RET defer func() { 0x45538e e88d56fdff CALL runtime.deferreturn(SB) 0x455393 488b442408 MOVQ 0x8(SP), AX 0x455398 488b6c2478 MOVQ 0x78(SP), BP 0x45539d 4883ec80 SUBQ $-0x80, SP 0x4553a1 c3 RET func incr(a int) (b int) { 0x4553a2 4889442408 MOVQ AX, 0x8(SP) 0x4553a7 e854ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4553ac 488b442408 MOVQ 0x8(SP), AX 0x4553b1 e92affffff JMP main.incr(SB) 图片备注：图片+78处的runtime.main BP应该是main.main BP。\n寻址方式 如果把整个函数栈帧视为一个struct，SP存储着这个struct的起始地址，然后就可以通过【基址+位移】的方式来寻址struct的各个字段，也就是栈帧上的局部变量、参数和返回值。 在Go汇编中，寄存器的名字没有位数之分，比如AX寄存器没有什么RAX、EAX之类的名字，指令中一律只能使用AX。所以如果指令中有操作的寄存器或是指令需要访问内存，则操作码都需要带上后缀 B(8位)、W(16位)、D(32位)、Q(64位)。 Go 语言中函数的返回值可以是匿名的，也可以是命名的。 对于匿名返回值而言，只能通过return语句为返回值赋值。 对于命名返回值，可以在代码中通过其名称直接操作，与参数和局部变量类似。 调用约定 在进行函数调用的时候，调用者需要把参数传递给被调用者，而被调用者也要把返回值回传给调用者。 调用约定就是用来规范参数和返回值的传递问题的。如果基于栈传递还会规定栈空间由谁负责分配、释放。 调用约定： 返回值和参数都通过栈传递，对应的栈空间由调用者负责分配和释放。 返回值和参数在栈上的布局等价于两个struct，struct的起始地址按照平台机器字节长度对齐。 寄存器传参 Go在1.17版本前都是采用的栈的形式传递参数和返回值。这样实现简单且能支持海量的参数传递，缺点就是与寄存器传参相比性能方面会差一些。 在1.17版本后Go采用了寄存器传参，当然只是在部分硬件架构上实现了。即使有16个通用寄存器的amd64架构，可用于传参的寄存器也是有上限的，参数太多时还是有一部分通过栈传递。 Go采用AX、BX、CX、DI、SI、R8、R9、R10、R11这9个寄存器依顺序传递参数或返回值，多有的参数或返回值则时通过栈传递的方式。 总体来讲，使用9个通用寄存器传递参数进行优化，最多只能传递9个机器字节大小，而不是9个参数或返回值。像string会占用两个机器字节，slice则会占用三个机器字节。 参考 https://mp.weixin.qq.com/s/zcqzarXMJrDUY5DLXZXY1Q ","permalink":"https://heliu.site/posts/golang/func/stack/","summary":"函数调用栈介绍。","title":"函数调用栈"},{"content":"内存对齐 在C语言函数调用中，通过栈传递的参数需要对齐到平台的位宽。 假如通过栈传递4个char类型的参数，GCC生成的 32 位程序需要 16 字节空间，64 位程序需要 32 字节栈空间。 如果传递大量参数，则这种对齐方式会存在很大的栈空间浪费。 Go语言函数栈帧中返回值和参数的对齐方式与 struct 类似，对于有返回值和参数的函数，可以把所有返回值和所有参数等价成两个 struct： 一个【返回值 struct】 和一个【参数 struct】。 因为内存对齐方式更加紧凑，所以在支持大量参数和返回值时能够做到较高的栈空间利用率。 通过如下示例可以验证函数参数和返回值的对齐方式与 struct 成员的对齐方式是一致的，代码如下： 以上的描述都是在函数通过栈传递参数和返回值的基础上的。在go1.18后版本中采用了寄存器传参。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main type args struct { a int8 // 1 b int64 // 8 c int32 // 4 d int16 // 2 } //go:noinline func f1(a args) (r args) { println(\u0026amp;r.d, \u0026amp;r.c, \u0026amp;r.b, \u0026amp;r.a, \u0026amp;a.d, \u0026amp;a.c, \u0026amp;a.b, \u0026amp;a.a) return } //go:noinline func f2(aa int8, ab int64, ac int32, ad int16) (ra int8, rb int64, rc int32, rd int16) { println(\u0026amp;rd, \u0026amp;rc, \u0026amp;rb, \u0026amp;ra, \u0026amp;ad, \u0026amp;ac, \u0026amp;ab, \u0026amp;aa) return } func main() { f1(args{}) // 0xc000034744 r.d // 0xc000034740 r.c // 0xc000034738 r.b // 0xc000034730 r.a // 0xc00003476c a.d // 0xc000034768 a.c // 0xc000034760 a.b // 0xc000034758 a.a f2(0, 0, 0, 0) // 0xc00003473a rd // 0xc00003473c rc // 0xc000034740 rb // 0xc000034739 ra // 0xc00003476c ad // 0xc000034768 ac // 0xc000034760 ab // 0xc000034758 aa } 汇编代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 TEXT main.main(SB) /mnt/hgfs/workspace/helium/main.go func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7657 JBE 0x45523d 0x4551e6 4883ec38 SUBQ $0x38, SP 0x4551ea 48896c2430 MOVQ BP, 0x30(SP) 0x4551ef 488d6c2430 LEAQ 0x30(SP), BP f1(args{}) 0x4551f4 c644241800 MOVB $0x0, 0x18(SP) # a.a 0x4551f9 48c744242000000000 MOVQ $0x0, 0x20(SP) # a.b 0x455202 c744242800000000 MOVL $0x0, 0x28(SP) # a.c 0x45520a 66c744242c0000 MOVW $0x0, 0x2c(SP) # a.d 0x455211 0fb6442418 MOVZX 0x18(SP), AX # a.a AX 0x455216 488b5c2420 MOVQ 0x20(SP), BX # a.b BX 0x45521b 8b4c2428 MOVL 0x28(SP), CX # a.c CX 0x45521f 31ff XORL DI, DI # a.d DI 0x455221 e83a000000 CALL main.f1(SB) f2(0, 0, 0, 0) 0x455226 31c0 XORL AX, AX # aa AX 0x455228 31db XORL BX, BX # ab BX 0x45522a 31c9 XORL CX, CX # ac CX 0x45522c 31ff XORL DI, DI # ad DI 0x45522e e8ad010000 CALL main.f2(SB) } 0x455233 488b6c2430 MOVQ 0x30(SP), BP 0x455238 4883c438 ADDQ $0x38, SP 0x45523c c3 RET func main() { 0x45523d 0f1f00 NOPL 0(AX) 0x455240 e81bcdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455245 eb99 JMP main.main(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 TEXT main.f1(SB) /mnt/hgfs/workspace/helium/main.go func f1(a args) (r args) { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 0f8642010000 JBE 0x45532c 0x4551ea 4883ec68 SUBQ $0x68, SP 0x4551ee 48896c2460 MOVQ BP, 0x60(SP) 0x4551f3 488d6c2460 LEAQ 0x60(SP), BP # 参数分配栈大小空间 0x4551f8 88442470 MOVB AL, 0x70(SP) # a.a 0x4551fc 48895c2478 MOVQ BX, 0x78(SP) # a.b 0x455201 898c2480000000 MOVL CX, 0x80(SP) # a.c 0x455208 6689bc2484000000 MOVW DI, 0x84(SP) # a.d # 返回值分配栈大小空间 0x455210 c644240800 MOVB $0x0, 0x8(SP) # r.a 0x455215 48c744241000000000 MOVQ $0x0, 0x10(SP) # r.b 0x45521e c744241800000000 MOVL $0x0, 0x18(SP) # r.c 0x455226 66c744241c0000 MOVW $0x0, 0x1c(SP) # r.d println(\u0026amp;r.d, \u0026amp;r.c, \u0026amp;r.b, \u0026amp;r.a, \u0026amp;a.d, \u0026amp;a.c, \u0026amp;a.b, \u0026amp;a.a) ... ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 TEXT main.f2(SB) /mnt/hgfs/workspace/helium/main.go func f2(aa int8, ab int64, ac int32, ad int16) (ra int8, rb int64, rc int32, rd int16) { 0x455360 493b6610 CMPQ 0x10(R14), SP 0x455364 0f8631010000 JBE 0x45549b 0x45536a 4883ec60 SUBQ $0x60, SP 0x45536e 48896c2458 MOVQ BP, 0x58(SP) 0x455373 488d6c2458 LEAQ 0x58(SP), BP # 参数传参，使用寄存器，但是参数空间还是没有优化 0x455378 88442468 MOVB AL, 0x68(SP) # aa 0x45537c 48895c2470 MOVQ BX, 0x70(SP) # ab 0x455381 894c2478 MOVL CX, 0x78(SP) # ac 0x455385 66897c247c MOVW DI, 0x7c(SP) # ad # 返回值分配栈大小空间 0x45538a c644240900 MOVB $0x0, 0x9(SP) # ra 0x45538f 48c744241000000000 MOVQ $0x0, 0x10(SP) # rb 0x455398 c744240c00000000 MOVL $0x0, 0xc(SP) # rc 0x4553a0 66c744240a0000 MOVW $0x0, 0xa(SP) # rd println(\u0026amp;rd, \u0026amp;rc, \u0026amp;rb, \u0026amp;ra, \u0026amp;ad, \u0026amp;ac, \u0026amp;ab, \u0026amp;aa) ... ... 逃逸分析 什么是逃逸分析 局部变量地址作为返回值(1) 在解释逃逸分析之前，先来思考一个场景，如果一个函数把自已栈帧上某个局部变量的地址作为返回值返回。 会有什么问题？示例代码如下： 1 2 3 4 5 6 7 8 9 10 11 package main func main() { println(*newInt()) } //go:noinline func newInt() *int { var a int return \u0026amp;a } 前面对函数栈布局的讲解 newInt() 函数的局部变量a应该分配在函数栈的 locals 区间。 在newInt()函数返回后，它的栈随即销毁，返回的变量a的地址就会变成一个悬挂指针，caller 中对该地址进行的所有读写都是不合法的，会造成程序逻辑错误甚至崩溃。 事实是这样的吗？上述分析有个前提条件，即变量 a 被分配在栈上。假如编译器能够检测到这种模式，而自动把变量 a 改为堆分配，就不存在上述问题了。 反编译 newInt() 函数，看一下结果，代码如下： 重点关注上述汇编代码中 runtime.newobject() 函数调用，该函数是 Go 语言内置函数 new() 的具体实现，用来在运行阶段分配单个对象。 CALL 指令 AX 寄存器就是 *int 类型，也是返回的值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 TEXT main.newInt(SB) /mnt/hgfs/workspace/helium/main.go func newInt() *int { 0x455240 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455244 7643 JBE 0x455289 0x455246 4883ec28 SUBQ $0x28, SP 0x45524a 48896c2420 MOVQ BP, 0x20(SP) 0x45524f 488d6c2420 LEAQ 0x20(SP), BP 0x455254 48c744241000000000 MOVQ $0x0, 0x10(SP) # *int 临时返回值空间 var a int 0x45525d 488d05bc4a0000 LEAQ 0x4abc(IP), AX # type.int 元类型 # func newobject(typ *_type) unsafe.Pointer # 这里调用 newobject 函数进行了堆分配 0x455264 e8d75cfbff CALL runtime.newobject(SB) # AX=*int 类型 0x455269 4889442418 MOVQ AX, 0x18(SP) 0x45526e 48c70000000000 MOVQ $0x0, 0(AX) # *a=0 return \u0026amp;a 0x455275 488b442418 MOVQ 0x18(SP), AX 0x45527a 4889442410 MOVQ AX, 0x10(SP) # 返回值 AX 0x45527f 488b6c2420 MOVQ 0x20(SP), BP 0x455284 4883c428 ADDQ $0x28, SP 0x455288 c3 RET func newInt() *int { 0x455289 e8d2ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x45528e ebb0 JMP main.newInt(SB) 局部变量地址作为返回值(2) 如果把 newInt() 函数中的取地址运算改成使用内置函数 new()，效果也是一样的，代码如下： 1 2 3 4 //go:noinline func newInt() *int { return new(int) } 相关汇编： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 $ go build -gcflags=\u0026#34;-N -l\u0026#34; -o ./h1 myzx.cn/helium $ go tool objdump -S -s \u0026#39;^main.newInt$\u0026#39; ./h1 TEXT main.newInt(SB) /mnt/hgfs/workspace/helium/main.go func newInt() *int { 0x455240 493b6610 CMPQ 0x10(R14), SP 0x455244 7637 JBE 0x45527d 0x455246 4883ec28 SUBQ $0x28, SP 0x45524a 48896c2420 MOVQ BP, 0x20(SP) 0x45524f 488d6c2420 LEAQ 0x20(SP), BP 0x455254 48c744241000000000 MOVQ $0x0, 0x10(SP) # *int 返回值空间 return new(int) # func newobject(typ *_type) unsafe.Pointer 0x45525d 488d05bc4a0000 LEAQ 0x4abc(IP), AX # type.int 元类型 0x455264 e8d75cfbff CALL runtime.newobject(SB) # AX=*int 0x455269 4889442418 MOVQ AX, 0x18(SP) 0x45526e 4889442410 MOVQ AX, 0x10(SP) 0x455273 488b6c2420 MOVQ 0x20(SP), BP 0x455278 4883c428 ADDQ $0x28, SP 0x45527c c3 RET func newInt() *int { 0x45527d 0f1f00 NOPL 0(AX) 0x455280 e8dbccffff CALL runtime.morestack_noctxt.abi0(SB) 0x455285 ebb9 JMP main.newInt(SB) 当函数局部变量的生命周期超过函数栈的生命周期时，编译器把该局部变量由栈分配改为堆分配，即变量从栈上逃逸到堆上。 不逃逸分析 只要使用了new()函数就会造成堆分配?\n前面逃逸分析代码示例中将函数的某个局部变量的地址作为返回值返回，或者通过内置函数 new() 动态分配变量并返回其地址。 其中内置函数new()有着非常明显的堆分配的含义，是不是只要使用了new()函数就会造成堆分配呢？ 进一步猜想，如果对局部变量进行取地址操作会被转换为new()函数调用，那就不会进行所谓的逃逸分析了。 先验证new()函数与堆分配是否有必然关系，代码如下： 1 2 3 4 5 //go:noinline func New() int { p := new(int) return *p } 反编译new()函数，得到的汇编代码如下： 即便代码中使用了new()函数，只要变量的生命周期没有超过过当前函数栈的生命周期，编译器就不会进行堆分配。 事实上，只要代码逻辑允许，编译器总是倾向于把变量分配在栈上，因为比配在堆上更高效。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 TEXT main.New(SB) /mnt/hgfs/workspace/helium/main.go func New() int { 0x455240 4883ec20 SUBQ $0x20, SP 0x455244 48896c2418 MOVQ BP, 0x18(SP) 0x455249 488d6c2418 LEAQ 0x18(SP), BP 0x45524e 48c7042400000000 MOVQ $0x0, 0(SP) # 返回地址 int p := new(int) # new 函数直接是在栈上分配的 0x455256 48c744240800000000 MOVQ $0x0, 0x8(SP) # 0x8(SP) 用作int类型存储 0 0x45525f 488d4c2408 LEAQ 0x8(SP), CX # CX=0x8(SP); 也就是 *int 0x455264 48894c2410 MOVQ CX, 0x10(SP) # 0x10(SP); *int return *p 0x455269 8401 TESTB AL, 0(CX) 0x45526b 488b442408 MOVQ 0x8(SP), AX 0x455270 48890424 MOVQ AX, 0(SP) 0x455274 488b6c2418 MOVQ 0x18(SP), BP 0x455279 4883c420 ADDQ $0x20, SP 0x45527d c3 RET 这也就是本节所谓的不逃逸分析，或者说未逃逸分析，这种说法并不严谨，主要是为了突出编译器倾向于让变量不逃逸。 不逃逸判断 包级别指针(1) 本节主要探索编译器进行逃逸分析时追踪的范围，以及在什么情况下就认为变量逃逸了或者确定变量没有逃逸。 前面研究变量逃逸所有的方法，主要通过让函数返回局部变量的地址，使局部变量的生命周期超过对应函数栈帧的生命周期。 按照这个规则来猜想，如果把局部变量的地址赋值给包级别的指针变量，应该也会造成变量逃逸。 准备一个示例，代码如下： 1 2 3 4 5 6 7 var pt *int //go:noinline func setNew() { var a int pt = \u0026amp;a } 反编译 setNew() 函数，代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 TEXT main.setNew(SB) /mnt/hgfs/workspace/helium/main.go func setNew() { 0x455220 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455224 765d JBE 0x455283 0x455226 4883ec20 SUBQ $0x20, SP 0x45522a 48896c2418 MOVQ BP, 0x18(SP) 0x45522f 488d6c2418 LEAQ 0x18(SP), BP var a int 0x455234 488d05e54a0000 LEAQ 0x4ae5(IP), AX # type.int 元类型 0x45523b 0f1f440000 NOPL 0(AX)(AX*1) # func newobject(typ *_type) unsafe.Pointer # 这里直接调用了 newobject 堆分配了 int 0x455240 e8fb5cfbff CALL runtime.newobject(SB) # *int 0x455245 4889442410 MOVQ AX, 0x10(SP) 0x45524a 48c70000000000 MOVQ $0x0, 0(AX) # a = 0 pt = \u0026amp;a 0x455251 488b4c2410 MOVQ 0x10(SP), CX # CX=0x10(SP)=*int # 判断是否开启写屏障，因为可能在GC阶段，变量的赋值需要写屏障 0x455256 833d0320090000 CMPL $0x0, runtime.writeBarrier(SB) 0x45525d 7403 JE 0x455262 0x45525f 90 NOPL 0x455260 eb09 JMP 0x45526b 0x455262 48890db7320600 MOVQ CX, main.pt(SB) # 给全局变量 pt 赋值 0x455269 eb0e JMP 0x455279 0x45526b 488d3dae320600 LEAQ main.pt(SB), DI # 写屏障开启的时候调用写屏障相关函数，记录指针的变更，已帮助GC 0x455272 e8a9d0ffff CALL runtime.gcWriteBarrierCX(SB) 0x455277 eb00 JMP 0x455279 } 0x455279 488b6c2418 MOVQ 0x18(SP), BP 0x45527e 4883c420 ADDQ $0x20, SP 0x455282 c3 RET func setNew() { 0x455283 e8d8ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x455288 eb96 JMP main.setNew(SB) 通过 runtime.newobject() 函数调用就能确定，变量a逃逸到了堆上，验证了上述猜想。 包级别指针(2) 进一步还可以验证逃逸分析的依赖传递性，准备示例代码如下： 1 2 3 4 5 6 7 8 9 var pp **int //go:noinline func dep() { var a int var p *int p = \u0026amp;a pp = \u0026amp;p } 反编译 dep() 函数： 可以发现，变量 p 和 a 都逃逸了。 p 的地址被赋值给包级别的指针变量 pp，而 a 的地址又被赋值给了 p，因为 p 逃逸造成 a 也逃逸了。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 TEXT main.dep(SB) /mnt/hgfs/workspace/helium/main.go func dep() { 0x455220 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455224 0f86b0000000 JBE 0x4552da 0x45522a 4883ec28 SUBQ $0x28, SP 0x45522e 48896c2420 MOVQ BP, 0x20(SP) 0x455233 488d6c2420 LEAQ 0x20(SP), BP var a int 0x455238 488d05e14a0000 LEAQ 0x4ae1(IP), AX # type.int 元类型; 0x45523f 90 NOPL # func newobject(typ *_type) unsafe.Pointer 0x455240 e8fb5cfbff CALL runtime.newobject(SB) # 堆分配了 a 变量; AX *int 0x455245 4889442418 MOVQ AX, 0x18(SP) # 0x18(SP); 是a的内存空间，指向堆分配数据 0x45524a 48c70000000000 MOVQ $0x0, 0(AX) # 初始化 0 var p *int 0x455251 488d0508320000 LEAQ 0x3208(IP), AX # type *int 元类型 # func newobject(typ *_type) unsafe.Pointer 0x455258 e8e35cfbff CALL runtime.newobject(SB) # **int 0x45525d 4889442410 MOVQ AX, 0x10(SP) 0x455262 833df71f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x455269 7402 JE 0x45526d 0x45526b eb09 JMP 0x455276 0x45526d 48c70000000000 MOVQ $0x0, 0(AX) 0x455274 eb11 JMP 0x455287 0x455276 4889c7 MOVQ AX, DI 0x455279 31c0 XORL AX, AX 0x45527b 0f1f440000 NOPL 0(AX)(AX*1) 0x455280 e89bcfffff CALL runtime.gcWriteBarrier(SB) 0x455285 eb00 JMP 0x455287 p = \u0026amp;a 0x455287 488b7c2410 MOVQ 0x10(SP), DI 0x45528c 488b442418 MOVQ 0x18(SP), AX 0x455291 833dc81f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x455298 7402 JE 0x45529c 0x45529a eb06 JMP 0x4552a2 0x45529c 488907 MOVQ AX, 0(DI) 0x45529f 90 NOPL 0x4552a0 eb07 JMP 0x4552a9 0x4552a2 e879cfffff CALL runtime.gcWriteBarrier(SB) 0x4552a7 eb00 JMP 0x4552a9 pp = \u0026amp;p 0x4552a9 488b442410 MOVQ 0x10(SP), AX 0x4552ae 833dab1f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x4552b5 7402 JE 0x4552b9 0x4552b7 eb09 JMP 0x4552c2 0x4552b9 48890560320600 MOVQ AX, main.pp(SB) 0x4552c0 eb0e JMP 0x4552d0 0x4552c2 488d3d57320600 LEAQ main.pp(SB), DI 0x4552c9 e852cfffff CALL runtime.gcWriteBarrier(SB) 0x4552ce eb00 JMP 0x4552d0 } 0x4552d0 488b6c2420 MOVQ 0x20(SP), BP 0x4552d5 4883c428 ADDQ $0x28, SP 0x4552d9 c3 RET func dep() { 0x4552da e881ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552df 90 NOPL 0x4552e0 e93bffffff JMP main.dep(SB) 假如某个函数有一个参数和一个返回值，类型都是整型指针，函数只是简单地把参数作为返回值。 在函数间传递 就像下面的 gom.RetArg() 函数，代码如下： 1 2 3 4 5 6 package gom //go:noinline func RetArg(p *int) *int { return p } 在另一个包中 arg() 函数调用了 inner.RetArg() 函数将局部变量 a 的地址作为参数，并返回了一个 int 类型的返回值。 代码如下： 1 2 3 4 5 6 7 package main //go:noinline func arg() int { var a int return *gom.RetArg(\u0026amp;a) } 在 arg() 函数中并没有把变量 a 的地址作为返回值，也不存在到某个包级别指针变量的依赖链路，所以变量a是否会逃逸的关键就在于inner.RetArg()函数。 inner. RetArg()函数只是把传过去的指针又传了回来，而且作为被调用者来讲，它的生命周期是完全包含在arg()函数的生命周期以内的，所以不应该造成变量 a 逃逸。 事实到底如何呢? 还要通过反编译验证，节选部分关键汇编代码如下： 变量a确实是在栈上分配的，也就说明编译器参考了inner.RetArg()函数的具体实现，基于代码逻辑判定变量 a 没有逃逸。 虽然代码中通过**noinline阻止了内联优化，但是没能阻止编译器参考函数实现**。 假如通过某种方式能够阻止编译器参考函数实现，又会有什么样的结果呢? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 TEXT main.arg(SB) /mnt/hgfs/workspace/helium/main.go func arg() int { 0x455240 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455244 7643 JBE 0x455289 0x455246 4883ec28 SUBQ $0x28, SP 0x45524a 48896c2420 MOVQ BP, 0x20(SP) 0x45524f 488d6c2420 LEAQ 0x20(SP), BP 0x455254 48c744240800000000 MOVQ $0x0, 0x8(SP) # return int var a int 0x45525d 48c744241000000000 MOVQ $0x0, 0x10(SP) return *gom.RetArg(\u0026amp;a) # 可以看出这里调用gom.RetArg函数时参数直接是在栈上分配的，并没有堆分配 0x455266 488d442410 LEAQ 0x10(SP), AX 0x45526b e870ffffff CALL example.com/helium/gom.RetArg(SB) 0x455270 4889442418 MOVQ AX, 0x18(SP) 0x455275 8400 TESTB AL, 0(AX) 0x455277 488b00 MOVQ 0(AX), AX 0x45527a 4889442408 MOVQ AX, 0x8(SP) 0x45527f 488b6c2420 MOVQ 0x20(SP), BP 0x455284 4883c428 ADDQ $0x28, SP 0x455288 c3 RET func arg() int { 0x455289 e8d2ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x45528e ebb0 JMP main.arg(SB) linkname 机制 可以使用 linkname 机制，连同修改后的 arg() 函数的代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import ( \u0026#34;example.com/helium/gom\u0026#34; _ \u0026#34;unsafe\u0026#34; // 使用了 go:linkname 必须要引入 unsafe 包 ) func main() { arg() } //go:linkname retArg example.com/helium/gom.RetArg func retArg(p *int) *int //go:noinline func arg() int { var a int var b int return *gom.RetArg(\u0026amp;a) + retArg(\u0026amp;b) } 再次反编译 arg() 函数，节选变量 a 和 b 分配相关的汇编代码如下： 变量 a 依旧是栈分配，变量 b 已经逃逸了。 在上述代码中的 retArg() 函数只是个函数声明没有给出具体实现，通过 linkname 机制让链接器在链接阶段链接到 inner.RetArg() 函数。 retArg() 函数只有声明没有实现，而且编译器不会跟踪 linkname，所以无法根据代码逻辑判定变量 b 到底有没有逃逸。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 TEXT main.arg(SB) /mnt/hgfs/workspace/helium/main.go func arg() int { 0x455240 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455244 7677 JBE 0x4552bd 0x455246 4883ec40 SUBQ $0x40, SP 0x45524a 48896c2438 MOVQ BP, 0x38(SP) 0x45524f 488d6c2438 LEAQ 0x38(SP), BP 0x455254 48c744241000000000 MOVQ $0x0, 0x10(SP) # return int var a int 0x45525d 48c744241800000000 MOVQ $0x0, 0x18(SP) # a,0 var b int 0x455266 488d05b34a0000 LEAQ 0x4ab3(IP), AX # type.int 0x45526d e8ce5cfbff CALL runtime.newobject(SB) # *int 0x455272 4889442430 MOVQ AX, 0x30(SP) # 变量b，堆分配了 0x455277 48c70000000000 MOVQ $0x0, 0(AX) return *gom.RetArg(\u0026amp;a) + *retArg(\u0026amp;b) 0x45527e 488d442418 LEAQ 0x18(SP), AX 0x455283 e858ffffff CALL example.com/helium/gom.RetArg(SB) 0x455288 4889442428 MOVQ AX, 0x28(SP) 0x45528d 488b442430 MOVQ 0x30(SP), AX 0x455292 e849ffffff CALL example.com/helium/gom.RetArg(SB) 0x455297 4889442420 MOVQ AX, 0x20(SP) 0x45529c 488b4c2428 MOVQ 0x28(SP), CX 0x4552a1 8401 TESTB AL, 0(CX) 0x4552a3 8400 TESTB AL, 0(AX) 0x4552a5 488b09 MOVQ 0(CX), CX 0x4552a8 480308 ADDQ 0(AX), CX 0x4552ab 48894c2410 MOVQ CX, 0x10(SP) 0x4552b0 4889c8 MOVQ CX, AX 0x4552b3 488b6c2438 MOVQ 0x38(SP), BP 0x4552b8 4883c440 ADDQ $0x40, SP 0x4552bc c3 RET func arg() int { 0x4552bd 0f1f00 NOPL 0(AX) 0x4552c0 e89bccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552c5 e976ffffff JMP main.arg(SB) 把逻辑上没有逃逸的变量分配到堆上不会造成错误，只是效率低一些。 但是把逻辑上逃逸了的变量分配到栈上就会造成悬挂指针等问题。 因此编译器只有在能够确定变量没有逃逸的情况下，才会将其分配到栈上，在能够确定变量已经逃逸或无法确定到底有没有逃逸的情况下，都要按照已经逃逸来处理。 这也就解释了为什么在上述代码中的变量 b 逻辑上没逃逸却被分配在了堆上。 函数示例 示例一 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main func main() { sum(1, 2) } // sum 计算a, b的平方和 func sum(a, b int) int { a2 := a * a b2 := b * b c := a2 + b2 return c } main.main汇编： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 TEXT main.main(SB) /mnt/hgfs/g/hello1/hello.go # 判断栈是否溢出 0x10(R14)指向g.stackguard0位置 hello.go:3 0x45b4a0 493b6610 cmp rsp, qword ptr [r14+0x10] cmp 0x10(R14), rsp # 跳转到0x45b4cf处设置栈信息，在重新调main.main函数 hello.go:3 0x45b4a4 7629 jbe 0x45b4cf jbe 0x45b4cf # 为当前栈预分配参数空间，第一个8B存储runtime.main的rbp，第二个8B存储main.sun的参数b为1，第三个8B存储main.sun的参数a为2 hello.go:3 0x45b4a6 4883ec18 sub rsp, 0x18 sub 0x18, rsp # 把runtime.main的栈rbp存入0x10(rsp)处 hello.go:3 0x45b4aa 48896c2410 mov qword ptr [rsp+0x10], rbp mov rbp, 0x10(rsp) # 从新设置当前main.main的栈rbp值为0x10(rsp)处 hello.go:3 0x45b4af 488d6c2410 lea rbp, ptr [rsp+0x10] lea 0x10(rsp), rbp # 为main.sum准备第一个参数，放入寄存器AX中 hello.go:4 0x45b4b4 b801000000 mov eax, 0x1 mov 0x1, AX # 为main.sum准备第二个参数，放入寄存器BX中 hello.go:4 0x45b4b9 bb02000000 mov ebx, 0x2 mov 0x2, BX hello.go:4 0x45b4be 6690 data16 nop hello.go:4 0x45b4c0 e81b000000 call $main.sum call $main.sum # 把runtime.main的栈rbp值从0x10(rsp)处放入rbp寄存器 hello.go:5 0x45b4c5 488b6c2410 mov rbp, qword ptr [rsp+0x10] mov 0x10(rsp), rbp # rsp寄存器恢复调用main.main之前情况 hello.go:5 0x45b4ca 4883c418 add rsp, 0x18 add 0x18, rsp # 返回，rsp-8弹出返回地址给rip返回的runtime.main继续执行 hello.go:5 0x45b4ce c3 ret ret hello.go:3 0x45b4cf e88ccdffff call $runtime.morestack_noctxt call $runtime.morestack_noctxt .:0 0x45b4d4 ebca jmp $main.main jmp $main.main main.sum汇编： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 TEXT main.sum(SB) /mnt/hgfs/g/hello1/hello.go # 为main.sum栈预分配0x28空间 hello.go:8 0x45b4e0 4883ec28 sub rsp, 0x28 sub 0x28, rsp # 把main.main的rbp存储到0x20(rsp)位置 hello.go:8 0x45b4e4 48896c2420 mov qword ptr [rsp+0x20], rbp mov rbp, 0x20(rsp) # 从新设置main.sum的rbp值 hello.go:8 0x45b4e9 488d6c2420 lea rbp, ptr [rsp+0x20] lea 0x20(rsp), rbp # 把传递的第一个参数入栈，注意看这里参参数栈分配在main.main的栈上 hello.go:8 0x45b4ee 4889442430 mov qword ptr [rsp+0x30], rax mov AX, 0x30(rsp) # a = 1 # 把传递的第二个参数入栈，注意看这里参参数栈分配在main.main的栈上 hello.go:8 0x45b4f3 48895c2438 mov qword ptr [rsp+0x38], rbx mov BX, 0x38(rsp) # b = 2 # 初始化rsp的第一个8字节吗，返回值空间初始化 hello.go:8 0x45b4f8 48c7042400000000 mov qword ptr [rsp], 0x0 mov 0x0, (rsp) # return # 为乘法运算做准备，把变量a的值放入寄存器 hello.go:9 0x45b500 488b4c2430 mov rcx, qword ptr [rsp+0x30] mov 0x30(rsp), CX # 为乘法运算做准备，把变量a的值放入寄存器 hello.go:9 0x45b505 488b542430 mov rdx, qword ptr [rsp+0x30] mov 0x30(rsp), DX # 乘法运算，结果存储在DX中 hello.go:9 0x45b50a 480fafd1 imul rdx, rcx imul CX, DX # a*a # 0X18(rsp)的地址为变量a2 hello.go:9 0x45b50e 4889542418 mov qword ptr [rsp+0x18], rdx mov DX, 0X18(rsp) # a2=a*a # 为乘法运算做准备，把变量b的值放入寄存器 hello.go:10 0x45b513 488b4c2438 mov rcx, qword ptr [rsp+0x38] mov 0x38(rsp), CX # 为乘法运算做准备，把变量b的值放入寄存器 hello.go:10 0x45b518 488b542438 mov rdx, qword ptr [rsp+0x38] mov 0x38(rsp), DX # 乘法运算，结果存储在DX中 hello.go:10 0x45b51d 480fafd1 imul rdx, rcx imul CX, DX # b*b # 0X10(rsp)的地址为变量b2 hello.go:10 0x45b521 4889542410 mov qword ptr [rsp+0x10], rdx mov DX, 0x10(rsp) # b2 = b*b # 把a2值放入CX寄存器 hello.go:11 0x45b526 488b4c2418 mov rcx, qword ptr [rsp+0x18] mov 0x18(rsp), CX # 计算 a2 + b2 hello.go:11 0x45b52b 488d0411 lea rax, ptr [rcx+rdx*1] lea (CX+DX*1), AX # a2+b2 # a2 + b2 值存入0x8(rsp)是变量的值 hello.go:11 0x45b52f 4889442408 mov qword ptr [rsp+0x8], rax mov AX, 0x8(rsp) # c = a2+b2 # a2 + b2 值存入(rsp) 该值是返回值空间 hello.go:13 0x45b534 48890424 mov qword ptr [rsp], rax mov AX, (rsp) # return # 弹出main.main的rbp hello.go:13 0x45b538 488b6c2420 mov rbp, qword ptr [rsp+0x20] mov 0x20(rsp), rbp # 使rsp指向main.main的栈rsp位置 .:0 0x45b53d 4883c428 add rsp, 0x28 add 0x28, rsp # 弹出main.main的下一条指令地址 .:0 0x45b541 c3 ret ret 栈分布情况： // 我们看一下代码在14行时也就是main.sum函数返回前的栈布局情况 // // 栈底 // ---------------------------- 高地址 // | b // ---------------------------- // | a runtime.main函数栈帧 // ---------------------------- // | 返回到runtime.main的地址 +0x48 // -----------\u0026gt; ---------------------------- \u0026lt;------------------------------------- // | 调用函数runtime.main的rbp +0x40 // ---------------------------- // | main.sum的第二个参数 0x2 +0x38 // ---------------------------- main.main函数栈帧 // | main.sum的第一个参数 0x1 +0x30 // ---------------------------- // | 返回到main.main的地址 +0x28 // -----------\u0026gt; ---------------------------- \u0026lt;------------------------------------- // | 调用函数main.main的rbp +0x20 // ---------------------------- // | 变量a2 0x1 +0x18 // ---------------------------- // | 变量b2 0x4 +0x10 main.sum函数栈帧 // ---------------------------- // | 变量c 0x5 +0x8 // ---------------------------- // | main.sum的返回值地址 0x5 +0x0 // -----------\u0026gt; ---------------------------- \u0026lt;------------------------------------- 编译指令 编译指令：go build -gcflags=\u0026quot;-N -l\u0026quot; slice1.go。 查看具体方法的汇编指令：go tool objdump -S -s \u0026lsquo;^main.main$\u0026rsquo; slice1。 ","permalink":"https://heliu.site/posts/golang/func/align/","summary":"Golang 内存对齐和逃逸分析介绍。","title":"内存对齐和逃逸分析"},{"content":" 函数在 Go 语言中属于第一类值(First Class Value)，该类型的值可以作为函数的参数和返回值，也可以赋给变量。 当把一个函数赋值给某个变量后，这个变量就被称为 Function Value。 声明一个 Function Value 变量的示例代码如下： var fn func(a, b int) int 其中 fn 就是个 Function Value 变量，它的类型是 func(int, int) int。 Function Value 可以像一般函数那样被调用，在使用体验上非常类似于 C 语言中的函数指针。 Function Value 本质上是不是函数指针呢？ 本节会分析 Function Value 和函数指针的实现原理，还有闭包的实现原理，以及 Function Value 是如何支持闭包的。 函数指针 熟悉 C 语言的读者应该有过使用函数指针的经验，函数指针存储的都是地址，只不过不是指向某种类型的数据。 而是指向代码段中某个函数的第一条指令，如图所示。 Function Value 分析 准备一个 go 文件并写入，示例代码如下： 1 2 3 4 5 6 7 8 9 10 package main func main() { println(helper(nil, 0, 0)) } //go:noinline func helper(fn func(int, int) int, a, b int) int { return fn(a, b) } 依然把 Function Value 的调用隔离在一个函数中，以便于分析。main.helper反编译代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 $ go build -gcflags=\u0026#34;-N -l\u0026#34; -o ./h1 myzx.cn/helium $ go tool objdump -S -s \u0026#39;^main.helper$\u0026#39; ./h1 TEXT main.helper(SB) /mnt/hgfs/workspace/helium/main.go func helper(fn func(int, int) int, a, b int) int { 0x455240 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455244 7650 JBE 0x455296 0x455246 4883ec28 SUBQ $0x28, SP 0x45524a 48896c2420 MOVQ BP, 0x20(SP) 0x45524f 488d6c2420 LEAQ 0x20(SP), BP 0x455254 4889442430 MOVQ AX, 0x30(SP) # fn 0x455259 48895c2438 MOVQ BX, 0x38(SP) # a 0x45525e 48894c2440 MOVQ CX, 0x40(SP) # b 0x455263 48c744241000000000 MOVQ $0x0, 0x10(SP) # return int return fn(a, b) 0x45526c 488b442438 MOVQ 0x38(SP), AX # AX=a 0x455271 488b5c2440 MOVQ 0x40(SP), BX # BX=b 0x455276 488b542430 MOVQ 0x30(SP), DX # DX=fn # 这里看出 Function Value 是一个二级指针 0x45527b 488b0a MOVQ 0(DX), CX # CX=fn.fn 0x45527e 6690 NOPW # DX 寄存器存储的是 fn，也就是上下文 # CALL CX; 指令说明，CX寄存器最终存储的是实际函数的地址 0x455280 ffd1 CALL CX # CALL fn.fn 0x455282 4889442418 MOVQ AX, 0x18(SP) 0x455287 4889442410 MOVQ AX, 0x10(SP) 0x45528c 488b6c2420 MOVQ 0x20(SP), BP 0x455291 4883c428 ADDQ $0x28, SP 0x455295 c3 RET func helper(fn func(int, int) int, a, b int) int { 0x455296 4889442408 MOVQ AX, 0x8(SP) 0x45529b 48895c2410 MOVQ BX, 0x10(SP) 0x4552a0 48894c2418 MOVQ CX, 0x18(SP) 0x4552a5 e8b6ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552aa 488b442408 MOVQ 0x8(SP), AX 0x4552af 488b5c2410 MOVQ 0x10(SP), BX 0x4552b4 488b4c2418 MOVQ 0x18(SP), CX 0x4552b9 eb85 JMP main.helper(SB) 通过上述逻辑，可以确定Function Value确实是个指针，而且是个两级指针。 如图所示，Function Value 不直接指向目标函数，而是一个目标函数的指针。 闭包 说到Go语言的闭包，比较直观的感受就是个有状态的 Function Value。 在Go语言中比较典型的闭包场景就是在某个函数内定义了另一个函数，内层函数使用了外层函数的局部变量，并且内层函数最终被外层函数作为返回值返回。 代码如下： 1 2 3 4 5 func mc(n int) func() int { return func() int { return n } } 每次调用 mc() 函数都会返回一个新的闭包，闭包记住了参数的值，所以是有状态的。 基于目前对函数栈帧的了解，函数栈帧随着函数返回而销毁，不能用来保存状态。 研究函数指针和 Function Value 的时候也没有发现哪里用来保存状态，所以这里就有个问题，闭包的状态保存在哪里呢？ 闭包对象 为了摘清楚这个问题，先来尝试一下反编译，从汇编代码中找答案，main.mc反编译代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 $ go build -gcflags=\u0026#34;-N -l\u0026#34; -o ./h1 myzx.cn/helium $ go tool objdump -S -s \u0026#39;^main.mc$\u0026#39; ./h1 TEXT main.mc(SB) /mnt/hgfs/workspace/helium/main.go func mc(n int) func() int { 0x455220 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455224 765b JBE 0x455281 0x455226 4883ec28 SUBQ $0x28, SP 0x45522a 48896c2420 MOVQ BP, 0x20(SP) 0x45522f 488d6c2420 LEAQ 0x20(SP), BP # 参数栈空间分配 0x455234 4889442430 MOVQ AX, 0x30(SP) # n # 返回值栈空间分配 0x455239 48c744241000000000 MOVQ $0x0, 0x10(SP) # return func() int return func() int { # 0x7497(IP) 是 Function Value 的结构元类型 # type funcval struct {fn unsafe.Pointer, n int} 0x455242 488d0597740000 LEAQ 0x7497(IP), AX # Function Value 结构的元类型 # 创建 funcval 结构需要的内存空间，是堆分配 0x455249 e8f25cfbff CALL runtime.newobject(SB) # AX=\u0026amp;funcval 0x45524e 4889442418 MOVQ AX, 0x18(SP) # 这里main.mc.func1(SB)是mc返回的闭包在代码段的地址 0x455253 488d0d46000000 LEAQ main.mc.func1(SB), CX # CX=main.mc.func1(SB) 0x45525a 488908 MOVQ CX, 0(AX) # funcval.fn=main.mc.func1(SB) 0x45525d 488b4c2418 MOVQ 0x18(SP), CX 0x455262 8401 TESTB AL, 0(CX) 0x455264 488b542430 MOVQ 0x30(SP), DX # DX=n # 可以看出这里捕获了变量n，并且是拷贝捕获 0x455269 48895108 MOVQ DX, 0x8(CX) # funcval.n = n 0x45526d 488b442418 MOVQ 0x18(SP), AX # AX=\u0026amp;funcval 0x455272 4889442410 MOVQ AX, 0x10(SP) 0x455277 488b6c2420 MOVQ 0x20(SP), BP 0x45527c 4883c428 ADDQ $0x28, SP 0x455280 c3 RET func mc(n int) func() int { 0x455281 4889442408 MOVQ AX, 0x8(SP) 0x455286 e8d5ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x45528b 488b442408 MOVQ 0x8(SP), AX 0x455290 eb8e JMP main.mc(SB) 根据上面代码可以推断出Function Value动态分配的对象的类型。 应该是一个 struct 类型，第1个字段是函数地址，第2个字段是 int 类型，代码如下： 1 2 3 4 struct { F uintptr n int } 说明编译器识别出了闭包这种代码模式，并且自动定义了这个 struct 类型进行支持，出于面向对象编程中把数据称为对象的习惯，后文中就把这种 struct 称为闭包对象。 闭包对象的成员可以进一步划分，第1个字段F用来存储目标函数的地址，这在所有的闭包对象中都是一致的，后文中将这个目标函数称为闭包函数。 从第2个字段开始，后续的字段称为闭包的捕获列表，也就是内层函数中用到的所有定义在外层函数中的变量。 编译器认为这些变量被闭包捕获了，会把它们追加到闭包对象的 struct 定义中。 上例中只捕获了一个变量 n，如果捕获的变量增多，struct 的捕获列表也会加长。 一个捕获两个变量的闭包示例代码如下： 1 2 3 4 5 func mc(n, m int) func() (int, int) { return func() (int, int) { return n, m } } 上述代码对应的闭包对象定义代码如下： 1 2 3 4 5 struct { F uintptr n int m int } 看到闭包 通过反编译来逆向推断闭包对象的结构还是比较烦琐的，如果能有一种方法，能够直观看到闭包对象的结构定义，那真是再好不过了。 根据之前的探索，已经知道 Go 序在运行阶段会通过 runtime.newobject() 函数动态匹配闭包对象。 Go 源码中 newobject() 函数的原型如下： func newobject(typ *_type) unsafe.Pointer 函数的返回值是个指针，也就是新分配的对象的地址，参数是个 _type 类型的指针。 通过源码可以得知这个 _type 是个 struct，在 Go 语言的 runtime 包中被用来描述一个数据类型，通过它可以找到目标数据类型的大小，对齐边界，类型名称等。 假如能够获得传递给 runtime.newobjet() 函数的类型元数据指针 typ，再通过反射进行解析，就能打印出闭包对象的结构定义了。那如何才能获得这个 typ 参数呢？ 在C语言中有种常用的函数 Hook 技术，就是在运行阶段将目标函数头部的代码替换为一条跳转指令，跳转到一个新的函数。 在 x86 平台上就是在进程地址空间中找到要 Hook 的函数，将其头部替换为一条 JMP 指令，同时指定 JMP 指令要跳转到的新函数的地址。 这项技术在 Go 程序中依然适用，可以用一个自己实现的函数换掉 runtime.newobject() 函数，在这个函数中就能获得 typ 参数并进行解析了。 还有一个问题是 runtime.newobiect() 函数属于未导出的函数，在runtime包外无法访问。 这一点可以通过 linkname 机制来绕过，在当前包中声明一个类似的函数，让链接器将其链接到runtime.newobject()函数即可。 本书使用开源模块 github.com/fengyoulin/hookingo 实现运行阶段函数替换，打印闭包对象结构的完整代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 package main import ( \u0026#34;github.com/fengyoulin/hookingo\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;unsafe\u0026#34; ) var hno hookingo.Hook //go:linkname newobject runtime.newobject func newobject(typ unsafe.Pointer) unsafe.Pointer //go:linkname newobject2 runtime.mallocgc func newobject2(size uintptr, typ unsafe.Pointer, b bool) unsafe.Pointer func fno(typ unsafe.Pointer) unsafe.Pointer { t := reflect.TypeOf(0) // type Type interface{} // 这里为什么赋值的是下标1？接下来我们分析为什么是1而不是0下标。 // 根据后面分析确实是修改下标1，因为t.String()需要用到1这个下标的数据。 (*(*[2]unsafe.Pointer)(unsafe.Pointer(\u0026amp;t)))[1] = typ // 相当于反射了闭包类型 println(t.String()) //fn, ok := hno.Origin().(func(typ unsafe.Pointer) unsafe.Pointer) //if ok { // return fn(typ) // 调用原runtime.newobject //} //println(\u0026#34;ok\u0026#34;, ok) //os.Exit(1) println(*(*uintptr)(unsafe.Pointer(typ))) return newobject2(*(*uintptr)(typ), typ, true) } // 创建一个闭包，make closure func mc(start int, text string) func() string { // 这里 start 需要堆分配 // func() string 也需要堆分配 return func() string { l := len(text) s := start % l r := text[s:] start++ return r } } func main() { var err error hno, err = hookingo.Apply(newobject, fno) // 应用钩子，替换函数 if err != nil { panic(err) } f := mc(10, \u0026#34;hello, closure!\u0026#34;) println(f()) } $ C:\\Users\\Helium\\go\\bin\\go1.17.exe run -gcflags -l . # go1.17 版本 int # 打印的是mc的start堆分配 8 # int 占用内存大小 struct { F uintptr; text string; start *int } 32 sure! $ go run -gcflags -l . # go1.20.3版本 int 8 struct { F uintptr; text string; start *int } 32 sure! 因为start会被修改，所以捕获地址造成堆分配，因此结果第一行打印了一个int。 第二行的struct就是闭包结构的类型，这是通过类型元数据直接获取到的，是由编译器构造的结构类型。 我们抄部分fno()函数的相关代码：typ unsafe.Pointer：来自类型的*_type类型数据。 1 2 3 4 5 6 7 func fno(typ unsafe.Pointer) unsafe.Pointer { t := reflect.TypeOf(0) // type Type interface{} // 这里为什么赋值的是下标1？接下来我们分析为什么是1而不是0下标。 (*(*[2]unsafe.Pointer)(unsafe.Pointer(\u0026amp;t)))[1] = typ // 相当于反射了闭包类型 println(t.String()) // ... ... } 分析reflect.TypeOf()函数如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // TypeOf returns the reflection Type that represents the dynamic type of i. // If i is a nil interface value, TypeOf returns nil. func TypeOf(i any) Type { // emptyInterface 是空接口的内存结构 eface := *(*emptyInterface)(unsafe.Pointer(\u0026amp;i)) // eface.typ 这里直接取了 typ 字段，没有要word字段 // 通过分析toType()函数可知，把eface.typ放入了非空接口Type中。 // 因此必须要分析非空接口中存储的是什么？非空接口内存布局 // type iface struct { // tab *itab // 类型元数据 // data *unsafe.Pointer // 装箱的数据 // } // 因此 tab *itab 装载的是 *rtype 类型结构，也就是结构体指针 // 按照传入参数0这里可以看出应该是int的元类型 // 重要的是 data，这存储的是 *rtype 这个指针数据，类型反射就是依靠这个data。 // 因为我们调用Type非空接口的所有方法接收器的参数都是 *rtype，这也就是为什么修改下标1的原因。 // 我们在调用t.String()方法时，需要的时data这个是我们想要的类型即可。 return toType(eface.typ) } // emptyInterface is the header for an interface{} value. type emptyInterface struct { typ *rtype // 存储着类型结构 word unsafe.Pointer } 分析toType()函数如下： 1 2 3 4 5 6 7 8 9 10 11 // toType converts from a *rtype to a Type that can be returned // to the client of package reflect. In gc, the only concern is that // a nil *rtype must be replaced by a nil Type, but in gccgo this // function takes care of ensuring that multiple *rtype for the same // type are coalesced into a single Type. func toType(t *rtype) Type { if t == nil { return nil } return t } 调用闭包 闭包函数在被调用的时候，必须得到当前闭包对象的地址才能访问其中的捕获列表，这个地址是如何传递的呢？ 调用者在调用 Function Value 的时候只是像调用一个普通函数那样传递了声明的参数，如果 Function Value 背后是个闭包函数，则无法通过栈上的参数得到闭包对象地址。 除非编译器传递了一个隐含的参数，这个参数如果通过栈传递，那就改变了函数的原型，这样就会造成不一致，是行不通的。 还是通过反汇编来看一下闭包函数是从哪里得到的这个地址，先来构造闭包，代码如下： 1 2 3 4 5 func mc(n int) func int { return func() int { return n } } 根据前面的探索，可以确定闭包对象的结构定义代码如下： 1 2 3 4 struct { F uintptr n int } 反编译闭包函数得到的汇编代码如下： 第7行，将 DX 寄存器用作基址,再加上位移 8，把该地址处的值复制到 CX 寄存器中。 第8行，把 CX 寄存器值复制给闭包函数的返回值。 第11行，把返回值放入AX寄存器中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ go tool objdump -S -s \u0026#39;^main.mc.func1$\u0026#39; ./h1 TEXT main.mc.func1(SB) /mnt/hgfs/workspace/helium/main.go return func() int { 0x4552a0 4883ec18 SUBQ $0x18, SP 0x4552a4 48896c2410 MOVQ BP, 0x10(SP) 0x4552a9 488d6c2410 LEAQ 0x10(SP), BP 0x4552ae 488b4a08 MOVQ 0x8(DX), CX # CX=0x8(DX) 0x4552b2 48894c2408 MOVQ CX, 0x8(SP) 0x4552b7 48c7042400000000 MOVQ $0x0, 0(SP) return n 0x4552bf 488b442408 MOVQ 0x8(SP), AX # AX=0x8(DX) 0x4552c4 48890424 MOVQ AX, 0(SP) 0x4552c8 488b6c2410 MOVQ 0x10(SP), BP 0x4552cd 4883c418 ADDQ $0x18, SP 0x4552d1 c3 RET 显然，DX寄存器存储的就是闭包对象的地址，调用者负责在调用之前把闭包对象的地址存储到 DX 寄存器中，跟 C++ 中的 thiscall非常类似。 之前有很多读者在反编译 Function Value 调用代码时，总会看到为 DX 寄存器赋值，并为此感到疑惑，这就是原因。 调用者不必区分是不是闭包、有没有捕获列表，实际上也区分不了，只能统一作为闭包来处理，所以总要通过 DX 传递地址。 如果 Function Value 背后不是闭包，这个地址就不会被用到，也不会造成什么影响。 闭包与变量逃逸 变量逃逸跟闭包之间的关系很密切，因为 Function Value 本身就是个指针，编译器也可以按照同样的方式来分析 Function Value 有没有逃逸。 如果 Function Value 没有逃逸那就可以不用在堆上分配闭包对象了，分配在栈上即可。 使用一个示例进行验证，代码如下： 1 2 3 4 5 6 func sc(n int) int { f := func() int { return n } return f() } 代码逻辑过于简单，为了避免闭包函数被编译器优化掉，编译时需要禁用内联优化，命令如下：$ go build -gcflags='-l'。 再来反编译 sc() 函数，main.sc反编译命令及输出结果如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 $ go build -gcflags=\u0026#34;-l -N\u0026#34; -o ./h1 myzx.cn/helium $ go tool objdump -S -s \u0026#39;^main.sc$\u0026#39; ./h1 TEXT main.sc(SB) /mnt/hgfs/workspace/helium/main.go func sc(n int) int { 0x455220 493b6610 CMPQ 0x10(R14), SP 0x455224 7664 JBE 0x45528a 0x455226 4883ec38 SUBQ $0x38, SP 0x45522a 48896c2430 MOVQ BP, 0x30(SP) 0x45522f 488d6c2430 LEAQ 0x30(SP), BP 0x455234 4889442440 MOVQ AX, 0x40(SP) # 分配参数空间 0x455239 48c7042400000000 MOVQ $0x0, 0(SP) # 分配返回值空间 f := func() int { 0x455241 440f117c2410 MOVUPS X15, 0x10(SP) 0x455247 488d542410 LEAQ 0x10(SP), DX # \u0026amp;funcval 0x45524c 4889542428 MOVQ DX, 0x28(SP) 0x455251 8402 TESTB AL, 0(DX) 0x455253 488d0546000000 LEAQ main.sc.func1(SB), AX 0x45525a 4889442410 MOVQ AX, 0x10(SP) # funcval.fn 0x10(SP) 0x45525f 8402 TESTB AL, 0(DX) 0x455261 488b442440 MOVQ 0x40(SP), AX # 参数n的值 0 0x455266 4889442418 MOVQ AX, 0x18(SP) # funcval.data 0x18(SP) 0 0x45526b 4889542420 MOVQ DX, 0x20(SP) return f() 0x455270 488b442410 MOVQ 0x10(SP), AX 0x455275 ffd0 CALL AX 0x455277 4889442408 MOVQ AX, 0x8(SP) 0x45527c 48890424 MOVQ AX, 0(SP) 0x455280 488b6c2430 MOVQ 0x30(SP), BP 0x455285 4883c438 ADDQ $0x38, SP 0x455289 c3 RET func sc(n int) int { 0x45528a 4889442408 MOVQ AX, 0x8(SP) 0x45528f e8ccccffff CALL runtime.morestack_noctxt.abi0(SB) 0x455294 488b442408 MOVQ 0x8(SP), AX 0x455299 eb85 JMP main.sc(SB) 函数 在Go语言中函数属于头等对象，可以被当作参数传递、也可以作为函数返回值、绑定到变量。 Go语言称这样的参数、返回值和变量为Function Value。 Function Value本质上是一个指针，却不直接指向函数指令入口，而是指向runtime.funcval结构体，函数变量存储的是*funcval类型，也就是funcval结构体的地址。 1 2 3 4 5 6 7 8 9 10 11 // 闭包是函数类型funcType // 闭包捕获的变量，系统维护着一个关系列表，根据这个列表能正确的找到捕获的变量类型大小等信息 type funcval struct { fn uintptr // 指向程序的代码段 // variable-size, fn-specific data here } // 紧接着funcval结构体后面内存地址是捕获的的变量列表 // 注意捕获的是变量的地址，使用的却是变量的值 // 闭包中捕获的如果是指针类型那么是引用，是普通类型那么是拷贝 // f -\u0026gt; *funcval 这个结构体从定义上看只有一个地址，这个地址才是函数的指令入口。一个Function Value是以下图所示形式存在的。 闭包 Closure：维基百科 闭包在实现上是一个结构体，它存储了一个函数（通常是其入口地址）和一个关联的环境（相当于一个符号查找表）。 环境里是若干对符号和值的对应关系，它既要包括约束变量（该函数内部绑定的符号），也要包括自由变量（在函数外部定义但在函数内被引用），有些函数也可能没有自由变量。 闭包跟函数最大的不同在于，当捕捉闭包的时候，它的自由变量会在捕捉时被确定，这样即便脱离了捕捉时的上下文，它也能照常运行。 所以像下面这个例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func create() func(){ c := 2 // c会被分配在栈上，以拷贝形式被捕获 return func(){ // 【由于c变量后面没有变化，所以这里捕获变成拷贝c的值2就行，不需要捕获c的地址】 fmt.Println(c) } } func main(){ // f1 { // fn ---\u0026gt; 闭包函数地址 // 2 ---\u0026gt; 拷贝c的值即可（不需要捕获c的地址），这里2 // } f1 := create() f2 := create() f1() f2() // 闭包函数的内存结构布局 s := **(**struct{ fn uintptr // 指向函数代码地址 data1 int // 捕获变量 })(unsafe.Pointer(\u0026amp;f1)) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, s) // struct {fn uintptr;data1 int}{fn:0x47f520, data1:2} } create函数的返回值是一个函数，并且引用了其外层函数定义的局部变量c。 而且，即便create函数结束，依然可以通过f1和f2正常执行这个函数并使用定义在create内部的变量c。 所以这个返回值符合闭包的定义，而这个自由变量c，通常被称为捕获变量。 虽然create函数的返回值函数形成闭包，但是Go语言里并没有把闭包从Function Value中特别区分出来。 在Go语言中闭包只是拥有一个或多个捕获变量的Function Value而已。 这些捕获变量就是它的捕获列表，就放在对应的funcval结构体的后面。 所以上例中，f1和f2的内存布局如下图所示： 每个闭包对象都是一个Function Value，但是各自持有自己的捕获列表，这也是称闭包为有状态的函数的原因。 闭包捕获变量值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main func main() { f := create() _ = f() } //go:noinline func create() func() int { c := 2 // 堆分配 struct { F uintptr; c int } return func() int { // 注意这里的c变量不需要被捕获 // c没有更改，只需要拷贝变量c的值即可 return c } } main 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x4551e4 7629 JBE 0x45520f 0x4551e6 4883ec10 SUBQ $0x10, SP # main.main栈分配 0x4551ea 48896c2408 MOVQ BP, 0x8(SP) 0x4551ef 488d6c2408 LEAQ 0x8(SP), BP f := create() 0x4551f4 e827000000 CALL main.create(SB) # AX返回\u0026amp;funcval 0x4551f9 48890424 MOVQ AX, 0(SP) _ = f() 0x4551fd 488b08 MOVQ 0(AX), CX # CX=funcval.fn 0x455200 4889c2 MOVQ AX, DX # DX=\u0026amp;funcval 0x455203 ffd1 CALL CX } 0x455205 488b6c2408 MOVQ 0x8(SP), BP 0x45520a 4883c410 ADDQ $0x10, SP 0x45520e c3 RET func main() { 0x45520f e84ccdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455214 ebca JMP main.main(SB) create 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func create() func() int { 0x455220 493b6610 CMPQ 0x10(R14), SP # 栈增长判断 0x455224 765f JBE 0x455285 0x455226 4883ec30 SUBQ $0x30, SP # 分配create栈空间 0x45522a 48896c2428 MOVQ BP, 0x28(SP) 0x45522f 488d6c2428 LEAQ 0x28(SP), BP 0x455234 48c744241800000000 MOVQ $0x0, 0x18(SP) # 临时返回空间8字节，*funcval c := 2 0x45523d 48c744241002000000 MOVQ $0x2, 0x10(SP) # 参数 c return func() int { # AX=0x7493(IP)，funcval结构体类型的_type类型指针位置，内存大小16B 0x455246 488d0593740000 LEAQ 0x7493(IP), AX # 根据*_type进行堆分配，AX=\u0026amp;funcval 0x45524d e8ee5cfbff CALL runtime.newobject(SB) 0x455252 4889442420 MOVQ AX, 0x20(SP) # CX=main.create.func1 代码地址 0x455257 488d0d42000000 LEAQ main.create.func1(SB), CX 0x45525e 488908 MOVQ CX, 0(AX) # funcval.fn=main.create.func1 0x455261 488b4c2420 MOVQ 0x20(SP), CX # CX=\u0026amp;funcval 0x455266 8401 TESTB AL, 0(CX) 0x455268 488b542410 MOVQ 0x10(SP), DX # DX=0x2 0x45526d 48895108 MOVQ DX, 0x8(CX) # funcval.data=0x2 0x455271 488b442420 MOVQ 0x20(SP), AX # AX=\u0026amp;funcval 0x455276 4889442418 MOVQ AX, 0x18(SP) 0x45527b 488b6c2428 MOVQ 0x28(SP), BP 0x455280 4883c430 ADDQ $0x30, SP 0x455284 c3 RET func create() func() int { 0x455285 e8d6ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x45528a eb94 JMP main.create(SB) main.create.func1 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 TEXT main.create.func1(SB) /mnt/hgfs/g/hello1/func1.go return func() int { 0x4552a0 4883ec18 SUBQ $0x18, SP 0x4552a4 48896c2410 MOVQ BP, 0x10(SP) 0x4552a9 488d6c2410 LEAQ 0x10(SP), BP 0x4552ae 488b4a08 MOVQ 0x8(DX), CX # CX=0x2 0x4552b2 48894c2408 MOVQ CX, 0x8(SP) 0x4552b7 48c7042400000000 MOVQ $0x0, 0(SP) // 注意这里的c变量不需要被捕获 0x4552bf 488b442408 MOVQ 0x8(SP), AX # AX=0x2 0x4552c4 48890424 MOVQ AX, 0(SP) 0x4552c8 488b6c2410 MOVQ 0x10(SP), BP 0x4552cd 4883c418 ADDQ $0x18, SP 0x4552d1 c3 RET main和create的栈分布。 | runtime.main callback -------------------------- +40 +08 | runtime.main BP -------------------------- BP --------------- +38 +00 | create.r *funcval main.main栈 -------------------------- SP --------------- +30 | main.main callback -------------------------- +28 | main.main BP -------------------------- BP --------------- +20 | \u0026amp;funcval create.o -\u0026gt; 临时funcval堆分配 -------------------------- +18 | \u0026amp;funcval create.r -\u0026gt; create的返回值 -------------------------- +10 | 0x2 create.c main.create栈 -------------------------- +08 | -------------------------- +00 | -------------------------- SP --------------- 闭包捕获变量地址 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main func main() { f := create() _ = f() } //go:noinline func create() func() int { c := 2 // 堆分配 struct { F uintptr; c *int } return func() int { c++ // 捕获c变量地址，在堆上分配 return c } } main 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7629 JBE 0x45520f 0x4551e6 4883ec10 SUBQ $0x10, SP 0x4551ea 48896c2408 MOVQ BP, 0x8(SP) 0x4551ef 488d6c2408 LEAQ 0x8(SP), BP f := create() 0x4551f4 e827000000 CALL main.create(SB) # 调用函数 AX返回\u0026amp;funcval 0x4551f9 48890424 MOVQ AX, 0(SP) _ = f() 0x4551fd 488b08 MOVQ 0(AX), CX # CX=funcval.fn 0x455200 4889c2 MOVQ AX, DX # DX=\u0026amp;funcval 0x455203 ffd1 CALL CX } 0x455205 488b6c2408 MOVQ 0x8(SP), BP 0x45520a 4883c410 ADDQ $0x10, SP 0x45520e c3 RET func main() { 0x45520f e84ccdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455214 ebca JMP main.main(SB) create 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 func create() func() int { 0x455220 493b6610 CMPQ 0x10(R14), SP 0x455224 0f8686000000 JBE 0x4552b0 0x45522a 4883ec30 SUBQ $0x30, SP 0x45522e 48896c2428 MOVQ BP, 0x28(SP) 0x455233 488d6c2428 LEAQ 0x28(SP), BP 0x455238 48c744241000000000 MOVQ $0x0, 0x10(SP) c := 2 0x455241 488d05f84a0000 LEAQ 0x4af8(IP), AX # AX=0x4af8(IP)，int的元类型 0x455248 e8f35cfbff CALL runtime.newobject(SB) # 申请内存，AX=*int 0x45524d 4889442420 MOVQ AX, 0x20(SP) # 变量c 0x455252 48c70002000000 MOVQ $0x2, 0(AX) # 给c赋值2 return func() int { 0x455259 488d0580740000 LEAQ 0x7480(IP), AX # funcval的元类型，申请16B 0x455260 e8db5cfbff CALL runtime.newobject(SB) # AX=\u0026amp;funcval 0x455265 4889442418 MOVQ AX, 0x18(SP) 0x45526a 488d0d4f000000 LEAQ main.create.func1(SB), CX # CX=main.create.func1 0x455271 488908 MOVQ CX, 0(AX) # funcval.fn=main.create.func1 0x455274 488b4c2418 MOVQ 0x18(SP), CX # CX=\u0026amp;funcval 0x455279 8401 TESTB AL, 0(CX) 0x45527b 488b542420 MOVQ 0x20(SP), DX # DX=*int -\u0026gt; 2 0x455280 488d7908 LEAQ 0x8(CX), DI # DI=funcval.data 0x455284 833dd51f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x45528b 7402 JE 0x45528f 0x45528d eb06 JMP 0x455295 0x45528f 48895108 MOVQ DX, 0x8(CX) # funcval.data=*int -\u0026gt; 2 0x455293 eb07 JMP 0x45529c 0x455295 e8a6d0ffff CALL runtime.gcWriteBarrierDX(SB) 0x45529a eb00 JMP 0x45529c 0x45529c 488b442418 MOVQ 0x18(SP), AX # AX=\u0026amp;funcval 0x4552a1 4889442410 MOVQ AX, 0x10(SP) 0x4552a6 488b6c2428 MOVQ 0x28(SP), BP 0x4552ab 4883c430 ADDQ $0x30, SP 0x4552af c3 RET func create() func() int { 0x4552b0 e8abccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552b5 e966ffffff JMP main.create(SB) main.create.func1 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 TEXT main.create.func1(SB) /mnt/hgfs/g/hello1/func1.go return func() int { 0x4552c0 4883ec18 SUBQ $0x18, SP 0x4552c4 48896c2410 MOVQ BP, 0x10(SP) 0x4552c9 488d6c2410 LEAQ 0x10(SP), BP 0x4552ce 488b4a08 MOVQ 0x8(DX), CX 0x4552d2 48894c2408 MOVQ CX, 0x8(SP) 0x4552d7 48c7042400000000 MOVQ $0x0, 0(SP) c++ // 捕获c变量地址，在堆上分配 0x4552df 488b4c2408 MOVQ 0x8(SP), CX 0x4552e4 488b09 MOVQ 0(CX), CX 0x4552e7 488b542408 MOVQ 0x8(SP), DX 0x4552ec 48ffc1 INCQ CX 0x4552ef 48890a MOVQ CX, 0(DX) return c 0x4552f2 488b4c2408 MOVQ 0x8(SP), CX 0x4552f7 488b01 MOVQ 0(CX), AX 0x4552fa 48890424 MOVQ AX, 0(SP) 0x4552fe 488b6c2410 MOVQ 0x10(SP), BP 0x455303 4883c418 ADDQ $0x18, SP 0x455307 c3 RET main和create的栈分布。 | runtime.main callback ------------------------- +40 +08 | runtime.main BP ------------------------- BP ------------ +38 +00 | \u0026amp;funcval c.r main.main栈 ------------------------- SP ------------ +30 | main.main callback ------------------------- +28 | main.main BP ------------------------- BP ------------ +20 | *int -\u0026gt; 2 c ------------------------- +18 | \u0026amp;funcval c.o ------------------------- +10 | \u0026amp;funcval c.r ------------------------- +08 | ------------------------- +00 | ------------------------- SP ------------ 调用 通过Function Value调用函数时，会把对应的funcval结构体地址存入特定寄存器，如amd64平台使用的是DX寄存器，参看上面的汇编确实使用DX寄存器存储的。 继续使用闭包的示例，通过f1调用闭包函数时，会把f1存储的funcval结构体地址存入寄存器DX，这样在闭包函数的指令中就可以通过这个寄存器存储的地址加上8字节的偏移，就找到f1的捕获变量了。 同样的，通过f2调用闭包函数时，会把f2存储的funcval结构体地址存入寄存器，闭包函数执行时找到的就是f2的捕获变量了。 如果是没有捕获列表的Function Value，直接忽略这个寄存器即可。 通过这样的方式，Go语言实现了对Function Value的统一调用。 静态分配 对于没有捕获列表的Function Value，如果多个变量关联到同一个函数，编译器会做出优化，让它们共用一个funcval结构体。 注意 funcval 后面存储的是捕获的参数，实际传参不在这里，在调用该函数时在调用栈上。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 func A(i int) { i++ fmt.Println(i) } func B(){ f1 := A f1(1) } func C(){ f2 := A f2(1) } 像上面这种情况，编译阶段会创建一个funcval结构体放到只读数据段，而执行阶段，f1和f2都会使用它。 静态分配验证 1 2 3 4 5 6 7 8 9 10 11 package main func main() { f1 := A f1(1) } //go:noinline func A(i int) { i++ } main 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7632 JBE 0x455218 0x4551e6 4883ec18 SUBQ $0x18, SP 0x4551ea 48896c2410 MOVQ BP, 0x10(SP) 0x4551ef 488d6c2410 LEAQ 0x10(SP), BP f1 := A 0x4551f4 488d15251d0100 LEAQ 0x11d25(IP), DX # DX=\u0026amp;funcval 0x4551fb 4889542408 MOVQ DX, 0x8(SP) f1(1) 0x455200 488b0d191d0100 MOVQ 0x11d19(IP), CX # CX=funcval.fn，函数A的地址 0x455207 b801000000 MOVL $0x1, AX # AX=0x1，参数 0x45520c ffd1 CALL CX } 0x45520e 488b6c2410 MOVQ 0x10(SP), BP 0x455213 4883c418 ADDQ $0x18, SP 0x455217 c3 RET func main() { 0x455218 e843cdffff CALL runtime.morestack_noctxt.abi0(SB) 0x45521d ebc1 JMP main.main(SB) A 函数汇编代码。 1 2 3 4 5 6 7 8 TEXT main.A(SB) /mnt/hgfs/g/hello1/func1.go func A(i int) { 0x455220 4889442408 MOVQ AX, 0x8(SP) i++ 0x455225 48ffc0 INCQ AX 0x455228 4889442408 MOVQ AX, 0x8(SP) } 0x45522d c3 RET main和A的栈分布。 | runtime.main callback ------------------------------- +10 | runtime.main BP ------------------------------- BP +08 | 0x11d25(IP) A ------------------------------- +00 | ------------------------------- SP 捕获列表 因为捕获列表需要由闭包对象各自持有，所以有捕获列表的Function Value要到执行阶段才会在堆上分配对应的funcval结构体以及捕获列表空间。 但是，捕获列表里存什么？直接拷贝捕获变量值吗？才没有那么简单。 闭包捕获的变量要在闭包函数和外层函数中表现一致，如果单纯值拷贝，就无法保证这一点，所以编译器针对捕获变量的不同情况分别做出了不同的处理。 捕获变量【除了初始化赋值外在任何地方都没有被修改过，那就可以直接拷贝值】，因为它不会再变化。 捕获变量除了初始化赋值外，还被修改过，就要再细分了。 捕获局部变量 这个例子中，被捕获的是局部变量i，除了初始化赋值外还被修改过，所以局部变量i改为堆分配，栈上只存一个地址。 在这个示例中，为了让被捕获的局部变量在闭包函数和外层函数中保持一致，本该在栈上分配的局部变量被分配到堆上，这其实也是变量逃逸的一种场景。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func create() (fs [2]func()){ for i := 0; i \u0026lt; 2; i++ { // struct { F uintptr; i *int } fs[i] = func(){ fmt.Println(\u0026amp;i, i) } } return } func main() { fs := create() for i := 0; i \u0026lt; len(fs); i++ { fs[i]() } // Output: // 0xc0000ac058 2 // 0xc0000ac058 2 } 捕获局部变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main func main() { fs := create() for i := 0; i \u0026lt; len(fs); i++ { fs[i]() } } //go:noinline func create() (fs [2]func()) { for i := 0; i \u0026lt; 2; i++ { // 堆分配 struct { F uintptr; i *int } fs[i] = func() { i++ } } return } main 汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7675 JBE 0x45525b 0x4551e6 4883ec30 SUBQ $0x30, SP 0x4551ea 48896c2428 MOVQ BP, 0x28(SP) 0x4551ef 488d6c2428 LEAQ 0x28(SP), BP fs := create() 0x4551f4 e887000000 CALL main.create(SB) # 调用main.create 0x4551f9 0f100424 MOVUPS 0(SP), X0 # 将0(SP)后16B内容放入X0，这里的两行代码相当于fs赋值 0x4551fd 0f11442418 MOVUPS X0, 0x18(SP) # 将X0迁移到0x18(SP)后16B for i := 0; i \u0026lt; len(fs); i++ { 0x455202 48c744241000000000 MOVQ $0x0, 0x10(SP) # i初始化 0 0x45520b eb00 JMP 0x45520d 0x45520d 48837c241002 CMPQ $0x2, 0x10(SP) # i和0x2比较 \u0026lt;--- 循环判断条件 0x455213 7c02 JL 0x455217 0x455215 eb2f JMP 0x455246 fs[i]() 0x455217 488b442410 MOVQ 0x10(SP), AX # AX=0 0x45521c 0f1f4000 NOPL 0(AX) 0x455220 4883f802 CMPQ $0x2, AX 0x455224 7202 JB 0x455228 0x455226 eb28 JMP 0x455250 0x455228 488d44c418 LEAQ 0x18(SP)(AX*8), AX # AX=\u0026amp;funcval 0x45522d 488b10 MOVQ 0(AX), DX # DX=\u0026amp;funcval.fn 0x455230 488b02 MOVQ 0(DX), AX # AX=funcval.fn 0x455233 ffd0 CALL AX # 调用函数 0x455235 eb00 JMP 0x455237 for i := 0; i \u0026lt; len(fs); i++ { 0x455237 488b5c2410 MOVQ 0x10(SP), BX # BX=0 0x45523c 48ffc3 INCQ BX # BX=1 0x45523f 48895c2410 MOVQ BX, 0x10(SP) # i=1 0x455244 ebc7 JMP 0x45520d # \u0026lt;--- 一轮循环结束跳转循环开头 } 0x455246 488b6c2428 MOVQ 0x28(SP), BP 0x45524b 4883c430 ADDQ $0x30, SP 0x45524f c3 RET fs[i]() 0x455250 b902000000 MOVL $0x2, CX 0x455255 e866d4ffff CALL runtime.panicIndex(SB) 0x45525a 90 NOPL func main() { 0x45525b 0f1f440000 NOPL 0(AX)(AX*1) 0x455260 e8fbccffff CALL runtime.morestack_noctxt.abi0(SB) 0x455265 e976ffffff JMP main.main(SB) create 汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 func create() (fs [2]func()) { 0x455280 493b6610 CMPQ 0x10(R14), SP 0x455284 0f86d0000000 JBE 0x45535a 0x45528a 4883ec28 SUBQ $0x28, SP 0x45528e 48896c2420 MOVQ BP, 0x20(SP) 0x455293 488d6c2420 LEAQ 0x20(SP), BP 0x455298 440f117c2430 MOVUPS X15, 0x30(SP) # 0x30(SP)开始的16B地址清零 for i := 0; i \u0026lt; 2; i++ { 0x45529e 488d059b4a0000 LEAQ 0x4a9b(IP), AX # AX=0x4a9b(IP)，int的元类型 \u0026lt;--- 变量i初始化 0x4552a5 e8965cfbff CALL runtime.newobject(SB) # 变量i申请内存，AX返回 *int 0x4552aa 4889442418 MOVQ AX, 0x18(SP) 0x4552af 48c70000000000 MOVQ $0x0, 0(AX) # i变量赋值0 0x4552b6 eb00 JMP 0x4552b8 0x4552b8 488b4c2418 MOVQ 0x18(SP), CX # CX=\u0026amp;i \u0026lt;--- 循环从这里开始，后面满足条件会跳转回来 0x4552bd 48833902 CMPQ $0x2, 0(CX) # i与2比较 0x4552c1 7c05 JL 0x4552c8 0x4552c3 e97d000000 JMP 0x455345 fs[i] = func() { # struct { F uintptr; i *int } 0x4552c8 488d0511740000 LEAQ 0x7411(IP), AX # AX=0x7411(IP)，funcval元类型 内存16B 0x4552cf e86c5cfbff CALL runtime.newobject(SB) # 申请内存16B，AX=\u0026amp;funcval 0x4552d4 4889442410 MOVQ AX, 0x10(SP) 0x4552d9 488d0da0000000 LEAQ main.create.func1(SB), CX # CX=main.create.func1 0x4552e0 488908 MOVQ CX, 0(AX) # funcval.fn=main.create.func1 0x4552e3 488b4c2410 MOVQ 0x10(SP), CX # CX=\u0026amp;funcval 0x4552e8 8401 TESTB AL, 0(CX) 0x4552ea 488b542418 MOVQ 0x18(SP), DX # DX=\u0026amp;int 0x4552ef 488d7908 LEAQ 0x8(CX), DI # DI=funcval.data 0x4552f3 833d661f090000 CMPL $0x0, runtime.writeBarrier(SB) # 检查写屏障 0x4552fa 7402 JE 0x4552fe 0x4552fc eb06 JMP 0x455304 0x4552fe 48895108 MOVQ DX, 0x8(CX) # funcval.data=\u0026amp;int 0x455302 eb07 JMP 0x45530b 0x455304 e837d0ffff CALL runtime.gcWriteBarrierDX(SB) # 调用写屏障函数 0x455309 eb00 JMP 0x45530b 0x45530b 488b542418 MOVQ 0x18(SP), DX # DX=\u0026amp;int 0x455310 488b02 MOVQ 0(DX), AX # AX=0 0x455313 488b542410 MOVQ 0x10(SP), DX # DX=\u0026amp;funcval 0x455318 4883f802 CMPQ $0x2, AX # AX和2比较 0x45531c 7204 JB 0x455322 0x45531e 6690 NOPW 0x455320 eb2d JMP 0x45534f 0x455322 488d4cc430 LEAQ 0x30(SP)(AX*8), CX # CX=0x30(SP)(AX*8)，AX=0 -\u0026gt; 0x30(SP)，AX=1 -\u0026gt; 0x38(SP) 0x455327 488911 MOVQ DX, 0(CX) # 返回数组遍历赋值 0x45532a eb00 JMP 0x45532c for i := 0; i \u0026lt; 2; i++ { 0x45532c 488b4c2418 MOVQ 0x18(SP), CX # CX=\u0026amp;int 0x455331 488b09 MOVQ 0(CX), CX # CX=0 0x455334 488b542418 MOVQ 0x18(SP), DX # DX=\u0026amp;int 0x455339 48ffc1 INCQ CX # CX=1 0x45533c 48890a MOVQ CX, 0(DX) # i赋值1 0x45533f 90 NOPL 0x455340 e973ffffff JMP 0x4552b8 # 跳转到前面开始下一轮循环 return 0x455345 488b6c2420 MOVQ 0x20(SP), BP 0x45534a 4883c428 ADDQ $0x28, SP 0x45534e c3 RET fs[i] = func() { 0x45534f b902000000 MOVL $0x2, CX 0x455354 e867d3ffff CALL runtime.panicIndex(SB) 0x455359 90 NOPL func create() (fs [2]func()) { 0x45535a e801ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x45535f 90 NOPL 0x455360 e91bffffff JMP main.create(SB) main和create的栈布局。 | runtime.main callback --------------------------- +58 +28 | runtime.main BP --------------------------- BP --------------- +50 +20 | \u0026amp;funcval c.r --------------------------- +48 +18 | \u0026amp;funcval c.r --------------------------- +40 +10 | 0x0 i main.main栈 --------------------------- +38 +08 | \u0026amp;funcval fs[1] --------------------------- +30 +00 | \u0026amp;funcval fs[0] --------------------------- SP --------------- +28 | main.main callback --------------------------- +20 | main.main BP --------------------------- BP --------------- +18 | *int -\u0026gt; 0 1 i --------------------------- +10 | \u0026amp;funcval --------------------------- main.create栈 +08 | --------------------------- +00 | --------------------------- SP --------------- 捕获参数 如果是参数被捕获，那么调用者依然从栈上传递参数，但是被调用函数会把它拷贝到堆上一份，然后和闭包函数都使用堆上分配的那一个。\n值传递参数时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func Te1(a int) func() int { // 此时的a参数在堆上分配 // 返回闭包捕获了函数参数，参数a会被复制到堆上供整个Te1函数及返回闭包使用 // 堆分配 struct { F uintptr; a *int } return func() int { a++ return a } } func main() { var a1 int f := Te1(a1) fmt.Println(f()) // 1 fmt.Println(a1) // 0 // 可以看出 参数被闭包捕获关系的只是捕获函数内相关参数，参看下面汇编 } 值传递参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main func main() { a1 := 1 b := Te1(a1) b() } //go:noinline func Te1(a int) func() int { // 返回闭包捕获了函数参数 // 参数a会被复制到堆上供整个Te1函数及返回闭包使用 // struct { F uintptr; a *int } // 根据汇编可见，Te1堆分配了a，并把传入的参数1拷贝给了a。 return func() int { a++ return a } } main 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7638 JBE 0x45521e 0x4551e6 4883ec20 SUBQ $0x20, SP 0x4551ea 48896c2418 MOVQ BP, 0x18(SP) 0x4551ef 488d6c2418 LEAQ 0x18(SP), BP a1 := 1 0x4551f4 48c744240801000000 MOVQ $0x1, 0x8(SP) # a1=1 b := Te1(a1) 0x4551fd b801000000 MOVL $0x1, AX # AX=0x1 0x455202 e839000000 CALL main.Te1(SB) # 调用函数 0x455207 4889442410 MOVQ AX, 0x10(SP) b() 0x45520c 488b08 MOVQ 0(AX), CX # CX=funcval.fn 0x45520f 4889c2 MOVQ AX, DX # DX=\u0026amp;funcval 0x455212 ffd1 CALL CX } 0x455214 488b6c2418 MOVQ 0x18(SP), BP 0x455219 4883c420 ADDQ $0x20, SP 0x45521d c3 RET func main() { 0x45521e 6690 NOPW 0x455220 e83bcdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455225 ebb9 JMP main.main(SB) main.Te1 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 func Te1(a int) func() int { 0x455240 493b6610 CMPQ 0x10(R14), SP 0x455244 0f8691000000 JBE 0x4552db 0x45524a 4883ec30 SUBQ $0x30, SP 0x45524e 48896c2428 MOVQ BP, 0x28(SP) 0x455253 488d6c2428 LEAQ 0x28(SP), BP 0x455258 4889442438 MOVQ AX, 0x38(SP) # 参数a 0x45525d 48c744241000000000 MOVQ $0x0, 0x10(SP) 0x455266 488d05d34a0000 LEAQ 0x4ad3(IP), AX # AX=0x4ad3(IP)，int元类型，参数a堆分配 0x45526d e8ce5cfbff CALL runtime.newobject(SB) # 申请内存 AX=\u0026amp;int *int 0x455272 4889442420 MOVQ AX, 0x20(SP) # 堆分配的变量a *int 0x455277 488b4c2438 MOVQ 0x38(SP), CX # CX=1 0x45527c 488908 MOVQ CX, 0(AX) # AX=\u0026amp;int -\u0026gt; 1 return func() int { # struct { F uintptr; a *int } 0x45527f 488d055a740000 LEAQ 0x745a(IP), AX # AX=0x745a(IP)，funcval结构体元类型，占16B 0x455286 e8b55cfbff CALL runtime.newobject(SB) # 申请内存，AX=\u0026amp;funcval 0x45528b 4889442418 MOVQ AX, 0x18(SP) 0x455290 488d0d69000000 LEAQ main.Te1.func1(SB), CX # CX=main.Te1.func1 0x455297 488908 MOVQ CX, 0(AX) # funcval.fn=main.Te1.func1 0x45529a 488b4c2418 MOVQ 0x18(SP), CX # CX=\u0026amp;funcval 0x45529f 8401 TESTB AL, 0(CX) 0x4552a1 488b542420 MOVQ 0x20(SP), DX # DX=\u0026amp;int 0x4552a6 488d7908 LEAQ 0x8(CX), DI # DI=funcval.data 0x4552aa 833daf1f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x4552b1 7402 JE 0x4552b5 0x4552b3 eb0b JMP 0x4552c0 0x4552b5 48895108 MOVQ DX, 0x8(CX) # funcval.data=\u0026amp;int 0x4552b9 eb0c JMP 0x4552c7 0x4552bb 0f1f440000 NOPL 0(AX)(AX*1) 0x4552c0 e87bd0ffff CALL runtime.gcWriteBarrierDX(SB) 0x4552c5 eb00 JMP 0x4552c7 0x4552c7 488b442418 MOVQ 0x18(SP), AX # AX=\u0026amp;funcval 0x4552cc 4889442410 MOVQ AX, 0x10(SP) 0x4552d1 488b6c2428 MOVQ 0x28(SP), BP 0x4552d6 4883c430 ADDQ $0x30, SP 0x4552da c3 RET func Te1(a int) func() int { 0x4552db 4889442408 MOVQ AX, 0x8(SP) 0x4552e0 e87bccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552e5 488b442408 MOVQ 0x8(SP), AX 0x4552ea e951ffffff JMP main.Te1(SB) main.Te1.func1 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 TEXT main.Te1.func1(SB) /mnt/hgfs/workspace/helium/main.go return func() int { 0x455300 4883ec18 SUBQ $0x18, SP 0x455304 48896c2410 MOVQ BP, 0x10(SP) 0x455309 488d6c2410 LEAQ 0x10(SP), BP 0x45530e 488b4a08 MOVQ 0x8(DX), CX 0x455312 48894c2408 MOVQ CX, 0x8(SP) 0x455317 48c7042400000000 MOVQ $0x0, 0(SP) a++ 0x45531f 488b4c2408 MOVQ 0x8(SP), CX 0x455324 488b09 MOVQ 0(CX), CX 0x455327 488b542408 MOVQ 0x8(SP), DX 0x45532c 48ffc1 INCQ CX 0x45532f 48890a MOVQ CX, 0(DX) return a 0x455332 488b4c2408 MOVQ 0x8(SP), CX 0x455337 488b01 MOVQ 0(CX), AX 0x45533a 48890424 MOVQ AX, 0(SP) 0x45533e 488b6c2410 MOVQ 0x10(SP), BP 0x455343 4883c418 ADDQ $0x18, SP 0x455347 c3 RET 栈布局信息。 +58 +20 | runtime.main callback ---------------------------------- +50 +18 | runtime.main BP ---------------------------------- BP -------------- +48 +10 | \u0026amp;funcval 变量b ---------------------------------- +40 +08 | 0x1 变量a1 main.main栈 ---------------------------------- +38 +00 | 0x1 参数a ---------------------------------- SP -------------- +30 | main.main callback ---------------------------------- +28 | main.main BP ---------------------------------- BP -------------- +20 | \u0026amp;int -\u0026gt; 1 a ---------------------------------- +18 | \u0026amp;funcval r.o ---------------------------------- +10 | \u0026amp;funcval r main.Te1栈 ---------------------------------- +08 | ---------------------------------- +00 | ---------------------------------- SP -------------- 引用传递参数时。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 如果捕获的是指针情况呢，根据下面代码可以看出跟上面情况一样的规则 // 这种情况跟捕获全局变量基本表现一致 func Te1(a *int) func() int { // 返回闭包捕获了函数参数，参数a会被复制到栈上供整个Te1函数及返回闭包使用 // 堆分配 struct { F uintptr; a *int } return func() int { *a++ return *a } } func main() { var a1 int f := Te1(\u0026amp;a1) fmt.Println(a1) // 0 fmt.Println(f()) // 1 fmt.Println(a1) // 1 a1++ fmt.Println(f()) // 3 fmt.Println(a1) // 3 // 注意这里下面的一行代码，会先执行f() f() 在打印所以出现了奇怪的输出 // 因为参数会先被实时计算，因此先执行了f()和f()，然后再打印数据的。 // fmt.Println(a1, f(), a1, f(), a1) // 2 1 2 2 2 } 引用传递参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main func main() { a1 := 1 b := Te1(\u0026amp;a1) b() } //go:noinline func Te1(a *int) func() int { // 返回闭包捕获了函数参数 // 参数a会被复制到堆上供整个Te1函数及返回闭包使用 // struct { F uintptr; a *int } return func() int { *a++ return *a } } main 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 764c JBE 0x455232 0x4551e6 4883ec28 SUBQ $0x28, SP 0x4551ea 48896c2420 MOVQ BP, 0x20(SP) 0x4551ef 488d6c2420 LEAQ 0x20(SP), BP a1 := 1 # 这里可以看出，直接就给a堆分配了 0x4551f4 488d05454b0000 LEAQ 0x4b45(IP), AX # AX=0x4b45(IP)，int元类型 0x4551fb 0f1f440000 NOPL 0(AX)(AX*1) 0x455200 e83b5dfbff CALL runtime.newobject(SB) # AX=\u0026amp;int 0x455205 4889442418 MOVQ AX, 0x18(SP) 0x45520a 48c70001000000 MOVQ $0x1, 0(AX) # a=1 b := Te1(\u0026amp;a1) 0x455211 488b442418 MOVQ 0x18(SP), AX # AX=\u0026amp;int 0x455216 e825000000 CALL main.Te1(SB) # 调用函数，AX=\u0026amp;funcval 0x45521b 4889442410 MOVQ AX, 0x10(SP) b() 0x455220 488b08 MOVQ 0(AX), CX # CX=funcval.fn 0x455223 4889c2 MOVQ AX, DX # DX=\u0026amp;funcval 0x455226 ffd1 CALL CX # 调用函数 } 0x455228 488b6c2420 MOVQ 0x20(SP), BP 0x45522d 4883c428 ADDQ $0x28, SP 0x455231 c3 RET func main() { 0x455232 e829cdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455237 eba7 JMP main.main(SB) main.Te1 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 func Te1(a *int) func() int { 0x455240 493b6610 CMPQ 0x10(R14), SP 0x455244 7675 JBE 0x4552bb 0x455246 4883ec28 SUBQ $0x28, SP 0x45524a 48896c2420 MOVQ BP, 0x20(SP) 0x45524f 488d6c2420 LEAQ 0x20(SP), BP 0x455254 4889442430 MOVQ AX, 0x30(SP) # 参数a *int 0x455259 48c744241000000000 MOVQ $0x0, 0x10(SP) # 返回值 func() int return func() int { # struct { F uintptr; i *int } 0x455262 488d0577740000 LEAQ 0x7477(IP), AX # AX=0x7477(IP)，funcval结构体 16B 0x455269 e8d25cfbff CALL runtime.newobject(SB # AX=\u0026amp;funcval 0x45526e 4889442418 MOVQ AX, 0x18(SP) 0x455273 488d0d66000000 LEAQ main.Te1.func1(SB), CX # CX=main.Te1.func1 0x45527a 488908 MOVQ CX, 0(AX) # funcval.fn=main.Te1.func1 0x45527d 488b4c2418 MOVQ 0x18(SP), CX # CX=\u0026amp;funcval 0x455282 8401 TESTB AL, 0(CX) 0x455284 488b542430 MOVQ 0x30(SP), DX # DX=\u0026amp;int 0x455289 488d7908 LEAQ 0x8(CX), DI # DI=funcval.data 0x45528d 833dcc1f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x455294 7402 JE 0x455298 0x455296 eb08 JMP 0x4552a0 0x455298 48895108 MOVQ DX, 0x8(CX) # funcval.data=\u0026amp;int 0x45529c eb09 JMP 0x4552a7 0x45529e 6690 NOPW 0x4552a0 e89bd0ffff CALL runtime.gcWriteBarrierDX(SB) 0x4552a5 eb00 JMP 0x4552a7 0x4552a7 488b442418 MOVQ 0x18(SP), AX # AX=\u0026amp;funcval 0x4552ac 4889442410 MOVQ AX, 0x10(SP) 0x4552b1 488b6c2420 MOVQ 0x20(SP), BP 0x4552b6 4883c428 ADDQ $0x28, SP 0x4552ba c3 RET main.Te1.func1 函数汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func Te1(a *int) func() int { 0x4552bb 4889442408 MOVQ AX, 0x8(SP) 0x4552c0 e89bccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552c5 488b442408 MOVQ 0x8(SP), AX 0x4552ca e971ffffff JMP main.Te1(SB) return func() int { 0x4552e0 4883ec18 SUBQ $0x18, SP 0x4552e4 48896c2410 MOVQ BP, 0x10(SP) 0x4552e9 488d6c2410 LEAQ 0x10(SP), BP 0x4552ee 488b4a08 MOVQ 0x8(DX), CX # CX=\u0026amp;int 0x4552f2 48894c2408 MOVQ CX, 0x8(SP) 0x4552f7 48c7042400000000 MOVQ $0x0, 0(SP) *a++ 0x4552ff 488b4c2408 MOVQ 0x8(SP), CX # CX=\u0026amp;int 0x455304 8401 TESTB AL, 0(CX) 0x455306 488b542408 MOVQ 0x8(SP), DX # DX=\u0026amp;int 0x45530b 8402 TESTB AL, 0(DX) 0x45530d 488b09 MOVQ 0(CX), CX # CX=1 0x455310 48ffc1 INCQ CX # CX=2 0x455313 48890a MOVQ CX, 0(DX) # \u0026amp;int -\u0026gt; 2 return *a 0x455316 488b4c2408 MOVQ 0x8(SP), CX # CX=\u0026amp;int 0x45531b 8401 TESTB AL, 0(CX) 0x45531d 488b01 MOVQ 0(CX), AX # AX=2 0x455320 48890424 MOVQ AX, 0(SP) 0x455324 488b6c2410 MOVQ 0x10(SP), BP 0x455329 4883c418 ADDQ $0x18, SP 0x45532d c3 RET 栈分布情况。 +58 +28 | address of runtime.main ------------------------------ +50 +20 | BP of runtime.main ------------------------------ BP +48 +18 | \u0026amp;int -\u0026gt; 1 a1 ------------------------------ +40 +10 | \u0026amp;funcval b ------------------------------ +38 +08 | ------------------------------ +30 +00 | \u0026amp;int T.a ------------------------------ SP +28 | address of main.main ------------------------------ +20 | BP of main.main ------------------------------ BP +18 | \u0026amp;funcval T.o ------------------------------ +10 | \u0026amp;funcval T.r ------------------------------ +08 | ------------------------------ +00 | ------------------------------ SP 捕获返回值 如果是返回值被捕获，那么处理方式就又有些不同了。 返回值空间依然由调用者在栈上分配，但是被调用函数（闭包的外层函数）会在堆上也分配一个，并且与闭包函数都使用堆上这一个，但是，在外层函数返回前要把堆上的返回值拷贝到栈上那一个。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main func main() { b, _ := Te1() b() } //go:noinline func Te1() (y func() int, y1 int) { y1++ // 1 // 堆分配 struct { F uintptr; y1 *int } return func() int { y1++ return 1 }, y1 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 763b JBE 0x455221 0x4551e6 4883ec18 SUBQ $0x18, SP 0x4551ea 48896c2410 MOVQ BP, 0x10(SP) 0x4551ef 488d6c2410 LEAQ 0x10(SP), BP b, _ := Te1() 0x4551f4 48c744240800000000 MOVQ $0x0, 0x8(SP) 0x4551fd 0f1f00 NOPL 0(AX) 0x455200 e83b000000 CALL main.Te1(SB) 0x455205 4889442408 MOVQ AX, 0x8(SP) 0x45520a 48890424 MOVQ AX, 0(SP) b() 0x45520e 488b1424 MOVQ 0(SP), DX 0x455212 488b02 MOVQ 0(DX), AX 0x455215 ffd0 CALL AX } 0x455217 488b6c2410 MOVQ 0x10(SP), BP 0x45521c 4883c418 ADDQ $0x18, SP 0x455220 c3 RET func main() { 0x455221 e83acdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455226 ebb8 JMP main.main(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 func Te1() (y func() int, y1 int) { 0x455240 493b6610 CMPQ 0x10(R14), SP 0x455244 0f868e000000 JBE 0x4552d8 0x45524a 4883ec30 SUBQ $0x30, SP 0x45524e 48896c2428 MOVQ BP, 0x28(SP) 0x455253 488d6c2428 LEAQ 0x28(SP), BP 0x455258 48c744241000000000 MOVQ $0x0, 0x10(SP) 0x455261 488d05d84a0000 LEAQ 0x4ad8(IP), AX # AX=0x4ad8(IP)，int元类型 0x455268 e8d35cfbff CALL runtime.newobject(SB) # AX=\u0026amp;int 0x45526d 4889442420 MOVQ AX, 0x20(SP) y1++ 0x455272 48ff00 INCQ 0(AX) # y1=1 return func() int { # struct { F uintptr; y1 *int } 0x455275 488d0564740000 LEAQ 0x7464(IP), AX # AX=0x7464(IP)，funcval元类型 16B 0x45527c 0f1f4000 NOPL 0(AX) 0x455280 e8bb5cfbff CALL runtime.newobject(SB) # AX=\u0026amp;funcval 0x455285 4889442418 MOVQ AX, 0x18(SP) 0x45528a 488d0d6f000000 LEAQ main.Te1.func1(SB), CX # CX=main.Te1.func1 0x455291 488908 MOVQ CX, 0(AX) # funcval.fn=main.Te1.func1 0x455294 488b4c2418 MOVQ 0x18(SP), CX # CX=\u0026amp;funcval 0x455299 8401 TESTB AL, 0(CX) 0x45529b 488b542420 MOVQ 0x20(SP), DX # DX=\u0026amp;int 0x4552a0 488d7908 LEAQ 0x8(CX), DI # DI=funcval.data 0x4552a4 833db51f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x4552ab 7402 JE 0x4552af 0x4552ad eb06 JMP 0x4552b5 0x4552af 48895108 MOVQ DX, 0x8(CX) # funcval.data=\u0026amp;int 0x4552b3 eb07 JMP 0x4552bc 0x4552b5 e886d0ffff CALL runtime.gcWriteBarrierDX(SB) 0x4552ba eb00 JMP 0x4552bc 0x4552bc 488b442418 MOVQ 0x18(SP), AX # AX=\u0026amp;funcval 返回参数1 0x4552c1 4889442410 MOVQ AX, 0x10(SP) 0x4552c6 488b4c2420 MOVQ 0x20(SP), CX # CX=\u0026amp;int 0x4552cb 488b19 MOVQ 0(CX), BX # BX=1 返回参数2 0x4552ce 488b6c2428 MOVQ 0x28(SP), BP 0x4552d3 4883c430 ADDQ $0x30, SP 0x4552d7 c3 RET func Te1() (y func() int, y1 int) { 0x4552d8 e883ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x4552dd 0f1f00 NOPL 0(AX) 0x4552e0 e95bffffff JMP main.Te1(SB) +50 +18 | address of runtime.main ----------------------------- +48 +10 | BP of runtime.main ----------------------------- BP +40 +08 | 0 ----------------------------- +38 +00 | ----------------------------- SP +30 | address of main.main ----------------------------- +28 | BP of main.main ----------------------------- BP +20 | \u0026amp;int 1 y1 ----------------------------- +18 | \u0026amp;funcval y ----------------------------- +10 | \u0026amp;funcval ----------------------------- +08 | ----------------------------- +00 | ----------------------------- SP 自己捕获自己 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package main func main() { x()() } //go:noinline func x() (y func()) { // struct { F uintptr } y = func() { //println(\u0026#34;y\u0026#34;) } // defer在return赋值完成之后执行 //defer func() { //\ty = func() { // fmt.Println(\u0026#34;我能改变了Y的值？\u0026#34;) //\t} //}() // struct { F uintptr; y *func() } return func() { //println(\u0026#34;z\u0026#34;) y() } } main 汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main() { 0x4551e0 493b6610 CMPQ 0x10(R14), SP 0x4551e4 7629 JBE 0x45520f 0x4551e6 4883ec10 SUBQ $0x10, SP 0x4551ea 48896c2408 MOVQ BP, 0x8(SP) 0x4551ef 488d6c2408 LEAQ 0x8(SP), BP x()() 0x4551f4 e847000000 CALL main.x(SB) # AX=\u0026amp;funcval 0x4551f9 48890424 MOVQ AX, 0(SP) 0x4551fd 488b08 MOVQ 0(AX), CX # CX=funcval.fn 0x455200 4889c2 MOVQ AX, DX # DX=\u0026amp;funcval 0x455203 ffd1 CALL CX } 0x455205 488b6c2408 MOVQ 0x8(SP), BP 0x45520a 4883c410 ADDQ $0x10, SP 0x45520e c3 RET func main() { 0x45520f e84ccdffff CALL runtime.morestack_noctxt.abi0(SB) 0x455214 ebca JMP main.main(SB) x 汇编代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 func x() (y func()) { 0x455240 493b6610 CMPQ 0x10(R14), SP 0x455244 0f86bf000000 JBE 0x455309 0x45524a 4883ec28 SUBQ $0x28, SP 0x45524e 48896c2420 MOVQ BP, 0x20(SP) 0x455253 488d6c2420 LEAQ 0x20(SP), BP # func() 变量y 0x455258 488d05e1480000 LEAQ 0x48e1(IP), AX # AX=0x48e1(IP)，funcval元类型 0x45525f 90 NOPL 0x455260 e8db5cfbff CALL runtime.newobject(SB) # AX=\u0026amp;funcval 0x455265 4889442418 MOVQ AX, 0x18(SP) y = func() { 0x45526a 833def1f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x455271 7402 JE 0x455275 0x455273 eb0d JMP 0x455282 # funcval.fn -\u0026gt; println(\u0026#34;y\u0026#34;) 替换 y 0x455275 488d0d841d0100 LEAQ 0x11d84(IP), CX # CX=0x11d84(IP)，函数代码处 0x45527c 488908 MOVQ CX, 0(AX) # funcval.fn=0x11d84(IP) 0x45527f 90 NOPL 0x455280 eb11 JMP 0x455293 0x455282 4889c7 MOVQ AX, DI 0x455285 488d0d741d0100 LEAQ 0x11d74(IP), CX 0x45528c e88fd0ffff CALL runtime.gcWriteBarrierCX(SB) 0x455291 eb00 JMP 0x455293 return func() { # struct { F uintptr; y *func() } 0x455293 488d0586740000 LEAQ 0x7486(IP), AX # AX=0x7486(IP)，funcval元类型 16B 0x45529a e8a15cfbff CALL runtime.newobject(SB) # AX=\u0026amp;funcval.1 0x45529f 4889442410 MOVQ AX, 0x10(SP) 0x4552a4 488d0d75000000 LEAQ main.x.func2(SB), CX # CX=main.x.func2 0x4552ab 488908 MOVQ CX, 0(AX) # funcval.1.fn=main.x.func2 0x4552ae 488b4c2410 MOVQ 0x10(SP), CX # CX=\u0026amp;funcval.1 0x4552b3 8401 TESTB AL, 0(CX) 0x4552b5 488b542418 MOVQ 0x18(SP), DX # DX=\u0026amp;funcval 0x4552ba 488d7908 LEAQ 0x8(CX), DI # DI=funcval.1.data 0x4552be 833d9b1f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x4552c5 7402 JE 0x4552c9 0x4552c7 eb06 JMP 0x4552cf 0x4552c9 48895108 MOVQ DX, 0x8(CX) # funcval.1.data=\u0026amp;funcval 0x4552cd eb07 JMP 0x4552d6 0x4552cf e86cd0ffff CALL runtime.gcWriteBarrierDX(SB) 0x4552d4 eb00 JMP 0x4552d6 0x4552d6 488b7c2418 MOVQ 0x18(SP), DI # DI=\u0026amp;funcval 0x4552db 488b4c2410 MOVQ 0x10(SP), CX # CX=\u0026amp;funcval.1 0x4552e0 833d791f090000 CMPL $0x0, runtime.writeBarrier(SB) 0x4552e7 7402 JE 0x4552eb 0x4552e9 eb05 JMP 0x4552f0 0x4552eb 48890f MOVQ CX, 0(DI) # funcval.fn=\u0026amp;funcval.1 0x4552ee eb07 JMP 0x4552f7 0x4552f0 e82bd0ffff CALL runtime.gcWriteBarrierCX(SB) 0x4552f5 eb00 JMP 0x4552f7 0x4552f7 488b4c2418 MOVQ 0x18(SP), CX # CX=\u0026amp;funcval 0x4552fc 488b01 MOVQ 0(CX), AX # AX=funcval.fn 0x4552ff 488b6c2420 MOVQ 0x20(SP), BP 0x455304 4883c428 ADDQ $0x28, SP 0x455308 c3 RET func x() (y func()) { 0x455309 e852ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x45530e e92dffffff JMP main.x(SB) unsafe Go语言里Function Value本质上是指向funcval结构体的指针 Go语言里闭包只是拥有捕获列表的Function Value 捕获变量在外层函数与闭包函数中要保持一致 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type fv struct { fn unsafe.Pointer i *int // 捕获的变量i } func main() { g := callback() fn := **(**fv)(unsafe.Pointer(\u0026amp;g)) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, fn) fmt.Println(*(fn.i)) // 13 // Output: // main.fv{fn:(unsafe.Pointer)(0xeccdc0), i:(*int)(0xc00000a098)} // 13 // 可以看出捕获的是i的地址 } func callback() func() { i := 13 // struct { F uintptr; i *int } return func() { i++ } } 参考 本篇文章参考了《深度探索Go语言》书内容。 参考 https://mp.weixin.qq.com/s/hO0S4WcG0hUzCmMNMKtS-g。 ","permalink":"https://heliu.site/posts/golang/func/value/","summary":"本篇介绍闭包的组成结构。","title":"Function Value"},{"content":"defer 的三个规则：\n规则一：defer 声明时，其后面函数参数会被实时解析。 规则二：defer 执行顺序为先进后出（FILO）(First Insert Last Out)。 规则三：defer 可以读取函数的有名返回值。 defer函数参数会被实时解析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package main import \u0026#34;fmt\u0026#34; func main() { var i int = 1 // 规则一：当defer被声明时，其后面函数参数会被实时解析 // 注意，fmt.Println 在defer后面，它的参数会实时计算 // 输出：result =\u0026gt; 2 (而不是4) defer fmt.Println(\u0026#34;result1 =\u0026gt;\u0026#34;, func() int {return i*2}()) i++ // 【闭包中的i在后面有修改，所以闭包捕获的是变量i的地址】 // 所以闭包执行时，i的值为3 // struct { F uintptr; i *int } defer func() { fmt.Println(\u0026#34;result2 =\u0026gt;\u0026#34;, i*2) }() i++ // Output: // result2 =\u0026gt; 6 // result1 =\u0026gt; 2 } defer执行顺序是先进后出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import \u0026#34;fmt\u0026#34; func main() { defer fmt.Print(\u0026#34; !!! \u0026#34;) defer fmt.Print(\u0026#34; world \u0026#34;) fmt.Print(\u0026#34;hello \u0026#34;) // hello \u0026lt;- world \u0026lt;- !!! // 注册顺序：\u0026lt;----------------------- // 执行顺序：-----------------------\u0026gt; // Output: // hello world !!! } defer可以读取函数的有名返回值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;result2 =\u0026gt;\u0026#34;, fun1()) // Output: // result2 =\u0026gt; 11 } func fun1() (i int) { // 堆分配 struct { F uintptr; i *int } defer func() { i = i + 10 }() return 1 } 汇编代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 TEXT main.fun1(SB) /mnt/hgfs/workspace/helium/main.go func fun1() (i int) { 0x4552e0 493b6610 CMPQ 0x10(R14), SP 0x4552e4 0f868a000000 JBE 0x455374 0x4552ea 4883ec78 SUBQ $0x78, SP 0x4552ee 48896c2470 MOVQ BP, 0x70(SP) 0x4552f3 488d6c2470 LEAQ 0x70(SP), BP 0x4552f8 48c744240800000000 MOVQ $0x0, 0x8(SP) # i int defer func() { 0x455301 440f117c2460 MOVUPS X15, 0x60(SP) 0x455307 488d4c2460 LEAQ 0x60(SP), CX 0x45530c 48894c2458 MOVQ CX, 0x58(SP) 0x455311 8401 TESTB AL, 0(CX) # funcval.fn 0x455313 488d1566000000 LEAQ main.fun1.func1(SB), DX 0x45531a 4889542460 MOVQ DX, 0x60(SP) 0x45531f 8401 TESTB AL, 0(CX) # *int 捕获的是有名返回值地址 0x455321 488d542408 LEAQ 0x8(SP), DX 0x455326 4889542468 MOVQ DX, 0x68(SP) # funcval.data=i *int 0x45532b 48894c2428 MOVQ CX, 0x28(SP) # defer.fn=\u0026amp;funcval 0x455330 488d442410 LEAQ 0x10(SP), AX # AX=0x10(SP)=\u0026amp;_defer # AX 寄存器存储的是runtime.deferprocStack()函数的参数 *_defer 0x455335 e8c650fdff CALL runtime.deferprocStack(SB) # panic流程recover后会恢复到这里，并把AX置为1。 # 正常情况下AX置为0的。 0x45533a 85c0 TESTL AX, AX 0x45533c 7522 JNE 0x455360 0x45533e 6690 NOPW 0x455340 eb00 JMP 0x455342 return 1 0x455342 48c744240801000000 MOVQ $0x1, 0x8(SP) 0x45534b e8d056fdff CALL runtime.deferreturn(SB) 0x455350 488b442408 MOVQ 0x8(SP), AX 0x455355 488b6c2470 MOVQ 0x70(SP), BP 0x45535a 4883c478 ADDQ $0x78, SP 0x45535e c3 RET 0x45535f 90 NOPL defer func() { 0x455360 e8bb56fdff CALL runtime.deferreturn(SB) 0x455365 488b442408 MOVQ 0x8(SP), AX 0x45536a 488b6c2470 MOVQ 0x70(SP), BP 0x45536f 4883c478 ADDQ $0x78, SP 0x455373 c3 RET func fun1() (i int) { 0x455374 e887ccffff CALL runtime.morestack_noctxt.abi0(SB) 0x455379 e962ffffff JMP main.fun1(SB) 1 2 3 4 5 6 7 8 9 10 11 12 13 TEXT main.fun1.func1(SB) /mnt/hgfs/workspace/helium/main.go defer func() { 0x455380 4883ec10 SUBQ $0x10, SP 0x455384 48896c2408 MOVQ BP, 0x8(SP) 0x455389 488d6c2408 LEAQ 0x8(SP), BP 0x45538e 488b4208 MOVQ 0x8(DX), AX # AX=i int 0x455392 48890424 MOVQ AX, 0(SP) i += 10 0x455396 4883000a ADDQ $0xa, 0(AX) }() 0x45539a 488b6c2408 MOVQ 0x8(SP), BP 0x45539f 4883c410 ADDQ $0x10, SP 0x4553a3 c3 RET 由于在Go语言中，return语句不是原子操作，return等函数执行defer和销毁栈等操作。 最先是所有返回值在进入函数时都会初始化为其类型的零值（姑且称为ret赋值） 退出时先给返回值赋值 然后执行defer命令 最后才是return操作，return操作包含两个步骤，一是给被调用栈的返回值赋值，然后执行defer注册函数，二是把被调函数的栈的返回值返回给调用函数 返回值=xxx | v 调用defer() | v return 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;=====================================\u0026#34;) fmt.Println(\u0026#34;fun1 return:\u0026#34;, fun1()) // fun1 return:2 fmt.Println(\u0026#34;=====================================\u0026#34;) fmt.Println(\u0026#34;fun2 return:\u0026#34;, fun2()) // fun2 return:0 fmt.Println(\u0026#34;=====================================\u0026#34;) fmt.Println(\u0026#34;fun3 return:\u0026#34;, fun3()) // fun3 return:5 fmt.Println(\u0026#34;=====================================\u0026#34;) fmt.Println(\u0026#34;fun4 return:\u0026#34;, fun4()) // fun4 return:19 // Output: // ===================================== // fun1 defer1:1 // fun1 defer2:2 // fun1 return:2 // ===================================== // fun2 defer1:1 // fun2 defer2:2 // fun2 return:0 // ===================================== // fun3 defer:10 // fun3 return:5 // ===================================== // fun4 defer:8 // fun4 return:19 } func fun1() (i int) { // struct { F uintptr; i *int } defer func() { i++ fmt.Println(\u0026#34;fun1 defer2:\u0026#34;, i) // fun1 defer2:2 }() // struct { F uintptr; i *int } defer func() { i++ fmt.Println(\u0026#34;fun1 defer1:\u0026#34;, i) // fun1 defer1:1 }() // 这里也是给i赋值 // 当做i=0;return; return 0 } func fun2() int { var i int // struct { F uintptr; i *int } defer func() { i++ fmt.Println(\u0026#34;fun2 defer2:\u0026#34;, i) // fun2 defer2: 2 }() // struct { F uintptr; i *int } defer func() { i++ fmt.Println(\u0026#34;fun2 defer1:\u0026#34;, i) // fun2 defer1: 1 }() return i } func fun3() (r int) { t := 5 // struct { F uintptr; t *int } defer func() { t = t + 5 fmt.Println(\u0026#34;fun3 defer:\u0026#34;, t) // fun3 defer:10 }() return t } func fun4() int { i := 8 // struct { F uintptr, i int } // 因为是显示传参 defer func(i int) { fmt.Println(\u0026#34;fun4 defer:\u0026#34;, i) // fun4 defer:8 }(i) i = 19 return i } 匿名返回值。 defer计算函数执行时间 根据defer延迟执行的特性，可以利用它来计算代码块的执行时间。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { defer timeCost(time.Now()) // 这里利用参数是实时解析的 fmt.Println(\u0026#34;start ...\u0026#34;) time.Sleep(time.Second * 5) fmt.Println(\u0026#34;finish ...\u0026#34;) // Output: // start ... // finish ... // 5.0068172s } func timeCost(start time.Time) { terminal := time.Since(start) // now - start fmt.Println(terminal) } ","permalink":"https://heliu.site/posts/golang/func/defer-use/","summary":"defer 的使用规则介绍。","title":"defer(使用)"},{"content":" 跟在defer后面的函数调用不会立刻执行，像是被注册到了当前函数中，等到当前函数返回之前按照先进后出（First In Last Out）顺序调用所有注册的函数。 defer后出现多次调用，只针对最后那个函数会被延迟。比如 defer fn()()，fn()返回一个闭包函数。 1 2 3 4 5 6 7 // defer fn()() func fn() func() { return func() { println(\u0026#34;defer\u0026#34;) } } 被延迟调用的函数的参数会立刻求值。比如 defer close(getChan())。 注册的defer会在以下三个地方被运行： (1)函数返回也就是 return 时，一般情况在deferreturn()函数中。 (2)panic() 函数触发时。 (3)runtime.Goexit() 函数被调用时。 defer结构 defer存在三种情况： (1)堆分配 defer 结构体，使用 defer 链表。 (2)defer 结构体分配在函数调用栈上，使用 defer 链表。 (3)使用 open-coded defer 形式，不用堆分配也不用 defer 链表。 但是还是需要一个 _defer 结构体记录相关信息，该链表记录在全局链表后面存储的这个函数注册的所有 defer 信息。 该链表在 panic 发生是或 runtime.Goexit() 触发时，通过栈扫描形式被追加到 goroutine._panic 后面。 文件位置：go1.19.3/src/runtime/runtime2.go。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 // A _defer holds an entry on the list of deferred calls. // If you add a field here, add code to clear it in deferProcStack. // This struct must match the code in cmd/compile/internal/ssagen/ssa.go:deferstruct // and cmd/compile/internal/ssagen/ssa.go:(*state).call. // Some defers will be allocated on the stack and some on the heap. // All defers are logically part of the stack, so write barriers to // initialize them are not required. All defers must be manually scanned, // and for heap defers, marked. type _defer struct { // 表示有个 panic 或者 runtime.Goexit() 函数触发开始执行该defer函数。 started bool // started和_panic被用于panic发生时，正常这里是 false // 是否为堆分配，是(true) 否(false) // 1. 堆分配则是通过 deferproc() 函数注册的defer链表 // 2. 栈分配则是通过 deferprocStack() 函数注册defer链表 heap bool // 堆分配时会调用 deferproc() 函数 // openDefer indicates that this _defer is for a frame with open-coded // defers. We have only one defer record for the entire frame (which may // currently have 0, 1, or more defers active). // // 是否是展开方式\topen-coded defer // 展开方式的信息记录在fd、varp、framepc中 openDefer bool // sp和pc用于在发生 panic() 并且有 recover() 函数恢复的情况下程序需要跳转到哪里， // 注意一旦使用这里跳转那么 return0() 函数将返回1表示后面接到执行 deferreturn() 函数。 // getcallersp()函数获取调用者的SP，也就是调用deferproc()函数之前的SP寄存器的值(调用者函数SP寄存器值)， // 用于记录当前函数的rsp栈信息，在deferreturn()函数中用于判断defer是否由当前函数注册。 // 这个值有两个用途： // 1. 在deferreturn()函数执行defer函数时用来判断该defer是不是被当前函数注册的。 // 2. 在执行recover()函数的时候用来还原栈指针。 sp uintptr // sp at time of defer\tSP寄存器的值 // getcallerpc()函数获取调用者指令指针的位置，从调用者视角看来就是CALL runtime.deferproc后面的那条指令的地址 // 主要用途：在执行recover()函数的时候还原IP寄存器指令指针 pc uintptr // pc at time of defer\tIP寄存器的值 // open-coded defers 时该值是nil。 // 注意：在前面1.12版本中fn的类型是*funcval，而这里是func()函数类型， // 所有defer后面的不是func()形式的都会在封装一层，形成Function Value形式。 // 因为存在这样一层封装，旧版的 siz 字段可以丢弃。 fn func() // can be nil for open-coded defers // 是触发defer函数执行的panic指针，正常流程执行defer时它就是nil // _panic的值是在当前goroutine发生panic后，runtime在执行defer函数时，将该指针指向当前的_panic结构 // 有panic触发时，_panic指向触发的panic，记录当前触发这个defer的panic结构体。 _panic *_panic // panic that is running defer // link指针用来指向下一个_defer结构，从而形成链表 link *_defer // next defer on G; can point to either heap or stack!\t// If openDefer is true, the fields below record values about the stack // frame and associated function that has the open-coded defer(s). sp // above will be the sp for the frame, and pc will be address of the // deferreturn call in the function. // // 如果 openDefer 为真，则下面的字段记录有关栈帧和具有open-coded defer的关联函数的值 // 下面字段记录着通过栈扫描形式的所有defer信息，以便执行发生异常是能正确找到所有的defer fd unsafe.Pointer // funcdata for the function associated with the frame\tvarp uintptr // value of varp for the stack frame // framepc is the current pc associated with the stack frame. Together, // with sp above (which is the sp associated with the stack frame), // framepc/sp can be used as pc/sp pair to continue a stack trace via // gentraceback(). framepc uintptr } 堆分配 deferproc() 函数用于注册 defer 函数，也是堆分配的相关函数。 这种形式注册的 defer 是最慢的。 deferproc() 函数的大致逻辑： 把defer函数的相关数据存储在runtime._defer这个结构中并添加到当前goroutine的defer链表头部。 通过deferproc()函数注册完一个defer函数后，deferproc()函数的返回值是0（该函数并没有返回值，只是通过return0()函数把0写入AX寄存器）。 后面如果发生了panic，又通过该defer函数成功recover()，那么指令指针和栈指针就会恢复到这里设置的pc、sp处，看起来就像刚从runtime.deferproc()函数返回，只不过返回值为1，编译器插入的if语句继而会跳过函数体，仅执行末尾的deferreturn()函数。 deferproc() 创建一个新的 defer函数 fn，它没有参数和返回值。 编译器将defer语句转换成对这个函数this调用。 fn是来自defer func()后面的函数其结构是一个funcval指针。 参数：fn func()，可以理解为defer a(1)这种形式封装成defer func(){a(1)}形式的调用。 相比于之前的deferproc()函数，这里少了参数的拷贝。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 // Create a new deferred function fn, which has no arguments and results. // The compiler turns a defer statement into a call to this. func deferproc(fn func()) { // 1) 获取当前正在运行的g gp := getg()\t// gp.m.curg记录当前工作线程正在运行的g，如果不相等那说明应该是在g0栈 if gp.m.curg != gp {\t// go code on the system stack can\u0026#39;t defer throw(\u0026#34;defer on system stack\u0026#34;) } // 2) 获取或者创建一个defer，注意该defer结构体是在【堆】上分配的 d := newdefer()\tif d._panic != nil { // 从缓存中获取的存在其他panic触发标记 throw(\u0026#34;deferproc: d.panic != nil after newdefer\u0026#34;) } // 3) 比如现在有三个defer需要注册：defer 1, defer 2, defer 3 // g._defer = 3 通过link形成链表 3 -\u0026gt; 2 -\u0026gt; 1 注册顺序 // 执行顺序：3 -\u0026gt; 2 -\u0026gt; 1 // goroutine上_defer始终存储的是最新的_defer结构 d.link = gp._defer // 记录goroutine上的defer链表信息，gp._defer记录的是链表的最后一个_defer结构体的指针 gp._defer = d // 当前goroutine链接上defer链表，gp._defer始终记录的是最后一个 // 4) 这里都是func()形式的闭包，不是该形式的会在外层封装一层 d.fn = fn // 记录当前defer注册函数 // 5) getcallerpc()函数获取调用者指令指针的位置， // 从调用者视角看来就是【CALL runtime.deferproc】后面的那条指令的地址 // 主要用途：在执行recover()函数的时候还原指令指针 d.pc = getcallerpc() // 记录当前注册defer函数时的下一条指令地址 IP地址 // We must not be preempted between calling getcallersp and // storing it to d.sp because getcallersp\u0026#39;s result is a // uintptr stack pointer. // // 6) getcallersp()函数获取调用者的SP，也就是调用deferproc()函数之前的SP寄存器的值 // 这个值有两个用途： // 1. 在deferreturn()函数执行defer函数时用来判断该defer是不是被当前函数注册的 // 2. 在执行recover()函数的时候用来还原栈指针 d.sp = getcallersp() // 记录当前调用函数的rsp栈信息 SP栈顶 // deferproc returns 0 normally. // a deferred func that stops a panic // makes the deferproc return 1. // the code the compiler generates always // checks the return value and jumps to the // end of the function if deferproc returns != 0. // // 7) deferproc 正常返回 0 // 一个停止painc的defer函数使 deferproc 返回 1 // 编译器生成的代码总是检查返回值，如果 deferproc returns != 0 则跳转到函数的末尾 return0()\t// 是否改掉deferreturn函数 // No code can go here - the C return register has // been set and must not be clobbered. // return0() 函数把返回值0或1写入【AX】寄存器中 } newdefer() 该函数用处创建_defer结构体。 该函数为了避免频繁的堆分配_defer结构体而采用的缓存池。 要释放 defer 需要调用 freedefer() 函数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // Allocate a Defer, usually using per-P pool. // Each defer must be released with freedefer. The defer is not // added to any defer chain yet. func newdefer() *_defer { var d *_defer // 初始化一个变量，此时为nil mp := acquirem() // 获取当前的M并禁止被抢占 pp := mp.p.ptr() // 获取当前的P // len(pp.deferpool) == 0：当前P上的可用defer结构如果为空 // sched.deferpool != nil：当前全局sched.deferpool的可用defer不为空 // P上的deferpool是切片[]*_defer， // sched上的是链表形式*_defer if len(pp.deferpool) == 0 \u0026amp;\u0026amp; sched.deferpool != nil {\t// 把全局的defer拿部分放到P的defer中备用 lock(\u0026amp;sched.deferlock) // 锁住sched.deferlock // 如果当前P上的长度 \u0026lt; 其容量的一半 并且 全局sched.deferpool存在 // 这里的循环保证P本地池子的defer大于一半 for len(pp.deferpool) \u0026lt; cap(pp.deferpool)/2 \u0026amp;\u0026amp; sched.deferpool != nil { d := sched.deferpool // 从sched拿到链表信息 sched.deferpool = d.link // 把当前链表的上一个返回给sched，这样就去下了最后一个defer结构 d.link = nil // 把当前的defer结构link给重置nil，表示无链接到其他defer pp.deferpool = append(pp.deferpool, d) // 把取下的这个放入P的defer池子中 } unlock(\u0026amp;sched.deferlock) // 解锁 } // 判断当前P中的defer池子是否存在空闲的defer结构 if n := len(pp.deferpool); n \u0026gt; 0 { d = pp.deferpool[n-1] // 取P最后一个defer结构 // 这一步是为了帮助GC pp.deferpool[n-1] = nil // 把取下的这个defer从P的空闲池子中重置为nil pp.deferpool = pp.deferpool[:n-1] // 缩短P空闲池的长度 } releasem(mp) // 取消当前M禁止被抢占锁 mp, pp = nil, nil // 帮助GC，清除指针引用 // 如果上面没有找到空闲的，那么就使用new()函数自己创建一个 // 注意这里是new()函数在堆上分配了一个_defer结构体 if d == nil { // Allocate new defer. d = new(_defer) } d.heap = true // 标记当前defer是堆分配 return d } return0() return0() 是一个存根，用于从 deferproc() 返回 0。 它在 deferproc() 的最后被调用，以通知调用 Go 函数它不应该跳转到 deferreturn()。 异常情况下 return0() 函数会返回 1，此时 GO 就会跳转到执行 deferreturn()。 也就是 panic 发生时 recover() 函数又恢复了，接到执行时这里会返回 1，表示去执行 deferreturn() 函数处理剩下的 defer。 1 2 3 4 5 6 // return0 is a stub used to return 0 from deferproc. // It is called at the very end of deferproc to signal // the calling Go function that it should not jump // to deferreturn. // in asm_*.s func return0() 栈分配 相比堆上分配，栈上分配做了一点优化，即把 runtime._defer 结构分配到当前函数的栈帧上。 很明显这不适合于循环中的 defer，循环中的 defer 仍然需要通过 deferproc() 函数实现，这种优化只适合用于只会执行一次的 defer。 编译器通过 runtime.deferprocStack() 函数来执行这类 defer 的注册，相比于 runtime.deferproc() 函数， 少了通过缓冲池或堆分配 _defer 结构的步骤，性能方面还是稍有提升的。 deferprocStack 该函数用于_defer结构体在函数栈上分配时，需要把这个_defer追加到当前g的_defer上去，以及初始化一些信息。 该函数的功能和deferproc()函数功能类似，唯一区别就是fn是在调用deferprocStack()函数前就被设置在调用栈上。 deferprocStack() 将一个新的延迟函数与堆栈上的延迟记录进行排队。 runtime._defer 结构中新增了一个 bool 型的字段 heap 来表示是否为堆上分配，对于这种栈上分配的 _defer 结构， deferreturn() 函数就不会用 freedefer() 函数进行释放了。因为编译器在栈帧上已经把 _defer 结构的某些字段包括后面追加的 fn 参数都准备好了， 所以 deferprocStack() 函数这里只需为剩余的几个字段赋值，与 deferproc() 函数的逻辑基本一致。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 // deferprocStack queues a new deferred function with a defer record on the stack. // The defer record must have its fn field initialized. // All other fields can contain junk. // Nosplit because of the uninitialized pointer fields on the stack. // //go:nosplit func deferprocStack(d *_defer) { gp := getg() // 获取当前g if gp.m.curg != gp { // go code on the system stack can\u0026#39;t defer throw(\u0026#34;defer on system stack\u0026#34;) } // fn is already set. // The other fields are junk on entry to deferprocStack and // are initialized here. // // fn在调用deferprocStack()函数前已被设置 // 其他字段在进入deferprocStack()时是垃圾字段，并在此处初始化 d.started = false // 当前defer未开始 d.heap = false // 不是堆分配 d.openDefer = false // 不是 open-coded defer 形式 d.sp = getcallersp() // 记录当前被调用函数的下一条指令处 d.pc = getcallerpc() // 记录当前被调用函数的rsp寄存器信息 d.framepc = 0 d.varp = 0 // The lines below implement: // d.panic = nil // d.fd = nil // d.link = gp._defer // gp._defer = d // But without write barriers. The first three are writes to // the stack so they don\u0026#39;t need a write barrier, and furthermore // are to uninitialized memory, so they must not use a write barrier. // The fourth write does not require a write barrier because we // explicitly mark all the defer structures, so we don\u0026#39;t need to // keep track of pointers to them with a write barrier. // // 下面的行实现： // d.panic = nil // d.fd = nil // d.link = gp._defer // gp._defer = d // 但没有书写障碍。前三个是对栈的写入，因此它们不需要写屏障， // 而且是对未初始化内存的写入，所以它们不能使用写屏障。 // 第四次写入不需要写屏障，因为我们显式标记了所有的defer结构， // 所以我们不需要用写屏障跟踪指向它们的指针 // 因为d结构是在栈上分配的，GC会扫描goroutine栈 *(*uintptr)(unsafe.Pointer(\u0026amp;d._panic)) = 0\t*(*uintptr)(unsafe.Pointer(\u0026amp;d.fd)) = 0 *(*uintptr)(unsafe.Pointer(\u0026amp;d.link)) = uintptr(unsafe.Pointer(gp._defer))\t*(*uintptr)(unsafe.Pointer(\u0026amp;gp._defer)) = uintptr(unsafe.Pointer(d)) return0() // No code can go here - the C return register has // been set and must not be clobbered. } open code defer 编译器直接将 defer 函数注入到函数调用代码中，这样既不使用堆分配_defer也不使用链表链接_defer。 Go1.14 后面的版本支持 open code defer。 Go1.14通过增加一个标识变量df来解决这类问题，用df中的每一位对应标识当前函数中的一个defer函数是否要执行。(8bit位) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func A(i int) { defer A1(i, 2*i) if (i \u0026gt; 1) { defer A2(\u0026#34;Hello\u0026#34;, \u0026#34;eggo\u0026#34;) } // code to do something return } func A1(a,b int){ //...... } func A2(m,n string){ //...... } 经过编译器转换后。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func A(i int){ var df byte //A1的参数 var a, b int = i, 2*i df |= 1 //A2的参数 var m,n string = \u0026#34;Hello\u0026#34;, \u0026#34;eggo\u0026#34; if i \u0026gt; 1 { df |= 2 } //code to do something //判断A2是否要调用 if df\u0026amp;2 \u0026gt; 0 { df = df\u0026amp;^2 A2(m, n) } //判断A1是否要调用 if df\u0026amp;1 \u0026gt; 0 { df = df\u0026amp;^1 A1(a, b) } return //省略部分与recover相关的逻辑 } Go1.14把defer函数在当前函数内展开并直接调用，这种方式被称为open coded defer，这种方式不仅不用创建_defer结构体，也脱离了defer链表的束缚，不过这种方式依然不适用于循环中的defer，所以1.12版本defer的处理方式是一直保留的。 open code defer 满足的条件 没有禁用编译器优化，即没有设置 -gcflags \u0026quot;-N\u0026quot;。 函数中存在defer的使用。 函数内 defer 的数量不超过8个，且返回语句(return)与延迟语句(defer)个数的数量的乘积不超过15。 没有defer发生在循环语句中。 运行defer deferreturn() 开始运行defer链表，该函数在return前被调用。 该函数是defer在堆上分配和栈上分配时最后return都会调用的函数。 open-coded defer形式正确情况下是不会调用deferreturn()函数，如果调用该函数一定是有panic()或Goexit()发生。因为open-coded defer没有defer链表必须要先从函数栈中回溯找出defer结构内容。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 // deferreturn runs deferred functions for the caller\u0026#39;s frame. // The compiler inserts a call to this at the end of any // function which calls defer. // // deferreturn 函数为调用者的栈帧运行 defer 函数 // 编译器在调用 defer 函数的末尾插入对 deferretrun 函数的调用 func deferreturn() { // 因为当前g上的defer存储的是最新的_defer结构 gp := getg() // 获取当前的goroutine for { // 1) 获取goroutine最新的_defer // 这里决定了defer是倒叙，也就是后面的defer先执行，前面的defer后执行 // gp._defer -\u0026gt; defer3 -\u0026gt; defer2 -\u0026gt; defer d := gp._defer // 获取当前g后面的defer链表 if d == nil { // 没有链表则返回 return } // 2) 判断 defer 函数注册是否在当前调用 deferreturn 函数的栈中 // 也就是 deferreturn 函数只能运行当前调用者函数注册的 defer 函数 // 函数的栈SP是在函数开始就分配的，在本函数内该SP值是不会发生变化的 sp := getcallersp() // 获取当前调用函数的栈帧，在Go中函数的rsp栈是已开始就被预分配的 // 这里的判断条件也表明自己函数注册的defer不能跑其他函数里面取运行 if d.sp != sp { // 如果和注册的defer不一致说明当前defer不是该函数的，直接返回 return } // 3) 运行注册的defer函数，并释放_defer对象 // 3.1) open coded defer形式 // d.openDefer为真，说明当前是从 gopanic 函数的 open coded defers 跳转而来 if d.openDefer {\t// 此时d是同一个函数的一群_defer // done为true，表示没有recover或其他，这一组defer都执行完。 // 前面在panic中回溯栈后组装了一组defer函数成_defer结构，其中某个函数的recover生效了， // 最后会继续执行deferreturn()函数，会找这里继续执行剩下的defer函数。 done := runOpenDeferFrame(gp, d) // 去运行这一群defer，相当于循环 // done defer是否执行完，正常逻辑到这里是没有panic的，因为刚从recover恢复过来接到执行后面的defer // 如果上面defer函数中又出现panic则，不会再回到这里了。 if !done { // 只有出现程序逻辑错误这里才会判断为真 throw(\u0026#34;unfinished open-coded defers in deferreturn\u0026#34;) } // 这一组defer运行完了，_defer结构可以释放了。 gp._defer = d.link // 移除当前defer在g中的链接 freedefer(d) // 释放当前的defer占用内存 // If this frame uses open defers, then this // must be the only defer record for the // frame, so we can just return. // // 如果此栈帧使用open defers，那么这一定是该栈帧的唯一延迟记录，因此我们可以直接返回 return } // 3.2) 堆和栈形式的_defer对象，执行并释放_defer对象 fn := d.fn // 获取当前注册的函数 d.fn = nil // 帮助GC gp._defer = d.link // 移除当前defer在g中的链接 freedefer(d) // 释放当前的defer占用内存 fn() // 执行当前注册的函数 } } freedefer() 释放defer（针对堆分配情况），该函数用于deferreturn()执行完需要处理_defer结构体的收尾工作。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // Free the given defer. // The defer cannot be used after this call. // // This is nosplit because the incoming defer is in a perilous state. // It\u0026#39;s not on any defer list, so stack copying won\u0026#39;t adjust stack // pointers in it (namely, d.link). Hence, if we were to copy the // stack, d could then contain a stale pointer. // //go:nosplit func freedefer(d *_defer) { d.link = nil // 设置link为nil // After this point we can copy the stack. if d._panic != nil { // 如果当前_panic存在值则抛出异常 freedeferpanic() // 直接抛出异常 } if d.fn != nil { // 如果当前fn存在值则抛出异常 freedeferfn() // 直接抛出异常 } if !d.heap { // 如果当前不是堆分配，直接返回 return } // 以下是针对defer结构体是堆分配的情况 mp := acquirem() // 获取M并禁止当前被抢占 pp := mp.p.ptr() // 获取P // 当前P的本地池满了，需要移除一半到全局池中去 // pp.deferpool 是一个切片 if len(pp.deferpool) == cap(pp.deferpool) { // 这里说明P的空闲池满了 // Transfer half of local cache to the central cache. // // 将P得一半的defer转移到sched的defer空闲列表中去 // first：记录第一个_defer // last：记录最后一个_defer // 通过link形成链表 var first, last *_defer for len(pp.deferpool) \u0026gt; cap(pp.deferpool)/2 {\tn := len(pp.deferpool) d := pp.deferpool[n-1] // 注意这里的d是局部变量 pp.deferpool[n-1] = nil // 帮助GC pp.deferpool = pp.deferpool[:n-1] if first == nil { first = d } else { last.link = d } last = d } lock(\u0026amp;sched.deferlock) // 加锁 last.link = sched.deferpool // 把全局的链接到last后面 sched.deferpool = first // 把第一个first追加到全局池中 unlock(\u0026amp;sched.deferlock) // 解锁 } *d = _defer{} // 清空当前defer pp.deferpool = append(pp.deferpool, d) // 把d放入P中的空闲defer池中 releasem(mp) // 取消M禁止被抢占 mp, pp = nil, nil } runOpenDeferFrame() 展开形式的defer处理函数，运行注册的defer。 为开放编码做了特殊的优化，运行时会调用runtime.runOpenDeferFrame()执行活跃的开放编码延迟函数， 该函数会执行以下的工作： 从runtime._defer结构体中读取 deferBits、函数 defer 数量等信息； 循环中依次读取函数的地址和参数信息并通过 deferBits 判断该函数是否需要被执行； 调用deferCallSave()需要执行的 defer 函数； 该函数如果在deferreturn()函数中被调用，那函数里存在的panic()标志没有作用，因为正常流程不会调用deferreturn()函数，只是在panic()和runtime.Goexit()需要注意。 通过返回值来判断目标栈帧上的open coded defer已经完全执行，并且没有recover。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 // runOpenDeferFrame runs the active open-coded defers in the frame specified by // d. It normally processes all active defers in the frame, but stops immediately // if a defer does a successful recover. It returns true if there are no // remaining defers to run in the frame. // // gp *g 当前的goroutine // d *_defer 当前g后面的defer链表 func runOpenDeferFrame(gp *g, d *_defer) bool { done := true // 所有defer信息都存储在funcdata中 fd := d.fd\t// readvarintUnsafe 从 fd 开始以 varint 格式读取 uint32，并返回 uint32 和指向 varint 后面字节的指针 deferBitsOffset, fd := readvarintUnsafe(fd) nDefers, fd := readvarintUnsafe(fd) // nDefers注册的defer个数，函数中defer数量 // 当前执行的defer deferBits := *(*uint8)(unsafe.Pointer(d.varp - uintptr(deferBitsOffset))) // deferBits就是注册函数的记录标志 // 遍历注册的defer数量 for i := int(nDefers) - 1; i \u0026gt;= 0; i-- { // read the funcdata info for this defer 从defer中读取funcdata信息 var closureOffset uint32 closureOffset, fd = readvarintUnsafe(fd) // closureOffset defer注册函数的偏移量 if deferBits\u0026amp;(1\u0026lt;\u0026lt;i) == 0 { // 判断当前位上是否有defer满足条件的注册 continue } // 执行的函数和参数 closure := *(*func())(unsafe.Pointer(d.varp - uintptr(closureOffset))) // 得到注册的函数 d.fn = closure // 8bit 0000_0000 deferBits = deferBits \u0026amp;^ (1 \u0026lt;\u0026lt; i) // 清零指定i位上的标志 *(*uint8)(unsafe.Pointer(d.varp - uintptr(deferBitsOffset))) = deferBits // 回写内存 p := d._panic // Call the defer. Note that this can change d.varp if // the stack moves. deferCallSave(p, d.fn) // 调用注册的函数并处理panic相关，fn()里面可能再次发生panic导致这里执行了部分 if p != nil \u0026amp;\u0026amp; p.aborted { // 如果当前defer由panic触发，并且已被中止，则直接退出，这里好像永远为false break } d.fn = nil // 如果当前defer由panic触发，并且当前panic被恢复了，应该结束defer继续去执行panic之后的代码 if d._panic != nil \u0026amp;\u0026amp; d._panic.recovered { done = deferBits == 0 // 标记defer函数是否已被处理完 break } } return done } deferCallSave() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // deferCallSave calls fn() after saving the caller\u0026#39;s pc and sp in the // panic record. This allows the runtime to return to the Goexit defer // processing loop, in the unusual case where the Goexit may be // bypassed by a successful recover. // // This is marked as a wrapper by the compiler so it doesn\u0026#39;t appear in // tracebacks. func deferCallSave(p *_panic, fn func()) { if p != nil { // 以下参数在fn()中如果存在recover函数时会被用到 p.argp = unsafe.Pointer(getargp()) p.pc = getcallerpc() p.sp = unsafe.Pointer(getcallersp()) } fn() // 调用注册的defer函数 if p != nil { // 以下参数在下一个open defers时被用到 p.pc = 0 p.sp = unsafe.Pointer(nil) } } readvarintUnsafe() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // readvarintUnsafe reads the uint32 in varint format starting at fd, and returns the // uint32 and a pointer to the byte following the varint. // // There is a similar function runtime.readvarint, which takes a slice of bytes, // rather than an unsafe pointer. These functions are duplicated, because one of // the two use cases for the functions would get slower if the functions were // combined. // // readvarintUnsafe 从 fd 开始以 varint 格式读取 uint32，并返回 uint32 和指向 varint 后面字节的指针 // 还有一个类似的函数运行时。readvarint，它需要一个字节片，而不是一个不安全的指针。 // 这些功能是重复的，因为如果将这些功能组合起来，两个功能用例中的一个会变慢 func readvarintUnsafe(fd unsafe.Pointer) (uint32, unsafe.Pointer) { var r uint32 var shift int for { b := *(*uint8)((unsafe.Pointer(fd))) fd = add(fd, unsafe.Sizeof(b)) if b \u0026lt; 128 { return r + uint32(b)\u0026lt;\u0026lt;shift, fd } r += ((uint32(b) \u0026amp;^ 128) \u0026lt;\u0026lt; shift) shift += 7 if shift \u0026gt; 28 { panic(\u0026#34;Bad varint\u0026#34;) } } } addOneOpenDeferFrame() 该函数是发生panic()或runtime.Goexit()时回溯栈寻找defer信息函数。 将最近的一个open coded defer栈帧添加到_defer链表中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 // addOneOpenDeferFrame scans the stack (in gentraceback order, from inner frames to // outer frames) for the first frame (if any) with open-coded defers. If it finds // one, it adds a single entry to the defer chain for that frame. The entry added // represents all the defers in the associated open defer frame, and is sorted in // order with respect to any non-open-coded defers. // // addOneOpenDeferFrame stops (possibly without adding a new entry) if it encounters // an in-progress open defer entry. An in-progress open defer entry means there has // been a new panic because of a defer in the associated frame. addOneOpenDeferFrame // does not add an open defer entry past a started entry, because that started entry // still needs to finished, and addOneOpenDeferFrame will be called when that started // entry is completed. The defer removal loop in gopanic() similarly stops at an // in-progress defer entry. Together, addOneOpenDeferFrame and the defer removal loop // ensure the invariant that there is no open defer entry further up the stack than // an in-progress defer, and also that the defer removal loop is guaranteed to remove // all not-in-progress open defer entries from the defer chain. // // If sp is non-nil, addOneOpenDeferFrame starts the stack scan from the frame // specified by sp. If sp is nil, it uses the sp from the current defer record (which // has just been finished). Hence, it continues the stack scan from the frame of the // defer that just finished. It skips any frame that already has a (not-in-progress) // open-coded _defer record in the defer chain. // // Note: All entries of the defer chain (including this new open-coded entry) have // their pointers (including sp) adjusted properly if the stack moves while // running deferred functions. Also, it is safe to pass in the sp arg (which is // the direct result of calling getcallersp()), because all pointer variables // (including arguments) are adjusted as needed during stack copies. // // gp *g 当前goroutine // pc uintptr 当前发生panic的下一条指令处 // sp unsafe.Pointer 当前发生panic的函数栈顶 func addOneOpenDeferFrame(gp *g, pc uintptr, sp unsafe.Pointer) { var prevDefer *_defer\t// goroutine的上一个defer结构 if sp == nil { prevDefer = gp._defer pc = prevDefer.framepc sp = unsafe.Pointer(prevDefer.sp) } systemstack(func() { gentraceback(pc, uintptr(sp), 0, gp, 0, nil, 0x7fffffff, func(frame *stkframe, unused unsafe.Pointer) bool { if prevDefer != nil \u0026amp;\u0026amp; prevDefer.sp == frame.sp { // Skip the frame for the previous defer that // we just finished (and was used to set // where we restarted the stack scan) return true } f := frame.fn fd := funcdata(f, _FUNCDATA_OpenCodedDeferInfo) if fd == nil { return true } // Insert the open defer record in the // chain, in order sorted by sp. d := gp._defer var prev *_defer for d != nil { dsp := d.sp if frame.sp \u0026lt; dsp { break } if frame.sp == dsp { if !d.openDefer { throw(\u0026#34;duplicated defer entry\u0026#34;) } // Don\u0026#39;t add any record past an // in-progress defer entry. We don\u0026#39;t // need it, and more importantly, we // want to keep the invariant that // there is no open defer entry // passed an in-progress entry (see // header comment). if d.started { return false } return true } prev = d d = d.link } if frame.fn.deferreturn == 0 { throw(\u0026#34;missing deferreturn\u0026#34;) } d1 := newdefer() d1.openDefer = true d1._panic = nil // These are the pc/sp to set after we\u0026#39;ve // run a defer in this frame that did a // recover. We return to a special // deferreturn that runs any remaining // defers and then returns from the // function. d1.pc = frame.fn.entry() + uintptr(frame.fn.deferreturn) d1.varp = frame.varp d1.fd = fd // Save the SP/PC associated with current frame, // so we can continue stack trace later if needed. d1.framepc = frame.pc d1.sp = frame.sp d1.link = d if prev == nil { gp._defer = d1 } else { prev.link = d1 } // Stop stack scanning after adding one open defer record return false }, nil, 0) }) } runtime.Goexit() 立即终止当前goroutine执行，在终止调用它的Goroutine的运行之前会先执行该Goroution中还没有执行的defer语句。 该函数运行完defer链表注册的函数，直接调用goexit1()函数，该函数直接切换goroutine处理goroutine的后续工作。 Goexit()代码的逻辑与gopanic()函数相似度很高。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 // Goexit terminates the goroutine that calls it. No other goroutine is affected. // Goexit runs all deferred calls before terminating the goroutine. Because Goexit // is not a panic, any recover calls in those deferred functions will return nil. // // Calling Goexit from the main goroutine terminates that goroutine // without func main returning. Since func main has not returned, // the program continues execution of other goroutines. // If all other goroutines exit, the program crashes. func Goexit() { // Run all deferred functions for the current goroutine. // This code is similar to gopanic, see that implementation // for detailed comments. gp := getg() // Create a panic object for Goexit, so we can recognize when it might be // bypassed by a recover(). // 为 Goexit 创建一个恐慌对象，这样我们就可以识别它何时可能被 recover() 绕过 var p _panic p.goexit = true p.link = gp._panic gp._panic = (*_panic)(noescape(unsafe.Pointer(\u0026amp;p))) addOneOpenDeferFrame(gp, getcallerpc(), unsafe.Pointer(getcallersp())) // 运行defer函数 for { d := gp._defer if d == nil { break } if d.started { if d._panic != nil { d._panic.aborted = true d._panic = nil } if !d.openDefer { d.fn = nil gp._defer = d.link freedefer(d) continue } } d.started = true d._panic = (*_panic)(noescape(unsafe.Pointer(\u0026amp;p))) if d.openDefer { done := runOpenDeferFrame(gp, d) if !done { // We should always run all defers in the frame, // since there is no panic associated with this // defer that can be recovered. throw(\u0026#34;unfinished open-coded defers in Goexit\u0026#34;) } if p.aborted { // Since our current defer caused a panic and may // have been already freed, just restart scanning // for open-coded defers from this frame again. addOneOpenDeferFrame(gp, getcallerpc(), unsafe.Pointer(getcallersp())) } else { addOneOpenDeferFrame(gp, 0, nil) } } else { // Save the pc/sp in deferCallSave(), so we can \u0026#34;recover\u0026#34; back to this // loop if necessary. deferCallSave(\u0026amp;p, d.fn) } if p.aborted { // We had a recursive panic in the defer d we started, and // then did a recover in a defer that was further down the // defer chain than d. In the case of an outstanding Goexit, // we force the recover to return back to this loop. d will // have already been freed if completed, so just continue // immediately to the next defer on the chain. p.aborted = false continue } if gp._defer != d { throw(\u0026#34;bad defer entry in Goexit\u0026#34;) } d._panic = nil d.fn = nil gp._defer = d.link freedefer(d) // Note: we ignore recovers here because Goexit isn\u0026#39;t a panic } // 这里是Goexit()函数关键，处理完defer后直接切换goroutine了。 goexit1() } ","permalink":"https://heliu.site/posts/golang/func/defer-theory/","summary":"defer 组成介绍。","title":"defer(原理)"},{"content":" 只有在 defer 函数中调用 recover() 函数才有效，因为发生 panic 之后只有 defer 函数能够得到执行。 Go 语言在设计上保证所有的 defer 函数都能够得到调用，所以适合用 defer 来释放资源，即使发生 panic 也不会造成资源泄露。 type _panic struct 该结构体存储着panic的相关信息。 文件位置：go1.19.3/src/runtime/runtime2.go。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // A _panic holds information about an active panic. // // A _panic value must only ever live on the stack. // // The argp and link fields are stack pointers, but don\u0026#39;t need special // handling during stack growth: because they are pointer-typed and // _panic values only live on the stack, regular stack pointer // adjustment takes care of them. type _panic struct { // argp 设置为当前gopanic()函数栈帧上args to callee区间的起始地址。 // 主要作用：用于defer()函数执行时判断recover()函数所在范围是否能生效。 argp unsafe.Pointer // pointer to arguments of deferred call run during panic; cannot move - known to liblink // 则是panic函数自己的参数，也就是【panic(v any)】这里的空接口【v】的参数。 // 主要作用：结束时用于打印错误信息。 arg any // argument to panic // 通过link链接到前一个注册的panic形成链表， // 解释：新增的panic总是从左边插入 link *_panic // link to earlier panic\tg._painc // pc 来自 defer.pc 拷贝的值 // 主要作用：用于当前panic被恢复时要执行的下一条指令地址及IP寄存器的值 pc uintptr // where to return to in runtime if this panic is bypassed\t// sp 来自 defer.sp 拷贝的值 // 主要作用：用于当前panic被恢复时要恢复的栈顶SP寄存器的值 sp unsafe.Pointer // where to return to in runtime if this panic is bypassed // 表示当前panic已经被某个defer函数通过recover恢复。【已恢复】 // 解释：该值在recover()函数中被标记 recovered bool // whether this panic is over // 表示发生了嵌套的panic，旧的panic被新的panic流程标记为aborted。【已中止】 // 解释：就是发生了嵌套panic了。 aborted bool // the panic was aborted // 是否执行runtime.Goexit()函数，runtime.Goexit()函数是 // goroutine执行完后跳转到的清理首尾工作的函数 // goexit字段在，runtime.Goexit()函数中被标记为true。 goexit bool } panic 1 2 3 4 5 6 7 8 9 10 11 // The panic built-in function stops normal execution of the current // goroutine. When a function F calls panic, normal execution of F stops // immediately. Any functions whose execution was deferred by F are run in // the usual way, and then F returns to its caller. To the caller G, the // invocation of F then behaves like a call to panic, terminating G\u0026#39;s // execution and running any deferred functions. This continues until all // functions in the executing goroutine have stopped, in reverse order. At // that point, the program is terminated with a non-zero exit code. This // termination sequence is called panicking and can be controlled by the // built-in function recover. func panic(v any) gopanic() gopanic() 也就是 panic() 发生时调用的函数。 gopanic() 函数中关键的 open coded defer 部分： 在 for 循环开始之前，先通过 addOneOpenDeferFrame() 函数将最近的一个 open coded defer 栈帧添加到 _defer 链表中。 在调用 defer 函数的时候，如果 openDefer 为 true ，则使用 runOpenDeferFrame() 函数来执行，通过返回值来判断目标栈帧上的 open coded defer 已经完全执行，并且没有 recover，就再次调用 addOneOpenDeferFrame() 函数把下一个 open coded defer 栈帧添加到 _defer 链表。 根据 runOpenDeferFrame() 函数的返回值来判断，只有完全执行的节点才能从 _defer 链表中移除。事实上只有 openDefer 节点才有可能出现不完全执行的情况，因为一个栈帧上可能有多个 open coded defer 函数，假如其中某一个函数调用了 recover() 函数，后续的就不会再被调用了，所以该节点不能从 _defer 链表中移除，recover 之后的逻辑负责调用这些剩余的 open coded defer。 检查到当前 panic 的 recover 为 true 后，需要把 _defer 链表中尚未开始执行的 openDefer 节点移除，因为 recover 之后这些 open coded defer 会被正常调用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 // The implementation of the predeclared function panic. func gopanic(e any) { // 获取当前正在运行的goroutine gp := getg() // 调用gopanic()应该是在用户栈上发生的 if gp.m.curg != gp { print(\u0026#34;panic: \u0026#34;) printany(e) print(\u0026#34;\\n\u0026#34;) // panic 在系统栈上 throw(\u0026#34;panic on system stack\u0026#34;) } // 申请内存期间不允许panic if gp.m.mallocing != 0 { print(\u0026#34;panic: \u0026#34;) printany(e) print(\u0026#34;\\n\u0026#34;) // malloc 期间 panic // malloc 是在申请内存期间 throw(\u0026#34;panic during malloc\u0026#34;) } // 抢占期间不允许panic if gp.m.preemptoff != \u0026#34;\u0026#34; { print(\u0026#34;panic: \u0026#34;) printany(e) print(\u0026#34;\\n\u0026#34;) print(\u0026#34;preempt off reason: \u0026#34;) print(gp.m.preemptoff) print(\u0026#34;\\n\u0026#34;) throw(\u0026#34;panic during preemptoff\u0026#34;) } // M持有锁期间不允许panic if gp.m.locks != 0 { print(\u0026#34;panic: \u0026#34;) printany(e) print(\u0026#34;\\n\u0026#34;) throw(\u0026#34;panic holding locks\u0026#34;) } // 1) 创建一个_panic结构并初始化 // 可以看出panic和defer结构都是用的用户内存空间 // 初始化一个panic结构体，在栈上分配 var p _panic\tp.arg = e // 保存panic的参数，该参数是panic(v any) // _panic通过link链接其他panic // 记录goroutine上的最后一个panic，也就是形成一个panic的链表 p.link = gp._panic\t// g._panic 保存的是最新的panic // 特意使用noescape函数来避免p逃逸，应为panic本身就是与栈的状态强相关的 // 当前panic追加到goroutine的panic链表上，记录最新的一个panic gp._panic = (*_panic)(noescape(unsafe.Pointer(\u0026amp;p)))\t// 使用原子锁标记panic正在发生，用于runtime.main()函数等待 // 当runtime.main()即将要结束时，需要循环等待panic完成。 // 具体代码参看 runtime.main() 函数。 atomic.Xadd(\u0026amp;runningPanicDefers, 1) // 2) open code defers 形式扫描栈，收集信息,已备后面循环gp.defer // By calculating getcallerpc/getcallersp here, we avoid scanning the // gopanic frame (stack scanning is slow...) // // 通过这里计算getcallerpc/getcallersp，我们避免扫描gopanic帧（堆栈扫描很慢......） // 将最近的一个open coded defer栈帧添加到_defer链表中，可能是一组defer函数组成的一个_defer结构。 addOneOpenDeferFrame(gp, getcallerpc(), unsafe.Pointer(getcallersp())) // 在这个循环中逐个调用链表中的defer函数，并检测recover的状态。 // 如果所有的defer函数都执行完后还是没有recover，则循环就会结束， // 最后的fatalpanic()函数就会结束当前进程。 for { // 取最新的一个defer // 这里可以看看出取出的defer不一定是当前发生panic注册的defer可能是上游调用函数注册的 d := gp._defer if d == nil { // defer已经运行完了，结束循环 break } // If defer was started by earlier panic or Goexit (and, since we\u0026#39;re back here, that triggered a new panic), // take defer off list. An earlier panic will not continue running, but we will make sure below that an // earlier Goexit does continue running. // // d.started为真，表明当前是一个嵌套的panic， // 也就是在原有panic或Goexit()函数执行defer函数的时候又触发了panic // 因为触发panic的defer函数还没有执行完，所以还没有从链表中移除。 // 这里会把d相关的旧的_panic设置为aborted，然后把d从链表中移除，并通过freedefer()函数释放defer。 if d.started { // 首次触发panic这里为 false，多次触发这里为 true // d._panic记录的是前一个panic， // 在执行d.fn()函数的时候又发生了panic的情况。 if d._panic != nil { // 把前一个panic标记为已终止状态 d._panic.aborted = true // 已终止 } d._panic = nil // 不是open defers形式时，则直接回收当前defer结构体即可， // 因为当前gopanic()正是当前defer函数中触发，因此直接结束本次循环即可。 if !d.openDefer {\t// For open-coded defers, we need to process the // defer again, in case there are any other defers // to call in the frame (not including the defer // call that caused the panic). // // 当前defer已执行完，即将被回收。 d.fn = nil gp._defer = d.link // 因为当前defer中发生了panic，后续代码不会被执行，直接回收defer即可 freedefer(d)\tcontinue } // 否则应该去runOpenDeferFrame回收 } // 后续的3大块逻辑就是：调用defer函数、释放_defer结构和检测recover。 // 2.1) 调用defer函数 // Mark defer as started, but keep on list, so that traceback // can find and update the defer\u0026#39;s argument frame if stack growth // or a garbage collection happens before executing d.fn. // // 如果defer函数又触发了panic，新的panic遍历defer链表时，就能够通过started // 的值确定确定该defer函数已经被调用过了，避免重复调用。 d.started = true // 标记当前defer被panic触发 // Record the panic that is running the defer. // If there is a new panic during the deferred call, that panic // will find d in the list and will mark d._panic (this panic) aborted. // // 为d._panic赋值，将d关联到当前panic对象p， // 使用noescape函数避免p逃逸，这一步是为了后续嵌套的panic能够通过d._panic找到上一个panic d._panic = (*_panic)(noescape(unsafe.Pointer(\u0026amp;p))) // 当前defer的_panic记录触发的panic是那个 done := true if d.openDefer { // 当前是open code defers模式时 // 运行当前defer的fn函数，done=true表示所有的defer已经运行完 // 通过返回值来判断目标栈帧上的open coded defer已经完全执行，并且没有recover， // 就再次调用addOneOpenDeferFrame()函数把下一个open coded defer栈帧添加到_defer链表 done = runOpenDeferFrame(gp, d) // 这里运行的是一组defer // 因为上面运行的d.fn()函数，可能其中存在recover()函数，所以要判断recovered字段 if done \u0026amp;\u0026amp; !d._panic.recovered {\t// done=true，并且当前这个panic并没有被恢复时 // 再去寻找后面函数的defer // 从调用栈的栈顶开始回溯扫描，直到找到一个带有open coded defer的栈帧， // 为该栈帧分配一个_defer结构，为各个字段赋值后添加到defer链表中合适的位置。 // 不管目标栈帧上有几个open coded defer函数，只分配一个_defer结构， // 因为后续通过runOpenDeferFrame()函数来执行的时候，会一并执行栈帧上的所有 // open coded defer函数。添加到_defer链表中的位置是根据目标栈帧在调用栈中的位置 // 计算的，而不是添加到头部。 addOneOpenDeferFrame(gp, 0, nil)\t} } else {\t// defer是堆或栈分布时 // getargp()：设置为当前gopanic()函数栈帧上args to callee区间的起始地址， // recover()函数通过这个值来判断自身是否直接被defer函数调用 p.argp = unsafe.Pointer(getargp()) // 该值在fn执行函数中用于recover函数比较判断 // 执行defer注册的函数，如果这里又发生了panic时则当前defer并未被清除，又会从新gopanic d.fn()\t} // 为什么前面设置了argp值这里又要清除掉？ // 因此d.fn()执行的defer函数中可能会有recover()函数，需要判断argp的值 p.argp = nil // 清除 // 2.2) 释放_defer结构 // Deferred function did not panic. Remove d. // // 调用完d.fn()函数后，不应该会出现gp._defer不等于d这种情况。 // 假如在d.fn()函数执行的过程中没有造成新的panic，那么所有新注册的defer都应该在 // d.fn()函数返回的时候被deferreturn()函数移出链表。 // 假如d.fn()函数执行过程中造成了新的panic，若没有recover，则不会再回到这里， // 若经recover之后再回到这里，则所有在d.fn()函数执行过程中注册的defer也 // 都应该在d.fn()函数返回之前被移除链表。 if gp._defer != d {\tthrow(\u0026#34;bad defer entry in panic\u0026#34;) } // 当前defer执行完需要把_panic标记为nil，后面会删除这个defer d._panic = nil\t// trigger shrinkage to test stack copy. See stack_test.go:TestStackPanic //GC() // 把pc和sp字段保存在局部变量中，供接下来检测执行recover时使用 // 此处额sp类型必须时指针，因为后续如果栈被移动，只有指针类型会得到更新 pc := d.pc // 要恢复的PC和SP的值 sp := unsafe.Pointer(d.sp) // must be pointer so it gets adjusted during stack copy if done { // done=true，这一组defer函数已执行完 // 因此defer函数可以被释放掉 d.fn = nil\tgp._defer = d.link // 从goroutine._defer上移除自己 freedefer(d) // 回收defer } // 2.3)检测 recover() 是否标记了panic // 如果 d.fn() 函数成功地执行了recover()，则当前_panic对象的p的recovered字段就会被设置为true // 此处通过检测后就会执行recover逻辑。这里才是recover()函数的具体实现功能，跳转到指定代码处。 if p.recovered { // 2.3.1) recover()生效 // 1. 移除当前_panic，因为当前_panic已被恢复 // 2. 向前寻找移除被标记为aborted为真的_panic gp._panic = p.link\t// 把当前panic从goroutine._panic上移除掉自己 // gp._panic != nil：后面还有 panic // gp._panic.goexit：由runtime.Goexit()函数触发 // gp._panic.aborted：当前panic已被终止 if gp._panic != nil \u0026amp;\u0026amp; gp._panic.goexit \u0026amp;\u0026amp; gp._panic.aborted {\t// A normal recover would bypass/abort the Goexit. Instead, // we return to the processing loop of the Goexit. // // 正常恢复将 bypass/abort到 Goexit。 相反，我们返回到 Goexit 的处理循环。 gp.sigcode0 = uintptr(gp._panic.sp) // 并没有值 gp.sigcode1 = uintptr(gp._panic.pc) // mcall函数从当前g栈切换到g0栈，在执行recovery函数，恢复后是接到从当前最新panic的处往下执行 // recovery函数判断栈溢出后，直接把sp和pc值赋值给当前goroutine的sched然后使用gogo函数再次被调度起来接到执行 mcall(recovery)\t// 这种情况应该报错 // 从这里跳转到deferreturn函数 throw(\u0026#34;bypassed recovery failed\u0026#34;) // mcall should not return 应该永远不会返回到这里 } // 解锁panic标志，runtime.main()可以继续执行 atomic.Xadd(\u0026amp;runningPanicDefers, -1)\t// After a recover, remove any remaining non-started, // open-coded defer entries, since the corresponding defers // will be executed normally (inline). Any such entry will // become stale once we run the corresponding defers inline // and exit the associated stack frame. We only remove up to // the first started (in-progress) open defer entry, not // including the current frame, since any higher entries will // be from a higher panic in progress, and will still be // needed. d := gp._defer var prev *_defer if !done { // Skip our current frame, if not done. It is // needed to complete any remaining defers in // deferreturn() // // 跳过当前帧，如果还没有完成。需要在deferreturn()中完成所有剩余的延迟 // open coded defer时发生了recover时。 prev = d d = d.link } for d != nil { if d.started { // This defer is started but we // are in the middle of a // defer-panic-recover inside of // it, so don\u0026#39;t remove it or any // further defer entries // // 这个defer已经启动，但是我们正在它内部进行一个 defer-panic-recovery // 所以不要删除它或任何进一步的defer条目 break } if d.openDefer { if prev == nil { gp._defer = d.link } else { prev.link = d.link } newd := d.link freedefer(d) d = newd } else { prev = d d = d.link } } gp._panic = p.link // Aborted panics are marked but remain on the g.panic list. // Remove them from the list. // // 循环移除链表头部所有已经标记为aborted的_panic // 这里可以看出当最后一个panic被恢复前面的所有已标记aborted中止的panic会被移除。 for gp._panic != nil \u0026amp;\u0026amp; gp._panic.aborted { gp._panic = gp._panic.link } // 如果没有发生panic，则此时gp._panic应该为nil，不为nil就表明发生了嵌套的panic // 而且只是内层的panic被recover if gp._panic == nil { // must be done with signal gp.sig = 0 } // Pass information about recovering frame to recovery. // 要恢复的PC和SP的值，也就是当前defer注册的后一条指令处，是一条JMP指令 // 跳转去执行deferreturn()函数。 gp.sigcode0 = uintptr(sp) // 需要恢复到的SP地址，也就是注册defer函数的栈顶寄存器 gp.sigcode1 = pc // 需要恢复到IP地址，也就是注册defer函数的下一条指令处 // recovery函数负责用存储在sigcode0和sigcode1中的sp和pc恢复gp的执行状态 mcall(recovery) // mcall函数切换到系统g0栈去调用gogo函数执行跳转 throw(\u0026#34;recovery failed\u0026#34;) // mcall should not return } } // 所有的defer注册函数都没有recover，最后会到这里去打印错误信息 // ran out of deferred calls - old-school panic now // Because it is unsafe to call arbitrary user code after freezing // the world, we call preprintpanics to invoke all necessary Error // and String methods to prepare the panic strings before startpanic. // // gp._panic：保存的最新的panic preprintpanics(gp._panic)\t// 把panic的参数解析放入arg // 打印panic信息，并结束当前进程 fatalpanic(gp._panic) // should not return // 向一个nil的地址写入值，会报错，下面这行代码是防止万一，不应该执行到这里在前一个函数中会结束调进程 *(*int)(nil) = 0 // not reached } runOpenDeferFrame() 循环执行指定栈帧上所有的open coded defer函数。 返回值表示栈帧上所有的open coded defer函数是否都执行完毕，如果因为某个defer函数执行了recover 而造成循环中止，则返回值为false。 addOneOpenDeferFrame()和runOpenDeferFrame()函数都依赖符号表中目标栈帧的OpenCodedDerferInfo。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // runOpenDeferFrame runs the active open-coded defers in the frame specified by // d. It normally processes all active defers in the frame, but stops immediately // if a defer does a successful recover. It returns true if there are no // remaining defers to run in the frame. func runOpenDeferFrame(gp *g, d *_defer) bool { done := true fd := d.fd deferBitsOffset, fd := readvarintUnsafe(fd) nDefers, fd := readvarintUnsafe(fd) // 当前的df位，记录着defer执行与否的相关信息 deferBits := *(*uint8)(unsafe.Pointer(d.varp - uintptr(deferBitsOffset))) // 遍历当前函数注册的defer列表 for i := int(nDefers) - 1; i \u0026gt;= 0; i-- { // read the funcdata info for this defer var closureOffset uint32 closureOffset, fd = readvarintUnsafe(fd) if deferBits\u0026amp;(1\u0026lt;\u0026lt;i) == 0 { // 当前位没有注册defer直接跳过 continue } closure := *(*func())(unsafe.Pointer(d.varp - uintptr(closureOffset))) d.fn = closure // defer注册的函数 deferBits = deferBits \u0026amp;^ (1 \u0026lt;\u0026lt; i) // 清除当前标记位 *(*uint8)(unsafe.Pointer(d.varp - uintptr(deferBitsOffset))) = deferBits // 回写给内存 p := d._panic // Call the defer. Note that this can change d.varp if // the stack moves. // 再次panic时，直接跳转，其他情况继续走下面流程 deferCallSave(p, d.fn) // 调用fn函数，可能recover也可能panic // 这种情况是又panic if p != nil \u0026amp;\u0026amp; p.aborted { break } d.fn = nil // 帮助GC // 该panic是否被恢复 if d._panic != nil \u0026amp;\u0026amp; d._panic.recovered { done = deferBits == 0 // deferBits == 0 表示open code defers的defer以运行完 break } } return done } recovery() 该函数负责用于存储在sigcode0和sigcode1中的sp和pc恢复gp的执行状态。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // Unwind the stack after a deferred function calls recover // after a panic. Then arrange to continue running as though // the caller of the deferred function returned normally. func recovery(gp *g) { // Info about defer passed in G struct. sp := gp.sigcode0 pc := gp.sigcode1 // d\u0026#39;s arguments need to be in the stack. // // 确保sp不为0，并在在gp的栈中 if sp != 0 \u0026amp;\u0026amp; (sp \u0026lt; gp.stack.lo || gp.stack.hi \u0026lt; sp) { print(\u0026#34;recover: \u0026#34;, hex(sp), \u0026#34; not in [\u0026#34;, hex(gp.stack.lo), \u0026#34;, \u0026#34;, hex(gp.stack.hi), \u0026#34;]\\n\u0026#34;) throw(\u0026#34;bad recovery\u0026#34;) } // Make the deferproc for this d return again, // this time returning 1. The calling function will // jump to the standard return epilogue. // // 把sp和pc赋值给gp.sched中对应的字段， // 并把返回值设置为1。 gp.sched.sp = sp // 为跳转准备 SP gp.sched.pc = pc // 为跳转准备 PC gp.sched.lr = 0 gp.sched.ret = 1 // 设置返回值 1,这里就是AX=1的由来 // 调用gogo()函数之后，gp的栈指针和指令指针机会恢复到sp和pc的位置， // 而这个位置是deferproc()函数通过getcallersp()函数和getcallerpc()函数获得的。 gogo(\u0026amp;gp.sched) // 调用gogo函数去跳转 } preprintpanics() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // Call all Error and String methods before freezing the world. // Used when crashing with panicking. func preprintpanics(p *_panic) { // 防止panic defer func() { if recover() != nil { throw(\u0026#34;panic while printing panic value\u0026#34;) } }() for p != nil { // p.arg是any类型，来自panic(v any) switch v := p.arg.(type) { case error: // 实现了error接口 p.arg = v.Error() // 保存信息 string case stringer:\t// 实现了stringer接口 p.arg = v.String() // 保存信息 string } p = p.link // 指向下一个panic } } printpanics() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // Print all currently active panics. Used when crashing. // Should only be called after preprintpanics. func printpanics(p *_panic) { if p.link != nil { // 递归回调从注册第一个panic开始 printpanics(p.link) // 不是goexit，打印符号 if !p.link.goexit { print(\u0026#34;\\t\u0026#34;) } } // 是goexit触发直接返回 if p.goexit { return } print(\u0026#34;panic: \u0026#34;) // 打印错误信息 printany(p.arg) // 如果已经recovered，则打印 [recovered] if p.recovered { print(\u0026#34; [recovered]\u0026#34;) } print(\u0026#34;\\n\u0026#34;) } recover() 1 2 3 4 5 6 7 8 9 10 // The recover built-in function allows a program to manage behavior of a // panicking goroutine. Executing a call to recover inside a deferred // function (but not any function called by it) stops the panicking sequence // by restoring normal execution and retrieves the error value passed to the // call of panic. If recover is called outside the deferred function it will // not stop a panicking sequence. In this case, or when the goroutine is not // panicking, or if the argument supplied to panic was nil, recover returns // nil. Thus the return value from recover reports whether the goroutine is // panicking. func recover() any gorecover() 该函数必须在defer中作为一部分被使用。 该函数主要作用是设置 painc 的 recovered 表示已被恢复。 被恢复的panic会跳转到恢复的defer注册下一行指令处通过if条件跳转到deferreturn函数处去执行剩余的defer。 gopanic()函数的主要逻辑，其中for循环每调用完一个defer函数都会检查p.recovered字段，如果值为true就执行 recover逻辑。也就是说真正的recover逻辑是在gopanic()函数中实现的，defer函数中调用了内置函数recover()， 实际上只会设置_panic的一种状态。内置函数recover()对应runtime中gorecover()函数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // The implementation of the predeclared function recover. // Cannot split the stack because it needs to reliably // find the stack segment of its caller. // // TODO(rsc): Once we commit to CopyStackAlways, // this doesn\u0026#39;t need to be nosplit. //go:nosplit func gorecover(argp uintptr) any { // argp 参数根据AX寄存器传递 // 1. 该参数是来自调用当前defer函数的调用者SP栈 // 2. 因此顶层的defer能捕获下层的panic // Must be in a function running as part of a deferred call during the panic. // Must be called from the topmost function of the call // (the function used in the defer statement). // p.argp is the argument pointer of that topmost deferred function call. // Compare against argp reported by caller. // If they match, the caller is the one who can recover. // // 必须在一个函数中，该函数作为 panic 期间 defer 调用的一部分运行 // 必须从调用的最顶层函数调用 (在defer语句中使用的函数) // p.argp 是最上面那个 defer 函数调用的实参指针 // 与调用者报告的 argp 进行比较 // 如果它们匹配，调用方就可以恢复 gp := getg() // 获取当前正在执行的g p := gp._panic // 最新注册的panic // p != nil：存在注册的panic // !p.goexit：不是goexit函数触发的 // !p.recovered：该panic没有被恢复 // argp == uintptr(p.argp)：必须在defer函数中直接调用recover函数才有用，不可嵌套在其他函数中 // 1. p.argp：存储的是调用panic的调用者栈SP位置 if p != nil \u0026amp;\u0026amp; !p.goexit \u0026amp;\u0026amp; !p.recovered \u0026amp;\u0026amp; argp == uintptr(p.argp) { p.recovered = true // 标识当前这个panic从异常或错误场景中恢复 return p.arg // 该参数是panic(v any)传递的空接口参数，直接返回给recover函数调用者即可 } return nil } 内置函数recover()是没有参数的，但是gorecover()函数却有一个参数argp，这也是编译器做的手脚。 编译器会把调用者的args from caller区间的起始地址作为参数传递给gorecover()函数。 1 2 3 4 5 6 func fn() { defer func(a int) { recover() println(a) }(0) } 经编译转换后的等价代码如下： 1 2 3 4 5 6 func fn() { defer func(a int) { gorecover(uintptr(unsafe.Pointer(\u0026amp;a))) println(\u0026amp;a) }(0) } 为什么要传递这个argp参数呢？ 从代码逻辑来看，gorecover()函数会把它跟当前_panic对象p的argp字段比较，只有相等时才会把p.recovered设置为true。 从参数逻辑上看argp == uintptr(p.argp)是不相等的，编译器会在调用fn()函数中插入以下代码逻辑来修正argp的值。 如果gp._panic不为nil且gp._panic.argp的值等于当前函数栈帧args from caller区间的起始地址，就把它的值改成当前 函数栈帧args to callee区间的起始地址。与编译器插入的这些指令等价的Go代码如下： 1 2 3 4 5 6 7 gp := getg() if gp._panic != nil { // 这一条限制只是限制了recover()必须在defer函数中【直接调用】才起作用。 if gp._panic.argp == uintptr(unsafe.Pointer(\u0026amp;argtype)) { gp._panic.argp = getargp(0) } } Go语言对recover强加的一条限制：必须在defer函数中直接调用recover()函数才有用，不可嵌套在其他函数中。 recover()函数调用有效的示例代码： 1 2 3 4 5 func fn() { defer func() { recover() }() } recover()函数调用无效的示例代码： 1 2 3 4 5 6 7 8 9 func fn() { defer func() { r() }() } func r() { recover() } Go语言的recover与其他语言的try和catch有明显的不同，即不像catch语句那样能够限定异常的类型。 如果没有对recover的这种限制，就会使代码行为变得不可控，panic可能经常会被某个深度嵌套的recover恢复，然而这并不是开发者想要的。 panic()汇编 1 2 3 4 5 package main func main() { panic(\u0026#34;111111\u0026#34;) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 TEXT main.main(SB) /mnt/hgfs/g/hello1/hello.go hello.go:3 0x45b4a0 493b6610 cmp rsp, qword ptr [r14+0x10] hello.go:3 0x45b4a4 7622 jbe 0x45b4c8 hello.go:3 0x45b4a6 4883ec18 sub rsp, 0x18 hello.go:3 0x45b4aa 48896c2410 mov qword ptr [rsp+0x10], rbp hello.go:3 0x45b4af 488d6c2410 lea rbp, ptr [rsp+0x10] # 准备空接口参数 AX=rip+0x4c65 etype.type *type类型 hello.go:4 0x45b4b4 488d05654c0000 lea rax, ptr [rip+0x4c65] # 准备空接口参数 BX=rip+0x1463e etype.data uintptr类型 hello.go:4 0x45b4bb 488d1d3e460100 lea rbx, ptr [rip+0x1463e] # gopanic标识panic开始，AX和BX寄存器存储的是要传递的数据 hello.go:4 0x45b4c2 e8d946fdff call $runtime.gopanic hello.go:4 0x45b4c7 90 nop hello.go:3 0x45b4c8 e893cdffff call $runtime.morestack_noctxt .:0 0x45b4cd ebd1 jmp $main.main ","permalink":"https://heliu.site/posts/golang/func/painc-theory/","summary":"panic、recover 相关流程介绍。","title":"painc、recover(原理)"},{"content":" 接口类型：是Go语言的一种数据类型，被设计成一个容器装载其他非接口类型。 接口是什么 接口是能装载任意其他类型的容器，接口分【空接口】和【非空接口】。 空接口：能装载其他任意非接口类型。 非空接口：也能装载其他非接口类型，但是必须实现了非空接口的所有方法集。 非空接口 定义了一组方法集合，这些方法集合只是被定义，并没有在接口中实现。 因此非空接口装载的类型必定是实现了非空接口定义的所有方法。 接口中定义的方法如果有非导出方法时（也就是小写字母开头的方法）只能在定义该接口的同一包中被其他类型实现。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package gom type Connectable interface { // 这里接口定义非导出方法 // 只能是gom这个包范围的类型才能实现Connectable接口 connect() } type Point struct { X float64 } // Point 实现了 Connectable 接口 // gom 以外的包实现不了 Connectable 接口，因为包含小写方法 func (p Point) connect() { } 非空接口存储结构： 1 2 3 4 type iface struct { itab *itab // 存储非空接口和装载类型的相关信息 data unsafe.Pointer // 装载类型的动态值地址 } 空接口 没有必须实现的一组方法集合，因此非空接口能装载任意其他类型。 所有的类型包括自定义类型其实都已经实现了空接口interface{}，所以空接口interface{}可以存任意类型。 空接口存储结构： 1 2 3 4 type eface struct { typ *_type // 存储类型的类型元数据信息 data unsafe.Pointer // 存储类型的存储值地址 } 空接口和非空接口 接口类型的初始化变量的值为nil。 1 2 3 4 5 6 7 8 9 10 11 // 空接口初始值 type eface struct { typ *_type // nil data unsafe.Pointer // nil } // 非空接口初始值 type iface struct { itab *itab // nil data unsafe.Pointer // nil } 空接口示例 1 2 3 4 5 6 7 8 9 // 接口i可以装载任意其他类型 var i interface{} = 99 // type eface struct { // typ *_type ---\u0026gt; 存储的是int类型的_type指针 // data uintptr ---\u0026gt; 存储的地址指针内存是99 // } i = 44.09 // 接口存储的是float64类型 i = \u0026#34;All\u0026#34; // 接口存储的是string类型 非空接口示例 接口就是一组抽象方法的集合，它必须由其他非interface类型（具体类型）实现，而不能自我实现。 1 2 3 type Stringer interface{ String() string } 单方法接口由方法名称加上er后缀或类似修改来命名，以构造代理名词，如Reader、Writer、Formatter、CloseNotifer等。 还有一些不常用的方式（当后缀er不合适），比如Recoverable，此时接口名以able结尾，或者以I开头等 1 2 3 4 5 6 7 type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } 在Go语言中，如果接口的所有方法在某个类型方法集中被实现，则认为该类型实现了这个接口。 类型不用显示声明实现接口，只需要实现接口所有方法，这样的隐式实现解耦了实现接口的包和定义接口的包。 同一个接口可被多个类型实现，一个类型也可以实现多个接口： 实现某个接口的类型，还可以有其他的方法，比如内嵌其他字段这些字段分别实现了部分方法从而实现接口。 有时甚至都不知道某个类型定义的方法集巧合地实现了另外一个接口。 类型需要实现接口方法集中的所有方法，类型实现了这个接口，那么接口类型的变量也就可以存放该类型的值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // B 接口中有非导出方法时，只能在本包中被实现，其他包中实现不了该接口 // 1. 这种情况常常被用于，某个导出的接口不想让外部包的其他类实现时。 // 在导出接口中定义非导出方法时 // 2. 在非导出接口中定义全部都是导出方法，外包能实现该接口，但是非导出接口却不可用。 type B interface { f() } type A struct { Books int } func (a A) f() { fmt.Println(\u0026#34;A.f()：\u0026#34;, a.Books) } type I int func (i I) f() { fmt.Println(\u0026#34;I.f()\u0026#34;, i) } func main() { var a A = A{Books: 9} a.f() // A.f(a) // Output: // A.f()：9 // 接口类型可接受结构体A的值，因为结构体A实现了接口 var b B = A{Books: 99} b.f() // B.f(b) // Output: // A.f()：99 // I是int类型引申出来的新类型 var i I = 199 i.f() // Output: // I.f()199 // 接口类型可接受新类型I的值，因为新类型I实现了接口 var b2 B = I(299) b2.f() // Output: // I.f()299 } 接口嵌入 一个接口可以包含一个或多个其他的接口：但在接口内不能嵌入结构体。不能嵌入接口自身，或者形成闭环，否则编译会出错误。 接口嵌入形成闭环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 1. 编译错误 接口不能嵌入自身 会形成无限循环 // Bad \u0026lt;---\u0026gt; Bad 闭环 type Bad interface { Bad } // 2. 编译错误 接口之前互相嵌套形成闭环 形成无限循环 // Bad1 --\u0026gt; Bad2 --\u0026gt; Bad1 闭环 type Bad1 interface { Bad2 } type Bad2 interface { Bad1 } 嵌入接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type ReadWrite interface { Read(b Buffer) bool Write(b Buffer) bool } type Lock interface { Lock() Unlock() } // 嵌入其他接口 type File interface { Lock // 嵌入的接口Lock Close() // 自带的Close()方法 } 类型断言 可以把实现了某个接口的类型值保存在接口变量中，但是反过来某个接口变量属于哪个类型呢? 如何检测接口变量的类型呢？这就是类型断言的作用（注意的是：接口断言时是接口特有的）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 type I interface { f() } type T string func (t T) f() { fmt.Println(\u0026#34;T Method\u0026#34;) } type Stringer interface { String() string } func main() { // 类型断言 var varI I = T(\u0026#34;Tstring\u0026#34;) // 1. 非空接口.(具体类型) // 如果断言成功，v是varL转换到类型I的值，ok的值是true // 否则v是类型T的零值，ok的值是false，也没有运行时错误发生 if v, ok := varI.(T); ok { fmt.Println(\u0026#34;varI类型断言结果为：\u0026#34;, v) v.f() } // Output: // varI类型断言结果为： Tstring // T Method // Type-Switch 做类型断言 var value interface{} // value.(type) 只能在switch中使用，会依次检查case的值进行断言，如value.(string)再试value.(Stringer)、value.(int) 等 // 这种形式下不允许使用 fallthrough 关键字 // 在处理未知类型的数据（例如解析JSON等编码的数据）更加方便 switch str := value.(type) { // str 是断言出来的值也就是 eface.data case string: fmt.Println(\u0026#34;string：\u0026#34;, str) case Stringer: fmt.Println(\u0026#34;Stringer：\u0026#34;, str) case int,uint,float32,float64: fmt.Println(\u0026#34;我是上面类型其中一个\u0026#34;) case nil: fmt.Println(\u0026#34;nil\u0026#34;) default: fmt.Println(\u0026#34;value类型不在上面中\u0026#34;) } // Output: // nil // Comma-ok 断言 // 断言是否是某个具体的类型 其实上面的 value.(type) 就是这种形式的组合 value = \u0026#34;类型断言检查\u0026#34; if str, ok := value.(string); ok { fmt.Printf(\u0026#34;value类型断言结果为：%T\\n\u0026#34;, str) // str已近转为string类型 } else { fmt.Printf(\u0026#34;value 不是 string 类型 \\n\u0026#34;) } // Output: // value类型断言结果为：string } 类型实现不同的接口将拥有不同的行为方法结合，这就是多态的本质。 使用接口代码更具有普适性，例如函数的参数为接口变量。标准库所有包中遵循了这个原则。 在Go语言中，一个接口值其实由两部分组成：type:value。 所以在做类型断言时，变量只能是接口类型变量，断言得到的值其实就是接口值中对应的类型名。 接口与动态类型 接受一个（或多个）接口类型作为参数的函数，实参可以是任何实现了该接口的类型，实现了某个接口的类型可以被传给任何以此接口为参数的函数。 Go语言动态类型的实现通常需要编译器静态检查的支持： 当变量被赋值给一个接口类型的变量时，编译器会检查其是否实现了该接口的所有方法（在赋值时检查） 也可以通过类型断言来检查接口变量是否实现了相应类型。 接口的继承 当一个类型包含（内嵌）另外一个类型（实现了一个或多个接口）时，这个类型就可以使用（另一个类型）所有的接口方法。 类型可以通过继承多个接口来提供像多重继承一样的特性。 1 2 3 4 5 6 // 在结构体中内嵌接口，该结构体将具有接口的方法 // 关于这种在结构体中会详细介绍 type ReaderWriter struct { io.Reader // 接口 io.Writer // 接口 } 使用示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // Sayer 单方法接口，待实现方法say type Sayer interface { say() } // dog 空结构体 type dog struct {} // say dog结构体定义say方法 func (d dog) say() { fmt.Println(\u0026#34;wan ...\u0026#34;) } // cat 空结构体 type cat struct {} // say cat结构体定义say方法 func (c cat) say() { fmt.Println(\u0026#34;miao ...\u0026#34;) } func main() { var x Sayer a := cat{} b := dog{} // 接口Sayer装载cat结构体 x = a x.say() // miao ... // 接口Sayer装载dog结构体 x = b x.say() // wan ... } 接口装载指针类型和值类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // Sayer 单方法接口，待实现方法say type Sayer interface { say() } // dog 空结构体 type dog struct {} // say cat结构体定义say方法 func (d dog) say() { fmt.Println(\u0026#34;wan ...\u0026#34;) } func main() { var x Sayer b := dog{} // 接口Sayer装载dog结构体 x = b x.say() // dog.say(x) // 接口Sayer装载*dog类型 c := \u0026amp;dog{} x = c // x.say() -\u0026gt; (*dog).say(x) -\u0026gt; dog.say(*c) // (*dog).say(x) 是接口生成的包装方法，里面会调用 dog.say(*c) 方法 x.say() // (*c).say() -\u0026gt; dog.say(*c) 这里并不是语法糖形式 // Output: // wan ... // wan ... } ","permalink":"https://heliu.site/posts/golang/interface/use/","summary":"Golang interface 使用介绍。","title":"接口(使用)"},{"content":" 示例代码。 1 2 3 4 5 6 7 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello World!\u0026#34;) } 程序加载阶段 程序在被操作系统加载起来运行时都会依次经过如下阶段： 从磁盘上把可执行程序读入内存。 创建进程和主线程。 为主线程分配栈空间。 把由用户在命令行输入的参数拷贝到主线程的栈。 把主线程放入操作系统的运行队列等待被调度执行起来运行。 在主线程第一次被调度起来执行第一条指令之前，主线程的函数栈如下图所示：sp指向栈顶。 相关概念： rsp：指向当前栈的栈顶，表示当前栈已经用到什么位置。 rbp：指向当前栈的栈底，表示当前栈的起点位置。 rip：CPU即将执行的下一条指令在内存中的地址，控制着程序的流程。 SB：GO汇编相关的虚拟寄存器，保存程序地址空间的起始地址。 SB寄存器保存的是当前函数在代码区的起始位置。 出现在GO汇编的函数定义、函数调用、全局变量定义以及对其引用会用到这个SB虚拟寄存器。 FP：GO汇编相关的虚拟寄存器，主要用来引用函数参数。 Go语言规定函数调用时参数都必须放在栈上，比如被调用函数使用first_arg+0(FP)来引用调用者传递进来的第一个参数。 用second_arg+8(FP)来引用第二个参数等。这里的first_arg和second_arg仅仅是一个帮助我们阅读源代码的符号。 对编译器来说无实际意义，+0和+8表示相对于FP寄存器的偏移量。 $16-8：数字16说明此函数的栈帧大小为16字节，8说明此函数的参数和返回值一共需要占用8字节内存。 程序入口 第一行代码：定义了_rt0_amd64_linux这个符号，并不是真正的CPU指令。 NOSPLIT告诉编译器不要在这个函数中插入检查栈是否溢出的代码。 第二行的JMP指令：才是主线程的第一条指令。 这条指令简单的跳转到（相当于go语言或c中的goto关键字）_rt0_amd64 这个符号处继续执行。 文件位置：go1.19.3/src/runtime/rt0_linux_amd64.s。 7 8 TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8 JMP _rt0_amd64(SB) 前两行指令：把操作系统内核传递过来的参数argc和argv数组的地址分别放在DI和SI寄存器中。 需要注意的是：【MOVQ 0(SP), DI】拷贝的是argc的值是个8字节的存储的是参数的个数，是个数字。 【LEAQ 8(SP), SI】则是取的argv的地址，是个指针*argv，也是8字节。 第三行指令：跳转到 rt0_go 去执行。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 11 12 13 14 15 16 17 18 19 # _rt0_amd64 is common startup code for most amd64 systems when using # internal linking. This is the entry point for the program from the # kernel for an ordinary -buildmode=exe program. The stack holds the # number of arguments and the C-style argv. TEXT _rt0_amd64(SB),NOSPLIT,$-8 MOVQ 0(SP), DI # DI = argc # 假设SP存储值为0x00ff00，则SI=0x00ff08，指向的是 *argv LEAQ 8(SP), SI # SI = 8(SP); *argv JMP\truntime·rt0_go(SB) rt0_go函数完成了go程序启动时的所有初始化工作。 第4条指令（ANDQ $~15, SP）： 用于调整栈顶寄存器的值使其按16字节对齐，也就是让栈顶寄存器SP指向的内存的地址为16的倍数。 之所以要按16字节对齐，是因为CPU有一组SSE指令，这些指令中出现的内存地址必须是16的倍数。 最后两条指令：把argc和argv搬到新的位置。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 159 160 161 162 163 164 165 166 167 168 169 170 171 172 TEXT runtime·rt0_go(SB),NOSPLIT|TOPFRAME,$0 # copy arguments forward on an even stack # # 在偶数栈上向前复制参数 # argc是个8字节的数值，因此AX存储的是拷贝的值 # argv根据前面可知，这里BX存储的是argv的地址，因此原数据还在8(SP)的位置 MOVQ DI, AX # AX=argc MOVQ SI, BX # BX=*argv SUBQ $(5*8), SP # 3args 2auto # $~15：0000_1111 -\u0026gt; 1111_0000 # 经过 ANDQ 调整后，一定是大于等于40byte ANDQ $~15, SP # 调整栈顶寄存器使其按16字节对齐 MOVQ AX, 24(SP) # argc放在SP+24字节处 MOVQ BX, 32(SP) # argv放在SP+32字节处，此时是argv的地址，*argv 总结：这部分代码完成了argc和argv的拷贝（argv是拷贝了地址，argv则是拷贝了副本值），栈按照16字节对齐了。 初始化g0 g0的主要作用是提供一个栈供runtime代码执行，因此这里主要对g0的几个与栈有关的成员进行了初始化。 从这里可以看出g0的栈大约有64KB，地址范围为SP - 64*1024 + 104 ～ SP。 注意：虽然这里给g0指定了大概64KB大小的栈空间大小，但是SP寄存器的值却没有减去64KB大小。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 168 169 170 171 172 173 174 175 176 177 178 179 180 181 # create istack out of the given (operating system) stack. # _cgo_init may update stackguard. # 从给定的操作系统栈中创建 istack (自己的栈)。_cgo_init 可能会更新 stackguard。 # 下面这段代码从系统线程的栈空分出一部分当做g0的栈，然后初始化g0的栈信息和stackgard MOVQ $runtime·g0(SB), DI # DI = \u0026amp;g0 LEAQ (-64*1024+104)(SP), BX # BX = SP - 64*1024 + 104 # g0.stackguard0和g0.stackguard1用于栈溢出检查，实现栈的自动伸缩，抢占调度也会用到stackguard0 MOVQ BX, g_stackguard0(DI) # g0.stackguard0 = SP - 64*1024 + 104 MOVQ BX, g_stackguard1(DI) # g0.stackguard1 = SP - 64*1024 + 104 # g0.stack 主要用来记录goroutine所使用的栈，[lo, hi) # g0.stack.lo 栈顶，指向内存低地址 # g0.stack.hi 栈底，指向内存高地址 MOVQ BX, (g_stack+stack_lo)(DI) # g0.stack.lo = SP - 64*1024 + 104 lo MOVQ SP, (g_stack+stack_hi)(DI) # g0.stack.hi = SP hi 运行完上面这几行指令后g0与栈之间的关系如下图所示： 总结：这部分代码给g0预留了大约64KB的小的栈空间（注意这里的SP寄存器值并没有被修改），设置了stack、stackguard0、stackguard1字段，这些字段都是与g0栈相关的。 CPU 相关 调用CPU相关指令，尝试获取CPU相关信息，比如CPU的厂商、处理器型号等，如果获取成功则记录在全局变量中。 判断是否需要调用初始化CGO相关函数（程序中有相关C代码则会调用，没有则不会调用）。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 # find out information about the processor we\u0026#39;re on # # 找出我们正在使用的处理器信息 # EAX寄存器设置为编号0，因为CPUID指令会使用到该寄存器。 MOVL $0, AX # EAX = 0 # CPUID 是一种用于查询处理器信息的指令，它可以返回处理器支持的功能列表和特性信息。 # CPUID 指令需要将查询信息的编号存储在 EAX 寄存器中，然后执行 CPUID 指令。 # 处理器将返回结果存储在 EAX、EBX、ECX 和 EDX 四个寄存器中，具体的返回值格式和含义取决于查询信息的编号。 # EAX 是 0 时：返回最大支持的功能编号（包括该编号）和厂商 ID（12 个字符）。 # 1. EAX：返回最大支持的功能编号 # 2. EBX：如果是 Inter 返回 \u0026#34;Genu\u0026#34;。如果是 AMD 返回 \u0026#34;Auth\u0026#34; 。 # 3. ECX：如果是 Inter 返回 \u0026#34;ntel\u0026#34;。如果是 AMD 返回 \u0026#34;enti\u0026#34; 。 # 4. EDX：如果是 Inter 返回 \u0026#34;ntel\u0026#34;。如果是 AMD 返回 \u0026#34;cAMD\u0026#34; 。 # Genuntelntel是英特厂商名称。AuthenticAMD表示是AMD厂商名称。 # EAX 是 1 时：返回处理器的基本信息，包括处理器型号、系列、扩展型号、扩展系列等。 # 1. EAX 的位0-3将包含处理器类型编码，位4-7将包含处理器家族编码，位8-11将包含处理器型号编码， # 位12-13将包含处理器扩展型号编码，位14-15将包含处理器扩展家族编码。 # 2. EBX、ECX、EDX 三个寄存器将包含其他处理器特性的信息。此处我们不关心这些数据。 # 查询 CPU 支持的功能列表（编号 0）：0、1、2、4、0x80000000、0x80000001 # 1. EAX 的值为 0x0：返回最大支持的功能编号（包括该编号）和厂商 ID（12 个字符）。 # 2. EAX 的值为 0x1：返回处理器的基本信息，包括处理器型号、系列、扩展型号、扩展系列等。 # 3. EAX 的值为 0x80000000h：返回最大支持的扩展功能编号和厂商 ID（12 个字符）。 # 4. EAX 的值为 0x80000001h：返回处理器的扩展信息，包括扩展特性、虚拟化支持等。 CPUID CMPL AX, $0 JE nocpuinfo # AX == 0，没有CPU信息 # 以下判断当前处理器是否是 GenuineIntel # BX != \u0026#34;Genu\u0026#34;; JNE 就会跳转 CMPL BX, $0x756E6547 # \u0026#34;Genu\u0026#34; JNE\tnotintel # 不是英特处理器时 # BX != \u0026#34;ineI\u0026#34;; JNE 就会跳转 CMPL DX, $0x49656E69 # \u0026#34;ineI\u0026#34; JNE\tnotintel # 不是英特处理器时 # BX != \u0026#34;ntel\u0026#34;; JNE 就会跳转 CMPL CX, $0x6C65746E # \u0026#34;ntel\u0026#34; JNE\tnotintel # 不是英特处理器时 # 将runtime的全局变量 isIntel 设置为 1 # 该变量在 runtime/runtime2.go 全局变量中 # 表示当前处理器是 GenuineIntel MOVB $1, runtime·isIntel(SB) notintel: # 不是intel # Load EAX=1 cpuid flags MOVL $1, AX CPUID # 将runtime的全局变量 processorVersionInfo 设置为 AX # AX寄存器存储的是处理器的标识，可以识别特定的处理器。 # 由于判断CPU是否支持相关的指令集，比如AVX指令集。 MOVL AX, runtime·processorVersionInfo(SB) nocpuinfo: # 没有cpu信息 # if there is an _cgo_init, call it. # # 如果存在_cgo_init，则调用它。代码中存在调用C相关函数时这里AX会有值并判断成功 # cgo_init函数是一个内部函数，用于初始化C语言代码和Go代码之间的接口。 # cgo_init函数是Go运行时系统的一部分，它在程序启动时被自动调用。 # 它会初始化cgo相关的全局变量，设置cgo的信号处理器，并将C语言代码中的函数指针转换为Go语言中的函数类型， # 以便能够在Go语言中调用它们。 # 使用 CGO 的情况下： # 1. Go会创建一个C语言的线程，并使用线程本地存储（Thread-Local Storage，TLS）来存储C语言函数所需要的数据。 # 2. 当使用cgo调用C语言函数时，cgo会自动初始化这个线程的TLS。这个初始化是在_cgo_init函数中完成的， # 这个函数是由Go编译器自动生成的。 MOVQ _cgo_init(SB), AX # 将寄存器 AX 中的值与自己进行按位逻辑与运算，并更新标志寄存器的值。 # 如果全部为 1，那么结果就是非零值，否则就是零。 # 这条指令的作用就是判断 AX 的值是否为零。 TESTQ AX, AX # 这条指令是一个条件跳转指令，它会根据上一条指令更新的标志寄存器的值来判断是否跳转到目标标签 needtls。 # JZ 是“Jump if Zero”的缩写，意思是如果上一条指令的【结果为零】，则跳转到目标标签。 # 跳转这里表示修改去 TLS 设置 JZ\tneedtls # 没有 _cgo_init 函数时跳转到 needtls # arg 1: g0, already in DI # 参数1：g0, 已经在 DI 中，前面初始化g0时放入DI中的 # 参数2：setg_gcc 放入 SI MOVQ $setg_gcc\u0026lt;\u0026gt;(SB), SI # arg 2: setg_gcc #ifdef GOOS_android\tMOVQ $runtime·tls_g(SB), DX # arg 3: \u0026amp;tls_g # arg 4: TLS base, stored in slot 0 (Android\u0026#39;s TLS_SLOT_SELF). # Compensate for tls_g (+16). MOVQ -16(TLS), CX #else # 参数3,4：都为0，使用平台的TLS时不使用 MOVQ $0, DX\t# arg 3, 4: not used when using platform\u0026#39;s TLS MOVQ $0, CX #endif #ifdef GOOS_windows # Adjust for the Win64 calling convention. MOVQ CX, R9 # arg 4 MOVQ DX, R8 # arg 3 MOVQ SI, DX # arg 2 MOVQ DI, CX # arg 1 #endif # DI、SI、DX、CX参数已准备好 # DI = \u0026amp;g0 # SI = setg_gcc # DX = 0 # CX = 0 # AX=_cgo_init; 调用 _cgo_init 函数 CALL AX # update stackguard after _cgo_init # 在 _cgo_init 后更新 stackguard，因为更新了stack.lo的值了。 MOVQ $runtime·g0(SB), CX # CX = \u0026amp;g0 MOVQ (g_stack+stack_lo)(CX), AX # AX = g0.stack.lo; lo = SP + 8MB - 4KB # _StackGuard 是 928byte ADDQ $const__StackGuard, AX # AX = AX + _StackGuard # g0.stackguard0 = g0.stack.lo + _StackGuard # g0.stack.lo = SP + 8MB - 4KB # stackguard0 用于 runtime 栈溢出判断。 MOVQ AX, g_stackguard0(CX) # g0.stackguard1 = g0.stack.lo + _StackGuard # stackguard1 被 g0 和 gsignal 中的C代码使用。用于栈溢出判断 MOVQ AX, g_stackguard1(CX) ## 这里是 ifndef，不是windows则JMP ok不需要去TLS ## 这种情况发生在 _cgo_init 函数被调用时候 # #ifndef GOOS_windows JMP ok #endif needtls: ## 需要TLS的情况判断 #ifdef GOOS_plan9 # skip TLS setup on Plan 9 JMP ok ## 跳过TLS设置，不要手动设置 #endif #ifdef GOOS_solaris # skip TLS setup on Solaris JMP ok ## 跳过TLS设置，不要手动设置 #endif #ifdef GOOS_illumos # skip TLS setup on illumos JMP ok ## 跳过TLS设置，不要手动设置 #endif #ifdef GOOS_darwin # skip TLS setup on Darwin JMP ok ## 跳过TLS设置，不要手动设置 #endif #ifdef GOOS_openbsd # skip TLS setup on OpenBSD JMP ok ## 跳过TLS设置，不要手动设置 #endif cgo初始化 初始化 C 语言代码和 Go 代码之间的接口。 参数： G *g：\u0026amp;runtime.g0。 void (*setg)(void*)：setg_gcc函数。 void **tlsg：NULL。 void **tlsbase：NULL。 文件位置：go1.19.3/src/runtime/cgo/gcc_linux_amd64.c。 该函数只是设置了g0栈的stack.lo = SP - 8MB + 4KB，并没有创建新的线程。 这段代码执行了以下重要任务： 线程栈的初始化和设置： Go运行时使用goroutines来并发执行代码，每个goroutine有自己的栈。 当使用cgo时，Go运行时需要与C代码的线程栈进行交互。 这段代码确保了C线程的栈与Go运行时的栈设置是一致的。 栈边界设置： 设置stacklo字段是为了确定goroutine栈的底部位置。 在Go中，每个goroutine的栈都有一个底部和顶部，stacklo和stackhi分别代表栈的底部和顶部地址。 以下是为什么要这样设置的原因： 安全边界：通过将stacklo设置为距离栈顶8MB减去4KB的位置，代码为栈溢出检测留出了空间。如果goroutine的栈增长超过了这个设置的范围，那么它将触发栈溢出错误，而不是覆盖其他内存，这有助于防止内存损坏。 栈空间预留：在C和Go代码之间进行切换时，可能需要额外的栈空间来处理函数调用、参数传递等。预留空间可以确保在这些操作中有足够的空间，避免栈溢出。 与Go运行时栈管理兼容：Go运行时负责管理goroutines的栈，包括栈的增长和收缩。这段代码确保了C线程的栈与Go运行时的栈管理策略兼容。 初始化setg_gcc：setg_gcc是一个全局变量，用于在C代码中设置当前的goroutine。在C代码中调用Go函数时，需要正确设置当前的goroutine，这样Go运行时才能正确管理goroutine的状态。 总的来说，这段代码是cgo初始化的一部分，目的是为了确保C线程的栈与Go运行时的goroutine栈能够正确地协同工作，同时保持栈的安全性和性能。 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 static void (*setg_gcc)(void*); // This will be set in gcc_android.c for android-specific customization. void (*x_cgo_inittls)(void **tlsg, void **tlsbase) __attribute__((common)); void x_cgo_init(G *g, void (*setg)(void*), void **tlsg, void **tlsbase) { // 申明一个 pthread_attr_t 类型变量 *attr，指针类型. // pthread_attr_t 是线程的属性结构 pthread_attr_t *attr; // 申明一个 size_t 类型变量 size。 size_t size; // 用于保存新创建的这个线程的栈大小 /* The memory sanitizer distributed with versions of clang before 3.8 has a bug: if you call mmap before malloc, mmap may return an address that is later overwritten by the msan library. Avoid this problem by forcing a call to malloc here, before we ever call malloc. This is only required for the memory sanitizer, so it\u0026#39;s unfortunate that we always run it. It should be possible to remove this when we no longer care about versions of clang before 3.8. The test for this is misc/cgo/testsanitizers. GCC works hard to eliminate a seemingly unnecessary call to malloc, so we actually use the memory we allocate. */ setg_gcc = setg; // 向setg_gcc全局静态变量赋值setg_gcc()函数的地址 // 向操作系统申请 *attr 类型需要的内存，其实就是一个指针大小。 attr = (pthread_attr_t*)malloc(sizeof *attr); if (attr == NULL) { // 申请失败 fatalf(\u0026#34;malloc failed: %s\u0026#34;, strerror(errno)); } // 初始化线程属性对象；创建的默认栈大小为8M pthread_attr_init(attr); // pthread_attr_getstacksize 获取线程的栈大小 pthread_attr_getstacksize(attr, \u0026amp;size); // __builtin_frame_address(0) 查看当前函数的栈帧地址，因此和SP寄存器值相差不大 // 注意这里修改的是 stack.lo = SP - 8MB + 4KB，加上4KB是为了判断当前分配的栈是否超过4KB // 因为g参数传递的是指针，这里直接修改了g0的stack.lo字段的值，这里相当于扩大了g0栈大小。 g-\u0026gt;stacklo = (uintptr)__builtin_frame_address(0) - size + 4096; // lo \u0026gt;= hi，错误的栈边界。hi-\u0026gt;lo（高-\u0026gt;低），判断是否溢出 if (g-\u0026gt;stacklo \u0026gt;= g-\u0026gt;stackhi) fatalf(\u0026#34;bad stack bounds: lo=%p hi=%p\\n\u0026#34;, g-\u0026gt;stacklo, g-\u0026gt;stackhi); // 销毁 attr 这个线程属性对象 pthread_attr_destroy(attr); free(attr); // 释放 attr 占用的内存 if (x_cgo_inittls) { x_cgo_inittls(tlsg, tlsbase); } } 根据汇编代码可知，setg_gcc()函数应该是把g放入TLS和R14寄存器中。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 1049 1050 1051 1052 1053 1054 # void setg_gcc(G*); set g called from gcc. TEXT setg_gcc\u0026lt;\u0026gt;(SB),NOSPLIT,$0 get_tls(AX) MOVQ DI, g(AX) MOVQ DI, R14 # set the g register RET 传入给x_cgo_init的G *g参数其实是g0，而g0结构体第一个字段就是stack，包含stacklo和stackhi，因此能直接转换。 文件位置：go1.19.3/src/runtime/cgo/libcgo.h。 17 18 19 20 21 22 23 24 25 26 27 /* * The beginning of the per-goroutine structure, * as defined in ../pkg/runtime/runtime.h. * Just enough to edit these two fields. */ typedef struct G G; struct G { uintptr stacklo; uintptr stackhi; }; 总结：这部分代码，尝试获取CPU相关信息并保存在全局变量中。判断是否存在CGO相关初始化，如果需要则从新设置g0的栈大小。 运行完上面这cgo初始化与栈之间的关系如下图所示： 主线程与m0绑定 设置tls 设置好g0栈之后，获取到CPU型号以及cgo初始化后，设置工作线程TLS。 调用settls函数初始化主线程的线程本地存储(TLS)，目的是把m0与主线程关联在一起。 设置了线程本地存储之后接下来的几条指令在于验证TLS功能是否正常，如果不正常则直接abort退出程序。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 # 1) 设置 TLS # 下面开始初始化tls（thread local storage，线程本地存储） # LEA将内存地址赋值给DI，取m0的tls成员的地址到DI寄存器 LEAQ runtime·m0+m_tls(SB), DI # DI=\u0026amp;m0.tls # 调用settls设置线程本地存储，settls函数的参数在DI寄存器中 CALL runtime·settls(SB) # 2) 验证 TLS 是否可用 # store through it, to make sure it works # # 通过它进行存储，以确保它有效 # 验证settls是否可以正常工作，如果有问题则abort退出程序 get_tls(BX)\t# 获取fs段基地址并放入BX寄存器，其实就是m0.tls[1]的地址，get_tls的代码由编译器生成 # 通过 FS 寄存器存储的值进行设置 MOVQ $0x123, g(BX) # 把整型常量0x123拷贝到fs段基地址偏移-8的内存位置，也就是m0.tls[0]=0x123 # 通过 runtime.mtls[0] 进行取值 MOVQ runtime·m0+m_tls(SB), AX # AX=m0.tls[0]，MOV将值赋值给AX # 比较 AX 与 $0x123 是否相等 CMPQ AX, $0x123 # 检查m0.tls[0]的值是否通过线程本地存储存入的0x123来验证tls功能是否正常 # 如果前面的比较结果是相等，跳转到当前指令地址加2个字节的位置（即下一条指令） # 如果比较结果不是相等，则继续执行下一条指令。 JEQ 2(PC) # 跳过下面这一条指令 CALL runtime·abort(SB) # 如果线程本地存储不能正常工作，退出程序 runtime·settls(SB) 将tls-base设置为DI寄存器的值，DI寄存器存储的是m0.tls的地址。 通过arch_prctl系统调用把m0.tls[1]的地址设置成了fs段的段基址。 CPU中有个叫fs的段寄存器与之对应： 而每个线程都有自己的一组CPU寄存器值，操作系统在把线程调离CPU运行时会帮我们把所有寄存器中的值保存在内存中。 调度线程起来运行时又会从内存中把这些寄存器的值恢复到CPU。在此之后工作线程代码就可以通过fs寄存器来找到m.tls。 文件位置：go1.19.3/src/runtime/sys_linux_amd64.s。 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 # set tls base to DI TEXT runtime·settls(SB),NOSPLIT,$32 #ifdef GOOS_android # Android stores the TLS offset in runtime·tls_g. SUBQ runtime·tls_g(SB), DI #else # DI寄存器中存放的是m.tls[0]的地址，m的tls成员是一个数组 # 下面这一句代码把DI寄存器中的地址加8，为什么要+8呢，主要跟ELF可执行文件格式中的TLS实现的机制有关 # 执行下面这句指令之后DI寄存器中存放的就是m.tls[1]的地址了 ADDQ $8, DI # ELF wants to use -8(FS) #endif # AMD64 Linux平台约定在进行系统调用时使用： # 1. rax寄存器存放系统调用编号 # 2. 同时约定使用rdi, rsi, rdx, r10, r8和r9来传递前6个系统调用参数 # 下面通过arch_prctl系统调用设置FS段基地址 # arch_prctl系统调用的第二个参数，设置该值为FS段基地址 MOVQ DI, SI # SI = DI # arch_prctl的第一个参数：ARCH_SET_FS 参数值表示设置线程的TLS地址的。 # 在 x86 架构中，FS 寄存器用于存储 TLS （Thread Local Storage）的地址 MOVQ $0x1002, DI\t# ARCH_SET_FS # AX 系统调用编号 MOVQ $SYS_arch_prctl, AX # AX = $SYS_arch_prctl # DI = ARCH_SET_FS # SI = \u0026amp;m.tls[1] SYSCALL # 系统调用，进入内核 # 判断系统调用是否成功 # 将 AX 寄存器中的值与 0xfffffffffffff001 进行比较 # 如果 AX 中的值小于等于 0xfffffffffffff001，则跳转到当前指令地址加上2的地址（即跳转到下一条指令的下一条指令）。 CMPQ AX, $0xfffffffffffff001 JLS\t2(PC) # 跳过以下两条指令 MOVL $0xf1, 0xf1 # crash 系统调用失败直接crash，失败原因是把$0xf1放入不存在地址里面 RET # 直接返回 相关宏定义。 文件位置：go1.19.3/src/runtime/go_tls.h。 9 10 11 12 #ifdef GOARCH_amd64 #define get_tls(r) MOVQ TLS, r // get_tls函数定义，TLS其实就是FS寄存器的值 #define g(r) 0(r)(TLS*1) // (r + TLS*1 + 0) #endif m0绑定 首先把g0的地址放入主线程的线程本地存储（TLS）中，然后通过【m0.g0=\u0026amp;g0】【g0.m=\u0026amp;m0】把m0和g0绑定在一起。 之后在主线程中通过get_tls可以获取到g0，通过g0的m成员又可以找到m0。 保存在主线程本地存储中的值是g0的地址，也就是说工作线程的私有全局变量其实是一个指向g的指针而不是指向m的指针。 目前这个指针指向g0，表示代码正运行在g0栈。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 ok: # 1) g0 与 TLS 绑定 # set the per-goroutine and per-mach \u0026#34;registers\u0026#34; get_tls(BX)\t# 获取fs段基地址到BX寄存器 LEAQ runtime·g0(SB), CX # CX = \u0026amp;g0; var g0 g; # 把g0的地址保存在线程本地存储里面 MOVQ CX, g(BX) # m0.tls[0]=\u0026amp;g0 LEAQ runtime·m0(SB), AX # AX = \u0026amp;m0; var m0 m; # 2) m0 和 g0 相互绑定 # m0.g0 = \u0026amp;g0 # g0.m = \u0026amp;m0 # save m-\u0026gt;g0 = g0 MOVQ CX, m_g0(AX) # m0.g0=g0 # save m0 to g0-\u0026gt;m # m的第一个字段就是m0.g0所以这里AX代表的就是m0.g0的地址处 MOVQ AX, g_m(CX) # g0.m=m0\t# CLD 指令是 Clear Direction Flag 的缩写。用于将方向标志位 DF（Direction Flag）清零。 # 在x86架构的计算机中，方向标志位DF是一个标志寄存器中的一位，用于指示字符串操作指令（如 MOVSB、LODSB、STOSB 等） # 在执行时是按照递增方向还是递减方向进行操作。 # 当 DF 为 0 时，字符串指针将按照递增方向移动；当 DF 为 1 时，字符串指针将按照递减方向移动。 # CLD 指令将方向标志位 DF 清零，表示字符串操作指令将按照递增方向进行操作。 # 如果我们使用MOVSB指令将一个长度为10字节的字符串从存储器中复制到寄存器中，它会按照递增方向从存储器中的第一个字节开始读取数据， # 并将它们复制到寄存器中。然后，它会递增存储器地址和寄存器地址，以便读取和复制下一个字节，直到整个字符串被复制到寄存器中为止。 # 意思是，在使用字符串操作指令时，这些指令会按照递增方向操作，即按照存储器地址递增的顺序复制数据。 CLD # convention is D is always left cleared 此时，主线程，m0，g0以及g0的栈之间的关系如下图所示： 总结：这段函数通过runtime·settls()函数把当前工作线程的FS寄存器地址设置为\u0026amp;m0.tls[1]地址的值，然后再验证是否设置成功。然后把g0地址放入FS段寄存器中，也就是\u0026amp;m0.tls[0]处，表示当前工作线程正在执行g0。接着设置m0.g0=g0和g0.m=m0，把g0和m0相关联起。 检查 编译器会在很多函数需要前封装一层把g写入R14寄存器中。这里编译器会把g0写入R14寄存其中。 主要是runtime·check()函数，检查内置类型的相关。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 # Check GOAMD64 reqirements # We need to do this after setting up TLS, so that # we can report an error if there is a failure. See issue 49586. # # 检查GOAMD64要求我们需要在设置TLS后执行此操作，以便在出现失败时报告错误。 #ifdef NEED_FEATURES_CX\tMOVL $0, AX CPUID CMPL AX, $0 JE\tbad_cpu MOVL $1, AX CPUID ANDL $NEED_FEATURES_CX, CX CMPL CX, $NEED_FEATURES_CX JNE\tbad_cpu #endif #ifdef NEED_MAX_CPUID MOVL $0x80000000, AX CPUID CMPL AX, $NEED_MAX_CPUID JL bad_cpu #endif #ifdef NEED_EXT_FEATURES_BX MOVL $7, AX MOVL $0, CX CPUID ANDL $NEED_EXT_FEATURES_BX, BX CMPL BX, $NEED_EXT_FEATURES_BX JNE bad_cpu #endif #ifdef NEED_EXT_FEATURES_CX MOVL $0x80000001, AX CPUID ANDL $NEED_EXT_FEATURES_CX, CX CMPL CX, $NEED_EXT_FEATURES_CX JNE bad_cpu #endif #ifdef NEED_OS_SUPPORT_AX XORL CX, CX XGETBV ANDL $NEED_OS_SUPPORT_AX, AX CMPL AX, $NEED_OS_SUPPORT_AX JNE bad_cpu #endif #ifdef NEED_DARWIN_SUPPORT MOVQ $commpage64_version, BX CMPW (BX), $13 # cpu_capabilities64 undefined in versions \u0026lt; 13 JL bad_cpu MOVQ $commpage64_cpu_capabilities64, BX MOVQ (BX), BX MOVQ $NEED_DARWIN_SUPPORT, CX ANDQ CX, BX CMPQ BX, CX JNE bad_cpu #endif # \u0026#34;TEXT runtime.check(SB)\u0026#34; 是由编译器实现，因为以下check方法由runtime的Go实现需要获取g。 # 编译器实现 \u0026#34;TEXT runtime.check(SB)\u0026#34; 是需要把g0写入R14中，然后JMP跳转到check # 该函数在 go1.19.3/src/runtime/runtime1.go:check() # 主要是检查go支持的变量内存情况，原子CAS函数等 CALL runtime·check(SB) runtime·check(SB) 汇编开头几行。 TEXT runtime.check(SB) \u0026lt;autogenerated\u0026gt; xorps xmm15, xmm15\t# 清除xmm15寄存器，可能后面函数需要使用 mov r14, qword ptr fs:[0xfffffff8] # R14 = g0 jmp $runtime.check # 跳转 check() 函数 runtime.check()的源码定义在/src/runtime/runtime1.go文件中。 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 func check() { var ( a int8 b uint8 c int16 d uint16 e int32 f uint32 g int64 h uint64 i, i1 float32 j, j1 float64 k unsafe.Pointer l *uint16 m [4]byte ) type x1t struct { x uint8 } type y1t struct { x1 x1t y uint8 } var x1 x1t var y1 y1t // 检查 int8 类型占用字节长度 if unsafe.Sizeof(a) != 1 { throw(\u0026#34;bad a\u0026#34;) } // 检查 uint8 类型占用字节长度 if unsafe.Sizeof(b) != 1 { throw(\u0026#34;bad b\u0026#34;) } if unsafe.Sizeof(c) != 2 { throw(\u0026#34;bad c\u0026#34;) } if unsafe.Sizeof(d) != 2 { throw(\u0026#34;bad d\u0026#34;) } if unsafe.Sizeof(e) != 4 { throw(\u0026#34;bad e\u0026#34;) } if unsafe.Sizeof(f) != 4 { throw(\u0026#34;bad f\u0026#34;) } if unsafe.Sizeof(g) != 8 { throw(\u0026#34;bad g\u0026#34;) } if unsafe.Sizeof(h) != 8 { throw(\u0026#34;bad h\u0026#34;) } if unsafe.Sizeof(i) != 4 { throw(\u0026#34;bad i\u0026#34;) } if unsafe.Sizeof(j) != 8 { throw(\u0026#34;bad j\u0026#34;) } if unsafe.Sizeof(k) != goarch.PtrSize { throw(\u0026#34;bad k\u0026#34;) } if unsafe.Sizeof(l) != goarch.PtrSize { throw(\u0026#34;bad l\u0026#34;) } if unsafe.Sizeof(x1) != 1 { throw(\u0026#34;bad unsafe.Sizeof x1\u0026#34;) } if unsafe.Offsetof(y1.y) != 1 { throw(\u0026#34;bad offsetof y1.y\u0026#34;) } if unsafe.Sizeof(y1) != 2 { throw(\u0026#34;bad unsafe.Sizeof y1\u0026#34;) } if timediv(12345*1000000000+54321, 1000000000, \u0026amp;e) != 12345 || e != 54321 { throw(\u0026#34;bad timediv\u0026#34;) } var z uint32 z = 1 // 检查原子操作相关 if !atomic.Cas(\u0026amp;z, 1, 2) { throw(\u0026#34;cas1\u0026#34;) } if z != 2 { throw(\u0026#34;cas2\u0026#34;) } z = 4 if atomic.Cas(\u0026amp;z, 5, 6) { throw(\u0026#34;cas3\u0026#34;) } if z != 4 { throw(\u0026#34;cas4\u0026#34;) } z = 0xffffffff if !atomic.Cas(\u0026amp;z, 0xffffffff, 0xfffffffe) { throw(\u0026#34;cas5\u0026#34;) } if z != 0xfffffffe { throw(\u0026#34;cas6\u0026#34;) } m = [4]byte{1, 1, 1, 1} atomic.Or8(\u0026amp;m[1], 0xf0) if m[0] != 1 || m[1] != 0xf1 || m[2] != 1 || m[3] != 1 { throw(\u0026#34;atomicor8\u0026#34;) } m = [4]byte{0xff, 0xff, 0xff, 0xff} atomic.And8(\u0026amp;m[1], 0x1) if m[0] != 0xff || m[1] != 0x1 || m[2] != 0xff || m[3] != 0xff { throw(\u0026#34;atomicand8\u0026#34;) } *(*uint64)(unsafe.Pointer(\u0026amp;j)) = ^uint64(0) if j == j { throw(\u0026#34;float64nan\u0026#34;) } if !(j != j) { throw(\u0026#34;float64nan1\u0026#34;) } *(*uint64)(unsafe.Pointer(\u0026amp;j1)) = ^uint64(1) if j == j1 { throw(\u0026#34;float64nan2\u0026#34;) } if !(j != j1) { throw(\u0026#34;float64nan3\u0026#34;) } *(*uint32)(unsafe.Pointer(\u0026amp;i)) = ^uint32(0) if i == i { throw(\u0026#34;float32nan\u0026#34;) } if i == i { throw(\u0026#34;float32nan1\u0026#34;) } *(*uint32)(unsafe.Pointer(\u0026amp;i1)) = ^uint32(1) if i == i1 { throw(\u0026#34;float32nan2\u0026#34;) } if i == i1 { throw(\u0026#34;float32nan3\u0026#34;) } testAtomic64() if _FixedStack != round2(_FixedStack) { throw(\u0026#34;FixedStack is not power-of-2\u0026#34;) } if !checkASM() { throw(\u0026#34;assembly checks failed\u0026#34;) } } 总结：这段代码主要是调用了runtime·check()函数，该函数主要是检查编译器是否按照预期，检查了相关内存占用值和原子操作等。 初始化m0 处理命令行参数，调用osinit函数获取CPU核的数量并保存在全局变量ncpu之中， 调度器初始化时需要知道当前系统有多少个CPU核。 调用runtime.args()函数来暂存命令行参数以待后续解析。部分系统会在这里获取与硬件相关的一些参数，例如物理页面大小。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 338 339 340 341 342 343 344 345 346 347 348 349 350 # 1) 准备调用args函数，前面四条指令把参数放在栈上 MOVL\t24(SP), AX\t# copy argc AX=argc MOVL\tAX, 0(SP)\t# argc放在栈顶，为调用runtime·args的第一个参数，var argc int32 MOVQ\t32(SP), AX\t# copy argv AX=*argv MOVQ\tAX, 8(SP)\t# argv放在SP+8的位置，为调用runtime·args的第二个参数，var argv **byte # 保存 argc和argv 遍历 auxv 设置 physPageSize 和 startupRandomData 以及处理 VDSO # 处理操作系统传递过来的参数和env，复制全局变量argc和argv值，并处理系统参数赋值给cpu相关 CALL\truntime·args(SB) # 获取CPU核数保存在ncpu中，获取physHugePageSize参数。 # physHugePageSize 是分配大页面时候被用到。 CALL\truntime·osinit(SB)\t# 执行的结果是全局变量ncpu = CPU核数 CALL\truntime·schedinit(SB)\t# 调度系统初始化 args(SB) 关于 argv 的分布图。 argv：是一个指向字符指针的指针数组，其中每个字符指针指向一个以 null 结尾的字符串，这些字符串代表了程序启动时在命令行上输入的参数。数组的第一个元素 argv[0] 通常包含了程序的名称或路径，而随后的元素 argv[1] 到 argv[argc-1] 包含了程序的实际参数。 envp：是一个指向环境变量的指针数组，这些环境变量在程序启动时由操作系统传递给程序。每个数组元素都是一个以 null 结尾的字符串，表示一个键值对，其中键和值之间通过等号(=)连接。环境变量是操作系统用来存储有关当前会话或执行环境的信息的一种方式。它们通常用于配置程序的行为，提供路径信息，或者存储用户特定的设置。 以下是一些常见的环境变量及其用途： HOME：用户的主目录路径。 PATH：执行命令时要搜索的目录列表。 PWD：当前工作目录的路径。 USER：当前登录的用户名。 SHELL：用户登录的 shell 的路径。 LANG：系统语言和地区设置。 DISPLAY：X Window System 的显示变量，用于图形界面程序。 EDITOR：用户的首选文本编辑器。 TERM：终端类型。 auxv：为程序提供了关于其执行环境的额外信息。 以下是一些常见的 auxv 条目类型及其含义： AT_NULL：标志着 auxv 数组的结束。 AT_EXECFD：执行文件的文件描述符。 AT_PHDR：程序头表的地址。 AT_PHENT：程序头表中每个条目的大小。 AT_PHNUM：程序头表中的条目数量。 AT_PAGESZ：系统的页面大小。 AT_BASE：动态链接器的基地址。 AT_ENTRY：程序的入口点地址。 AT_UID：执行程序的用户的真实用户 ID。 AT_EUID：执行程序的有效用户 ID。 AT_GID：执行程序的组 ID。 AT_EGID：执行程序的有效组 ID。 AT_SECURE：指示程序是否在 “secure mode” 下执行。 AT_RANDOM：提供随机值的指针，用于安全目的。 暂存命令行参数以待后续解析。 文件位置：go1.19.3/src/runtime/runtime1.go。 66 67 68 69 70 71 72 73 74 75 76 77 func args(c int32, v **byte) { // 保存 argc 和 argv argc = c // runtime的全局变量中 argv = v // runtime的全局变量中 // 加载 auxv sysargs(c, v) } var ( argc int32 argv **byte ) sysargs() 文件位置：go1.19.3/src/runtime/os_linux.go。 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 func sysargs(argc int32, argv **byte) { // 跳过 argv + NULL n := argc + 1 // skip over argv, envp to get to auxv // 跳过 argv 和 envp 直接到 auxv for argv_index(argv, n) != nil { n++ } // skip NULL separator n++ // 跳过 NULL // now argv+n is auxv // argv+n 后现在是 auxv。 auxv := (*[1 \u0026lt;\u0026lt; 28]uintptr)(add(unsafe.Pointer(argv), uintptr(n)*goarch.PtrSize)) if sysauxv(auxv[:]) != 0 { return } // In some situations we don\u0026#39;t get a loader-provided // auxv, such as when loaded as a library on Android. // Fall back to /proc/self/auxv. // // 在某些情况下，我们不会得到加载器提供的auxv，比如在Android上作为库加载时。 // 回到 /proc/self/auxv，去加载信息。 // var procAuxv []byte = []byte(\u0026#34;/proc/self/auxv\\x00\u0026#34;) fd := open(\u0026amp;procAuxv[0], 0 /* O_RDONLY */, 0) // 打开指定文件句柄 if fd \u0026lt; 0 { // On Android, /proc/self/auxv might be unreadable (issue 9229), so we fallback to // try using mincore to detect the physical page size. // mincore should return EINVAL when address is not a multiple of system page size. const size = 256 \u0026lt;\u0026lt; 10 // size of memory region to allocate p, err := mmap(nil, size, _PROT_READ|_PROT_WRITE, _MAP_ANON|_MAP_PRIVATE, -1, 0) if err != 0 { return } var n uintptr for n = 4 \u0026lt;\u0026lt; 10; n \u0026lt; size; n \u0026lt;\u0026lt;= 1 { err := mincore(unsafe.Pointer(uintptr(p)+n), 1, \u0026amp;addrspace_vec[0]) if err == 0 { physPageSize = n break } } if physPageSize == 0 { physPageSize = size } munmap(p, size) return } var buf [128]uintptr // 从当前文件中读取信息 n = read(fd, noescape(unsafe.Pointer(\u0026amp;buf[0])), int32(unsafe.Sizeof(buf))) closefd(fd) // 关闭文件句柄 if n \u0026lt; 0 { return } // Make sure buf is terminated, even if we didn\u0026#39;t read // the whole file. // 确保buf被终止，即使我们没有读取整个文件。 buf[len(buf)-2] = _AT_NULL sysauxv(buf[:]) } argv_index() 文件位置：go1.19.3/src/runtime/runtime1.go。 59 60 61 62 63 64 // nosplit for use in linux startup sysargs // //go:nosplit func argv_index(argv **byte, i int32) *byte { return *(**byte)(add(unsafe.Pointer(argv), uintptr(i)*goarch.PtrSize)) } sysauxv() 设置 startupRandomData 用于Hash，physPageSize 物理内存页大小，如果这些存在的情况下。 设置全局变量物理页面大小等。 文件位置：go1.19.3/src/runtime/os_linux.go。 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 func sysauxv(auxv []uintptr) int { var i int // 遍历auxv直到结束 _AT_NULL，一次性取两个分别是 tag 和 val for ; auxv[i] != _AT_NULL; i += 2 { tag, val := auxv[i], auxv[i+1] switch tag { case _AT_RANDOM: // The kernel provides a pointer to 16-bytes // worth of random data. // // 内核提供了一个指向16字节随机数据的指针。 // startupRandomData保存在启动时初始化的随机字节。这些来自ELF AT_RANDOM辅助向量。 startupRandomData = (*[16]byte)(unsafe.Pointer(val))[:] case _AT_PAGESZ: physPageSize = val // 如果是物理页大小设置该值 } archauxv(tag, val) // 该函数在linux下是空 vdsoauxv(tag, val) // 处理 vdso } return i / 2 } osinit(SB) runtime.osinit()函数中，所有的系统都会在这里获取CPU核心数，如果上一步runtime.args()没有成功获取物理页面大小，则部分系统会再次获取。Linux系统会在这里获取Huge物理页面的大小。 文件位置：go1.19.3/src/runtime/os_linux.go。 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 func osinit() { // 获取 CPU 核数 ncpu = getproccount() // 获取Linux中物理内存大页面大小。 // 大页面是指比普通页面（通常为 4KB）更大的页面大小，通常为 2MB 或 1GB。 // 使用大页面可以提高内存访问效率和系统性能，因为在使用大页面时，内核需要管理更少的页表和 TLB 条目。 // 该方法通过open去\u0026#34;/sys/kernel/mm/transparent_hugepage/hpage_pmd_size\u0026#34;路径读取的 physHugePageSize = getHugePageSize() if iscgo { // #42494 glibc and musl reserve some signals for // internal use and require they not be blocked by // the rest of a normal C runtime. When the go runtime // blocks...unblocks signals, temporarily, the blocked // interval of time is generally very short. As such, // these expectations of *libc code are mostly met by // the combined go+cgo system of threads. However, // when go causes a thread to exit, via a return from // mstart(), the combined runtime can deadlock if // these signals are blocked. Thus, don\u0026#39;t block these // signals when exiting threads. // - glibc: SIGCANCEL (32), SIGSETXID (33) // - musl: SIGTIMER (32), SIGCANCEL (33), SIGSYNCCALL (34) sigdelset(\u0026amp;sigsetAllExiting, 32) sigdelset(\u0026amp;sigsetAllExiting, 33) sigdelset(\u0026amp;sigsetAllExiting, 34) } osArchInit() // linux上该函数为空 } 获取cpu核数 这段代码通过调用操作系统的sched_getaffinity系统调用来获取当前进程的CPU亲和力掩码，这个掩码是一个位图，其中每个比特位对应一个CPU核心。如果某个比特位为1，则表示对应的CPU核心是可用的。代码通过遍历这个位图并计算为1的比特位的数量来得到可用的CPU核心数。这是一个高效的方式来获取系统资源信息，特别是在需要根据核心数来调整程序并行度的场景中。 文件位置：go1.19.3/src/runtime/os_linux.go。 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 func getproccount() int32 { // This buffer is huge (8 kB) but we are on the system stack // and there should be plenty of space (64 kB). // Also this is a leaf, so we\u0026#39;re not holding up the memory for long. // See golang.org/issue/11823. // The suggested behavior here is to keep trying with ever-larger // buffers, but we don\u0026#39;t have a dynamic memory allocator at the // moment, so that\u0026#39;s a bit tricky and seems like overkill. // // 这个缓冲区很大(8 kB)，但我们在系统堆栈上，应该有足够的空间(64 kB)。 // 而且这是一个叶子，所以我们不会占用内存很长时间。 // 这里建议的行为是继续尝试使用更大的缓冲区，但我们目前没有动态内存分配器，所以这有点棘手，似乎有点过度。 // 定义了一个常量maxCPUs，值为65536。 // 这个值并不是真正的CPU核心数，而是一个预定义的最大值，用于确定缓冲区大小。 const maxCPUs = 64 * 1024 // 65536 // 定义了一个字节切片buf，大小为8192字节（即8KB）。 // 这是因为每个CPU核心可以用一个比特位表示，所以8192字节可以表示65536个比特位，对应maxCPUs个CPU核心 var buf [maxCPUs / 8]byte // 8KB // 这行代码是核心，它调用了操作系统提供的sched_getaffinity系统调用。 // 这个系统调用用于获取给定进程ID（这里是0，表示当前进程）的CPU亲和力掩码。 // 1. 第一个参数0表示当前进程的进程ID。 // 2. 第二个参数是缓冲区buf的大小。 // 3. 第三个参数是缓冲区的指针。 // r是系统调用的返回值，它表示实际写入缓冲区的字节数。 r := sched_getaffinity(0, unsafe.Sizeof(buf), \u0026amp;buf[0]) // int32 // 如果系统调用返回负值，表示发生了错误。 // 在这种情况下，函数返回1，这可能意味着至少有一个CPU核心是可用的。 if r \u0026lt; 0 { return 1 } n := int32(0) // 遍历缓冲区直到实际写入的字节数。 // 这段代码实际上是在计算缓冲区中设置为1的比特位的数量，每个为1的比特位代表一个可用的CPU核心。 for _, v := range buf[:r] { // 对于缓冲区的每个字节，如果它不为0，则进行处理。 for v != 0 { // 通过检查每个比特位是否为1来计算核心数。 // 这里使用了位运算\u0026amp;来检查最低位是否为1，如果是，则增加核心数。 n += int32(v \u0026amp; 1) // 将字节右移一位，继续检查下一个比特位。 v \u0026gt;\u0026gt;= 1 } // n = 4 } // 如果计算得出的核心数为0（这可能是一个错误的情况），则默认设置为1。 if n == 0 { n = 1 } // 函数返回计算出的CPU核心数。 return n } sched_getaffinity 函数原型。 文件位置：go1.19.3/src/runtime/os_linux.go。 448 449 //go:noescape func sched_getaffinity(pid, len uintptr, buf *byte) int32 汇编文件地址：go1.19.3/src/runtime/sys_linux_amd64.s。 660 661 662 663 664 665 666 667 668 669 670 TEXT runtime·sched_getaffinity(SB),NOSPLIT,$0 # 第一个参数 pid 为 0 MOVQ pid+0(FP), DI\t# 第二个参数 len 占用内存大小字节 MOVQ len+8(FP), SI # 第三个参数 buf *byte 指针 MOVQ buf+16(FP), DX MOVL $SYS_sched_getaffinity, AX # $SYS_sched_getaffinity = 204 SYSCALL MOVL AX, ret+24(FP) # 保存返回值 RET 获取物理内存页大小 这段代码通过读取操作系统文件/sys/kernel/mm/transparent_hugepage/hpage_pmd_size来获取透明大页的大小。 这个文件通常包含一个整数，表示透明大页的大小（通常是2的幂）。代码通过标准的文件打开、读取和关闭操作来获取这个值，并进行了一些基本的错误处理和验证，以确保返回的是一个合理的页大小。如果文件不存在、无法读取或内容不符合预期，函数将返回0。返回值uintptr是一个无符号整数类型，足以存储内存页大小。 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 // 定义了一个字节切片sysTHPSizePath，其中包含了透明大页大小的配置文件路径。 // 末尾的\\x00是空字符，用于字符串的终止。 var sysTHPSizePath = []byte(\u0026#34;/sys/kernel/mm/transparent_hugepage/hpage_pmd_size\\x00\u0026#34;) func getHugePageSize() uintptr { var numbuf [20]byte // 调用open函数以只读模式打开上述路径指定的文件。 // 0作为第二个参数表示只读模式（O_RDONLY），第三个参数是模式，这里传0表示不需要特殊的文件权限。 fd := open(\u0026amp;sysTHPSizePath[0], 0 /* O_RDONLY */, 0) // 如果open函数返回的文件描述符小于0，表示打开文件失败，函数返回0。 if fd \u0026lt; 0 { return 0 } // 使用noescape函数来防止ptr逃逸到堆上，unsafe.Pointer将numbuf数组的地址转换为指针。 ptr := noescape(unsafe.Pointer(\u0026amp;numbuf[0])) // 调用read函数从文件描述符fd读取内容到numbuf数组中，最多读取numbuf的长度个字节。 n := read(fd, ptr, int32(len(numbuf))) // 读取完成后关闭文件描述符。 closefd(fd) // 如果读取的字节数小于或等于0，表示读取失败或文件为空，函数返回0。 if n \u0026lt;= 0 { return 0 } // 减去1，以移除读取到的字符串末尾的换行符。 n-- // remove trailing newline // 将读取到的字节转换为字符串，然后使用atoi函数将字符串转换为整数。ok表示转换是否成功。 v, ok := atoi(slicebytetostringtmp((*byte)(ptr), int(n))) // 如果转换失败或得到的值小于0，则将v设置为0。 if !ok || v \u0026lt; 0 { v = 0 } // 检查v是否为2的幂。 // 一个数是2的幂当且仅当它与其自身减1的位与结果为0。如果不是2的幂，则返回0。 if v\u0026amp;(v-1) != 0 { // v is not a power of 2 return 0 } // 如果一切正常，将读取到的值转换为uintptr类型并返回。 return uintptr(v) } schedinit(SB) 初始化调度系统，加载过程： call osinit：调用osinit()函数，设置runtime.ncpu和runtime.physHugePageSize参数的值。 call schedinit：调用schedinit()函数，初始化调度器。 make \u0026amp; queue new G：创建第一个main goroutine，并加入队列。 call runtime·mstart：调用runtime·mstart()函数开启调度循环。 这个新的goroutine运行runtime.main()函数。 文件位置：go1.19.3/src/runtime/proc.go。 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 // The bootstrap sequence is: // //\tcall osinit //\tcall schedinit //\tmake \u0026amp; queue new G //\tcall runtime·mstart // // The new G calls runtime·main. func schedinit() { // 初始化锁，如果有锁排名情况下 lockInit(\u0026amp;sched.lock, lockRankSched) lockInit(\u0026amp;sched.sysmonlock, lockRankSysmon) lockInit(\u0026amp;sched.deferlock, lockRankDefer) lockInit(\u0026amp;sched.sudoglock, lockRankSudog) lockInit(\u0026amp;deadlock, lockRankDeadlock) lockInit(\u0026amp;paniclk, lockRankPanic) lockInit(\u0026amp;allglock, lockRankAllg) lockInit(\u0026amp;allpLock, lockRankAllp) lockInit(\u0026amp;reflectOffs.lock, lockRankReflectOffs) lockInit(\u0026amp;finlock, lockRankFin) lockInit(\u0026amp;trace.bufLock, lockRankTraceBuf) lockInit(\u0026amp;trace.stringsLock, lockRankTraceStrings) lockInit(\u0026amp;trace.lock, lockRankTrace) lockInit(\u0026amp;cpuprof.lock, lockRankCpuprof) lockInit(\u0026amp;trace.stackTab.lock, lockRankTraceStackTab) // Enforce that this lock is always a leaf lock. // All of this lock\u0026#39;s critical sections should be // extremely short. // 强制这个锁始终是一个叶锁。所有锁的关键部分都应该非常短。 lockInit(\u0026amp;memstats.heapStats.noPLock, lockRankLeafRank) // raceinit must be the first call to race detector. // In particular, it must be done before mallocinit below calls racemapshadow. // // getg()函数在源代码中没有对应的定义，由编译器插入类似下面两行代码 // 1. get_tls(CX) =\u0026gt; MOVQ TLS, CX // 2. MOVQ g(CX), BX; // 起始就是从TLS中取出goroutine，此时应该是*g0。也就是\u0026amp;m0.tls[0]里面存储的值*g0。 // 前面代码可知，g0的地址被放入了TLS中，因此这里从TLS获取g0的地址 _g_ := getg() // _g_ = \u0026amp;g0 if raceenabled { _g_.racectx, raceprocctx0 = raceinit() } // 设置最多启动10000个操作系统线程，也就是最多10000个M sched.maxmcount = 10000 // The world starts stopped. // // 在没有锁排名下，该函数为空。因为此时就只有m0一个线程。 // 在有锁排名下，该函数把worldIsStopped全局变量设置为1，就返回了。 worldStopped() // STW // 校验程序的各个模块，因为golang支持shared、plugin等build模式，可能会有很多个二进制模块 // 这里会校验各个模块的符号、ABI等，确保模块间一致。 moduledataverify() // 栈内存初始化，stackpool 和 stackLarge 初始化 // goroutine的栈是动态分配、动态增长的，这一步会初始化用于栈分配的全局缓存池，以及相关的锁。 stackinit() // 栈内存初始化 // 堆内存初始化，包括初始化mheap、mcache0以及设置堆的arenaHint mallocinit()\t// 进行与CPU相关的初始化工作，检测CPU是否支持某些指令集，以及根据GODEBUG环境变量来启用或禁用某些硬件特性 cpuinit() // must run before alginit // 根据CPU对AES相关指令的支持情况，选择不同得Hash算法，所以必须在 cpuinit() 后面调用 // map、hash必须在 alginit() 函数调用后才可以使用 alginit() // maps, hash, fastrand must not be used before this call // 初始化 fastrandseed，在接下来的mcommoninit()函数中被用到 fastrandinit() // must run before mcommoninit // 初始化m0，因为从前的代码我们知道 g0-\u0026gt;m=\u0026amp;m0 // 为当前工作线程M分配ID、初始化gsignal，并把M添加到allm全局链表中 // 该函数在新创建工作线程时也会调用。 mcommoninit(_g_.m, -1) // m0 // 基于所有的已加载模块，构造一个活跃模块切片 modulesSlice，并初始化GC需要的Mask数据 modulesinit() // provides activeModules // Typelinksinit扫描来自额外模块的类型，并构建moduledata类型映射，用于消除重复类型指针。 // 基于活跃模块列表构建模块级的typemap，实现全局范围内对类型元数据去重。 typelinksinit() // uses maps, activeModules // 遍历活跃模块列表，将编译器阶段生成的所有itab添加到itabTable中 // 该函数会调用itabAdd()函数，接口的时候知道该函数会生成*itab itabsinit() // uses activeModules stkobjinit() // must run before GC starts sigsave(\u0026amp;_g_.m.sigmask) initSigmask = _g_.m.sigmask // 解析命令行参数，程序中通过os.Args得到的参数是在这里初始化的（Windows除外） // 存入 argslice []string 变量中 goargs() // 解析环境变量，程序中通过os.Getenv获取的环境变量是在这里初始化的（Windows除外） // 存入 envs []string 变量中 goenvs() // 解析环境变量GODEBUG，为runtime各个调试参数赋值 parsedebugvars() // 初始化与GC相关的参数，根据环境变量GOGC设置gcpercent gcinit() lock(\u0026amp;sched.lock) // 获取 mutex 解锁 // 上次网络轮询的时间点，设置为当前时间点 sched.lastpoll = uint64(nanotime()) // 系统中有多少核，就创建和初始化多少个P结构体对象 procs := ncpu\t// ncpu该值在runtime.osinit函数中被设置 // 如果环境变量指定了GOMAXPROCS，则创建指定数量的p if n, ok := atoi32(gogetenv(\u0026#34;GOMAXPROCS\u0026#34;)); ok \u0026amp;\u0026amp; n \u0026gt; 0 { procs = n\t} // procresize 创建和初始化全局变量allp // 根据 CPU 的核数或环境变量GOMAXPROC确定P的数量，调用procresize进行调整 // procresize 返回nil表示所有的P中本地队列都没有可运行的goroutine。 if procresize(procs) != nil { throw(\u0026#34;unknown runnable goroutine during bootstrap\u0026#34;) } unlock(\u0026amp;sched.lock) // mutex 解锁 // World is effectively started now, as P\u0026#39;s can run. worldStarted() // Start World // For cgocheck \u0026gt; 1, we turn on the write barrier at all times // and check all pointer writes. We can\u0026#39;t do this until after // procresize because the write barrier needs a P. // // 对于cgocheck \u0026gt; 1，我们在任何时候都打开写屏障并检查所有的指针写。 // 我们不能这样做，直到procresize之后，因为写屏障需要一个P。 if debug.cgocheck \u0026gt; 1 { // debug.cgocheck在parsedebugvars()函数中被设置为1 // 开启写屏障 writeBarrier.cgo = true writeBarrier.enabled = true // 初始化所有P上的写屏障缓存区 for _, p := range allp { p.wbBuf.reset() } } // 未知编译版本时 if buildVersion == \u0026#34;\u0026#34; { // Condition should never trigger. This code just serves // to ensure runtime·buildVersion is kept in the resulting binary. // // 条件应该永远不会触发。这段代码只是用于确保runtime·buildVersion保存在结果二进制文件中。 buildVersion = \u0026#34;unknown\u0026#34; } if len(modinfo) == 1 { // Condition should never trigger. This code just serves // to ensure runtime·modinfo is kept in the resulting binary. // // 条件应该永远不会触发。这段代码只是用于确保runtime·modinfo保存在结果二进制文件中。 modinfo = \u0026#34;\u0026#34; } } mcommoninit() getg()获取出来的是g0，然后调用mcommoninit函数对m0(g0.m)进行必要的初始化。 预分配的ID可以作为'id'传递，也可以通过传递 -1 来省略，系统默认分配。 该函数在新创建工作线程时也会被调用，因此可能会出现竞争。 总结：该方法主要为工作线程分配（指定一个唯一id），并初始化m的相关参数，把m加入到全局allm中。 文件位置：go1.19.3/src/runtime/proc.go。 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 // Pre-allocated ID may be passed as \u0026#39;id\u0026#39;, or omitted by passing -1. func mcommoninit(mp *m, id int64) { _g_ := getg() // \u0026amp;g0 // g0 stack won\u0026#39;t make sense for user (and is not necessary unwindable). // // g0堆栈对用户来说没有意义(并且不一定是可撤销的)。 if _g_ != _g_.m.g0 { callers(1, mp.createstack[:]) } // 获取 mutex 锁 lock(\u0026amp;sched.lock) if id \u0026gt;= 0 { mp.id = id // 使用传递来的id } else { mp.id = mReserveID() // 系统分配 } // 根据mp.id和fastrandseed生成随机hash lo := uint32(int64Hash(uint64(mp.id), fastrandseed)) // 根据cputicks()和^fastrandseed生成随机hash。cputicks()是当前CPU时间 hi := uint32(int64Hash(uint64(cputicks()), ^fastrandseed)) // 如果 lo 和 hi 刚好互补时 if lo|hi == 0 { hi = 1 } // Same behavior as for 1.17. // TODO: Simplify ths. // // 下面通过 uint32 的 lo 和 hi 组成一个(hi\u0026lt;\u0026lt;32 + lo)的uint64随机值 // 因为内存存储的原因所以有以下判断，以及数据的操作不一样 if goarch.BigEndian { // 数据存储是大端存储时 mp.fastrand = uint64(lo)\u0026lt;\u0026lt;32 | uint64(hi) } else { // 数据存储是小端存储时 // linux x86走这里。fastrand表示M的随机值。 mp.fastrand = uint64(hi)\u0026lt;\u0026lt;32 | uint64(lo) } // 创建信号处理的gsignal。 // 分配一个32KB大小的栈，然后 mp.gsignal.m = mp mpreinit(mp) if mp.gsignal != nil { // 设置 mp.gsignal.stackguard1 = 0 + _StackGuard mp.gsignal.stackguard1 = mp.gsignal.stack.lo + _StackGuard } // Add to allm so garbage collector doesn\u0026#39;t free g-\u0026gt;m // when it is just in a register or thread-local storage. mp.alllink = allm // mp.alllink 与 allm 绑定 // NumCgoCall() iterates over allm w/o schedlock, // so we need to publish it safely. atomicstorep(unsafe.Pointer(\u0026amp;allm), unsafe.Pointer(mp)) // atomically allm = mp unlock(\u0026amp;sched.lock) // mutex 解锁 // Allocate memory to hold a cgo traceback if the cgo call crashes. // 如果cgo调用崩溃，分配内存保存cgo回溯。 if iscgo || GOOS == \u0026#34;solaris\u0026#34; || GOOS == \u0026#34;illumos\u0026#34; || GOOS == \u0026#34;windows\u0026#34; { mp.cgoCallers = new(cgoCallers) } } mReserveID() 向系统申请ID。就是递增的值。 文件位置：go1.19.3/src/runtime/proc.go。 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 // mReserveID returns the next ID to use for a new m. This new m is immediately // considered \u0026#39;running\u0026#39; by checkdead. // // sched.lock must be held. func mReserveID() int64 { // 调用该方法时 sched.lock 锁必须已被持有 assertLockHeld(\u0026amp;sched.lock) // mnext 值已经溢出 if sched.mnext+1 \u0026lt; sched.mnext { throw(\u0026#34;runtime: thread ID overflow\u0026#34;) } id := sched.mnext // 分配该值 sched.mnext++ // 检查是否超出设置的最大值 checkmcount() return id } 759 760 761 762 763 764 765 766 767 768 // sched.lock must be held. func checkmcount() { assertLockHeld(\u0026amp;sched.lock) // sched.maxmcount 最大值默认被设置为 10000 if mcount() \u0026gt; sched.maxmcount { print(\u0026#34;runtime: program exceeds \u0026#34;, sched.maxmcount, \u0026#34;-thread limit\\n\u0026#34;) throw(\u0026#34;thread exhaustion\u0026#34;) } } 4490 4491 4492 4493 func mcount() int32 { // sched.nmfreed 已释放的工作线程数量 return int32(sched.mnext - sched.nmfreed) } mpreinit() mpreinit 为gsignal分配32KB栈，并绑定当前M。 文件位置：go1.19.3/src/runtime/os_linux.go。 381 382 383 384 385 386 // Called to initialize a new m (including the bootstrap m). // Called on the parent thread (main thread in case of bootstrap), can allocate memory. func mpreinit(mp *m) { mp.gsignal = malg(32 * 1024) // Linux wants \u0026gt;= 2K mp.gsignal.m = mp } atomicstorep() atomicstorep 原子地执行 *ptr = new，并调用一个写屏障。 文件位置：go1.19.3/src/runtime/atomic_pointer.go。 28 29 30 31 32 33 34 35 36 37 // atomicstorep performs *ptr = new atomically and invokes a write barrier. // //go:nosplit func atomicstorep(ptr unsafe.Pointer, new unsafe.Pointer) { // 如果开启了写屏障 if writeBarrier.enabled { atomicwb((*unsafe.Pointer)(ptr), new) } atomic.StorepNoWB(noescape(ptr), new) // *ptr = new } 此时，主线程，m0，g0以及g0的栈之间的关系如下图所示： goargs() 保存argv参数到argslice中。 文件位置：go1.19.3/src/runtime/runtime1.go。 72 73 74 75 76 77 78 79 80 81 82 83 84 85 func goargs() { if GOOS == \u0026#34;windows\u0026#34; { return } // 申请参数需要的内存大小 argslice = make([]string, argc) for i := int32(0); i \u0026lt; argc; i++ { // argv_index 在7.1.2中列出，就是偏移i个字节 argslice[i] = gostringnocopy(argv_index(argv, i)) } } var envs []string var argslice []string gostringnocopy组装成一个字符串。 文件位置：go1.19.3/src/runtime/string.go。 564 565 566 567 568 569 570 //go:nosplit func gostringnocopy(str *byte) string { // findnull寻找到null结束识别字符串长度 ss := stringStruct{str: unsafe.Pointer(str), len: findnull(str)} s := *(*string)(unsafe.Pointer(\u0026amp;ss)) return s } goenvs() 解析环境变量。 文件位置：go1.19.3/src/runtime/os_linux.go。 367 368 369 func goenvs() { goenvs_unix() } 文件位置：go1.19.3/src/runtime/runtime1.go。 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 func goenvs_unix() { // TODO(austin): ppc64 in dynamic linking mode doesn\u0026#39;t // guarantee env[] will immediately follow argv. Might cause // problems. n := int32(0) // 跳过argv + NULL，到envp，计算envp的长度。 // argv_index 参考7.1.2 for argv_index(argv, argc+1+n) != nil { n++ } envs = make([]string, n) // 申请n长度的内存 for i := int32(0); i \u0026lt; n; i++ { envs[i] = gostring(argv_index(argv, argc+1+i)) } } 文件位置：go1.19.3/src/runtime/string.go。 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 // This is exported via linkname to assembly in syscall (for Plan9). // //go:linkname gostring func gostring(p *byte) string { l := findnull(p) // 找出字符串长度 if l == 0 { return \u0026#34;\u0026#34; } // rawstring 函数在字符串包中已经介绍过 // 分会的s和b分别共用一个底层，这样操作b切片s也会跟着改变 s, b := rawstring(l) // s string, b []byte // 拷贝数据到b中从p拷贝长度l字节。 memmove(unsafe.Pointer(\u0026amp;b[0]), unsafe.Pointer(p), uintptr(l)) return s } 初始化allp 下面分析procresize()函数。 考虑到初始化完成之后用户代码还可以通过GOMAXPROCS()函数调用它重新创建和初始化p结构体对象。 而在运行过程中再动态的调整p牵涉到的问题比较多，所以这个函数的处理比较复杂。 procresize() 更改处理器数量。sched.lock必须被持有并且必须是在STW期间。 gcworkbufs不能被GC或写屏障代码修改，因此如果P数实际发生变化，GC必须不运行。 返回具有本地工作的p列表，它们需要由调用者调度。 该函数会在【程序初始化】或【startTheWorldWithSema】函数中被调用。 函数流程： 使用make([]*p, nprocs)初始化全局变量allp，即allp = make([]*p, nprocs)。 循环创建并初始化nprocs个p结构体对象并依次保存在allp切片之中。 把m0和allp[0]绑定在一起，即【m0.p = allp[0], allp[0].m = m0】。 把除了allp[0]之外的所有p放入到全局变量sched的pidle空闲队列之中。 文件位置：go1.19.3/src/runtime/proc.go。 4793 4794 4795 4796 4797 4798 4799 4800 4801 4802 4803 4804 4805 4806 4807 4808 4809 4810 4811 4812 4813 4814 4815 4816 4817 4818 4819 4820 4821 4822 4823 4824 4825 4826 4827 4828 4829 4830 4831 4832 4833 4834 4835 4836 4837 4838 4839 4840 4841 4842 4843 4844 4845 4846 4847 4848 4849 4850 4851 4852 4853 4854 4855 4856 4857 4858 4859 4860 4861 4862 4863 4864 4865 4866 4867 4868 4869 4870 4871 4872 4873 4874 4875 4876 4877 4878 4879 4880 4881 4882 4883 4884 4885 4886 4887 4888 4889 4890 4891 4892 4893 4894 4895 4896 4897 4898 4899 4900 4901 4902 4903 4904 4905 4906 4907 4908 4909 4910 4911 4912 4913 4914 4915 4916 4917 4918 4919 4920 4921 4922 4923 4924 4925 4926 4927 4928 4929 4930 4931 4932 4933 4934 4935 4936 4937 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951 4952 4953 4954 4955 4956 4957 4958 4959 4960 4961 4962 4963 4964 4965 4966 4967 4968 4969 4970 4971 4972 4973 4974 4975 4976 4977 4978 4979 4980 4981 4982 4983 4984 // Change number of processors. // // sched.lock must be held, and the world must be stopped. // // gcworkbufs must not be being modified by either the GC or the write barrier // code, so the GC must not be running if the number of Ps actually changes. // // Returns list of Ps with local work, they need to be scheduled by the caller. func procresize(nprocs int32) *p { // sched.lock 锁已经被持有 assertLockHeld(\u0026amp;sched.lock) // 必须是 STW 期间 assertWorldStopped() // 系统初始化时，gomaxprocs = 0 old := gomaxprocs // 旧的数量，也就是上次的数量 // nprocs 服务器cpu核数，或用户通过GOMAXPROCS环境变量指定的数量 if old \u0026lt; 0 || nprocs \u0026lt;= 0 { throw(\u0026#34;procresize: invalid arg\u0026#34;) } if trace.enabled { traceGomaxprocs(nprocs) } // update statistics now := nanotime() // 当前时间 // sched.procresizetime 最后一次改变gomaxprocs的时间 if sched.procresizetime != 0 { // 从备注中看出该值是procresizetime变化的积分，因该用于统计相关 // ∫gomaxprocs dt up to procresizetime sched.totaltime += int64(old) * (now - sched.procresizetime) } sched.procresizetime = now // 以32为一组，分别处理P的标志位 // idlepMask：表示在_Pidle列表中的位掩码，每一个P表示一位，记录那些P处理_Pidle（空闲）状态 // timerpMask：表示P在timer上的位掩码，每一个P表示一位，记录P与timer相关（1表示有timer，0表示没有timer） // idlepMask和timerpMask用于快速判断P的状态和P上是否有timer。 maskWords := (nprocs + 31) / 32 // int32 // Grow allp if necessary. // // 如果有必要扩展allp。 if nprocs \u0026gt; int32(len(allp)) { // 初始化时 或 P的数量扩大时 // Synchronize with retake, which could be running // concurrently since it doesn\u0026#39;t run on a P. lock(\u0026amp;allpLock)\t// 获取 mutex 锁 // 当前 allp 的容量足够本次扩展。处理P if nprocs \u0026lt;= int32(cap(allp)) { allp = allp[:nprocs] } else { // 从新申请内存并拷贝 nallp := make([]*p, nprocs) // Copy everything up to allp\u0026#39;s cap so we // never lose old allocated Ps. copy(nallp, allp[:cap(allp)]) allp = nallp } // idlepMask和timerpMask处理，容量够，直接使用 if maskWords \u0026lt;= int32(cap(idlepMask)) { idlepMask = idlepMask[:maskWords] timerpMask = timerpMask[:maskWords] } else { // 容量不够，申请内存并搬迁 // 创建一个 []uint32，每一位分别代表一个P nidlepMask := make([]uint32, maskWords) // No need to copy beyond len, old Ps are irrelevant. copy(nidlepMask, idlepMask) idlepMask = nidlepMask ntimerpMask := make([]uint32, maskWords) copy(ntimerpMask, timerpMask) timerpMask = ntimerpMask } unlock(\u0026amp;allpLock) // mutex 解锁 } // initialize new P\u0026#39;s // // 初始化所有新创建的P，从old处开始因此之前的已经初始化了 for i := old; i \u0026lt; nprocs; i++ { pp := allp[i] if pp == nil { // 可见P是堆分配的 pp = new(p) } pp.init(i) // 初始化当前P // 原子设置 【allp[i] = pp】 atomicstorep(unsafe.Pointer(\u0026amp;allp[i]), unsafe.Pointer(pp)) // 保存allp中去 } _g_ := getg() // g0 // 当前m绑定了P时，初始化时m并没有绑定P，_g_.m.p == 0。 // _g_.m.p != 0 \u0026amp;\u0026amp; _g_.m.p.ptr().id \u0026lt; nprocs 这种情况成立发生在： // 发生扩容 或 发生缩容(当前P并不在裁剪之外) if _g_.m.p != 0 \u0026amp;\u0026amp; _g_.m.p.ptr().id \u0026lt; nprocs { // continue to use the current P // // 继续使用当前P，_Prunning 运行中状态 _g_.m.p.ptr().status = _Prunning _g_.m.p.ptr().mcache.prepareForSweep() // 清理 } else { // release the current P and acquire allp[0]. // // We must do this before destroying our current P // because p.destroy itself has write barriers, so we // need to do that from a valid P. if _g_.m.p != 0 { // 这种情况发生在P在缩容(当前P并不在裁剪之外) if trace.enabled { // Pretend that we were descheduled // and then scheduled again to keep // the trace sane. traceGoSched() traceProcStop(_g_.m.p.ptr()) } // 当前M绑定的p与当前M解绑 // 因为 M 与 P 相互绑定的，这里要解绑 _g_.m.p.ptr().m = 0 // p.m = 0 } // 初始化时，会走这里 // 解绑M与P关系 _g_.m.p = 0 // m.p = 0 // 选取allp[0]绑定当前工作线程 p := allp[0] p.m = 0 // _Pidle 空闲状态 p.status = _Pidle // 标记当前P为空闲状态 // 该方法要求P和M都是没有绑定的，并且P一定是_Pidle状态。 // p.m = m; m.p = p; acquirep(p) // m与p相互绑定，并修改p的状态为运行中。 if trace.enabled { traceGoStart() } } // g.m.p is now set, so we no longer need mcache0 for bootstrapping. // // g.m.p 现在已经设置，因此我们不再需要 mcache0 来进行引导。 // mcache0 在 p.init() 函数中被使用 mcache0 = nil // 该值在前面schedinit()函数中，栈相关初始化时被设置 // release resources from unused P\u0026#39;s // // 从未使用的 P 释放资源，这种情况发生在缩容P时 for i := nprocs; i \u0026lt; old; i++ { p := allp[i] p.destroy() // 回收P // can\u0026#39;t free P itself because it can be referenced by an M in syscall // // 不能释放P本身，因为它可以被系统调用中的M引用 } // Trim allp. // 裁剪 allp。 if int32(len(allp)) != nprocs { lock(\u0026amp;allpLock) allp = allp[:nprocs] idlepMask = idlepMask[:maskWords] timerpMask = timerpMask[:maskWords] unlock(\u0026amp;allpLock) } var runnablePs *p // 遍历所有P，处理P的本地队列中有goroutine的需要绑定M运行这些goroutine。 for i := nprocs - 1; i \u0026gt;= 0; i-- { p := allp[i] // 跳过当前P，当前工作线程绑定的P正在执行这里的代码需要跳过 if _g_.m.p.ptr() == p { continue } p.status = _Pidle // 状态修改为 _Pidle 空闲 if runqempty(p) { // P的runq是空的时 pidleput(p, now) // 把当前P挂在全局sched空闲链表中 } else { p.m.set(mget()) // p绑定m p.link.set(runnablePs) runnablePs = p } } // 重置 stealOrder，该值用于随机从allp中偷取goroutine初始条件 stealOrder.reset(uint32(nprocs)) // 初始化P后面要用到偷取的数据 // 原子绑定 gomaxprocs = nprocs var int32p *int32 = \u0026amp;gomaxprocs // make compiler check that gomaxprocs is an int32 atomic.Store((*uint32)(unsafe.Pointer(int32p)), uint32(nprocs)) // gomaxprocs = nprocs if old != nprocs { // Notify the limiter that the amount of procs has changed. gcCPULimiter.resetCapacity(now, nprocs) } // runnablePs != nil 说明除了当前P外的其他P中存在goroutine return runnablePs } p.init() 初始化P。 文件位置：go1.19.3/src/runtime/proc.go。 4669 4670 4671 4672 4673 4674 4675 4676 4677 4678 4679 4680 4681 4682 4683 4684 4685 4686 4687 4688 4689 4690 4691 4692 4693 4694 4695 4696 4697 4698 4699 4700 4701 4702 4703 4704 4705 4706 4707 4708 4709 4710 4711 4712 // init initializes pp, which may be a freshly allocated p or a // previously destroyed p, and transitions it to status _Pgcstop. func (pp *p) init(id int32) { pp.id = id\t// 分配P的id，该id是唯一的 pp.status = _Pgcstop // 设置P状态 _Pgcstop GC停止状态 pp.sudogcache = pp.sudogbuf[:0] // P上sudog缓存 pp.deferpool = pp.deferpoolbuf[:0] // P上defer池 pp.wbBuf.reset() // P的wbBuf重置，该字段与写屏障相关 // pp.mcache 没有初始化 if pp.mcache == nil { if id == 0 { // 程序刚初始化时，mcache0在schedinit()中的mallocinit()函数中被创建 if mcache0 == nil { throw(\u0026#34;missing mcache?\u0026#34;) } // Use the bootstrap mcache0. Only one P will get // mcache0: the one with ID 0. pp.mcache = mcache0 } else { // 使用 allocmcache() 分配缓存 pp.mcache = allocmcache() } } if raceenabled \u0026amp;\u0026amp; pp.raceprocctx == 0 { if id == 0 { pp.raceprocctx = raceprocctx0 raceprocctx0 = 0 // bootstrap } else { pp.raceprocctx = raceproccreate() } } lockInit(\u0026amp;pp.timersLock, lockRankTimers) // 初始化 P.timersLock 锁 // This P may get timers when it starts running. Set the mask here // since the P may not go through pidleget (notably P 0 on startup). // // 这个P开始运行时可能会有times。在这里设置可能不会经过pidleget(特别是在启动时P 0)。 timerpMask.set(id) // Similarly, we may not go through pidleget before this P starts // running if it is P 0 on startup. // // 类似的，如果这个P是在启动的是P 0，我们可能不会在这个P开始运行之前经历pidleget。 idlepMask.clear(id) } acquirep() M和P相互绑定。m.p = p、p.m = m。 文件位置：go1.19.3/src/runtime/proc.go。 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951 4952 4953 4954 4955 4956 4957 4958 4959 4960 4961 // Associate p and the current m. // // This function is allowed to have write barriers even if the caller // isn\u0026#39;t because it immediately acquires _p_. // //go:yeswritebarrierrec func acquirep(_p_ *p) { // Do the part that isn\u0026#39;t allowed to have write barriers. // // 不允许有写入障碍的部分。 wirep(_p_) // m与p相互绑定，并修改p的状态为运行中。 // Have p; write barriers now allowed. // Perform deferred mcache flush before this P can allocate // from a potentially stale mcache. // // 在这个P可以从可能过期的mcache进行分配之前执行延迟的mcache刷写。 _p_.mcache.prepareForSweep() // GC相关 if trace.enabled { traceProcStart() } } wirep() wirep是acquirep 的第一步，它实际上将当前M关联到 _p_。 这里不允许栈检查，以及写屏障相关代码，因为M还没有绑定P。 m与p相互绑定，并修改p的状态为运行中。 文件位置：go1.19.3/src/runtime/proc.go。 4959 4960 4961 4962 4963 4964 4965 4966 4967 4968 4969 4970 4971 4972 4973 4974 4975 4976 4977 4978 4979 4980 4981 4982 4983 4984 4985 4986 4987 // wirep is the first step of acquirep, which actually associates the // current M to _p_. This is broken out so we can disallow write // barriers for this part, since we don\u0026#39;t yet have a P. // //go:nowritebarrierrec //go:nosplit func wirep(_p_ *p) { // 在当前这里只能是g0，但是其他地方可能是g _g_ := getg() // g0 // 此时M一定是没有绑定P的。 if _g_.m.p != 0 { throw(\u0026#34;wirep: already in go\u0026#34;) } // 此时p一定没有绑定M，并且P一定是_Pidle状态（空闲） if _p_.m != 0 || _p_.status != _Pidle { id := int64(0) if _p_.m != 0 { id = _p_.m.ptr().id } print(\u0026#34;wirep: p-\u0026gt;m=\u0026#34;, _p_.m, \u0026#34;(\u0026#34;, id, \u0026#34;) p-\u0026gt;status=\u0026#34;, _p_.status, \u0026#34;\\n\u0026#34;) throw(\u0026#34;wirep: invalid p state\u0026#34;) } // M与P相互绑定，并设置P的状态为运行中 _g_.m.p.set(_p_) // m.p = _p_ _p_.m.set(_g_.m) // _p_.m = m // _Prunning 运行中状态 _p_.status = _Prunning // 修改当前P为运行状态 } p.destroy() destroy释放与pp相关的所有资源，并将其转换为状态_Pdead。 sched.lock必须被持有并且STW。 该函数处理P中的goroutine，以及迁移pp上所有的timer，以及写屏障相关内存释放等。 文件位置：go1.19.3/src/runtime/proc.go。 4707 4708 4709 4710 4711 4712 4713 4714 4715 4716 4717 4718 4719 4720 4721 4722 4723 4724 4725 4726 4727 4728 4729 4730 4731 4732 4733 4734 4735 4736 4737 4738 4739 4740 4741 4742 4743 4744 4745 4746 4747 4748 4749 4750 4751 4752 4753 4754 4755 4756 4757 4758 4759 4760 4761 4762 4763 4764 4765 4766 4767 4768 4769 4770 4771 4772 4773 4774 4775 4776 4777 4778 4779 4780 4781 4782 4783 4784 4785 4786 4787 4788 4789 4790 4791 4792 4793 4794 4795 4796 4797 4798 4799 4800 4801 4802 4803 4804 4805 4806 4807 4808 // destroy releases all of the resources associated with pp and // transitions it to status _Pdead. // // sched.lock must be held and the world must be stopped. func (pp *p) destroy() { assertLockHeld(\u0026amp;sched.lock) assertWorldStopped() // Move all runnable goroutines to the global queue // // 将当前P的所有可运行的goroutines移动到全局队列 for pp.runqhead != pp.runqtail { // Pop from tail of local queue pp.runqtail-- gp := pp.runq[pp.runqtail%uint32(len(pp.runq))].ptr() // Push onto head of global queue globrunqputhead(gp) // 加入到全局队列池中 } // pp.runnext 上存在 goroutine，加入到全局池 if pp.runnext != 0 { globrunqputhead(pp.runnext.ptr()) pp.runnext = 0 } // P 中还有timer。 if len(pp.timers) \u0026gt; 0 { // 当前工作线程绑定的P plocal := getg().m.p.ptr() // The world is stopped, but we acquire timersLock to // protect against sysmon calling timeSleepUntil. // This is the only case where we hold the timersLock of // more than one P, so there are no deadlock concerns. // // STW了，但是我们获得了timersLock来防止sysmon调用timeSleepUntil // 这是我们持有不止一个P的定时器锁的唯一情况，因此不存在死锁问题。 lock(\u0026amp;plocal.timersLock) // plocal lock(\u0026amp;pp.timersLock) // pp // 把pp.timers中所有有效的timer重新添加到plocal.timers中 // 这里把需要删除的pp上的所有timer转移到当前工作线程绑定的P上面 moveTimers(plocal, pp.timers) pp.timers = nil // 情况 pp.timers，因为timers已经迁移到了当前工作线程的P了。 // numTimers：记录的是堆中 timer 的总数，应该与 timers 切片的长度一致。 pp.numTimers = 0 // deletedTimers：记录的是堆中已删除但还未被移除的 timer 的总数。 pp.deletedTimers = 0 // timer0When：表示位于最小堆堆顶的 timer 的触发时间，也就是赋值其 when 字段。 atomic.Store64(\u0026amp;pp.timer0When, 0) // pp.timer0When = 0 unlock(\u0026amp;pp.timersLock) unlock(\u0026amp;plocal.timersLock) } // Flush p\u0026#39;s write barrier buffer. // // 刷新p的写屏障缓冲区。写屏障相关 if gcphase != _GCoff { wbBufFlush1(pp) pp.gcw.dispose() } for i := range pp.sudogbuf { pp.sudogbuf[i] = nil } pp.sudogcache = pp.sudogbuf[:0] for j := range pp.deferpoolbuf { pp.deferpoolbuf[j] = nil } pp.deferpool = pp.deferpoolbuf[:0] // 切换到g0栈处理mspancache systemstack(func() { // 相关内存释放 for i := 0; i \u0026lt; pp.mspancache.len; i++ { // Safe to call since the world is stopped. mheap_.spanalloc.free(unsafe.Pointer(pp.mspancache.buf[i])) } pp.mspancache.len = 0 lock(\u0026amp;mheap_.lock) pp.pcache.flush(\u0026amp;mheap_.pages) unlock(\u0026amp;mheap_.lock) }) freemcache(pp.mcache) // 释放内存 pp.mcache = nil gfpurge(pp) // 回收P traceProcFree(pp) if raceenabled { if pp.timerRaceCtx != 0 { // The race detector code uses a callback to fetch // the proc context, so arrange for that callback // to see the right thing. // This hack only works because we are the only // thread running. mp := getg().m phold := mp.p.ptr() mp.p.set(pp) racectxend(pp.timerRaceCtx) pp.timerRaceCtx = 0 mp.p.set(phold) } raceprocdestroy(pp.raceprocctx) pp.raceprocctx = 0 } pp.gcAssistTime = 0 pp.status = _Pdead // 修改P状态为空闲 } pidleput() 参数： _p_ *p：当前操作的p，该p的本地队列应该是空的。 now int64：当前时间。 把当_p_挂在全局sched空闲链表中。 文件位置：go1.19.3/src/runtime/proc.go。 5696 5697 5698 5699 5700 5701 5702 5703 5704 5705 5706 5707 5708 5709 5710 5711 5712 5713 5714 5715 5716 5717 5718 5719 5720 5721 5722 5723 5724 5725 5726 5727 5728 5729 5730 // pidleput puts p on the _Pidle list. now must be a relatively recent call // to nanotime or zero. Returns now or the current time if now was zero. // // This releases ownership of p. Once sched.lock is released it is no longer // safe to use p. // // sched.lock must be held. // // May run during STW, so write barriers are not allowed. // //go:nowritebarrierrec func pidleput(_p_ *p, now int64) int64 { // 调用该函数时 sched.lock 必须被持有 assertLockHeld(\u0026amp;sched.lock) // 当前P准备放入空闲链表，因此runq中不能有goroutine if !runqempty(_p_) { throw(\u0026#34;pidleput: P has non-empty run queue\u0026#34;) } if now == 0 { now = nanotime() } // 更新TimerPMask updateTimerPMask(_p_) // clear if there are no timers. idlepMask.set(_p_.id) // 标记_p_是空闲的 // 放入全局链表中 _p_.link = sched.pidle sched.pidle.set(_p_) // sched.pidle = _p_ // 空闲P数量加一 atomic.Xadd(\u0026amp;sched.npidle, 1) // sched.npidle if !_p_.limiterEvent.start(limiterEventIdle, now) { throw(\u0026#34;must be able to track idle limiter event\u0026#34;) } return now } main goroutine schedinit完成调度系统初始化后。 返回到rt0_go函数中开始调用newproc()创建一个新的goroutine用于执行mainPC所对应的runtime·main函数。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 以下runtime·newproc、runtime·mstart将在后续文章中介绍。 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 # create a new goroutine to start program # # 创建一个新的goroutine来启动程序。 # AX = runtime·main # runtime·main 是一个闭包，\u0026amp;funcval{fn:runtime.main} MOVQ $runtime·mainPC(SB), AX # entry # 将AX的值压入栈中 PUSHQ AX # AX的值作为runtime·newproc()函数的参数 CALL runtime·newproc(SB) # 创建main goroutine POPQ AX # start this M CALL runtime·mstart(SB) # 主线程进入循环调度，运行刚刚创建的goroutine # 上面的mstart永远不应该返回的，如果返回了，一定是代码逻辑有问题，直接abort CALL runtime·abort(SB)\t# mstart should never return RET # 前面没有获取到CPU相关信息时会走这里的异常 bad_cpu: # show that the program requires a certain microarchitecture level. MOVQ $2, 0(SP) MOVQ $bad_cpu_msg\u0026lt;\u0026gt;(SB), AX MOVQ AX, 8(SP) MOVQ $84, 16(SP) CALL runtime·write(SB) MOVQ $1, 0(SP) CALL runtime·exit(SB) CALL runtime·abort(SB) RET # Prevent dead-code elimination of debugCallV2, which is # intended to be called by debuggers. MOVQ $runtime·debugCallV2\u0026lt;ABIInternal\u0026gt;(SB), AX RET 其他内容 argc和argv 在计算机编程中，通常使用命令行参数来向程序传递额外的信息。 C语言中的main函数接受两个参数，分别是argc和argv。 其中argc表示命令行参数的数量，而argv是一个指向参数字符串数组的指针，其中每个元素都包含一个命令行参数。 如果你在命令行中执行以下命令：$ my_program arg1 arg2 arg3 则argc的值将是4，其中包括程序名my_program和3个参数arg1、arg2和arg3。而argv指向一个字符串数组，其内容如下： argv[0] = \u0026#34;my_program\u0026#34; argv[1] = \u0026#34;arg1\u0026#34; argv[2] = \u0026#34;arg2\u0026#34; argv[3] = \u0026#34;arg3\u0026#34; 比如在Go语言中，argc和argv使用： 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { args := os.Args // []string fmt.Printf(\u0026#34;Path：%s\\n\u0026#34;, args[0]) fmt.Printf(\u0026#34;Args：%#v\\n\u0026#34;, args[1:]) } 当我们执行go run命令运行上面的程序并传递一些参数时，将会得到类似以下的输出： [root@localhost hello1]# go run tt12.go foo bar baz js Path：/tmp/go-build1239766326/b001/exe/tt12 Args：[]string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;, \u0026#34;js\u0026#34;} ","permalink":"https://heliu.site/posts/golang/goroutine/flow/","summary":"Golang 程序加载后的执行流程介绍。","title":"Go 执行流程"},{"content":" go关键字流程： newproc()函数是go关键字创建goroutine的初始化函数。 也是创建第一个goroutine(runtime.main)的函数。 newproc() 该函数是整个go关键字的执行流程代码，其中包括newg的创建，newg放入P中，唤醒其他P起来工作等。 创建一个新的goroutine运行fn。把它放到等待运行的g队列中。编译器将go语句转换为对this的调用。 关于参数的说明： fn *funcval：fn是一个闭包变量。看过之前版本的该函数就会发现go A(1,2)这种形式的参数怎么处理的？ 在之前版本中该函数的形式如这func newproc(siz int32, fn *funcval)，多了一个siz参数表示参数共占多少字节。 在之前的版本中Go的传参是入栈形式的，在1.18中已经改成了寄存器传参形式。 在1.18中在A函数的外层在封装了一层闭包所以少传一个参数，go A(1,2) -\u0026gt; go func() {A(1,2)}作为参数传入newproc函数。 fn *funcval：这里的函数原型是 func()，没有参数和返回值。 文件位置：go1.19.3/src/runtime/proc.go。 4091 4092 4093 4094 4095 4096 4097 4098 4099 4100 4101 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111 4112 4113 4114 4115 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125 4126 4127 4128 // Create a new g running fn. // Put it on the queue of g\u0026#39;s waiting to run. // The compiler turns a go statement into a call to this. func newproc(fn *funcval) { // getg函数在源代码中没有对应的定义，由编译器插入类似下面两行代码 // get_tls(CX); # 获取fs寄存器地址，放入寄存器CX中，fs地址被设置成\u0026amp;m.tls[1]处地址 // MOVQ g(CX), BX; # BX存器里面现在放的是当前g的地址，g(CX)获取fs-8位置存储数据,也就是当前执行的g，也就是m.tls[0]地址 gp := getg() // 获取当前运行的g，m.tls[0]存储的就是当前工作线程M绑定的g，也就是当前正在运行的g // getcallerpc()返回一个地址，也就是调用newproc时由call指令压栈的函数返回地址 // 对于我们现在这个场景来说，pc就是CALL runtime·newproc(SB)指令后面的POPQ AX这条指令的地址 // 主要用于新创建的 goroutine 记录自己是在哪里被创建的。 pc := getcallerpc() // systemstack的作用是切换到g0栈执行作为参数的函数 // 我们这个场景现在本身就在g0栈，因此什么也不做，直接调用作为参数的函数 systemstack(func() { // 创建一个新的goroutine并初始化，设置好栈大小执行地址和执行完返回地址 // 该闭包函数捕获fn、gp、pc三个变量 // 由于fn和gp都是指针，捕获值即可，而pc是uintptr类型，也是捕获的值 newg := newproc1(fn, gp, pc) // 由于当前在g0栈上，因此getg()获取的是g0 // getg().m 获取的是当前的工作线程M // 获取当前m绑定的P _p_ := getg().m.p.ptr() // 把newg放入_p_的运行队列，初始化的时候一定是p的本地运行队列 // 其它goroutine的时候可能因为本地队列满了而放入全局队列 runqput(_p_, newg, true) // true.放入P的第一位，false.放入P的最后一位 // mainStarted全局变量标记主线程runtime.main是否已经启动 // 即主goroutine已经开始执行，此后才会通过wakeup()函数启动新的工作线程， // 以保证main()函数总会被主线程调度执行。 if mainStarted { wakep()\t// 唤醒P } }) } systemstack() systemstack在系统栈上运行fn。 如果从per-OS-thread (g0)栈调用systemstack，或者从信号处理(gsignal)栈调用systemstack，则systemstack直接调用fn并且返回。 否则，systemstack将从普通goroutine的有限栈中调用。在这种情况下，systemstack切换到per-OS-thread栈，调用fn然后切换回来。 通常使用 fn 字面量作为参数，以便于系统栈调用周围的代码贡献输入和输出： // ... set up y ... systemstack(func() { x = bigcall(y) }) // ... use x ... go:noescape：指示编译器在编译代码时不对函数进行逃逸分析。 告诉编译器该函数不会将其参数的地址泄露到函数外部，因此可以避免逃逸分析和堆分配，从而提高代码的性能。 这个指令通常在一些需要高性能的函数中使用，如一些常用的内置函数或一些特定的库函数。 文件位置：go1.19.3/src/runtime/stubs.go。 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 // systemstack runs fn on a system stack. // If systemstack is called from the per-OS-thread (g0) stack, or // if systemstack is called from the signal handling (gsignal) stack, // systemstack calls fn directly and returns. // Otherwise, systemstack is being called from the limited stack // of an ordinary goroutine. In this case, systemstack switches // to the per-OS-thread stack, calls fn, and switches back. // It is common to use a func literal as the argument, in order // to share inputs and outputs with the code around the call // to system stack: // // ... set up y ... // systemstack(func() { // x = bigcall(y) // }) // ... use x ... // //go:noescape func systemstack(fn func()) runtime·systemstack() systemstack函数被设计用来临时性的切换至当前M的g0栈，完成某些操作后再切换回原来goroutine的栈。 该函数主要用于执行runtime中一些会触发栈增长的函数，因为goroutine的栈是被runtime管理的，所以runtime中这些逻辑就不能在普通的gorooutine上执行，以免陷入递归。 g0的栈是由操作系统分配的，可以认为空间足够大，被runtime用来执行自身逻辑非常安全。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 # func systemstack(fn func()) TEXT runtime·systemstack(SB), NOSPLIT, $0-8 # 闭包参数 fn func()，把fn存入DI寄存器 MOVQ fn+0(FP), DI # DI = fn get_tls(CX) # CX = \u0026amp;m.tls[1]; TLS # 这里获取的g是当前正在运行的g，可能是g0也可能不是 # 从TLS获取当前g，存入AX寄存器 MOVQ g(CX), AX # AX = g # 当前正在运行的工作线程m，将g.m存入BX寄存器中 MOVQ g_m(AX), BX # BX = m # 1) 验证数据 # 如果当前 g 是 m.gsignal # 跳转 noswitch 没有什么可做直接调用 fn 即可 # 可知m.gsignal的栈是g0栈 CMPQ AX, m_gsignal(BX) JEQ noswitch # gsignal 也是系统栈，不用切换 # 将m.g0存入DX寄存器 MOVQ m_g0(BX), DX # DX = g0 # 比较 g 和 g0，是否是一个，如果是直接跳转 noswitch # 比较当前g是不是g0 CMPQ AX, DX JEQ\tnoswitch # 已经在g0上，不需要切换 # 比较当前g是否和m.curg不一致 # 比较 g 和 m.curg，如果不相等跳转 bad # 程序刚启动初始化时m.curg为nil，会在前面的g0判断处直接跳转了，不会走到这里 # 为什么要比较crug是否是当前g?是因为从g0切换回当前g需要m.curg这个参数。 # 这种情况在普通 goroutine 切换 g0 栈时用到 CMPQ AX, m_curg(BX) JNE\tbad # 2) 存储g信息 # switch stacks # save our state in g-\u0026gt;sched. Pretend to # be systemstack_switch if the G stack is scanned. # # 将当前g的信息保存到 g-\u0026gt;sched 中。如果G栈已被扫描，则假装是 systemstack_switch 调用的。 # 保存 goroutine 的调度信息。 CALL gosave_systemstack_switch\u0026lt;\u0026gt;(SB) # 3) 切换到g0栈 # g0写入TLS、g0写入R14寄存器中、g0的栈顶值写入SP寄存器中 # switch to g0 MOVQ DX, g(CX) # g0写入TLS中 # R14 = g0 MOVQ DX, R14 # set the g register # BX = g0.sched.gobuf.sp MOVQ (g_sched+gobuf_sp)(DX), BX # SP = g0.sched.gobuf.sp MOVQ BX, SP # 恢复g0的SP # 4) 调用 fn 函数，此时已经切换到g0栈 # 上下文信息在DX寄存器中，包含闭包捕获的变量列表 # call target function MOVQ DI, DX # DX = fn = \u0026amp;funcval MOVQ 0(DI), DI # DI = funcval.fn CALL DI # fn() # 5) 切换回g栈 # 注意：当从g0切换回g的时候，并没有将g0的状态保存到g0.sched中 # 也就是说每次从g0切换至其他的goroutine后，g0栈上的内容就被抛弃了 # 下次切换至g0还是从头开始。 # 从m.curg中取出g，然后写入TLS中，恢复SP寄存器的值 # 这里没有恢复PC寄存器和BP寄存器的值，因为PC寄存器的值这里不需要恢复顺序执行代码即可， # BP寄存器的值在调用systemstack()函数的整个过程中都没有修改，因此也不需要恢复。 # switch back to g get_tls(CX) # CX = \u0026amp;m.tls[1] MOVQ g(CX), AX # AX = g0 MOVQ g_m(AX), BX # BX = m MOVQ m_curg(BX), AX # AX = m.curg; 当前g MOVQ AX, g(CX) # g存入TLS # 调用 systemstack 函数前的 SP; # R14寄存器在这个函数中没有被设置回来，应该是编译器负责设置回来吧。 MOVQ (g_sched+gobuf_sp)(AX), SP # 恢复SP; SP = g.sched.gobuf.sp MOVQ $0, (g_sched+gobuf_sp)(AX) # 清除 g.sched.gobuf.sp = 0 RET noswitch: # already on m stack; tail call the function # Using a tail call here cleans up tracebacks since we won\u0026#39;t stop # at an intermediate systemstack. # # 已经在m栈上；由于我们不会在中间系统栈上停止，因此在这里直接调用fn MOVQ DI, DX # DX = \u0026amp;funcval MOVQ 0(DI), DI # DI = funcval.fn JMP\tDI # 调用fn函数 bad: # Bad: g is not gsignal, not g0, not curg. What is it? # Bad：g 不是 gsignal，也不是 g0，不是 curg。它是什么？ MOVQ $runtime·badsystemstack(SB), AX CALL AX INT\t$3 # 调试错误 gosave_systemstack_switch() 保存调用者状态到g-\u0026gt;sched，但是伪装PC值从systemstack_switch函数调用的。 该函数只能从没有局部变量的（$0）的函数调用，否则systemstack_switch是不正确的。 R9寄存器的值被覆盖。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 # Save state of caller into g-\u0026gt;sched, # but using fake PC from systemstack_switch. # Must only be called from functions with no locals ($0) # or else unwinding from systemstack_switch is incorrect. # Smashes R9. TEXT gosave_systemstack_switch\u0026lt;\u0026gt;(SB),NOSPLIT,$0 MOVQ $runtime·systemstack_switch(SB), R9 # g.sched.gobuf.pc = $runtime·systemstack_switch # 伪装当前调用是从 runtime·systemstack_switch 函数开始的。 # 从systemstack()后面的代码看出，这里的PC值没有被使用，原因是PC不需要还原设置。 # 因为systemstack()函数是闭包调用fn()函数，因此执行完后还在调用者的代码中。 MOVQ R9, (g_sched+gobuf_pc)(R14) # g.sched.gobuf.pc = runtime·systemstack_switch # 因为调用gosave_systemstack_switch()函数使用了CALL指令，所以会把返回地址压入栈中 # 因此 8(SP)的位置正好是调用者函数的栈，也就是systemstack()函数的栈 # 从systemstack()函数的函数原型可知，该函数没有分配栈大小为0，因此也是调用systemstack()函数的SP值 # 这里是newproc()函数的的栈顶的值 LEAQ 8(SP), R9 # 8(SP) 是调用者前的SP指向的值 MOVQ R9, (g_sched+gobuf_sp)(R14) # g.sched.gobuf.sp 指向调用者SP MOVQ $0, (g_sched+gobuf_ret)(R14) # g.sched.gobuf.ret = 0 # BP寄存器与SP一样，这里也是newproc()函数的栈底的值 MOVQ BP, (g_sched+gobuf_bp)(R14) # g.sched.gobuf.bp = BP; 调用者BP # Assert ctxt is zero. See func save. # # 断言 ctxt 是0。参看 func save。 # g.sched.gobuf.ctxt 存储的是闭包的上下文，也就是DX寄存器的值是函数的\u0026amp;funcval MOVQ (g_sched+gobuf_ctxt)(R14), R9 # R9 = g.sched.gobuf.ctxt TESTQ R9, R9 JZ\t2(PC) # 判断结果为0则跳过abort()函数 CALL runtime·abort(SB) RET systemstack_switch() 文件位置：：go1.19.3/src/runtime/asm_amd64.s。 453 454 455 456 457 458 459 # systemstack_switch is a dummy routine that systemstack leaves at the bottom # of the G stack. We need to distinguish the routine that # lives at the bottom of the G stack from the one that lives # at the top of the system stack because the one at the top of # the system stack terminates the stack walk (see topofstack()). TEXT runtime·systemstack_switch(SB), NOSPLIT, $0-0 RET newproc1() 该函数主要是创建new goroutine，并设置new goroutine该从哪里进入哪里退出。 从fn开始，创建一个状态为_Grunnable的新g。 callerpc 是创建这个go语句的地址（也就是go关键字代码的下一条指针）。 调用者负责将新的g添加到调度器。 参数： fn *funcval：要执行函数的闭包。也就是go关键字后面的函数闭包，不过函数闭包原型是func()。 callergp *g：当前正在运行的goroutine。也就是调用go关键字的goroutine。 callerpc uintptr：go关键字的下一行指令地址。也就是调用go关键字后的下一条指令。 返回值：*g：新创建的goroutine。 文件位置：go1.19.3/src/runtime/proc.go。 4109 4110 4111 4112 4113 4114 4115 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125 4126 4127 4128 4129 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139 4140 4141 4142 4143 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153 4154 4155 4156 4157 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167 4168 4169 4170 4171 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181 4182 4183 4184 4185 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195 4196 4197 4198 4199 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209 4210 4211 4212 4213 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223 4224 4225 4226 4227 4228 4229 4230 4231 // Create a new g in state _Grunnable, starting at fn. callerpc is the // address of the go statement that created this. The caller is responsible // for adding the new g to the scheduler. func newproc1(fn *funcval, callergp *g, callerpc uintptr) *g { // 获取当前工作线程正在运行的g，该g是g0， // 因为newproc1()函数只会在g0栈中被调用。 _g_ := getg() // g0 // \u0026#34;go nil\u0026#34; 这种形式是不会允许的。 // var fn func() // nil // go fn() if fn == nil { _g_.m.throwing = -1 // do not dump full stacks throw(\u0026#34;go of nil func value\u0026#34;) } // 禁用抢占，因为它可以在本地变量中持有p // 将当前g.m.locks++，当前g是g0。 acquirem() // disable preemption because it can be holding p in a local var // 获取当前工作线程M绑定的P _p_ := _g_.m.p.ptr() // 初始化时_p_ = g0.m.p，从前面的分析可以知道其实就是allp[0] newg := gfget(_p_) // 从P的本地缓冲里获取一个没有使用的g，初始化时没有，返回nil // 如果从当前P的空闲g链表中没有获取到g，则创建一个 if newg == nil { // new一个g结构体对象，然后从堆上为其分配栈，并设置g的stack成员和两个stackgard成员 newg = malg(_StackMin) // _StackMin = 2048 // _Gidle = 0：该状态是G刚刚被分配还没初始化时 // _Gdead = 6：该状态表示当前没有被用到，它可能刚刚完成初始化或刚刚退出运行，在一个空闲链表中。 // 注意这里是CAS操作 casgstatus(newg, _Gidle, _Gdead) // 初始化g的状态为_Gdead // 放入全局变量【allgs切片】中，新增的g全部都会加入这里，并且不会移除，这也确保GC不会去释放它们 allgadd(newg) // publishes with a g-\u0026gt;status of Gdead so GC scanner doesn\u0026#39;t look at uninitialized stack. } // newg 缺少栈 if newg.stack.hi == 0 { throw(\u0026#34;newproc1: newg missing stack\u0026#34;) } // newg 的状态应该是 _Gdead：goroutine当前没有被用到 if readgstatus(newg) != _Gdead { throw(\u0026#34;newproc1: new g is not Gdead\u0026#34;) } // 调整goroutine的栈hi，用于 usesLR 为true时 // sys.MinFrameSize = 0; goarch.PtrSize = 8; totalSize = 32; // extra space in case of reads slightly beyond frame totalSize := uintptr(4*goarch.PtrSize + sys.MinFrameSize) // sys.StackAlign = 8; totalSize = 32; totalSize = alignUp(totalSize, sys.StackAlign) // 注意预留这32字节是从栈高地址开始的 sp := newg.stack.hi - totalSize // 预留32字节，主要用于下面usesLR spArg := sp if usesLR { // caller\u0026#39;s LR *(*uintptr)(unsafe.Pointer(sp)) = 0 prepGoExitFrame(sp) spArg += sys.MinFrameSize } // 把newg.sched结构体成员的所有成员设置为0 // newg.sched是一个gobuf结构体，保存的CPU主要的几个寄存器的值 memclrNoHeapPointers(unsafe.Pointer(\u0026amp;newg.sched), unsafe.Sizeof(newg.sched)) newg.sched.sp = sp // newg.sched.sp寄存器rsp得值，也就是newg的栈顶，注意这里其实指向的是rbp存储的值 newg.stktopsp = sp // 栈顶位置，该值用于回溯 // newg.sched.pc 保存的是rip寄存器的值，newg.sched.pc 表示当newg被调度起来运行时从这个地址开始执行指令 // 把pc设置成了goexit这个函数偏移1（sys.PCQuantum等于1）的位置， // 这里设置goroutine的执行地址为goexit函数的第二条指令的代码地址而不是fn.fn // 至于为什么要这么做需要等到分析完gostartcallfn函数才知道 // +PCQuantum so that previous instruction is in same function newg.sched.pc = abi.FuncPCABI0(goexit) + sys.PCQuantum newg.sched.g = guintptr(unsafe.Pointer(newg)) // 记录当前的gobuf是来自newg这个goroutine gostartcallfn(\u0026amp;newg.sched, fn) // 该函数处理newg从哪里进入从哪里退出 newg.gopc = callerpc // 保存go关键字后的下一条代码地址，主要用于traceback newg.ancestors = saveAncestors(callergp) // 保存当前创建go关键的的goroutine // 设置newg的startpc为fn.fn，该成员主要用于函数调用栈的traceback和栈收缩 // newg真正从哪里开始执行并不依赖于这个成员，而是sched.pc newg.startpc = fn.fn // 在isSystemGoroutine中被用到 // 判断当前goroutine是否是系统goroutine // runtime.main被认为不是系统goroutine。 if isSystemGoroutine(newg, false) { // sched.ngsys：记录的是系统goroutine的数量，会被原子性的更新。 atomic.Xadd(\u0026amp;sched.ngsys, +1) } else { // Only user goroutines inherit pprof labels. // user goroutine 继承 labels if _g_.m.curg != nil { newg.labels = _g_.m.curg.labels } } // Track initial transition? // 用于确实是否跟踪这个G newg.trackingSeq = uint8(fastrand()) // gTrackingPeriod = 8 if newg.trackingSeq%gTrackingPeriod == 0 { newg.tracking = true } // 设置g的状态为_Grunnable，表示这个g代表的goroutine可以运行了 // _Gdead = 6：该状态表示当前没有被用到，它可能刚刚完成初始化或刚刚退出运行，在一个空闲链表中。 // _Grunnable = 1：goroutine应该在某个runq中，当前并没有在运行用户代码，它的栈不归自己所有。 casgstatus(newg, _Gdead, _Grunnable) gcController.addScannableStack(_p_, int64(newg.stack.hi-newg.stack.lo)) if _p_.goidcache == _p_.goidcacheend { // Sched.goidgen is the last allocated id, // this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch]. // At startup sched.goidgen=0, so main goroutine receives goid=1. _p_.goidcache = atomic.Xadd64(\u0026amp;sched.goidgen, _GoidCacheBatch) _p_.goidcache -= _GoidCacheBatch - 1 _p_.goidcacheend = _p_.goidcache + _GoidCacheBatch } // goid 表示G的唯一ID newg.goid = int64(_p_.goidcache) // 设置当前go在P中的位置 _p_.goidcache++ if raceenabled { newg.racectx = racegostart(callerpc) } if trace.enabled { traceGoCreate(newg, newg.startpc) } releasem(_g_.m) // 允许当前M被抢占 return newg } gfget() 该函数主要是从当前P空闲的G链表中获取G，或者从全局的P链表中获取G，如果本地P中没有空闲的G则从全局的P中迁移部分G放入本地非P中。 从gfree列表获取。如果局部列表为空，则从全局列表中获取一部分到本地。 参看下面\u0026quot;空闲的g链表\u0026quot;中的gfget函数注释，有些变化。 文件位置：go1.19.3/src/runtime/proc.go。 4282 4283 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293 4294 4295 4296 4297 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307 4308 4309 4310 4311 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321 4322 4323 4324 4325 4326 4327 4328 4329 4330 4331 4332 // Get from gfree list. // If local list is empty, grab a batch from global list. func gfget(_p_ *p) *g { retry: // 如果当前P的gFree为空 并且 全局的gFree.stack或gFree.noStack不为空 // sched.gFree.stack 表示这里的goroutine带有栈大小的默认是2KB // sched.gFree.noStack 表示这里的goroutine没有分配栈大小，默认是0KB if _p_.gFree.empty() \u0026amp;\u0026amp; (!sched.gFree.stack.empty() || !sched.gFree.noStack.empty()) { lock(\u0026amp;sched.gFree.lock) // Move a batch of free Gs to the P. for _p_.gFree.n \u0026lt; 32 { // 当前P的gFree的数量小于32，从sched.gFree中移动一部分到P的gFree中 // Prefer Gs with stacks. gp := sched.gFree.stack.pop() // 从ched.gFree.stack取一个G if gp == nil { // 取不到，则从sched.gFree.noStack取一个G gp = sched.gFree.noStack.pop() if gp == nil { break } } sched.gFree.n-- // 记录当前sched.gFree减一 _p_.gFree.push(gp) // 把当前取到的G加入P的gFree中 _p_.gFree.n++ // 把P的gFree的数量加一 } unlock(\u0026amp;sched.gFree.lock) goto retry } gp := _p_.gFree.pop() // 从P中取出一个G if gp == nil { return nil } _p_.gFree.n-- // 标记当前P的gFree减一 if gp.stack.lo == 0 { // 如果当前G的栈顶为0，说明栈被释放了 // Stack was deallocated in gfput. Allocate a new one. // 堆栈在gfput()函数中被释放 分配一个新的 systemstack(func() { gp.stack = stackalloc(_FixedStack) // 重新分配栈信息 }) gp.stackguard0 = gp.stack.lo + _StackGuard // 把gp.stackguard0也执行该位置 } else { if raceenabled { racemalloc(unsafe.Pointer(gp.stack.lo), gp.stack.hi-gp.stack.lo) } if msanenabled { msanmalloc(unsafe.Pointer(gp.stack.lo), gp.stack.hi-gp.stack.lo) } if asanenabled { asanunpoison(unsafe.Pointer(gp.stack.lo), gp.stack.hi-gp.stack.lo) } } return gp } malg() 该函数主要是如果从gfget()函数中获取不到空闲的g，那么就自己分配一个，并设置栈空间 分配一个新的g，它的堆栈足够大，可以容纳stacksize字节。 文件位置：go1.19.3/src/runtime/proc.go。 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083 4084 4085 4086 4087 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097 // Allocate a new g, with a stack big enough for stacksize bytes. func malg(stacksize int32) *g { newg := new(g) // 创建一个G，这里是堆分配的 // 需要分配栈大小 if stacksize \u0026gt;= 0 { // _StackSystem = 0，round2函数向上取成2的幂次方，stacksize是2KB stacksize = round2(_StackSystem + stacksize) // 计算大小2的幂次方 // 切换到g0栈，去分配栈 systemstack(func() {\t// 分配栈，goroutine在linux上默认是2KB大小 newg.stack = stackalloc(uint32(stacksize)) }) // 注意：stackguard0 = newg.stack.lo + _StackGuard 溢出警戒线 newg.stackguard0 = newg.stack.lo + _StackGuard // 设置newg.stackguard0 newg.stackguard1 = ^uintptr(0) // Clear the bottom word of the stack. We record g // there on gsignal stack during VDSO on ARM and ARM64. // // 清除堆栈的底部单词。在ARM和ARM64上进行VDSO时，我们在gsignal堆栈上记录g。 // 这里修改的是 newg.stack.lo 地址指向的值为0，不是 newg.stack.lo = 0。 *(*uintptr)(unsafe.Pointer(newg.stack.lo)) = 0 } return newg } gostartcallfn() 该函数主要作用是处理go关键注册的闭包，以及newg从哪里进入从哪里退出等。 调整gobuf，让它像执行了对fn的调用一样，然后在fn中的第一个指令之前停止。 参数： gobuf *gobuf：goroutine的调度信息。 fv *funcval：goroutine要执行的闭包。 文件位置：go1.19.3/src/runtime/stack.go。 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 // adjust Gobuf as if it executed a call to fn // and then stopped before the first instruction in fn. func gostartcallfn(gobuf *gobuf, fv *funcval) { var fn unsafe.Pointer\tif fv != nil { // 知道闭包的结构，知道fv.fn为注册函数的地址 // fn: gorotine的入口地址，初始化时对应的是runtime.main fn = unsafe.Pointer(fv.fn)\t} else { // //go:nosplit // func nilfunc() { // *(*uint8)(nil) = 0 // } // 如果传入【nil】的函数闭包，则封装nilfunc函数，运行起来该函数会报错。 fn = unsafe.Pointer(abi.FuncPCABIInternal(nilfunc)) } // unsafe.Pointer(fv) 作为fn的上下文环境传入 // unsafe.Pointer(fv) 会传入DX寄存器，DX寄存器用于闭包调用隐藏传值 gostartcall(gobuf, fn, unsafe.Pointer(fv))\t} gostartcall() 该函数主要数处理newg从哪里进入从哪里退出。 伪装newg注册的函数是从goexit+1代码处调用fn函数，该newg执行完后会接到执行goexit+1后面代码。 该函数是设置goroutine从哪里进入从哪里出去的关键。 参数： buf *gobuf：goroutine的调度信息。 fn unsafe.Pointer：闭包函数funcval.fn的值。 ctxt unsafe.Pointer：闭包函数funcval的地址。 文件位置：go1.19.3/src/runtime/sys_x86.go。 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // adjust Gobuf as if it executed a call to fn with context ctxt // and then stopped before the first instruction in fn. func gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) { sp := buf.sp // buf.sp 栈开始的位置 sp -= goarch.PtrSize // 为返回地址预留8B空间 // 这里在伪装fn是被goexit()函数调用的，使得fn执行完后返回到goexit继续执行，从而完成清理工作 *(*uintptr)(unsafe.Pointer(sp)) = buf.pc // 把goexit+1代码地址放入该处，模拟是被goexit函数调用的 buf.sp = sp // 重新设置newg的栈顶寄存器 // 这里才真正让newg的ip寄存器指向fn函数，注意，这里只是在设置newg的一些信息，newg还未执行， // 等到newg被调度起来运行时，调度器会把buf.pc放入cpu的IP寄存器， // 从而使newg得以在cpu上真正的运行起来 buf.pc = uintptr(fn) // 该值用在闭包的调用 DX 寄存器需要的上下文，该值是调度起fn函数的关键 buf.ctxt = ctxt // 保存当前goroutine上下环境信息 } runtime.gpexit() 当goroutine运行完时会返回到该函数处继续运行后续收尾工作。 部分人可能担心goexit()函数加一会造成指令错乱，实际不会有问题，因为goexit()函数的代码已经考虑到这一层了。 首位各有一条NOP指令占位，所以入口地址加一后不会影响，正好对其到了接下来的CALL指令。 pc的值之所以需要是goexit()函数的地址加一，是因为这样才像是goexit()函数调用了fn()函数， 如果指向goexit()函数的起始地址就不合适了，那样goexit()函数看起来还没有执行。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 1591 1592 1593 1594 1595 1596 1597 // The top-most function running on a goroutine // returns to goexit+PCQuantum. TEXT runtime·goexit(SB),NOSPLIT|TOPFRAME,$0-0 BYTE $0x90 // NOP CALL runtime·goexit1(SB) // does not return // traceback from goexit1 must hit code range of goexit BYTE $0x90 // NOP runqput() 该函数主要是把设置好的newg放入M关联的P的首位置或全局P中等待被调度器调度起来执行。 该函数也是调度循环中从全局运行g链表中取出g放入本地P调用的函数。 参数： _p_ *p：当前工作线程m绑定的P。 gp *g：新创建的goroutine。 next bool：true.表示追加到P的首位置 false.表示追加到P的末尾位置。 文件位置：go1.19.3/src/runtime/proc.go。 5780 5781 5782 5783 5784 5785 5786 5787 5788 5789 5790 5791 5792 5793 5794 5795 5796 5797 5798 5799 5800 5801 5802 5803 5804 5805 5806 5807 5808 5809 5810 5811 5812 5813 5814 5815 5816 5817 5818 5819 5820 5821 5822 5823 5824 5825 5826 5827 5828 5829 5830 5831 5832 5833 5834 5835 5836 5837 // runqput tries to put g on the local runnable queue. // If next is false, runqput adds g to the tail of the runnable queue. // If next is true, runqput puts g in the _p_.runnext slot. // If the run queue is full, runnext puts g on the global queue. // Executed only by the owner P. func runqput(_p_ *p, gp *g, next bool) { // 这里是为了曾加随机性，newg不是总存入指定位置,fastrandn(2) 取随机数对2求余 if randomizeScheduler \u0026amp;\u0026amp; next \u0026amp;\u0026amp; fastrandn(2) == 0 { next = false } // 如果是追加到P的首位置处 if next { retryNext: // 把gp放在_p_.runnext成员里，runnext成员中的goroutine会被优先调度起来运行 oldnext := _p_.runnext // 处理旧的将要被执行的goroutine // 使用锁的形式替换_p_.runnext的值为gp新值，如果存在其他goroutine在操作runnext成员则需要重试 if !_p_.runnext.cas(oldnext, guintptr(unsafe.Pointer(gp))) { goto retryNext } // 如果之前需要处理的goroutine为空则返回即可 if oldnext == 0 { return } // Kick the old runnext out to the regular run queue. gp = oldnext.ptr() // 获取旧的goroutine地址 } retry: // P.runqhead uint32 记录着当前goroutine队列的队列头位置 一直往上加，到最大值变为0 // P.runqtail uint32 记录着当前goroutine队列的队列尾位置 一直往上加，到最大值变为0 // P.runq [256]guintptr 使用数组实现的循环队列 // 可能有其他线程正在并发取runqhead成员，所以需要跟其它线程同步 // 这里为什么只判断_p_.runqhead那是因为所以入数据的都是从首取走的 h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with consumers t := _p_.runqtail // 如果t-h \u0026lt; 256则是没有存满，可以接到存储g if t-h \u0026lt; uint32(len(_p_.runq)) { // 判断队列是否满了 // 队列还没存满可以放入本地P的队列中，这里放入的是t的位置处 _p_.runq[t%uint32(len(_p_.runq))].set(gp) // 虽然没有其他线程并发修改这个runqtail，但其他线程会并发读取该值以及p的runq成员 // 这里使用StoreRel是为了： // 1. 原子写入runqtail // 2. 防止编译器和CPU乱序，保证上一行代码对runq的修改发生在修改runqtail之前 // 3. 可见行屏障，保证当前线程对运行队列的修改对其他线程立马可见 atomic.StoreRel(\u0026amp;_p_.runqtail, t+1) // store-release, makes the item available for consumption return } // P的本地运行队列已满，需要放入全局运行队列 // 如果这里返回false，则说明P的本地运行队列G中部分G被其他M偷走了，继续执行goto retry if runqputslow(_p_, gp, h, t) { return } // the queue is not full, now the put above must succeed // 队列未满，现在上面的 put 必须成功 goto retry } runqputslow() 将P得本地队列的g迁移部分到全局队列中。 文件位置：go1.19.3/src/runtime/proc.go。 5818 5819 5820 5821 5822 5823 5824 5825 5826 5827 5828 5829 5830 5831 5832 5833 5834 5835 5836 5837 5838 5839 5840 5841 5842 5843 5844 5845 5846 5847 5848 5849 5850 5851 5852 5853 5854 5855 5856 5857 5858 5859 5860 5861 5862 5863 5864 5865 5866 5867 5868 5869 5870 // Put g and a batch of work from local runnable queue on global queue. // Executed only by the owner P. func runqputslow(_p_ *p, gp *g, h, t uint32) bool { var batch [len(_p_.runq)/2 + 1]*g // gp加上_p_本地队列的一半 // First, grab a batch from local queue. n := t - h // 计算当前P中存储的数量n n = n / 2 // 取一半 if n != uint32(len(_p_.runq)/2) { // 判断P是否已满 throw(\u0026#34;runqputslow: queue is not full\u0026#34;) } // 复制P本地队列G的一半，放入batch中 for i := uint32(0); i \u0026lt; n; i++ { // 从P的本地队列head开头开始复制一半存入batch中 batch[i] = _p_.runq[(h+i)%uint32(len(_p_.runq))].ptr() } // 这里把_p_.runqhead值设置成h+n，并判断旧值h是否发生变化，如果发生变化则说明其他goroutine正在偷取g if !atomic.CasRel(\u0026amp;_p_.runqhead, h, h+n) { // cas-release, commits consume // 如果cas操作失败，说明已经有其他工作线程从_p_的本地运行队列偷走一些goroutine，所以直接返回 return false } batch[n] = gp // 最后一个位置处追加gp // 增加随机性 打乱batch if randomizeScheduler { for i := uint32(1); i \u0026lt;= n; i++ { j := fastrandn(i + 1)\t// fastrand()%n batch[i], batch[j] = batch[j], batch[i] } } // Link the goroutines. // 全局运行队列是一个链表，这里首先把所有需要放入全局运行队列的g链接起来 // 减少后面对迁居链表的锁住时间，从而降低锁冲突 // 前一个和后一个链接起来 for i := uint32(0); i \u0026lt; n; i++ { batch[i].schedlink.set(batch[i+1]) } // type gQueue struct { // head guintptr // tail guintptr // } var q gQueue q.head.set(batch[0]) // 设置开头 q.tail.set(batch[n]) // 设置结尾 // Now put the batch on global queue. lock(\u0026amp;sched.lock) // 锁住当前sched globrunqputbatch(\u0026amp;q, int32(n+1)) // 拼接到全局sched.runq上去 unlock(\u0026amp;sched.lock) // 解锁当前sched return true } globrunqputbatch() 文件位置：go1.19.3/src/runtime/proc.go。 5587 5588 5589 5590 5591 5592 5593 5594 5595 5596 5597 5598 // Put a batch of runnable goroutines on the global runnable queue. // This clears *batch. // sched.lock must be held. // May run during STW, so write barriers are not allowed. //go:nowritebarrierrec func globrunqputbatch(batch *gQueue, n int32) { assertLockHeld(\u0026amp;sched.lock) sched.runq.pushBackAll(*batch) // 把当前batch链接到全局sched.runq上去 sched.runqsize += n // 累加当前sched.runqsize数量 *batch = gQueue{} // 清空 } acquirem() 文件位置：go1.19.3/src/runtime/runtime1.go。 473 474 475 476 477 478 //go:nosplit func acquirem() *m { _g_ := getg() _g_.m.locks++ return _g_.m } ","permalink":"https://heliu.site/posts/golang/goroutine/newproc/","summary":"Golang go关键字流程介绍。","title":"go 关键字"},{"content":" 本篇是接着上一篇《go关键字》的后续，goroutine运行完后的回收阶段。 goexit() goroutine运行结束后返回到goexit+PCQuantum处。const PCQuantum = 1。 也就是接着执行CALL runtime·goexit1(SB)这条指令。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 1591 1592 1593 1594 1595 1596 1597 1598 // The top-most function running on a goroutine // returns to goexit+PCQuantum. TEXT runtime·goexit(SB),NOSPLIT|TOPFRAME,$0-0 BYTE $0x90 // NOP 从下一条指令开始执行 CALL runtime·goexit1(SB) // 这条指令调用函数将永不返回 // traceback from goexit1 must hit code range of goexit // 从goexit1回溯必须达到goexit的代码范围 BYTE $0x90 // NOP goexit1() goexit1()函数通过调用mcall从当前运行的g2 goroutine切换到g0，然后在g0栈上调用和执行goexit0()这个函数。 文件位置：go1.19.3/src/runtime/proc.go。 3468 3469 3470 3471 3472 3473 3474 3475 3476 3477 3478 3479 3480 3481 3482 3483 // Finishes execution of the current goroutine. func goexit1() { if raceenabled { //与竞态检查有关，不关注 racegoend() } if trace.enabled { //与backtrace有关，不关注 traceGoEnd() } // 注意，mcall函数的参数是一个函数goexit0 // Function Value 结构 // type funcval struct { // fn uintptr // // 闭包捕获的参数在这 // } mcall(goexit0) } mcall() 函数原型：func mcall(fn func(*g))。 runtime.mcall()函数和systemstack()函数很像，也是切换到系统栈去执行某个Function Value。 但是也有些不同，mcall()函数不能在g0栈上调用，而且也不会再切换回来。 切换到m.g0栈，调用fn(g)。 Fn必须永不返回。它应该调用gogo(\u0026amp;g-\u0026gt;sched)来保持g的运行。这里的g应该是g0。 从当前运行的g切换到g0，这一步包括保存当前g的调度信息，把g0设置到tls中，修改CPU的rsp寄存器使其指向g0的栈。 以当前运行的g为参数调用fn函数(此处为goexit0)。 mcall函数不能在g0栈上调用，而且也不会再切换回来。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 # func mcall(fn func(*g)) # Switch to m-\u0026gt;g0\u0026#39;s stack, call fn(g). # Fn must never return. It should gogo(\u0026amp;g-\u0026gt;sched) # to keep running g. TEXT runtime·mcall\u0026lt;ABIInternal\u0026gt;(SB), NOSPLIT, $0-8 # 1) 从AX中获取参数，注意这里还是再普通goroutine中不是g0 # 在go1.17后版本中采用寄存器传参，因此AX作为第一个参数存储的是macll的参数 # 传参顺序 AX、BX、CX、DI、SI、R8、R9、R10、R11 MOVQ AX, DX # DX = \u0026amp;funcval; \u0026amp;funcval -\u0026gt; goexit0 # 2) 保存状态到 g-\u0026gt;sched。这里的g是当前正在运行的goroutine。 # save state in g-\u0026gt;sched # 以下保存当前状态到g-\u0026gt;sched中，在go 1.17版本后R14寄存器存储的是当前工作线程运行的goroutine # 0(SP)：存储的是goexit1函数调用mall函数的下一条指令地址。也就是goexit1()函数的返回地址 MOVQ 0(SP), BX # caller\u0026#39;s PC\tmcall返回地址放入BX # g.sched.pc = BX MOVQ BX, (g_sched+gobuf_pc)(R14) # g.sched.pc = BX，保存g的rip # fn+0(FP)表当前参数所在栈位置，也就是goexit1函数的SP位置处。因为参数在调用者栈上。 LEAQ fn+0(FP), BX # caller\u0026#39;s SP MOVQ BX, (g_sched+gobuf_sp)(R14) # g.sched.sp = BX，保存g的rsp # g.sched.bp = BP MOVQ BP, (g_sched+gobuf_bp)(R14) # g.sched.bp = BP，保存g的rbp # 3) 切换到 m-\u0026gt;g0 及其堆栈，调用fn函数。 # switch to m-\u0026gt;g0 \u0026amp; its stack, call fn # # BX = m MOVQ g_m(R14), BX # BX = g.m，拿到当前工作线程M # SI = g0 MOVQ m_g0(BX), SI # SI = g.m.g0，那当当前工作线程M的g0栈 # 此刻，SI = g0， R14 = g，所以这里在判断g是否是g0，如果g == g0则一定是哪里代码写错了 CMPQ SI, R14 # if g == m-\u0026gt;g0 call badmcall JNE goodm # SI和R14不相等则跳转 JMP runtime·badmcall(SB) goodm: # 正常流程跳转到这里 # AX = g MOVQ R14, AX # AX (and arg 0) = g，AX = g2，当前g不是g0，AX也是goexit0函数需要的参数 # R14 = g0 MOVQ SI, R14 # g = g.m.g0，R14 = g0，设置当前正在运行的是g0 # CX = \u0026amp;m.tls[1] get_tls(CX) # Set G in TLS # TLS = g0 MOVQ R14, g(CX) # sp = g0.sched.sp MOVQ (g_sched+gobuf_sp)(R14), SP # AX = g 入栈，此时已经在g0的栈上了 # AX存储的时普通的goroutine，这里入栈也是goexit0()函数的参数 PUSHQ AX # open up space for fn\u0026#39;s arg spill slot # R12 = funcval.fn; DX = \u0026amp;funcval MOVQ 0(DX), R12 # fn的第一个成员是goexit0函数代码地址处，R12 = fn.fn # 调用goexit0()函数，参数再AX寄存器中，上下文在DX寄存器中。 CALL R12 # 调用 goexit0(g)，这里【永不会返回】 POPQ AX JMP\truntime·badmcall2(SB) RET goexit0() 在g0上继续执行goexit0()。参数：gp *g，当前运行完的普通的goroutine。 从g2栈切换到g0栈之后，下面开始在g0栈执行goexit0()函数，该函数完成最后的清理工作： 把g的状态从_Grunning变更为_Gdead。 然后把g的一些字段清空成零值。 调用dropg函数解除g和m之间的关系，其实就是设置 g-\u0026gt;m = nil,m-\u0026gt;currg = nil。 把g放入p的freeg队列缓存起来供下次创建g时快速获取而不用从内存分配。freeg就是g的一个对象池。 调用schedule()函数再次进行调度。 文件位置：go1.19.3/src/runtime/runtime/proc.go。 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517 3518 3519 3520 3521 3522 3523 3524 3525 3526 3527 3528 3529 3530 3531 3532 3533 3534 3535 3536 3537 3538 3539 3540 3541 3542 3543 3544 3545 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555 3556 3557 3558 3559 3560 3561 3562 3563 3564 3565 // goexit continuation on g0. func goexit0(gp *g) { _g_ := getg() // _g_ = g0 _p_ := _g_.m.p.ptr() // _p_ = g0.m.p // _Grunning：2 表示这个 goroutine 可以执行用户代码。 堆栈由这个 goroutine 拥有。 // 它不在运行队列中。它被分配了一个 M 和一个 P（g.m 和 g.m.p 是有效的） // _Gdead：6 表示这个 goroutine 当前未被使用，它可能刚刚退出，在空闲列表中，或者刚刚被初始化 casgstatus(gp, _Grunning, _Gdead) // g马上退出，所以设置其状态为_Gdead gcController.addScannableStack(_p_, -int64(gp.stack.hi-gp.stack.lo)) // 已分配栈总量 // sSystemGoroutine 报告在堆栈转储和死锁检测器中是否必须省略 goroutine g // 这是在 runtime.* 入口点启动的任何 goroutine，除了 runtime.main、runtime.handleAsyncEvent // （仅限 wasm）和有时 runtime.runfinq // 如果 fixed 为真，任何可以在用户和系统之间变化的 goroutine（即终结器 goroutine）都被认为是用户 goroutine if isSystemGoroutine(gp, false) { atomic.Xadd(\u0026amp;sched.ngsys, -1) // sched.ngsys 记录系统goroutine的数量 } // 清空g保存的一些信息 gp.m = nil // lockedm 关联到与当前G绑定的M，可以参考下 LockOSThread。 locked := gp.lockedm != 0 gp.lockedm = 0 _g_.m.lockedg = 0 gp.preemptStop = false gp.paniconfault = false gp._defer = nil // should be true already but just in case. gp._panic = nil // non-nil for Goexit during panic. points at stack-allocated data. gp.writebuf = nil gp.waitreason = 0 gp.param = nil gp.labels = nil gp.timer = nil // gcBlackenEnabled：表示辅助助手和后台标记线程允许将对象置为黑色; // gcAssistBytes：表示当前goroutine还有信用值。（GC相关） if gcBlackenEnabled != 0 \u0026amp;\u0026amp; gp.gcAssistBytes \u0026gt; 0 { // Flush assist credit to the global pool. This gives // better information to pacing if the application is // rapidly creating an exiting goroutines. assistWorkPerByte := gcController.assistWorkPerByte.Load() scanCredit := int64(assistWorkPerByte * float64(gp.gcAssistBytes)) atomic.Xaddint64(\u0026amp;gcController.bgScanCredit, scanCredit) gp.gcAssistBytes = 0 } // g2-\u0026gt;m = nil, m-\u0026gt;currg = nil 解绑g和m之关系 // m-\u0026gt;currg记录着前一个g信息 // func dropg() { // _g_ := getg() // _g_ = g0 // setMNoWB(\u0026amp;_g_.m.curg.m, nil) // g2-\u0026gt;m = nil // setGNoWB(\u0026amp;_g_.m.curg, nil) // m-\u0026gt;currg = nil // } // // func setMNoWB(mp **m, new *m) { // (*muintptr)(unsafe.Pointer(mp)).set(new) // } dropg() // 解绑gp的m和当前m.currg值 if GOARCH == \u0026#34;wasm\u0026#34; { // no threads yet on wasm gfput(_p_, gp) schedule() // never returns } // lockedInt 内部lockOSThread的跟踪 if _g_.m.lockedInt != 0 { print(\u0026#34;invalid m-\u0026gt;lockedInt = \u0026#34;, _g_.m.lockedInt, \u0026#34;\\n\u0026#34;) throw(\u0026#34;internal lockOSThread error\u0026#34;) } // go keyword 文档关于 gfput 和 gfget 函数注解。 gfput(_p_, gp) // g2放入p的freeg队列，方便下次重用，免得再去申请内存，提高效率 if locked { // The goroutine may have locked this thread because // it put it in an unusual kernel state. Kill it // rather than returning it to the thread pool. // Return to mstart, which will release the P and exit // the thread. if GOOS != \u0026#34;plan9\u0026#34; { // See golang.org/issue/22227. gogo(\u0026amp;_g_.m.g0.sched) } else { // Clear lockedExt on plan9 since we may end up re-using // this thread. _g_.m.lockedExt = 0 } } schedule() // 下面再次调用schedule } ","permalink":"https://heliu.site/posts/golang/goroutine/user/","summary":"Golang user goroutine 介绍。","title":"user goroutine"},{"content":" 本篇介绍《Go 执行流程》中，关于runtime·mainPC(SB)这个函数的相关内容。 runtime·mainPC(SB) 该函数是主线程goroutine注册的函数，首先会被唤起执行。 也是runtime.gogo()函数切换栈和代码地址跳转而来。 文件位置：go1.19.3/src/runtime/proc.go。 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 // The main goroutine. func main() { g := getg()\t// goroutine -\u0026gt; runtime.main // Racectx of m0-\u0026gt;g0 is used only as the parent of the main goroutine. // It must not be used for anything else. // // m0-\u0026gt;g0 的 Racectx 仅用作主 goroutine 的父级 // 它不能用于其他任何事情，仅仅由于标识 g.m.g0.racectx = 0 // 0 表示主goroutime // Max stack size is 1 GB on 64-bit, 250 MB on 32-bit. // Using decimal instead of binary GB and MB because // they look nicer in the stack overflow failure message. // // 最大栈大小在 64 位上为 1 GB，在 32 位上为 250 MB。 // 使用十进制而不是二进制 GB 和 MB，因为它们在栈溢出失败消息中看起来更好。 if goarch.PtrSize == 8 { // maxstacksize 是单个goroutine栈大小的最大上限值。[2KB,1GB] maxstacksize = 1000000000 } else { maxstacksize = 250000000 } // An upper limit for max stack size. Used to avoid random crashes // after calling SetMaxStack and trying to allocate a stack that is too big, // since stackalloc works with 32-bit sizes. // // 栈大小的上限。用于避免在调用SetMaxStack并试图分配过大的栈之后的随机崩溃，因为stackalloc可以处理32位大小的栈。 // 用于判断单个goroutine栈大小上限。在newstack()函数中被使用。 maxstackceiling = 2 * maxstacksize // Allow newproc to start new Ms. // // 标记主线程runtime.main已启动，允许 newproc 启动新的M。 mainStarted = true // 【创建监控线程】，该线程独立于调度器之外，不需要跟P关联。 // wasm上还没有线程，所以没有sysmon。 if GOARCH != \u0026#34;wasm\u0026#34; { // no threads on wasm yet, so no sysmon // 切换到g0栈执行newm函数创建监控线程sysmon。 systemstack(func() { newm(sysmon, nil, -1) }) } // Lock the main goroutine onto this, the main OS thread, // during initialization. Most programs won\u0026#39;t care, but a few // do require certain calls to be made by the main thread. // Those can arrange for main.main to run in the main thread // by calling runtime.LockOSThread during initialization // to preserve the lock. // // 在初始化期间，将main goroutine锁定到这个主操作系统线程上。 // 大多数程序不会在意，但有一些确实需要main线程进行某些调用。 // 它们可以通过调用runtime来安排main.main在主线程中运行。LockOSThread在初始化期间保存锁。 lockOSThread() // runtime.main初始化时只有m0这个线程 if g.m != \u0026amp;m0 { throw(\u0026#34;runtime.main not on m0\u0026#34;) } // Record when the world started. // Must be before doInit for tracing init. // // runtimeInitTime 是运行时开始的nanotime()。 // 记录the world started开始时间。 // 如果要跟踪init，必须在doInit之前。 runtimeInitTime = nanotime() if runtimeInitTime == 0 { throw(\u0026#34;nanotime returning zero\u0026#34;) } if debug.inittrace != 0 { inittrace.id = getg().goid inittrace.active = true } // 初始化为runtime包完成的一组初始化，执行runtime包中所有的init函数。 // 必须在defer之前。递归调用runtime包的相关init()函数。 doInit(\u0026amp;runtime_inittask) // Must be before defer. // Defer unlock so that runtime.Goexit during init does the unlock too. // // 延迟解锁，以便 runtime.Goexit 在 init 期间也进行解锁 needUnlock := true\t// 标记当前主线程还未被解锁，main函数退出了需要执行defer解锁 defer func() { if needUnlock { unlockOSThread() } }() // 创建GC相关的扫描器和清理器。 gcenable() // 清扫协程，参看GC相关 // main_init_done 是 cgocallbackg 使用的一个信号，表明初始化已经完成 // 它是在 _cgo_notify_runtime_init_done 之前完成的，所以所有的 cgo 调用都可以依赖它存在 // 当 main_init 完成时，它被关闭，这意味着 cgocallbackg 可以可靠地从中接收 main_init_done = make(chan bool) if iscgo { if _cgo_thread_start == nil { throw(\u0026#34;_cgo_thread_start missing\u0026#34;) } if GOOS != \u0026#34;windows\u0026#34; { if _cgo_setenv == nil { throw(\u0026#34;_cgo_setenv missing\u0026#34;) } if _cgo_unsetenv == nil { throw(\u0026#34;_cgo_unsetenv missing\u0026#34;) } } if _cgo_notify_runtime_init_done == nil { throw(\u0026#34;_cgo_notify_runtime_init_done missing\u0026#34;) } // Start the template thread in case we enter Go from // a C-created thread and need to create a new thread. startTemplateThread() cgocall(_cgo_notify_runtime_init_done, nil) } // 递归调用main包相关引用包的init()函数 doInit(\u0026amp;main_inittask) // Disable init tracing after main init done to avoid overhead // of collecting statistics in malloc and newproc // // 在主初始化完成后禁用初始化跟踪以避免在 malloc 和 newproc 中收集统计信息的开销 inittrace.active = false close(main_init_done)\t// 关闭main_init_done，此时在main_init_done上面的goroutine将被执行 needUnlock = false\t// 标记当前主线程OS已被解锁 unlockOSThread()\t// 解锁主线程 if isarchive || islibrary { // A program compiled with -buildmode=c-archive or c-shared // has a main, but it is not executed. // 使用 -buildmode=c-archive 或 c-shared 编译的程序有一个 main，但它不会被执行 return } // 进行间接调用，因为链接器在放置运行时时不知道主包的地址 // main.main函数是我们主包的地址所在 fn := main_main // make an indirect call, as the linker doesn\u0026#39;t know the address of the main package when laying down the runtime fn() // 进入main.main开始执行代码 if raceenabled { racefini() } // Make racy client program work: if panicking on // another goroutine at the same time as main returns, // let the other goroutine finish printing the panic trace. // Once it does, it will exit. See issues 3934 and 20018. // // 让racy客户端程序工作：如果在main返回的同时在另一个goroutine上painc，让另一个goroutine完成打印painc跟踪 if atomic.Load(\u0026amp;runningPanicDefers) != 0 { // Running deferred functions should not take long. for c := 0; c \u0026lt; 1000; c++ { if atomic.Load(\u0026amp;runningPanicDefers) == 0 { break } Gosched() } } if atomic.Load(\u0026amp;panicking) != 0 { gopark(nil, nil, waitReasonPanicWait, traceEvGoStop, 1) } // 进入系统调用，退出进程，可以看出main goroutine并未返回，而是直接进入系统调用退出进程了 exit(0) // 保护性代码，如果exit意外返回，下面的代码也会让该进程crash死掉 for { var x *int32\t// 这里为nil *x = 0\t// 给一个不存在的地址赋值，会出错的 } } lockOSThread() 文件位置：go1.19.3/src/runtime/proc.go。 4416 4417 4418 4419 4420 //go:nosplit func lockOSThread() { getg().m.lockedInt++ dolockOSThread() } dolockOSThread() 下面的LockOSThread和lockOSThread在修改m.locked后调用dolockOSThread()。 在这个调用期间不允许抢占，否则这个函数中的m可能与调用者中的m不同。 文件位置：go1.19.3/src/runtime/proc.go。 4370 4371 4372 4373 4374 4375 4376 4377 4378 4379 4380 4381 4382 // dolockOSThread is called by LockOSThread and lockOSThread below // after they modify m.locked. Do not allow preemption during this call, // or else the m might be different in this function than in the caller. // //go:nosplit func dolockOSThread() { if GOARCH == \u0026#34;wasm\u0026#34; { return // no threads on wasm yet } _g_ := getg() _g_.m.lockedg.set(_g_) _g_.lockedm.set(_g_.m) } unlockOSThread() 文件位置：go1.19.3/src/runtime/proc.go。 4462 4463 4464 4465 4466 4467 4468 4469 4470 4471 //go:nosplit func unlockOSThread() { _g_ := getg() // 没有加锁时解锁。 if _g_.m.lockedInt == 0 { systemstack(badunlockosthread) } _g_.m.lockedInt-- dounlockOSThread() } dounlockOSThread() 文件位置：go1.19.3/src/runtime/proc.go。 4422 4423 4424 4425 4426 4427 4428 4429 4430 4431 4432 4433 4434 4435 4436 4437 // dounlockOSThread is called by UnlockOSThread and unlockOSThread below // after they update m-\u0026gt;locked. Do not allow preemption during this call, // or else the m might be in different in this function than in the caller. // //go:nosplit func dounlockOSThread() { if GOARCH == \u0026#34;wasm\u0026#34; { return // no threads on wasm yet } _g_ := getg() if _g_.m.lockedInt != 0 || _g_.m.lockedExt != 0 { return } _g_.m.lockedg = 0 _g_.lockedm = 0 } doInit() type initTask struct initTask表示需要为包执行的初始化集合。 与../../test/initempty.go:initTask保持同步。 文件位置：go1.19.3/src/runtime/proc.go。 6272 6273 6274 6275 6276 6277 6278 6279 6280 6281 6282 6283 6284 6285 6286 6287 6288 // An initTask represents the set of initializations that need to be done for a package. // Keep in sync with ../../test/initempty.go:initTask type initTask struct { // TODO: pack the first 3 fields more tightly? // // 将前3个字段封装得更紧密? // state：0 未初始化；1 初始化中；2 已初始化 state uintptr // 0 = uninitialized, 1 = in progress, 2 = done ndeps uintptr // 当前包依赖几个包 nfns uintptr // 当前包有几个init函数 // followed by ndeps instances of an *initTask, one per package depended on // followed by nfns pcs, one per init function to run // // 然后是*initTask的ndeps实例，每个包依赖于一个nfns pcs，每个init函数运行一个 // ndeps 个 *initTask // 指向当前包结构的那些包的initTask // nfns 个 func() // 当前包的那些init函数 } 结构图：一个initTask就是一个包结构。 [ndeps]*initTask：包含当前包引用的其他包结构。 [nfns]func()：表示当前包定义的所有init()函数。 runtime.main函数中会递归从最后调用init()函数。 包初始化，静态初始化、非静态初始化。 静态初始化：包级别变量的初始化工作应该在程序代码开始使用这些变量前完成，参看包初始化文档。 非静态初始化：包级别变量m的初始值需要进行函数调用，并不是一个能够被编译器在编译阶段求值的表达式时。 doInit()函数：只是执行注册包的init()函数作用。 文件位置：go1.19.3/src/runtime/proc.go。 6294 6295 6296 6297 6298 6299 6300 6301 6302 6303 6304 6305 6306 6307 6308 6309 6310 6311 6312 6313 6314 6315 6316 6317 6318 6319 6320 6321 6322 6323 6324 6325 6326 6327 6328 6329 6330 6331 6332 6333 6334 6335 6336 6337 6338 6339 6340 6341 6342 6343 6344 6345 6346 6347 6348 6349 6350 6351 6352 6353 6354 6355 6356 6357 6358 6359 6360 6361 6362 6363 6364 func doInit(t *initTask) { switch t.state { // 已初始化 case 2: // fully initialized return // 正在初始化中 case 1: // initialization in progress\tthrow(\u0026#34;recursive call during initialization - linker skew\u0026#34;) // 没有初始化 default: // not initialized yet\t// 标记当前包正在初始化中 t.state = 1 // initialization in progress // 遍历当前包依赖的包，t.ndeps记录的依赖的包数量 for i := uintptr(0); i \u0026lt; t.ndeps; i++ { // 偏移到指定位置，获取到ndeps位置的*initTask数据 // 3*goarch.PtrSize 表示前state、ndeps、nfns所占的内存大小 p := add(unsafe.Pointer(t), (3+i)*goarch.PtrSize) // 64位占8字节 t2 := *(**initTask)(p) // *initTask // 这里也是导致从最内层的包开始倒叙执行初始化的原因 doInit(t2) // 递归 } // 如果当前包没有init函数，直接把包标记成2已完成并直接返回 if t.nfns == 0 { t.state = 2 // initialization done return } var ( start int64 // 调试模式情况使用，记录开始时间 before tracestat ) if inittrace.active { start = nanotime() // Load stats non-atomically since tracinit is updated only by this init goroutine. before = inittrace } // 偏移到init函数的地址处 firstFunc := add(unsafe.Pointer(t), (3+t.ndeps)*goarch.PtrSize) // 遍历并执行包注册的init函数，同一个包的不同go文件中init函数执行时是无序的 for i := uintptr(0); i \u0026lt; t.nfns; i++ { p := add(firstFunc, i*goarch.PtrSize) // 偏移到init函数位置 f := *(*func())(unsafe.Pointer(\u0026amp;p))\t// func() f()\t// 执行init函数 } // 调试模式下 打印相关参数 if inittrace.active { end := nanotime() // Load stats non-atomically since tracinit is updated only by this init goroutine. after := inittrace f := *(*func())(unsafe.Pointer(\u0026amp;firstFunc)) pkg := funcpkgpath(findfunc(abi.FuncPCABIInternal(f))) var sbuf [24]byte print(\u0026#34;init \u0026#34;, pkg, \u0026#34; @\u0026#34;) print(string(fmtNSAsMS(sbuf[:], uint64(start-runtimeInitTime))), \u0026#34; ms, \u0026#34;) print(string(fmtNSAsMS(sbuf[:], uint64(end-start))), \u0026#34; ms clock, \u0026#34;) print(string(itoa(sbuf[:], after.bytes-before.bytes)), \u0026#34; bytes, \u0026#34;) print(string(itoa(sbuf[:], after.allocs-before.allocs)), \u0026#34; allocs\u0026#34;) print(\u0026#34;\\n\u0026#34;) } // 标记当前包已初始化完成 t.state = 2 // initialization done } } gcenable() gcenable在runtime初始化之后被调用，在我们准备让用户代码运行之前被调用。 它启动 background sweeper goroutine，以及 background scavenger goroutine，并启动GC。 文件位置：go1.19.3/src/runtime/mgc.go。 更详情介绍参看GC篇文章。 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 // gcenable is called after the bulk of the runtime initialization, // just before we\u0026#39;re about to start letting user code run. // It kicks off the background sweeper goroutine, the background // scavenger goroutine, and enables GC. func gcenable() { // Kick off sweeping and scavenging. // 启动 sweeping 和 scavenging。 c := make(chan int, 2) // 有缓冲2 go bgsweep(c) // 扫描 go bgscavenge(c) // 清扫 // 等待这两个goroutine运行起来。 \u0026lt;-c \u0026lt;-c // 现在运行时已经初始化，GC就可以了。 memstats.enablegc = true // now that runtime is initialized, GC is okay } bgsweep() 文件位置：go1.19.3/src/runtime/mgcsweep.go。 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 func bgsweep(c chan int) { sweep.g = getg() // sweep g // 初始化锁排名 lockInit(\u0026amp;sweep.lock, lockRankSweep) lock(\u0026amp;sweep.lock) // mutex lock sweep.parked = true c \u0026lt;- 1 // 通知 gcenable 函数解除阻塞 // 调离CPU goparkunlock(\u0026amp;sweep.lock, waitReasonGCSweepWait, traceEvGoBlock, 1) for { for sweepone() != ^uintptr(0) { sweep.nbgsweep++ Gosched() } for freeSomeWbufs(true) { Gosched() } lock(\u0026amp;sweep.lock) if !isSweepDone() { // This can happen if a GC runs between // gosweepone returning ^0 above // and the lock being acquired. unlock(\u0026amp;sweep.lock) continue } sweep.parked = true goparkunlock(\u0026amp;sweep.lock, waitReasonGCSweepWait, traceEvGoBlock, 1) } } bgscavenge() 后台清扫器。后台清扫程序在mheap结构体中比例清除统计信息所描述的线以下维护应用程序的RSS。 文件位置：go1.19.3/src/runtime/mgcscavenge.go。 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 // Background scavenger. // // The background scavenger maintains the RSS of the application below // the line described by the proportional scavenging statistics in // the mheap struct. func bgscavenge(c chan int) { scavenger.init() // scavenger 初始化 c \u0026lt;- 1 // 通知 gcenable 函数解除阻塞 // 调离CPU scavenger.park() for { released, workTime := scavenger.run() if released == 0 { scavenger.park() continue } atomic.Xadduintptr(\u0026amp;mheap_.pages.scav.released, released) scavenger.sleep(workTime) } } ","permalink":"https://heliu.site/posts/golang/goroutine/main/","summary":"Golang runtime.main gorouttine 介绍。","title":"main goroutine"},{"content":" 本篇介绍Golang相关调度代码，本篇也是理解GMP模型的重点篇节。 runtime·mstart(SB) 工作线程M的自旋状态(spinning)解释：工作线程在从其它工作线程的本地运行队列中盗取goroutine时的状态称为自旋状态。\n该函数是所有新创建的工作线程需要执行的函数，也是调度循环的入口函数。 所有【新创建的工作线程】开始运行的入口都是从这个函数开始运行的。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 389 390 391 392 393 TEXT runtime·mstart(SB),NOSPLIT|TOPFRAME,$0 # 调用runtime.mstart0函数，该函数永远不会返回 CALL runtime·mstart0(SB) # 未达到。不会到这里来。 RET # not reached mstart0() mstart0是新Ms的Go入口点。该函数是不允许栈增长检查的，因为我们甚至可能还没有设置堆栈边界。 能在STW期间运行（因为它还没有P），所以不允许写屏障。 初始化g0栈大小，以及调用mstart1()函数开启调度循环。 因为可能存在其他刚创建的工作线程并没有初始化g0栈大小，所以这里需要设置一下。 文件位置：go1.19.3/src/runtime/proc.go。 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 // mstart0 is the Go entry-point for new Ms. // This must not split the stack because we may not even have stack // bounds set up yet. // // May run during STW (because it doesn\u0026#39;t have a P yet), so write // barriers are not allowed. // //go:nosplit //go:nowritebarrierrec func mstart0() { // 该函数是工作线程M起来执行的入口函数，这里一定是g0栈。 _g_ := getg() // _g_ = g0 // 当前g是否已分配栈： // 1. 程序刚初始化时前面是分配了大约64KB大小栈。 // 2. 如果是通过wakeup()函数创建的工作线程，这里可能是没有分配栈大小的。 osStack := _g_.stack.lo == 0 // 判断当前g0是否分配栈 if osStack { // 栈未分配大小时，这也是新创建的工作线程需要处理的g栈情况 // Initialize stack bounds from system stack. // Cgo may have left stack size in stack.hi. // minit may update the stack bounds. // // 从系统栈初始化栈边界。Cgo 可能在 stack.hi 中留下了栈大小。minit 可能会更新栈边界。 // // Note: these bounds may not be very accurate. // We set hi to \u0026amp;size, but there are things above // it. The 1024 is supposed to compensate this, // but is somewhat arbitrary. // // 注意：这些界限可能不是很准确。 // 我们将 hi 设置为 \u0026amp;size，但是上面还有一些东西。 // 1024 应该可以弥补这一点，但有些武断。 // 以上的意思是直接在当前工作线程系统栈上给当前这个g0分配栈大小。 // 可能上面有栈数据，偏移1024字节应该能弥补这些数据。 size := _g_.stack.hi // size 多半是0; size 一定是分配在当前栈上的，因此\u0026amp;size就是栈地址。 if size == 0 {\t// sys.StackGuardMultiplier = 1; 可见其他工作线程的g0栈大约为8KB。 size = 8192 * sys.StackGuardMultiplier // 设置size为指定值 } // noescape函数取size地址并与0异或，实际作用是隐藏(防止)size变量逃逸分析指针 // 防止编译器把size变量堆分配，这里需要的是栈分配 // 因此当前_g_的栈备份分配到当前栈的size变量位置 // noescape函数： // func noescape(p unsafe.Pointer) unsafe.Pointer { // x := uintptr(p) // return unsafe.Pointer(x ^ 0) // 防止变量x逃逸 // } // 以\u0026amp;size为起点设置g0栈。g0.stack -\u0026gt; [\u0026amp;size, \u0026amp;size - 8192 + 1024] _g_.stack.hi = uintptr(noescape(unsafe.Pointer(\u0026amp;size))) // hi存储size的地址，也就是rbp _g_.stack.lo = _g_.stack.hi - size + 1024 // lo存储栈顶位置，也就是rsp } // Initialize stack guard so that we can start calling regular // Go code. // // 初始化栈保护，以便我们可以开始调用常规 Go 代码。 // stackguard0 = _g_.stack.lo + 928; 栈溢出检查的阈值点。 _g_.stackguard0 = _g_.stack.lo + _StackGuard // This is the g0, so we can also call go:systemstack // functions, which check stackguard1. // // 这是 g0，所以我们也可以调用 go:systemstack 函数来检查 stackguard1。 _g_.stackguard1 = _g_.stackguard0 mstart1() // 调用mstart1开启调度循环，该函数永远不会返回 // Exit this thread.\t// // 退出这个线程，程序不会到这里。 if mStackIsSystemAllocated() { // Windows, Solaris, illumos, Darwin, AIX and Plan 9 always system-allocate // the stack, but put it in _g_.stack before mstart, // so the logic above hasn\u0026#39;t set osStack yet. // // Windows、Solaris、illumos、Darwin、AIX 和Plan 9 总是系统分配栈，但是在mstart 之前放在_g_.stack 中， // 所以上面的逻辑还没有设置osStack osStack = true } mexit(osStack) // 结束当前线程。 } 总结：工作线程开始执行使，先判断g0是否分配了栈大小，没有则分配大约8KB大小栈空间，然后设置stackguard0、stackguard1。 mstart1() 设置g0被调度时的调度信息，比如从哪里进入，栈从哪里开始等，以及给当前工作线程M绑定个P并开启调度循环。 设置g0的调度信息是在于，在调度循环过程中会切换到g0栈执行runtime的相关函数，以免栈无限扩大。 文件位置：go1.19.3/src/runtime/proc.go。 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 // The go:noinline is to guarantee the getcallerpc/getcallersp below are safe, // so that we can set up g0.sched to return to the call of mstart1 above. //go:noinline func mstart1() { _g_ := getg() // _g_ = g0 // 当前_g_ 一定是g0，因为该函数只有程序初始化或线程刚启动时才会调用。 if _g_ != _g_.m.g0 { throw(\u0026#34;bad runtime·mstart\u0026#34;) } // Set up m.g0.sched as a label returning to just // after the mstart1 call in mstart0 above, for use by goexit0 and mcall. // We\u0026#39;re never coming back to mstart1 after we call schedule, // so other calls can reuse the current frame. // And goexit0 does a gogo that needs to return from mstart1 // and let mstart0 exit the thread. // // 将 m.g0.sched 设置为上面 mstart0 中 mstart1 调用后返回的标签，供 goexit0 和 mcall 使用 // 在调用 schedule 之后，我们永远不会回到 mstart1，因此其他调用可以重用当前帧 // 而goexit0做了一个gogo，需要从mstart1返回，让mstart0退出线程 // g0.sched.g = g0 _g_.sched.g = guintptr(unsafe.Pointer(_g_)) // 设置g0的调度信息是当前g // g0.sched.pc = getcallerpc() // getcallerpc()：调用者函数的下一条指令，也就是mstart0()函数调用mstart1()函数后的if判断指令代码处。 _g_.sched.pc = getcallerpc() // 这里是理解调度循环的关键，调度循环每次切换到g0栈都从这里(指定的固定位置)设置的位置开始使用栈。 // g0.sched.pc = getcallersp() // getcallersp()：调用者当前的SP寄存器值，也就是mstart0()函数调用mstart1()函数时SP寄存器的值。 // 设置rsp寄存器值为master0调用master1时的栈顶处，设置在这里便于每次切换的g0栈都是从固定位置开始 _g_.sched.sp = getcallersp() // go1.19.3/src/runtime/asm_amd64.s // TEXT runtime·asminit(SB),NOSPLIT,$0-0 // // No per-thread init. // RET // 没有什么可做的。 asminit() // 该函数的汇编代码什么都没做，初始化M工作线程 minit() // 调用以初始化一个新的 m（包括引导程序 m），在新线程上调用，无法分配内存 // Install signal handlers; after minit so that minit can // prepare the thread to be able to handle the signals. // // 安装信号处理程序； 在 minit 之后，以便 minit 可以准备线程以处理信号 if _g_.m == \u0026amp;m0 { // 判断g0绑定的m是否是m0，m0是main.goroutine也就是主线程时执行下面方法 mstartm0() } // 如果_g_.m.mstartfn存在则执行该函数： // 1. 一般的情况下该函数是，mspinning()函数。该函数只有一条指令，标记m的mspining字段为true。 // 2. 如果是sysmon线程下，这里是直接调用sysmon()函数，该函数是一个无限循环，这里不会返回。 if fn := _g_.m.mstartfn; fn != nil { fn() } // 程序刚初始化时，一定是m0，因为在前面m0已经绑定了P，所以是m0需要跳过。 // 通过wakeup()函数创建的新的工作线程m时，这里需要绑定个P。 if _g_.m != \u0026amp;m0 { // 不是m0则需要给工作线程M绑定一个P // _g_.m.nextp.ptr()获取下一个P，nextp在wakeup()函数相关被赋值。 acquirep(_g_.m.nextp.ptr()) // 调用acquirep(_g_.m.nextp.ptr())绑定p _g_.m.nextp = 0 } // 开启循环调度，该函数永远不返回 schedule() } minit() 初始化一个新的m（包括引导程序m）。在新线程上调用，无法分配内存。 文件位置：go1.19.3/src/runtime/os_linux.go。 390 391 392 393 394 395 396 397 398 399 400 // Called to initialize a new m (including the bootstrap m). // Called on the new thread, cannot allocate memory. func minit() { // 初始化 Signals minitSignals() // Cgo-created threads and the bootstrap m are missing a // procid. We need this for asynchronous preemption and it\u0026#39;s // useful in debuggers. getg().m.procid = uint64(gettid()) } 文件位置：go1.19.3/src/runtime/signal_unix.go。 1192 1193 1194 1195 1196 1197 // minitSignals is called when initializing a new m to set the // thread\u0026#39;s alternate signal stack and signal mask. func minitSignals() { minitSignalStack() minitSignalMask() } acquirep() 参数_p_ *p：空闲的p在wakeup()函数时存入m.nextp处，供工作线程启动后绑定这个P。 文件位置：go1.19.3/src/runtime/proc.go。 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951 4952 4953 4954 4955 4956 4957 4958 4959 // Associate p and the current m. // // This function is allowed to have write barriers even if the caller // isn\u0026#39;t because it immediately acquires _p_. // //go:yeswritebarrierrec func acquirep(_p_ *p) { // Do the part that isn\u0026#39;t allowed to have write barriers. wirep(_p_)\t// 绑定P与当前工作线程M // Have p; write barriers now allowed. // Perform deferred mcache flush before this P can allocate // from a potentially stale mcache. // // 在此 P 可以从可能过时的 mcache 分配之前执行延迟 mcache 刷新 _p_.mcache.prepareForSweep() if trace.enabled { traceProcStart() } } 绑定传入的P在当前工作线程。wirep是acquirep的第一步，实际上是将当前的M关联到_p_。 这是被打破的，所以我们可以禁止这部分的写屏障，因为我们还没有P。 文件位置：go1.19.3/src/runtime/proc.go。 4959 4960 4961 4962 4963 4964 4965 4966 4967 4968 4969 4970 4971 4972 4973 4974 4975 4976 4977 4978 4979 4980 4981 4982 4983 4984 4985 // wirep is the first step of acquirep, which actually associates the // current M to _p_. This is broken out so we can disallow write // barriers for this part, since we don\u0026#39;t yet have a P. // //go:nowritebarrierrec //go:nosplit func wirep(_p_ *p) { _g_ := getg() // 获取当前的g if _g_.m.p != 0 { // 当前工作线程如果绑定了P则有问题 throw(\u0026#34;wirep: already in go\u0026#34;) } // 当前P绑定了工作线程存在问题，该P不是空闲的 或 当前P不处于空闲状态 if _p_.m != 0 || _p_.status != _Pidle { id := int64(0) if _p_.m != 0 { id = _p_.m.ptr().id } print(\u0026#34;wirep: p-\u0026gt;m=\u0026#34;, _p_.m, \u0026#34;(\u0026#34;, id, \u0026#34;) p-\u0026gt;status=\u0026#34;, _p_.status, \u0026#34;\\n\u0026#34;) throw(\u0026#34;wirep: invalid p state\u0026#34;) } // 当前工作线程M绑定P _g_.m.p.set(_p_) // m.p = _p_\t// 当前P绑定工作线程M _p_.m.set(_g_.m) // _p_.m = m _p_.status = _Prunning // 把当前P状态修改为_Prunning } schedule() 循环调度开始。每轮循环都从这里开始。该函数算是调度器的核心函数，运行起来的线程会一直执行它。 一轮调度器：找到一个可运行的goroutine并执行它。永不返回。 文件位置：go1.19.3/src/runtime/proc.go。 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195 3196 3197 3198 3199 3200 3201 3202 3203 3204 3205 3206 3207 3208 3209 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223 3224 3225 3226 3227 3228 3229 3230 3231 3232 3233 3234 3235 3236 3237 3238 3239 3240 3241 3242 3243 3244 3245 3246 3247 3248 3249 3250 3251 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 // One round of scheduler: find a runnable goroutine and execute it. // Never returns. func schedule() { // 获取当前正在运行的g，执行该函数时一般都是系统栈g0 _g_ := getg() // _g_ = g0 // 调度开始时 g0.m.locks = 0 // 校验当前线程没有锁，不允许再持有锁的情况下进行调度，以免造成runtime内部错误 // 因为m.locks的加锁和解锁时成对出现的，因此这里应该为0 if _g_.m.locks != 0 { throw(\u0026#34;schedule: holding locks\u0026#34;) } // g0.m.lockedg = 0 // 判断当前M有没有和G绑定，如果有，这个M就不能用来执行其他的G了, // 只能挂起等待绑定的G得到调度。 if _g_.m.lockedg != 0 { stoplockedm() execute(_g_.m.lockedg.ptr(), false) // Never returns. } // We should not schedule away from a g that is executing a cgo call, // since the cgo call is using the m\u0026#39;s g0 stack. // // 我们不应该安排远离正在执行 cgo 调用的 g，因为 cgo 调用正在使用 m 的 g0 堆栈 // 判断线程是不是正在进行cgo函数调用，这种情况下g0栈正在被cgo使用，所以也不允许调度。 if _g_.m.incgo { throw(\u0026#34;schedule: in cgo\u0026#34;) } top: pp := _g_.m.p.ptr() // pp = p // 通过把preempt字段设置为false，来禁止对P的抢占。 pp.preempt = false // Safety check: if we are spinning, the run queue should be empty. // Check this before calling checkTimers, as that might call // goready to put a ready goroutine on the local run queue. // // 安全检查：如果我们正在自旋，那么运行队列应该是空的。 // 在调用checkTimers之前请检查这一点，因为这可能会调用goready将准备好的goroutine放入本地运行队列。 // 对 spinning 的判断属于一致性检验，在P本地runq有任务的情况下，M不应该处于spinning状态。 if _g_.m.spinning \u0026amp;\u0026amp; (pp.runnext != 0 || pp.runqhead != pp.runqtail) { throw(\u0026#34;schedule: spinning with local work\u0026#34;) } // 寻找一个可用的 goroutine // inheritTime：是否继承当前时间片 // 1. true 继承当前时间片 // 2. false 不继承当前时间片 // tryWakeP：当前goroutine是否是普通的。也就是user goroutine。 // 1. false 普通的goroutine。 // 2. true 不是普通的goroutine，可能是GC work、trace reader需要唤醒P。 // gp：当前找到的 goroutine。 gp, inheritTime, tryWakeP := findRunnable() // blocks until work is available // This thread is going to run a goroutine and is not spinning anymore, // so if it was marked as spinning we need to reset it now and potentially // start a new spinning M. // // 这个线程将运行一个goroutine，不再旋转，所以如果它被标记为旋转， // 我们现在需要重置它，并可能启动一个新的旋转M。 if _g_.m.spinning { // 重置当前M位非旋转，并尝试重新启动一个P标记为旋转。 resetspinning() } // sched.disable.user：禁止调度用户goroutine。 // !schedEnabled(gp)：gp是user goroutine。 // 可能来自GC，其中两种模式不允许GC期间运行user goroutine if sched.disable.user \u0026amp;\u0026amp; !schedEnabled(gp) { // Scheduling of this goroutine is disabled. Put it on // the list of pending runnable goroutines for when we // re-enable user scheduling and look again. // // 此goroutine的调度被禁用。 // 当我们重新启用用户调度并再次查看时，将它放在挂起的可运行goroutine列表中。 lock(\u0026amp;sched.lock) if schedEnabled(gp) { // Something re-enabled scheduling while we // were acquiring the lock. unlock(\u0026amp;sched.lock) } else { // user goroutine 时挂起 sched.disable.runnable.pushBack(gp) sched.disable.n++ unlock(\u0026amp;sched.lock) goto top } } // If about to schedule a not-normal goroutine (a GCworker or tracereader), // wake a P if there is one. // // 如果要调度一个不正常的goroutine (GCworker或tracereader)，如果有P，则唤醒P。 // 尝试换新一个新线程绑定P来工作。 if tryWakeP { wakep() } if gp.lockedm != 0 { // Hands off own p to the locked m, // then blocks waiting for a new p. // // 把自己的p交给锁住的m，然后block等待一个新的p。 startlockedm(gp) goto top } execute(gp, inheritTime) } findRunnable()🚀 查找要执行的可运行goroutine。试图从其他P中窃取，从本地或全局队列、轮询网络中获取g。 tryWakeP表示返回的不是普通的goroutine（GC工作程序、跟踪读取器），因此调用者应该尝试唤醒P。 文件位置：go1.19.3/src/runtime/proc.go。 2651 2652 2653 2654 2655 2656 2657 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023 3024 3025 3026 3027 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 // Finds a runnable goroutine to execute. // Tries to steal from other P\u0026#39;s, get g from local or global queue, poll network. // tryWakeP indicates that the returned goroutine is not normal (GC worker, trace // reader) so the caller should try to wake a P. func findRunnable() (gp *g, inheritTime, tryWakeP bool) { _g_ := getg() // _g_ = g0 // The conditions here and in handoffp must agree: if // findrunnable would return a G to run, handoffp must start // an M. // // 这里和handoffp中的条件必须一致：如果findrunnable将返回一个G来运行，则handoffp必须启动一个M。 top: _p_ := _g_.m.p.ptr() // _p_ = p // 1) 帮助STW，抢占当前P。 // STW 即将开始要求等待，挂起当前M。 // 检测sched.gcwaiting，挂起自己，以便及时响应STW， // 调度逻辑中很多地方都有对gcwaiting的检测。 if sched.gcwaiting != 0 { // 在GC的STW期间被设置 gcstopm() goto top } // 2) 检查当前P是否到达安全点。 // 如果当前P要求运行 runSafePointFn() 函数。 // runSafePointFn() 函数被GC用来在安全点执行清空工作队列之类的操作。 if _p_.runSafePointFn != 0 { runSafePointFn() } // 3) 去 timers 里看看，是否有到点的定时器。 // 这里如果有 timer 到触发点了，会触发并执行注册函数。 // 由于调度循环是以时间片形式调度的，因此 timer 的触发时间上线就是10ms。 // 因此抢占能抢占超过10ms以上的goroutine? // checkTimers 为准备好的 P 运行任何timers // 如果 now 不为 0，则为当前时间，如果 now 被传递为 0，则返回传递的时间或当前时间 // 以及下一个timer应该运行的时间，如果没有下一个计时器，则为 0，并报告它是否运行了任何计时器 // 如果下一个timer应该运行的时间不为0，它总是大于返回的时间 // func checkTimers(pp *p, now int64) (rnow, pollUntil int64, ran bool) // 参数： // 1. pp *p 当前需要检查的P // 2. now int64 当前时间，如果为0则取当前时间 // 返回值： // 1. rnow int64：参数now的时间。 // 2. pollUntil int64：\u0026gt;0.最近timer触发的时间点。0.没有任何timer。 // 3. ran bool timer里面是否存在已经延迟时间到点的g，true存在，false不存在 // now and pollUntil are saved for work stealing later, // which may steal timers. It\u0026#39;s important that between now // and then, nothing blocks, so these numbers remain mostly // relevant. // // now和pollUntil被保存以备以后窃取工作，这可能会窃取timers。 // 重要的是，从现在到那时，没有任何阻碍，所以这些数字仍然很重要。 // 处理当前P相关的timers，可能存在一些在timer中的g到时间点了需要放回P中等待被执行 now, pollUntil, _ := checkTimers(_p_, 0) // 4) 尝试安排 trace reader。 // Try to schedule the trace reader. // // 尝试安排 trace reader。 if trace.enabled || trace.shutdown { gp = traceReader() if gp != nil { casgstatus(gp, _Gwaiting, _Grunnable) traceGoUnpark(gp, 0) return gp, false, true } } // 5) 写标记期间，尝试安排 GC worker。 // Try to schedule a GC worker. // 尝试安排 GC worker。 if gcBlackenEnabled != 0 { // 在GC【并发标记】期间被设置 // 唤醒标记协程，参看GC文档 gp, now = gcController.findRunnableGCWorker(_p_, now) // 获取到标记协程 if gp != nil { return gp, false, true // 返回标记协程 } } // 6) P调度次数每满61次需要去全局队列拿去goroutine，防止全局goroutine一直得不到运行。 // Check the global runnable queue once in a while to ensure fairness. // Otherwise two goroutines can completely occupy the local runqueue // by constantly respawning each other. // // 偶尔检查一次全局可运行队列以确保公平性。 // 否则，两个goroutine可以通过不断地相互重新部署来完全占据本地运行队列。 // 为了保证调度的公平性，每个工作线程每进行61次调度就需要优先从全局运行队列中获取goroutine出来运行。 // 因为如果只调度本地运行队列中的goroutine，则全局运行队列中的goroutine有可能得不到运行。 // p.schedtick：记录调度发生的次数，实际上在每发生一次goroutine切换且不继承时间片的情况下，该字段会加一。 // sched.runqsize：记录的是全局就绪队列的长度。也就是全局队列goroutine的个数。 if _p_.schedtick%61 == 0 \u0026amp;\u0026amp; sched.runqsize \u0026gt; 0 { lock(\u0026amp;sched.lock) // 从sched中获取goroutine需要持有lock锁。 // 从全局队列中获取1个goroutine，然后放入P的本地队列。 gp = globrunqget(_p_, 1) // 只拿取一个 unlock(\u0026amp;sched.lock) // mutex 解锁 if gp != nil { return gp, false, false } } // 7) 是否有 finalizer G。 // Wake up the finalizer G. // // 唤醒 finalizer G。 // 该goroutine由runtime.SetFinalizer函数创造。 // 只会创建一个goroutine。 if fingwait \u0026amp;\u0026amp; fingwake { if gp := wakefing(); gp != nil { ready(gp, 0, true) } } if *cgo_yield != nil { asmcgocall(*cgo_yield, nil) } // 8) 从P的本地队列拿去 goroutine。 // local runq // 从本地P的队列中获取goroutine。 if gp, inheritTime := runqget(_p_); gp != nil { return gp, inheritTime, false } // 9) 从全局队列中拿去goroutine。 // global runq // 从全局队列中获取goroutine。 if sched.runqsize != 0 { lock(\u0026amp;sched.lock) gp := globrunqget(_p_, 0) // 拿取多个 unlock(\u0026amp;sched.lock) if gp != nil { return gp, false, false } } // 10) netpoll 是否有就绪的goroutine。 // Poll network. // This netpoll is only an optimization before we resort to stealing. // We can safely skip it if there are no waiters or a thread is blocked // in netpoll already. If there is any kind of logical race with that // blocked thread (e.g. it has already returned from netpoll, but does // not set lastpoll yet), this thread will do blocking netpoll below // anyway. // // netpollinited()：判断netpoll是否已经初始化。 // netpollWaiters：是否有等待的goroutine。 // sched.lastpoll：上次网络轮询的时间点。为0时表示有线程正在阻塞式调用netpoll函数 if netpollinited() \u0026amp;\u0026amp; atomic.Load(\u0026amp;netpollWaiters) \u0026gt; 0 \u0026amp;\u0026amp; atomic.Load64(\u0026amp;sched.lastpoll) != 0 { // netpoll(0)：判断当前是否有就绪事件，0表示立即返回。非阻塞。 if list := netpoll(0); !list.empty() { // non-blocking gp := list.pop() // 弹出一个goroutine。 injectglist(\u0026amp;list) // 处理剩下的goroutine casgstatus(gp, _Gwaiting, _Grunnable) // 修改goroutine状态 if trace.enabled { traceGoUnpark(gp, 0) } return gp, false, false } } // 11) 以上都没获取到goroutine。标记自旋尝试从其他P中偷取goroutine。 // Spinning Ms: steal work from other Ps. // // Limit the number of spinning Ms to half the number of busy Ps. // This is necessary to prevent excessive CPU consumption when // GOMAXPROCS\u0026gt;\u0026gt;1 but the program parallelism is low. // // Spinning Ms:从其他P那里窃取goroutine。 // 将自旋的M限制为繁忙M的一半。 // 这是必要的，以防止在 GOMAXPROCS\u0026gt;\u0026gt;1 但程序并行性较低时过度消耗CPU。 // 如果当前处于spinning状态的M的数量大于忙碌的P的数量的一半，就让当前M阻塞(休眠)。 // 目的是避免在gomaxprocs较大而程序实际的并发性很低的情况下，造成不必要的CPU消耗。 procs := uint32(gomaxprocs) // 获取当前P的数量 // _g_.m.spinning == true：当前M处于自旋。 // 2*atomic.Load(\u0026amp;sched.nmspinning) \u0026lt; procs-atomic.Load(\u0026amp;sched.npidle)：自旋是繁忙的一半还小时，标记当前M为自旋 if _g_.m.spinning || 2*atomic.Load(\u0026amp;sched.nmspinning) \u0026lt; procs-atomic.Load(\u0026amp;sched.npidle) { if !_g_.m.spinning { // 满足偷取的时候才会标记M为自旋状态 _g_.m.spinning = true // 标记为自旋状态 atomic.Xadd(\u0026amp;sched.nmspinning, 1) // 累加自旋M的数量 } // 去其他P中偷取 goroutine。偷取其他P中goroutine的一半。 // 从p.runnext中偷取的goroutine时，inheritTime该值为true，表示继承上个时间片。 gp, inheritTime, tnow, w, newWork := stealWork(now) now = tnow // 更新当前时间 // 成功偷取到goroutine if gp != nil { // Successfully stole. return gp, inheritTime, false } // newWork 某个P中有timer被触发了，在来一次调度循环 if newWork { // There may be new timer or GC work; restart to // discover. goto top } // w不为0，表示最近触发的timer的时间点 if w != 0 \u0026amp;\u0026amp; (pollUntil == 0 || w \u0026lt; pollUntil) { // Earlier timer to wait for. pollUntil = w // 记录最近要触发的时间点 } } // 12) 有GC标记工作这去帮助GC // We have nothing to do. // // If we\u0026#39;re in the GC mark phase, can safely scan and blacken objects, // and have work to do, run idle-time marking rather than give up the P. // // 我们无事可做。 // 如果我们在GC标记阶段，可以安全地扫描和变黑对象，并且有工作要做，运行空闲时间标记而不是放弃P。 if gcBlackenEnabled != 0 \u0026amp;\u0026amp; gcMarkWorkAvailable(_p_) \u0026amp;\u0026amp; gcController.addIdleMarkWorker() { node := (*gcBgMarkWorkerNode)(gcBgMarkWorkerPool.pop()) if node != nil { _p_.gcMarkWorkerMode = gcMarkWorkerIdleMode gp := node.gp.ptr() casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled { traceGoUnpark(gp, 0) } return gp, false, false } gcController.removeIdleMarkWorker() } // wasm only: // If a callback returned and no other goroutine is awake, // then wake event handler goroutine which pauses execution // until a callback was triggered. gp, otherReady := beforeIdle(now, pollUntil) // 在linux下返回 (nil, false) if gp != nil { casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled { traceGoUnpark(gp, 0) } return gp, false, false } if otherReady { goto top } // 13) 保存allp、idlepMask和timerpMask的快照 // 当前工作线程即将休眠，休眠前再次去快照里面看看有没有工作要做 // Before we drop our P, make a snapshot of the allp slice, // which can change underfoot once we no longer block // safe-points. We don\u0026#39;t need to snapshot the contents because // everything up to cap(allp) is immutable. // // 在我们丢弃P之前，做一个allp切片的快照，一旦我们不再阻塞safe-points，它就会改变。 // 我们不需要对内容进行快照，因为cap(allp)之前的所有内容都是不可变的。 allpSnapshot := allp // Also snapshot masks. Value changes are OK, but we can\u0026#39;t allow // len to change out from under us. // // 还有快照掩码。值更改是可以的，但是我们不能允许len从我们下面更改。 idlepMaskSnapshot := idlepMask timerpMaskSnapshot := timerpMask // 14) 在看一下gcwaiting和runSafePointFn，以及全局队列sched.runqsize // return P and block lock(\u0026amp;sched.lock) // 有GC等待 或 P有安全点函数执行 if sched.gcwaiting != 0 || _p_.runSafePointFn != 0 { unlock(\u0026amp;sched.lock) goto top } // 全局队列有 goroutine if sched.runqsize != 0 { // 因为 sched.lock 锁已被持有，所以一定能取出 gp。不为 nil。 gp := globrunqget(_p_, 0) unlock(\u0026amp;sched.lock) return gp, false, false } // 15) 解除当前M与P的绑定关系，并把P加入全局空闲队列中 // 解除m与p的绑定关系，并设置p为空闲状态。 if releasep() != _p_ { throw(\u0026#34;findrunnable: wrong p\u0026#34;) } // 把P加入空闲队列 now = pidleput(_p_, now) unlock(\u0026amp;sched.lock) // 16) 根据前面快照保存的信息，再次检查其他P是否可偷取，GC有没标记工作需要协助，timer有没触发 // Delicate dance: thread transitions from spinning to non-spinning // state, potentially concurrently with submission of new work. We must // drop nmspinning first and then check all sources again (with // #StoreLoad memory barrier in between). If we do it the other way // around, another thread can submit work after we\u0026#39;ve checked all // sources but before we drop nmspinning; as a result nobody will // unpark a thread to run the work. // // This applies to the following sources of work: // // * Goroutines added to a per-P run queue. // * New/modified-earlier timers on a per-P timer heap. // * Idle-priority GC work (barring golang.org/issue/19112). // // If we discover new work below, we need to restore m.spinning as a signal // for resetspinning to unpark a new worker thread (because there can be more // than one starving goroutine). However, if after discovering new work // we also observe no idle Ps it is OK to skip unparking a new worker // thread: the system is fully loaded so no spinning threads are required. // Also see \u0026#34;Worker thread parking/unparking\u0026#34; comment at the top of the file. wasSpinning := _g_.m.spinning // 处理当前M是自旋状态 if _g_.m.spinning { _g_.m.spinning = false // 标记当前M未非自旋 if int32(atomic.Xadd(\u0026amp;sched.nmspinning, -1)) \u0026lt; 0 { throw(\u0026#34;findrunnable: negative nmspinning\u0026#34;) } // Note the for correctness, only the last M transitioning from // spinning to non-spinning must perform these rechecks to // ensure no missed work. We are performing it on every M that // transitions as a conservative change to monitor effects on // latency. See golang.org/issue/43997. // Check all runqueues once again. // // 再次检查所有运行队列。 // 检查是否有可偷取的P，如果有则取出一个空闲的P绑定M。 _p_ = checkRunqsNoP(allpSnapshot, idlepMaskSnapshot) if _p_ != nil { acquirep(_p_) // 绑定P _g_.m.spinning = true atomic.Xadd(\u0026amp;sched.nmspinning, 1) goto top // 有工作可做再跑一遍调度循环 } // Check for idle-priority GC work again. // // 再次检查空闲优先级GC工作。是否有编辑工作需要做 _p_, gp = checkIdleGCNoP() if _p_ != nil { acquirep(_p_) // 绑定P _g_.m.spinning = true atomic.Xadd(\u0026amp;sched.nmspinning, 1) // Run the idle worker. _p_.gcMarkWorkerMode = gcMarkWorkerIdleMode casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled { traceGoUnpark(gp, 0) } return gp, false, false } // Finally, check for timer creation or expiry concurrently with // transitioning from spinning to non-spinning. // // Note that we cannot use checkTimers here because it calls // adjusttimers which may need to allocate memory, and that isn\u0026#39;t // allowed when we don\u0026#39;t have an active P. // // 最后，再看看timer。 pollUntil = checkTimersNoP(allpSnapshot, timerpMaskSnapshot, pollUntil) } // 17) network 是否有需要处理的goroutine，或timer是否即将触发， // 标记sched.lastpoll为0，阻塞式等待吧。netpoll中一些读写超时需要用到timer // Poll network until next timer. // // Poll network 直到下一个 timer。 // netpollinited()：netpoll 已初始化。 // netpollWaiters：记录当前goroutine被挂在epoll中的等待数量。 // pollUntil：\u0026gt;0.下个timer触发的而时间点。 // atomic.Xchg64(\u0026amp;sched.lastpoll, 0)：这里是唯一的把sched.lastpoll修改为0的情况， // 表示当前需要阻塞式的调用netpoll函数。 // 这里的atomic.Xchg64(\u0026amp;sched.lastpoll, 0) != 0 具有排他性。只能有一个工作线程处于阻塞等待中。 if netpollinited() \u0026amp;\u0026amp; (atomic.Load(\u0026amp;netpollWaiters) \u0026gt; 0 || pollUntil != 0) \u0026amp;\u0026amp; atomic.Xchg64(\u0026amp;sched.lastpoll, 0) != 0 { // sched.pollUntil = pollUntil，预计的阻塞时间点。 atomic.Store64(\u0026amp;sched.pollUntil, uint64(pollUntil)) if _g_.m.p != 0 { throw(\u0026#34;findrunnable: netpoll with p\u0026#34;) } if _g_.m.spinning { throw(\u0026#34;findrunnable: netpoll with spinning\u0026#34;) } // Refresh now. now = nanotime() delay := int64(-1) if pollUntil != 0 { // 计算预计阻塞的时间 delay = pollUntil - now if delay \u0026lt; 0 { // 触发时间以过，要求立即返回 delay = 0 } } // faketime是自1970年以来模拟的以纳秒为单位的时间。 // 0值意味着不使用faketime。 if faketime != 0 { // When using fake time, just poll. // 当使用 fake time，只是poll。 delay = 0 } // 阻塞直到有新的work可用，delay是一个具体的时间段 list := netpoll(delay) // block until new work is available atomic.Store64(\u0026amp;sched.pollUntil, 0) // sched.pollUntil = 0 atomic.Store64(\u0026amp;sched.lastpoll, uint64(now)) // sched.lastpoll = now if faketime != 0 \u0026amp;\u0026amp; list.empty() { // Using fake time and nothing is ready; stop M. // When all M\u0026#39;s stop, checkdead will call timejump. stopm() goto top } lock(\u0026amp;sched.lock) // 从空闲P链表中获取一个P _p_, _ = pidleget(now) unlock(\u0026amp;sched.lock) if _p_ == nil { // 没有可用的空闲P时。 // 如果有就绪的goroutine放入全局goroutine池。 injectglist(\u0026amp;list) } else { acquirep(_p_) // 绑定P if !list.empty() { // 取出一个goroutine，用于返回 gp := list.pop() // 剩余的优先加入全局池。 injectglist(\u0026amp;list) // 修改goroutine状态为待运行状态 casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled { traceGoUnpark(gp, 0) } // 返回找到的 goroutine return gp, false, false } // 如果之前M是自旋，则再次标记为自旋并从新再来一次。 if wasSpinning { _g_.m.spinning = true atomic.Xadd(\u0026amp;sched.nmspinning, 1) } goto top } } else if pollUntil != 0 \u0026amp;\u0026amp; netpollinited() { // 有其他的线程在阻塞 netpoll。 // sched.pollUntil：下次timer应该被唤醒时间点。 pollerPollUntil := int64(atomic.Load64(\u0026amp;sched.pollUntil)) // timer触发了 或 触发时间已到 叫醒阻塞的netpoll if pollerPollUntil == 0 || pollerPollUntil \u0026gt; pollUntil { netpollBreak() // 叫醒epoll } } // 挂起当前线程等待其他线程唤醒。 stopm() goto top } gcstopm() 为stopTheWorld停止当前M。 当TheWordStart时返回。辅助STW。 文件位置：go1.19.3/src/runtime/proc.go。 该方法在GC发起时，其他线程都在这个方法上把自己挂起。 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 // Stops the current m for stopTheWorld. // Returns when the world is restarted. func gcstopm() { _g_ := getg() // _g_ = g0 // sched.gcwaiting：是1，表示当前STW正在等待P停下来。 if sched.gcwaiting == 0 { throw(\u0026#34;gcstopm: not waiting for gc\u0026#34;) } // 当前M正处于自旋状态下。 if _g_.m.spinning { _g_.m.spinning = false // 清除自旋标记 // OK to just drop nmspinning here, // startTheWorld will unpark threads as necessary. // // 自旋计数出现错误 if int32(atomic.Xadd(\u0026amp;sched.nmspinning, -1)) \u0026lt; 0 { throw(\u0026#34;gcstopm: negative nmspinning\u0026#34;) } } // 解绑当前M与P _p_ := releasep() lock(\u0026amp;sched.lock) // _Pgcstop：GC停止状态。 // P被STW挂起以执行GC，所有权归执行STW的M所有，执行STW的M会继续使用处于_Pgcstop状态的P。 _p_.status = _Pgcstop // sched.stopwait：记录了STW需要停止的P的数量 sched.stopwait-- // 已经停下了所有的P，需要唤醒在 sched.stopnote 上发起STW的工作线程。 if sched.stopwait == 0 { notewakeup(\u0026amp;sched.stopnote) } unlock(\u0026amp;sched.lock) stopm() // 停止当前工作线程。 } releasep() 解除p和当前m的关联。 文件位置：go1.19.3/src/runtime/proc.go。 4984 4985 4986 4987 4988 4989 4990 4991 4992 4993 4994 4995 4996 4997 4998 4999 5000 5001 5002 5003 5004 5005 5006 5007 // Disassociate p and the current m. func releasep() *p { _g_ := getg() // _g_ = g0 if _g_.m.p == 0 { throw(\u0026#34;releasep: invalid arg\u0026#34;) } _p_ := _g_.m.p.ptr() // _p_ = p // _p_.m == _g_.m \u0026amp;\u0026amp; _p_.status == _Prunning if _p_.m.ptr() != _g_.m || _p_.status != _Prunning { print(\u0026#34;releasep: m=\u0026#34;, _g_.m, \u0026#34; m-\u0026gt;p=\u0026#34;, _g_.m.p.ptr(), \u0026#34; p-\u0026gt;m=\u0026#34;, hex(_p_.m), \u0026#34; p-\u0026gt;status=\u0026#34;, _p_.status, \u0026#34;\\n\u0026#34;) throw(\u0026#34;releasep: invalid p state\u0026#34;) } if trace.enabled { traceProcStop(_g_.m.p.ptr()) } // 解除 p 与 m 相互绑定的关系。 _g_.m.p = 0 _p_.m = 0 // _Pidle：空闲状态。 // 此时的P没有被用来执行用户代码或调度器代码，通常位于空闲链表中，能够被调度器获取。 _p_.status = _Pidle return _p_ } stopm() 停止执行当前m，直到有新的工作可用。返回获取的P。 文件位置：go1.19.3/src/runtime/proc.go。 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 // Stops execution of the current m until new work is available. // Returns with acquired P. func stopm() { _g_ := getg() // _g_ = g0 if _g_.m.locks != 0 { throw(\u0026#34;stopm holding locks\u0026#34;) } if _g_.m.p != 0 { throw(\u0026#34;stopm holding p\u0026#34;) } if _g_.m.spinning { throw(\u0026#34;stopm spinning\u0026#34;) } lock(\u0026amp;sched.lock) mput(_g_.m) // 把当前m加入sched.midle中。 unlock(\u0026amp;sched.lock) mPark() // 工作线程sleep在m.park上 // 工作线程再次被wakeup时，绑定P。 acquirep(_g_.m.nextp.ptr()) // 此处p来自m.nextp。 _g_.m.nextp = 0 } mput() 把mp列入midle列表中。 sched.lock 必须被持有。 可能在STW期间运行，因此不允许出现写屏障。 文件位置：go1.19.3/src/runtime/proc.go。 5533 5534 5535 5536 5537 5538 5539 5540 5541 5542 5543 5544 5545 5546 // Put mp on midle list. // sched.lock must be held. // May run during STW, so write barriers are not allowed. // //go:nowritebarrierrec func mput(mp *m) { assertLockHeld(\u0026amp;sched.lock) // 把当前m加入sched.midle。 mp.schedlink = sched.midle sched.midle.set(mp) sched.nmidle++ checkdead() // 检查死锁。 } mPark() mPark会导致线程自行停驻，一旦被唤醒就会返回。 文件位置：go1.19.3/src/runtime/proc.go。 1452 1453 1454 1455 1456 1457 1458 1459 // mPark causes a thread to park itself, returning once woken. // //go:nosplit func mPark() { gp := getg() // gp = g0 notesleep(\u0026amp;gp.m.park) // sleep noteclear(\u0026amp;gp.m.park) // 清除 m.park } acquirep() 关联p和当前m。 文件位置：go1.19.3/src/runtime/proc.go。 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951 4952 4953 4954 4955 4956 4957 // Associate p and the current m. // // This function is allowed to have write barriers even if the caller // isn\u0026#39;t because it immediately acquires _p_. // //go:yeswritebarrierrec func acquirep(_p_ *p) { // Do the part that isn\u0026#39;t allowed to have write barriers. wirep(_p_) // Have p; write barriers now allowed. // Perform deferred mcache flush before this P can allocate // from a potentially stale mcache. _p_.mcache.prepareForSweep() if trace.enabled { traceProcStart() } } globrunqget() 尝试从全局可运行队列中获取一批G，sched.lock必须被持有。 参数： _p_ *p：当前工作线程绑定的P。 max int32：从全局队列中拿多少个g到本地P中。该参数一般是1，如果是其他P偷取则是大于1。 返回值*g：从全局队列中那到的goroutine。 文件位置：go1.19.3/src/runtime/proc.go。 5601 5602 5603 5604 5605 5606 5607 5608 5609 5610 5611 5612 5613 5614 5615 5616 5617 5618 5619 5620 5621 5622 5623 5624 5625 5626 5627 5628 5629 5630 5631 5632 5633 5634 5635 5636 5637 5638 5639 5640 5641 5642 5643 5644 // Try get a batch of G\u0026#39;s from the global runnable queue. // sched.lock must be held. func globrunqget(_p_ *p, max int32) *g { assertLockHeld(\u0026amp;sched.lock) // sched.runqsize：记录的是全局就绪队列的长度。 // 也就是全局队列goroutine的个数。 if sched.runqsize == 0 { return nil } // 根据p的数量平分全局运行队列中的goroutines n := sched.runqsize/gomaxprocs + 1 // 上面计算n的方法可能导致n大于全局运行队列中的goroutine数量 if n \u0026gt; sched.runqsize { n = sched.runqsize } // max：表示最多拿去goroutine个数。 if max \u0026gt; 0 \u0026amp;\u0026amp; n \u0026gt; max { n = max } // 最多只能取本地队列容量的一半。 // _p_.runq：最大256。 if n \u0026gt; int32(len(_p_.runq))/2 { n = int32(len(_p_.runq)) / 2 } sched.runqsize -= n // 减去取出的数量 // pop从全局运行队列的队列头取一个goroutine。 // 这个goroutine用于返回。 gp := sched.runq.pop() n-- // 遍历从全局队列中拿取goroutine到P的本地队列中。 for ; n \u0026gt; 0; n-- { // 从全局运行队列中取出一个goroutine gp1 := sched.runq.pop() // 放入本地运行队列，false.放入尾部。 // 1. go关键字时，调用该方法传入的true // 2. 从全局拿取时，这里传入的时false runqput(_p_, gp1, false) } return gp } runqput() 把gp放入_p_的尾部。 参数： _p_ *p：本地P。 gp *g：需要放入_p_的goroutine。 next bool：true放入本地_p_的开头，false放入本地_p_的尾部。 文件位置：go1.19.3/src/runtime/proc.go。 5780 5781 5782 5783 5784 5785 5786 5787 5788 5789 5790 5791 5792 5793 5794 5795 5796 5797 5798 5799 5800 5801 5802 5803 5804 5805 5806 5807 5808 5809 5810 5811 5812 5813 5814 5815 5816 5817 // runqput tries to put g on the local runnable queue. // If next is false, runqput adds g to the tail of the runnable queue. // If next is true, runqput puts g in the _p_.runnext slot. // If the run queue is full, runnext puts g on the global queue. // Executed only by the owner P. func runqput(_p_ *p, gp *g, next bool) { if randomizeScheduler \u0026amp;\u0026amp; next \u0026amp;\u0026amp; fastrandn(2) == 0 { next = false } if next { retryNext: oldnext := _p_.runnext if !_p_.runnext.cas(oldnext, guintptr(unsafe.Pointer(gp))) { goto retryNext } if oldnext == 0 { return } // Kick the old runnext out to the regular run queue. gp = oldnext.ptr() } retry: h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with consumers t := _p_.runqtail if t-h \u0026lt; uint32(len(_p_.runq)) { _p_.runq[t%uint32(len(_p_.runq))].set(gp) atomic.StoreRel(\u0026amp;_p_.runqtail, t+1) // store-release, makes the item available for consumption return } // 从_P_中移除一部分到全局中，包含gp。 if runqputslow(_p_, gp, h, t) { return } // the queue is not full, now the put above must succeed goto retry } runqget() 从本地可运行队列中获取goroutine。 如果inheritTime为true，则gp应继承当前时间片中的剩余时间。否则，它应该开始一个新的时间片。 多有者由当前P拥有。 参数：_p_ *p：当前本地P，可能出现其他工作线程M偷取P的情况。 返回值： gp *g：当前获取到的goroutine。 inheritTime bool：是否继承当前时间片。 文件位置：go1.19.3/src/runtime/proc.go。 5893 5894 5895 5896 5897 5898 5899 5900 5901 5902 5903 5904 5905 5906 5907 5908 5909 5910 5911 5912 5913 5914 5915 5916 5917 5918 5919 5920 5921 5922 5923 5924 5925 5926 5927 5928 5929 5930 5931 5932 5933 5934 5935 // Get g from local runnable queue. // If inheritTime is true, gp should inherit the remaining time in the // current time slice. Otherwise, it should start a new time slice. // Executed only by the owner P. func runqget(_p_ *p) (gp *g, inheritTime bool) { // If there\u0026#39;s a runnext, it\u0026#39;s the next G to run. // // 如果有 runnext，它就是下一个要运行的 G next := _p_.runnext // If the runnext is non-0 and the CAS fails, it could only have been stolen by another P, // because other Ps can race to set runnext to 0, but only the current P can set it to non-0. // Hence, there\u0026#39;s no need to retry this CAS if it falls. // // 如果 runnext 是 non-0 并且 CAS 失败，它只能被另一个P窃取，因为其他P可以竞相将runnext设置为0， // 当前P可以将其设置为非 0。 因此，如果该 CAS 失败，则无需重试。 if next != 0 \u0026amp;\u0026amp; _p_.runnext.cas(next, 0) { // 从 p.runnext上取出的goroutine，都继承了上次的时间片 // channel 的send和recv操作都会把goroutine挂在 p.runnext 上 return next.ptr(), true } // p.runnext == 0 || 当前goroutine已被窃取。 for { // 原子读取 _p_.runqhead。 // 当前P和其他P来偷取goroutine都是从runqhead开始的，因此需要原子读取。 h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with other consumers // runqtail：只有本地P会修改这个值加入goroutine。当前P在此操作因此runqtail不会改变不需原子操作。 t := _p_.runqtail // 本地P队列为空。 if t == h { return nil, false } // 取出当前h位置上的g，注意循环队列是通过runqhead和runqtail不断的累加然后通过求余判断位置的 // 由于runqhead和runqtail都是uint32类型循环数组大小为256正好是整倍数， // 因此uint32不断累计最后会从0又开始，形成一个循环 gp := _p_.runq[h%uint32(len(_p_.runq))].ptr() // CAS 设置 _p_.runqhead，这段时间可能 _p_.runqhead 的值发生变化而失败。 if atomic.CasRel(\u0026amp;_p_.runqhead, h, h+1) { // cas-release, commits consume return gp, false } } } injectglist() injectglist 将列表上的每个可运行的G添加到某个运行队列，并清除glist。 如果当前不存在P，则将它们添加到全局队列，并启动多达npim个队列来运行它们。 否则，对于每个空闲的P，将G添加到全局队列，并启动一个m。剩余的G添加到当前P的本地就绪队列。 这可能会临时获取sched.lock。可以与GC并发运行。 该函数在netpoll后调用，可以是监控线程中这种情况下没有P，或则调度循环中。 文件位置：go1.19.3/src/runtime/proc.go。 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195 3196 3197 // injectglist adds each runnable G on the list to some run queue, // and clears glist. If there is no current P, they are added to the // global queue, and up to npidle M\u0026#39;s are started to run them. // Otherwise, for each idle P, this adds a G to the global queue // and starts an M. Any remaining G\u0026#39;s are added to the current P\u0026#39;s // local run queue. // This may temporarily acquire sched.lock. // Can run concurrently with GC. func injectglist(glist *gList) { // goroutine 空列表 if glist.empty() { return } if trace.enabled { for gp := glist.head.ptr(); gp != nil; gp = gp.schedlink.ptr() { traceGoUnpark(gp, 0) } } // Mark all the goroutines as runnable before we put them // on the run queues. head := glist.head.ptr() var tail *g // 获取队列最后一个 goroutine qsize := 0 // 记录goroutine数量 // 修改这些goroutine的状态 for gp := head; gp != nil; gp = gp.schedlink.ptr() { tail = gp qsize++ // _Gwaiting：goroutine阻塞在runtime中，没有执行用户代码。它不在任何runq中，但是应该被记录在其他地方。 // _Grunnable：goroutine应该在某个runq中，当前并没有在运行用户代码，它的栈不归自己所有。 casgstatus(gp, _Gwaiting, _Grunnable) } // Turn the gList into a gQueue. // 将这个gList转换为一个gQueue。 var q gQueue // 双向链表 q.head.set(head) q.tail.set(tail) *glist = gList{} startIdle := func(n int) { // 指定数量的空闲P起来工作 for ; n != 0 \u0026amp;\u0026amp; sched.npidle != 0; n-- { startm(nil, false) } } pp := getg().m.p.ptr() // pp // 如果来自sysmon监控线程，pp = nil。 if pp == nil { lock(\u0026amp;sched.lock) // 放入全局 sched.runq 池中 globrunqputbatch(\u0026amp;q, int32(qsize)) unlock(\u0026amp;sched.lock) // 唤醒qsize多个空闲P来处理这些goroutine startIdle(qsize) return } // 以下是存在P的情况 // 空闲的P的数量 npidle := int(atomic.Load(\u0026amp;sched.npidle)) var globq gQueue var n int // 把空闲P数量个数的goroutine放入全局池中，然后唤醒P起来工作 for n = 0; n \u0026lt; npidle \u0026amp;\u0026amp; !q.empty(); n++ { g := q.pop() globq.pushBack(g) } if n \u0026gt; 0 { lock(\u0026amp;sched.lock) // 放入全局 sched.runq 池中 globrunqputbatch(\u0026amp;globq, int32(n)) unlock(\u0026amp;sched.lock) // 唤醒qsize多个空闲P来处理这些goroutine startIdle(n) qsize -= n } if !q.empty() { // 还剩的goroutine放入本地队列中 runqputbatch(pp, \u0026amp;q, qsize) } } stealWork() stealWork试图从任何P中窃取一个可运行的goroutine或timer。 如果返回值newWork为true，则新工作可能已经准备好了。 如果now不是0，则为当前时间。stealWork返回经过的时间，如果now被传递为0，则返回当前时间。 参数now int64：不是 0，则为当前时间。 返回值： gp *g：获取到的goroutine。 inheritTime bool：是否继承当前时间片。 rnow int64：获取时间点。 pollUntil int64：timer的触发时间点。 newWork bool：为 true，则新工作可能已经准备好了。会跳转到findRunnable函数top标签处从新开始。 窃取逻辑会循环尝试4次，最后一次才会窃取runnext和timer，也就是说前3次只会从其他P的本地runq中窃取。 stealOrder用来实现一个公平的随机窃取顺序，timerpMask和idlepMask用来快速判断指定位置的P是否有timer或是空闲。 文件位置：go1.19.3/src/runtime/proc.go。 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013 3014 3015 3016 3017 // stealWork attempts to steal a runnable goroutine or timer from any P. // // If newWork is true, new work may have been readied. // // If now is not 0 it is the current time. stealWork returns the passed time or // the current time if now was passed as 0. func stealWork(now int64) (gp *g, inheritTime bool, rnow, pollUntil int64, newWork bool) { pp := getg().m.p.ptr() // pp = p ranTimer := false // newWork 的返回值 // 尝试偷取最大次数 const stealTries = 4 // 执行四次遍历，就是尽最大努力去其他P中查看 for i := 0; i \u0026lt; stealTries; i++ { // 最后一次时： // 1. 前三次尝试去P的runq本地队列中偷取goroutine。 // 2. 最后一次先去各个P的timers里看看，然后当偷取的P的runq为空时， // 尝试偷取P.runnext上的goroutine。 stealTimersOrRunNextG := i == stealTries-1 // randomOrder/randomEnum 是随机工作窃取的辅助类型，一轮allp遍历开始。 // 它们允许以不同的伪随机顺序枚举所有 P 而不重复。 // 该算法基于这样一个事实： // 如果我们有X使得X和GOMAXPROCS互质，那么(i + X)%GOMAXPROCS的序列给出所需的枚举。 // stealOrder.start(fastrand())：从一个随机位置开始。 // !enum.done()：当前是否已经遍历一圈了。 // enum.next()：跳转到下一个位置。 for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() { // 有STW正在等待P挂起。直接返回。 // 跳转到findRunnable函数top标签处从新开始。 if sched.gcwaiting != 0 { // GC work may be available. return nil, false, now, pollUntil, true } // 随机选的p，如果是当前的跳过。 // enum.position()：当前偷取P的下标。 p2 := allp[enum.position()] if pp == p2 { continue } // Steal timers from p2. This call to checkTimers is the only place // where we might hold a lock on a different P\u0026#39;s timers. We do this // once on the last pass before checking runnext because stealing // from the other P\u0026#39;s runnext should be the last resort, so if there // are timers to steal do that first. // // We only check timers on one of the stealing iterations because // the time stored in now doesn\u0026#39;t change in this loop and checking // the timers for each P more than once with the same value of now // is probably a waste of time. // // timerpMask tells us whether the P may have timers at all. If it // can\u0026#39;t, no need to check at all. // // 从p2中窃取 timers。对checkTimers的调用是唯一可以对不同P的timers持有锁的地方。 // 我们在检查runnext之前的最后一遍执行此操作，因为从另一个P的runnext中窃取计时器应该是最后的手段， // 所以如果有timers可以窃取，请先窃取。 // 我们只检查其中一个窃取迭代的定时器，因为存储在now中的时间在这个循环中不会改变， // 如果用相同的now值多次检查每个P的定时器，可能就是浪费时间。 // timerpMask告诉我们P是否有定时器。如果它不能，根本不需要检查。 // timerpMask 是P的位图记录当前P上是否有 timer。 if stealTimersOrRunNextG \u0026amp;\u0026amp; timerpMask.read(enum.position()) { // 再次看看 timers，是否有到点需要执行的timer。 // tnow：返回的now // w：触发时间点 // ran：timer是否已经运行了 // 如果ran为true，表示checkTimers()执行了p2的timer， // 可能会使某些goroutine变成_Grunnable状态， // 所以先检查当前P的本地runq，如果没有找到继续去偷取。 tnow, w, ran := checkTimers(p2, now) now = tnow // w != 0：还未触发的时间点 // pollUntil == 0：上次检查没有timer // w \u0026lt; pollUntil：触发时间点缩小 if w != 0 \u0026amp;\u0026amp; (pollUntil == 0 || w \u0026lt; pollUntil) { pollUntil = w // 最近的timer触发的时间点 } // 有触发timer运行，需要去P的本地runq中去找找可能有goroutine被放里面了。 // 比如time.Sleep。 if ran { // Running the timers may have // made an arbitrary number of G\u0026#39;s // ready and added them to this P\u0026#39;s // local run queue. That invalidates // the assumption of runqsteal // that it always has room to add // stolen G\u0026#39;s. So check now if there // is a local G to run. if gp, inheritTime := runqget(pp); gp != nil { return gp, inheritTime, now, pollUntil, ranTimer } // 标记为true，再次跑一边调度循环 ranTimer = true } } // Don\u0026#39;t bother to attempt to steal if p2 is idle. // // 如果p2是空闲的不要尝试偷取。 // 在创建goroutine时候我们遇见过idlepMask，该值是P的位图，记录了所有空闲的P的bit位(原子更新)。 // idlepMask.read(enum.position())：true.当前P是空闲的，false.当前P不是空闲的。 if !idlepMask.read(enum.position()) { // runqsteal 函数从p2中偷取goroutine到pp中。 // stealTimersOrRunNextG表示最大程度偷取runnext。 if gp := runqsteal(pp, p2, stealTimersOrRunNextG); gp != nil { return gp, false, now, pollUntil, ranTimer } } } } // No goroutines found to steal. Regardless, running a timer may have // made some goroutine ready that we missed. Indicate the next timer to // wait for. return nil, false, now, pollUntil, ranTimer } runqsteal() 从p2的本地可运行队列中窃取一半的g，并放入p的本地可运行队列中。 返回一个被窃取的g(如果失败则返回nil)。 参数： _p_ *p：当前窃取其他P的工作线程绑定的P。 p2 *p：被窃取的P。 stealRunNextG bool：true尽最大努力去p.runnext上偷取，false不偷取p.runnext的goroutine。 返回值*g：偷取到的goroutine。 文件位置：go1.19.3/src/runtime/proc.go。 6015 6016 6017 6018 6019 6020 6021 6022 6023 6024 6025 6026 6027 6028 6029 6030 6031 6032 6033 6034 6035 6036 6037 6038 6039 6040 6041 6042 6043 // Steal half of elements from local runnable queue of p2 // and put onto local runnable queue of p. // Returns one of the stolen elements (or nil if failed). func runqsteal(_p_, p2 *p, stealRunNextG bool) *g { t := _p_.runqtail // 尝试从p2中偷取一半的goroutine。 n := runqgrab(p2, \u0026amp;_p_.runq, t, stealRunNextG) // p2中也没有 if n == 0 { return nil } // 从p的本地runq中取出一个goroutine，用于返回给调度器调度起来。 n-- // 因为偷取是从runqtail开始的，因此runqtail处也是head头处。 // 其实是取的队列中的最后一个，方便后面 StoreRel 原子操作设置 runqtail 值。 gp := _p_.runq[(t+n)%uint32(len(_p_.runq))].ptr() if n == 0 { return gp } // 还有其他的需要处理，原子读取 _p_.runqhead h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with consumers // 这里判断偷取的g是否大于P本地的一半数量，则是溢出了 if t-h+n \u0026gt;= uint32(len(_p_.runq)) { throw(\u0026#34;runqsteal: runq overflow\u0026#34;) } // 原子设置 _p_.runqtail = t+n atomic.StoreRel(\u0026amp;_p_.runqtail, t+n) // store-release, makes the item available for consumption return gp } runqgrab() 从_p_的可运行队列中获取一批goroutines到batch。 Batch是一个从batchHead开始的环形缓冲区。 返回抓取的goroutines的数量。可以被任意P执行。 参数：假设从p2偷取到p。 _p_ *p：偷取目标的P。就是p2. batch *[256]guintptr：从_p_偷取goroutine需要放到的P的runq本地队列池。就是p的本地runq池。 batchHead uint32：p的runqtail处。 stealRunNextG bool：是否近最大努力去runnext上偷取。 返回值：uint32：偷取goroutine的数量。 文件位置：go1.19.3/src/runtime/proc.go。 5959 5960 5961 5962 5963 5964 5965 5966 5967 5968 5969 5970 5971 5972 5973 5974 5975 5976 5977 5978 5979 5980 5981 5982 5983 5984 5985 5986 5987 5988 5989 5990 5991 5992 5993 5994 5995 5996 5997 5998 5999 6000 6001 6002 6003 6004 6005 6006 6007 6008 6009 6010 6011 6012 6013 6014 6015 6016 6017 6018 6019 6020 6021 6022 6023 6024 6025 6026 6027 6028 6029 6030 6031 6032 6033 6034 6035 6036 6037 6038 6039 6040 6041 6042 6043 6044 6045 6046 6047 6048 // Grabs a batch of goroutines from _p_\u0026#39;s runnable queue into batch. // Batch is a ring buffer starting at batchHead. // Returns number of grabbed goroutines. // Can be executed by any P. func runqgrab(_p_ *p, batch *[256]guintptr, batchHead uint32, stealRunNextG bool) uint32 { // 偷取goroutine的代码采用的是自旋方式，而没有采用锁来实现。 for { // _p_ 是 p2，之所以需要原子读取因为p2正在运行有并发的可能。 h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with other consumers t := atomic.LoadAcq(\u0026amp;_p_.runqtail) // load-acquire, synchronize with the producer // 为什么不担心 runqtail 溢出？ // 因为，runqtail和runqhead都是uint32类型，就算溢出也能保证计算正确。比如 0 - 3 也能得到正确值 n := t - h n = n - n/2 // 计算偷取的数量，为当前容量的一半。 // p2 中本地runq池中没有goroutine。 if n == 0 { // p2本地runq池为空，尝试去 runnext 获取goroutine。 if stealRunNextG { // Try to steal from _p_.runnext. // // 尝试从 _p_.runnext 中偷取。 if next := _p_.runnext; next != 0 { // _p_.runnext 上有goroutine。 if _p_.status == _Prunning { // 当前P正在运行中 // Sleep to ensure that _p_ isn\u0026#39;t about to run the g // we are about to steal. // The important use case here is when the g running // on _p_ ready()s another g and then almost // immediately blocks. Instead of stealing runnext // in this window, back off to give _p_ a chance to // schedule runnext. This will avoid thrashing gs // between different Ps. // A sync chan send/recv takes ~50ns as of time of // writing, so 3us gives ~50x overshoot. // // Sleep 已确保 _p_ 不会运行我们将要切取的g。 // 这里的重要用例是当 g 在 _p_ ready() 上运行时，另一个 g 然后几乎立即阻塞。 // 不要在这个窗口期切取 runnext，而是退而求其次，让_p_有机会调度runnext。 // 这将避免g在不同的Ps之间的抖动。 // sync chan 的 send/recv 大约需要 ~50ns，所以给出 3us 大约是它的 50x 倍。 if GOOS != \u0026#34;windows\u0026#34; \u0026amp;\u0026amp; GOOS != \u0026#34;openbsd\u0026#34; \u0026amp;\u0026amp; GOOS != \u0026#34;netbsd\u0026#34; { usleep(3) // sleep 3us } else { // On some platforms system timer granularity is // 1-15ms, which is way too much for this // optimization. So just yield. // // 在某些平台上，系统计时器粒度为1-15ms，这对于这种优化来说太过了。所以就屈服吧。 osyield() // 在semaphore中有相关的介绍。会尝试让出CPU，让其他优先级更高的线程执行。 } } // CAS 操作交换 _p_.runnext 尝试偷取 goroutine。 // 大概率会失败从这里直接退出。 if !_p_.runnext.cas(next, 0) { continue } // 偷取到goroutine把它放入P的本地runq池。 batch[batchHead%uint32(len(batch))] = next return 1 } } return 0 } // 读取不一致的 h 和 t 值。 // 小细节：按理说队列中的goroutine个数最多就是len(_p_.runq)，所以n的最大值也就是len(_p_.runq)/2， // 那为什么需要这个判断呢？ // 原因：读取runqhead和runqtail是两个操作而非一个原子操作，当我们读取runqhead之后但还未读取runqtail之前， // 如果有其它线程快速的在增加（这是完全有可能的，其它偷取者从队列中偷取goroutine会增加runqhead， // 而队列的所有者往队列中添加goroutine会 增加runqtail）这两个值，则会导致我们读取出来的runqtail已经远远大于 // 我们之前读取出来放在局部变量h里面的runqhead了。 // 也就是代码注释中所说的h和t已经不一致了，所以这里需要这个if判断来检测异常情况。 // 如果 n \u0026gt; uint32(len(_p_.runq)/2) 成立说明在t := atomic.LoadAcq(\u0026amp;_p_.runqtail)代码后runqtail发生了变化。 if n \u0026gt; uint32(len(_p_.runq)/2) { // read inconsistent h and t continue } // 从p2中拷贝goroutine到p的runq本地池 for i := uint32(0); i \u0026lt; n; i++ { g := _p_.runq[(h+i)%uint32(len(_p_.runq))] // 从p2的h处往后取goroutine batch[(batchHead+i)%uint32(len(batch))] = g// 从p.runqtail往后最加 } // CAS 原子交换 p2.runqhead 从 h 修改为 h+n，如果失败说明h被修改了 // 1. 可能其他P也在偷取这个P的goroutine并且偷取成功了。 // 2. 当前被偷取的这个P可能也在取runqhead出的goroutine来运行。导致runqhead变化。 // 为什么不担心 runqtail 的值呢？而是只需要保证 runqhead 和 runqtail 一起是原子的呢？ // 因为，runqtail 只有当前P正最加，并且是递增的，能保证我们要去的数据n。 if atomic.CasRel(\u0026amp;_p_.runqhead, h, h+n) { // cas-release, commits consume return n } } } type randomOrder struct stealOrder用来实现一个公平的随机窃取顺序。 文件位置：go1.19.3/src/runtime/proc.go。 // 关于取P得算法 var stealOrder randomOrder // randomOrder/randomEnum are helper types for randomized work stealing. // They allow to enumerate all Ps in different pseudo-random orders without repetitions. // The algorithm is based on the fact that if we have X such that X and GOMAXPROCS // are coprime, then a sequences of (i + X) % GOMAXPROCS gives the required enumeration. // // randomOrder/randomEnum 是随机工作窃取的辅助类型 // 它们允许以不同的伪随机顺序枚举所有 P 而不重复 // 该算法基于这样一个事实： // 如果我们有 X 使得 X 和 GOMAXPROCS 互质，那么 (i + X) %GOMAXPROCS 的序列给出所需的枚举 type randomOrder struct { count uint32 // 存储当前所有的P数量，也是CPU的核数 coprimes []uint32 // 存储与count互质数集 } type randomEnum struct { i uint32 // 从0开始记录遍历的次数 count uint32 // randomOrder.count pos uint32 // 当前在[0, count-1]范围的下标位置 inc uint32 // 当前在randomOrder.coprimes中选取的值 } // 重置randomOrder func (ord *randomOrder) reset(count uint32) { ord.count = count\t// 记录总个数 ord.coprimes = ord.coprimes[:0] // 清空coprimes for i := uint32(1); i \u0026lt;= count; i++ { if gcd(i, count) == 1 { ord.coprimes = append(ord.coprimes, i) } } } // 生成互质数函数 func gcd(a, b uint32) uint32 { for b != 0 { a, b = b, a%b } return a } // 开始 func (ord *randomOrder) start(i uint32) randomEnum { return randomEnum{ count: ord.count, pos: i % ord.count, inc: ord.coprimes[i%uint32(len(ord.coprimes))], } } // 当前是否遍历一圈了 func (enum *randomEnum) done() bool { return enum.i == enum.count } // 下一个互质数 func (enum *randomEnum) next() { enum.i++ enum.pos = (enum.pos + enum.inc) % enum.count\t// 这里是随机的选取下一个随机处 } // 获取当前位置 func (enum *randomEnum) position() uint32 { return enum.pos } // 盗取算法解释 // 1. 盗取过程用了两个嵌套for循环。 // 2. 内层循环实现了盗取逻辑，从代码可以看出盗取的实质就是遍历allp中的所有p，查看其运行队列是否有goroutine，如果有， // 则取其一半到当前工作线程的运行队列，然后从findrunnable返回，如果没有则继续遍历下一个p // 3. 但这里为了保证公平性，遍历allp时并不是固定的从allp[0]即第一个p开始，而是从随机位置上的p开始， // 而且遍历的顺序也随机化了，并不是现在访问了第i个p下一次就访问第i+1个p， // 而是使用了一种伪随机的方式遍历allp中的每个p，防止每次遍历时使用同样的顺序访问allp中的元素 // 下面是这个算法的伪代码： // offset := uint32(random()) % nprocs // coprime := 随机选取一个小于nprocs且与nprocs互质的数 // for i := 0; i \u0026lt; nprocs; i++ { // p := allp[offset] // 从p的运行队列偷取goroutine // if 偷取成功 { // break // } // offset += coprime // offset = offset % nprocs // } // // 下面举例说明一下上述算法过程，现假设nprocs为8，也就是一共有8个p // 如果第一次随机选择的offset = 6，coprime = 3(3与8互质，满足算法要求)的话，则从allp切片中偷取的下标顺序为 // 6, 1, 4, 7, 2, 5, 0, 3，计算过程： // 6，(6+3)%8=1，(1+3)%8=4, (4+3)%8=7, (7+3)%8=2, (2+3)%8=5, (5+3)%8=0, (0+3)%8=3 // 如果第二次随机选择的offset = 4，coprime = 5的话，则从allp切片中偷取的下标顺序为 // 1, 6, 3, 0, 5, 2, 7, 4，计算过程： // 1，(1+5)%8=6，(6+5)%8=3, (3+5)%8=0, (0+5)%8=5, (5+5)%8=2, (2+5)%8=7, (7+5)%8=4 releasep() 解除当前M和P的绑定关系。 文件位置：go1.19.3/src/runtime/proc.go。 4984 4985 4986 4987 4988 4989 4990 4991 4992 4993 4994 4995 4996 4997 4998 4999 5000 5001 5002 5003 5004 5005 5006 5007 5008 5009 5010 // Disassociate p and the current m. func releasep() *p { _g_ := getg() // 获取当前运行的g，这里是g0 if _g_.m.p == 0 { // 当前要解绑的P不存在，系统代码有逻辑问题 throw(\u0026#34;releasep: invalid arg\u0026#34;) } _p_ := _g_.m.p.ptr() // 获取当前工作线程M绑定的P，也就是需要解绑的P // _Prunning 表示 P 由 M 拥有并用于运行用户代码或调度程序 // 只有拥有这个 P 的 M 才允许从 _Prunning 更改 P 的状态 // M 可以将 P 转换为 _Pidle（如果它没有更多工作要做）、_Psyscall（当进入系统调用时）或 _Pgcstop（停止 GC） // M 也可以将 P 的所有权直接交给另一个 M（例如，安排锁定的 G） if _p_.m.ptr() != _g_.m || _p_.status != _Prunning { // 当前P绑定的m与g绑定的m不是同一个 或 当前P不是_Prunning状态 print(\u0026#34;releasep: m=\u0026#34;, _g_.m, \u0026#34; m-\u0026gt;p=\u0026#34;, _g_.m.p.ptr(), \u0026#34; p-\u0026gt;m=\u0026#34;, hex(_p_.m), \u0026#34; p-\u0026gt;status=\u0026#34;, _p_.status, \u0026#34;\\n\u0026#34;) throw(\u0026#34;releasep: invalid p state\u0026#34;) } if trace.enabled { traceProcStop(_g_.m.p.ptr()) } _g_.m.p = 0\t// 解绑工作线程M与P的关联 _p_.m = 0\t// 解绑P与M的关联 // _Pidle 表示 P 未用于运行用户代码或调度程序 // 通常，它位于空闲 P 列表中并且可供调度程序使用，但它可能只是在其他状态之间转换 // P 由空闲列表或正在转换其状态的任何东西拥有。 它的运行队列是空的 _p_.status = _Pidle return _p_\t// 返回当前P } pidleput() pidleput 将p放到_Pidle列表中。 这释放了p的所有权。一旦sched.lock被释放，使用p就不再安全了。 sched.lock必须被持有，可以在STW期间运行，因此不允许写入屏障。 文件位置：go1.19.3/src/runtime/proc.go。 5696 5697 5698 5699 5700 5701 5702 5703 5704 5705 5706 5707 5708 5709 5710 5711 5712 5713 5714 5715 5716 5717 5718 5719 // pidleput puts p to on the _Pidle list. // // This releases ownership of p. Once sched.lock is released it is no longer // safe to use p. // // sched.lock must be held. // // May run during STW, so write barriers are not allowed. //go:nowritebarrierrec func pidleput(_p_ *p) { assertLockHeld(\u0026amp;sched.lock) // 判断P的本地队列不应该还有goroutine，判断下 if !runqempty(_p_) { throw(\u0026#34;pidleput: P has non-empty run queue\u0026#34;) } // 如果P没有timer，将清除timerpMask位上对应的掩码位，timerpMask是记录忙碌的 updateTimerPMask(_p_) // clear if there are no timers. idlepMask.set(_p_.id) // 设置idlepMask对应的P的掩码位，idlepMask是记录空闲的 _p_.link = sched.pidle // 当前P记录全局的空闲链表 sched.pidle.set(_p_) // 把当前P链接到全局空闲链表后 // 使用原子锁把当前sched空闲的P数量加1 atomic.Xadd(\u0026amp;sched.npidle, 1) // TODO: fast atomic } runqempty() runqempty 报告_p_在其本地运行队列中是否没有 Gs。 它永远不会虚假地返回true。 文件位置：go1.19.3/src/runtime/proc.go。 5752 5753 5754 5755 5756 5757 5758 5759 5760 5761 5762 5763 5764 5765 5766 5767 5768 5769 5770 5771 5772 5773 // runqempty reports whether _p_ has no Gs on its local run queue. // It never returns true spuriously. func runqempty(_p_ *p) bool { // Defend against a race where 1) _p_ has G1 in runqnext but runqhead == runqtail, // 2) runqput on _p_ kicks G1 to the runq, 3) runqget on _p_ empties runqnext. // Simply observing that runqhead == runqtail and then observing that runqnext == nil // does not mean the queue is empty. // // 以下情况： // 1. _p_ 在 runqnext 中有 G1 但 runqhead == runqtail // 2. _p_ 上的 runqput 将 G1 踢到 runq // 3. _p_ 上的 runqget 清空 runqnext // 简单地观察 runqhead == runqtail 然后观察 runqnext == nil 并不意味着队列是空的 for { head := atomic.Load(\u0026amp;_p_.runqhead)\ttail := atomic.Load(\u0026amp;_p_.runqtail) runnext := atomic.Loaduintptr((*uintptr)(unsafe.Pointer(\u0026amp;_p_.runnext))) if tail == atomic.Load(\u0026amp;_p_.runqtail) { return head == tail \u0026amp;\u0026amp; runnext == 0 } } } pidleget() 相关联函数pidleget从空闲列表中获取一个P。 文件位置：go1.19.3/src/runtime/proc.go。 5727 5728 5729 5730 5731 5732 5733 5734 5735 5736 5737 5738 5739 5740 5741 5742 5743 5744 5745 5746 5747 5748 5749 5750 // pidleget tries to get a p from the _Pidle list, acquiring ownership. // // sched.lock must be held. // // May run during STW, so write barriers are not allowed. // //go:nowritebarrierrec func pidleget(now int64) (*p, int64) { assertLockHeld(\u0026amp;sched.lock) _p_ := sched.pidle.ptr() if _p_ != nil { // Timer may get added at any time now. if now == 0 { now = nanotime() } timerpMask.set(_p_.id) idlepMask.clear(_p_.id) sched.pidle = _p_.link atomic.Xadd(\u0026amp;sched.npidle, -1) _p_.limiterEvent.stop(limiterEventIdle, now) } return _p_, now } checkRunqsNoP() 检查快照中所有的P是否有可以偷取的G。 文件位置：go1.19.3/src/runtime/proc.go。 2974 2975 2976 2977 2978 2979 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 2998 2999 // Check all Ps for a runnable G to steal. // // On entry we have no P. If a G is available to steal and a P is available, // the P is returned which the caller should acquire and attempt to steal the // work to. func checkRunqsNoP(allpSnapshot []*p, idlepMaskSnapshot pMask) *p { // 变量allp的快照，allp记录了所有的P列表 for id, p2 := range allpSnapshot {\t// 休眠之前在看一下是否有工作要做 // idlepMaskSnapshot 快照记录着当前P的状态 // !idlepMaskSnapshot.read(uint32(id)) 当前P状态不为空的 并且 当前P存储groutine的 if !idlepMaskSnapshot.read(uint32(id)) \u0026amp;\u0026amp; !runqempty(p2) { lock(\u0026amp;sched.lock) pp := pidleget()\t// 从空闲的P中拿去一个P，为后续M绑定P做准备，因为有全局的P存在g可以起去拿来用 unlock(\u0026amp;sched.lock) if pp != nil { return pp } // Can\u0026#39;t get a P, don\u0026#39;t bother checking remaining Ps. // 拿不到P，别费心检查剩余的P break } } return nil } checkIdleGCNoP() 检查是否有GC需要帮助。 文件位置：go1.19.3/src/runtime/proc.go。 3013 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023 3024 3025 3026 3027 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069 3070 3071 3072 3073 // Check for idle-priority GC, without a P on entry. // // If some GC work, a P, and a worker G are all available, the P and G will be // returned. The returned P has not been wired yet. func checkIdleGCNoP() (*p, *g) { // N.B. Since we have no P, gcBlackenEnabled may change at any time; we // must check again after acquiring a P. As an optimization, we also check // if an idle mark worker is needed at all. This is OK here, because if we // observe that one isn\u0026#39;t needed, at least one is currently running. Even if // it stops running, its own journey into the scheduler should schedule it // again, if need be (at which point, this check will pass, if relevant). if atomic.Load(\u0026amp;gcBlackenEnabled) == 0 || !gcController.needIdleMarkWorker() { return nil, nil } if !gcMarkWorkAvailable(nil) { return nil, nil } // Work is available; we can start an idle GC worker only if there is // an available P and available worker G. // // We can attempt to acquire these in either order, though both have // synchronization concerns (see below). Workers are almost always // available (see comment in findRunnableGCWorker for the one case // there may be none). Since we\u0026#39;re slightly less likely to find a P, // check for that first. // // Synchronization: note that we must hold sched.lock until we are // committed to keeping it. Otherwise we cannot put the unnecessary P // back in sched.pidle without performing the full set of idle // transition checks. // // If we were to check gcBgMarkWorkerPool first, we must somehow handle // the assumption in gcControllerState.findRunnableGCWorker that an // empty gcBgMarkWorkerPool is only possible if gcMarkDone is running. lock(\u0026amp;sched.lock) pp, now := pidlegetSpinning(0) if pp == nil { unlock(\u0026amp;sched.lock) return nil, nil } // Now that we own a P, gcBlackenEnabled can\u0026#39;t change (as it requires STW). if gcBlackenEnabled == 0 || !gcController.addIdleMarkWorker() { pidleput(pp, now) unlock(\u0026amp;sched.lock) return nil, nil } node := (*gcBgMarkWorkerNode)(gcBgMarkWorkerPool.pop()) if node == nil { pidleput(pp, now) unlock(\u0026amp;sched.lock) gcController.removeIdleMarkWorker() return nil, nil } unlock(\u0026amp;sched.lock) return pp, node.gp.ptr() } checkTimersNoP() 检查快照中所有的P是否有timer要触发了。 文件位置：go1.19.3/src/runtime/proc.go。 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 // Check all Ps for a timer expiring sooner than pollUntil. // // Returns updated pollUntil value. func checkTimersNoP(allpSnapshot []*p, timerpMaskSnapshot pMask, pollUntil int64) int64 { for id, p2 := range allpSnapshot { if timerpMaskSnapshot.read(uint32(id)) { w := nobarrierWakeTime(p2) if w != 0 \u0026amp;\u0026amp; (pollUntil == 0 || w \u0026lt; pollUntil) { pollUntil = w } } } return pollUntil } stopm() 工作线程进入休眠，等待被其他工作线程唤醒。 文件位置：go1.19.3/src/runtime/proc.go。 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 // Stops execution of the current m until new work is available. // Returns with acquired P. func stopm() { _g_ := getg() // 获取当前工作线程M绑定的g if _g_.m.locks != 0 { // 判断当前工作线程是否有锁为解锁 throw(\u0026#34;stopm holding locks\u0026#34;) } if _g_.m.p != 0 { // 判断当前工作线程是否还绑定了P，因为前面M与P已经解绑了 throw(\u0026#34;stopm holding p\u0026#34;) } if _g_.m.spinning { // 判断当前工作线程是否还处于自旋状态标记，应为前面已经取消了该标记 throw(\u0026#34;stopm spinning\u0026#34;) } lock(\u0026amp;sched.lock) // 锁住全局sched mput(_g_.m) // 把m结构体对象放入sched.midle空闲队列 unlock(\u0026amp;sched.lock) // 解锁 mPark() // 进入系统调用进入睡眠 acquirep(_g_.m.nextp.ptr()) // 工作线程被唤醒后从这里开始执行，给M绑定P _g_.m.nextp = 0 } mput() 当工作线程空闲时即将进入休眠状态时会判断一次checkdead()。 文件位置：go1.19.3/src/runtime/proc.go。 5533 5534 5535 5536 5537 5538 5539 5540 5541 5542 5543 5544 5545 5546 5547 // Put mp on midle list. // sched.lock must be held. // May run during STW, so write barriers are not allowed. //go:nowritebarrierrec func mput(mp *m) { assertLockHeld(\u0026amp;sched.lock) // 检查sched.lock锁 mp.schedlink = sched.midle // 当前M记录全局空闲M链表 sched.midle.set(mp) // 把当前M追加到全局空闲链表中去 sched.nmidle++ // 全局空闲M数量加一 // 检查死锁情况 // 检查基于运行 M 的数量，如果 0 -\u0026gt; 死锁 // sched.lock 必须被持有 checkdead() } mget() 文件位置：go1.19.3/src/runtime/proc.go。 5547 5548 5549 5550 5551 5552 5553 5554 5555 5556 5557 5558 5559 5560 // Try to get an m from midle list. // sched.lock must be held. // May run during STW, so write barriers are not allowed. //go:nowritebarrierrec func mget() *m { assertLockHeld(\u0026amp;sched.lock) mp := sched.midle.ptr() if mp != nil { sched.midle = mp.schedlink sched.nmidle-- } return mp } mPark() 睡眠函数，mPark()导致线程自行停放，一旦唤醒就返回。 stopm的核心是调用mput把m结构体对象放入sched的midle空闲队列，然后通过notesleep(\u0026amp;m.park)函数让自己进入睡眠状态。 note是go runtime实现的一次性睡眠和唤醒机制，一个线程可以通过调用notesleep(*note)进入睡眠状态，而另外一个线程则可以通过notewakeup(*note)把其唤醒。 note的底层实现机制跟操作系统相关，不同系统使用不同的机制： 比如linux下使用的futex系统调用。 而mac下则是使用的pthread_cond_t条件变量。 note对这些底层机制做了一个抽象和封装，这种封装给扩展性带来了很大的好处，比如当睡眠和唤醒功能需要支持新平台时，只需要在note层增加对特定平台的支持即可，不需要修改上层的任何代码。 回到stopm，当从notesleep函数返回后，需要再次绑定一个p，然后返回到findrunnable函数继续重新寻找可运行的goroutine，一旦找到可运行的goroutine就会返回到schedule函数，并把找到的goroutine调度起来运行，如何把goroutine调度起来运行的代码我们已经分析过了。 文件位置：go1.19.3/src/runtime/proc.go。 1452 1453 1454 1455 1456 1457 1458 // mPark causes a thread to park itself, returning once woken. //go:nosplit func mPark() { gp := getg() notesleep(\u0026amp;gp.m.park) // 进入休眠状态，这里传入M的park，睡眠在这个上面 noteclear(\u0026amp;gp.m.park) // 被其他工作线程唤醒，代码从这里开始执行 } notesleep() 实现休眠的函数。 notesleep函数调用futexsleep进入睡眠，这里之所以需要用一个循环，是因为futexsleep有可能意外从睡眠中返回，所以从futexsleep函数返回后还需要检查note.key是否还是0。 如果是0则表示并不是其它工作线程唤醒了我们，只是futexsleep意外返回了，需要再次调用futexsleep进入睡眠。 文件位置：go1.19.3/src/runtime/lock_futex.go。 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 func notesleep(n *note) { gp := getg() // 获取当前工作线程绑定的g，应该是g0在调度循环过程中被切换到g0了 if gp != gp.m.g0 { throw(\u0026#34;notesleep not on g0\u0026#34;) } ns := int64(-1) // 超时时间设置为-1，表示无限期等待 if *cgo_yield != nil { // Sleep for an arbitrary-but-moderate interval to poll libc interceptors. // 休眠一个任意但适中的间隔来轮询 libc 拦截器cgo相关的 ns = 10e6 } // 使用循环，保证不是意外被唤醒 for atomic.Load(key32(\u0026amp;n.key)) == 0 { gp.m.blocked = true // blocked表示M在当前的note上被屏蔽 futexsleep(key32(\u0026amp;n.key), 0, ns) // 进入休眠函数 if *cgo_yield != nil { asmcgocall(*cgo_yield, nil) } gp.m.blocked = false } } futexsleep() 原子的if(*addr == val)休眠，可能会被虚假唤醒； 这是允许的睡眠时间不要超过ns；ns \u0026lt; 0意味着永远。 文件位置：go1.19.3/src/runtime/os_linux.go。 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 // Atomically, //\tif(*addr == val) sleep // Might be woken up spuriously; that\u0026#39;s allowed. // Don\u0026#39;t sleep longer than ns; ns \u0026lt; 0 means forever. // //go:nosplit func futexsleep(addr *uint32, val uint32, ns int64) { // Some Linux kernels have a bug where futex of // FUTEX_WAIT returns an internal error code // as an errno. Libpthread ignores the return value // here, and so can we: as it says a few lines up, // spurious wakeups are allowed. // // 一些 Linux 内核存在一个错误，即 FUTEX_WAIT 的 futex 返回内部错误代码作为 errno // Libpthread 忽略了这里的返回值，我们也可以：正如它所说的几行，虚假唤醒是允许的 if ns \u0026lt; 0 {\t// 永久睡眠 futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, nil, nil, 0) return } var ts timespec ts.setNsec(ns) // 设置时间 futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, unsafe.Pointer(\u0026amp;ts), nil, 0) } futex() 函数原型：func futex(addr unsafe.Pointer, op int32, val uint32, ts, addr2 unsafe.Pointer, val3 uint32) int32由汇编实现。 futex系统调用为我们提供的功能为如果*addr == val则进入睡眠，否则直接返回。 文件位置：go1.19.3/src/runtime/sys_linux_amd64.s。 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 # int64 futex(int32 *uaddr, int32 op, int32 val, #\tstruct timespec *timeout, int32 *uaddr2, int32 val2); TEXT runtime·futex(SB),NOSPLIT,$0 # 下面的6条指令在为futex系统调用准备参数 MOVQ addr+0(FP), DI MOVL op+8(FP), SI MOVL val+12(FP), DX MOVQ ts+16(FP), R10 MOVQ addr2+24(FP), R8 MOVL val3+32(FP), R9 MOVL $SYS_futex, AX # 系统调用编号放入AX寄存器 SYSCALL # 执行futex系统调用进入睡眠，从睡眠中被唤醒后接着执行下一条MOVL指令 MOVL AX, ret+40(FP) # 保存系统调用的返回值 RET execute() 🚀 gp放到当前M上取运行。该函数从g0栈切换到普通goroutine栈上。 如果inheritTime为true，则gp将继承当前时间片中的剩余时间。否则，它将启动一个新的时间片。永远不返回。 写屏障是允许的，因为这是在几个地方获得P后立即调用的。 参数： gp *g：当前调度的goroutine。 inheritTime bool：true.继承当前时间片，false.不继承当前时间片。 文件位置：go1.19.3/src/runtime/proc.go。 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 // Schedules gp to run on the current M. // If inheritTime is true, gp inherits the remaining time in the // current time slice. Otherwise, it starts a new time slice. // Never returns. // // Write barriers are allowed because this is called immediately after // acquiring a P in several places. // //go:yeswritebarrierrec func execute(gp *g, inheritTime bool) { // 当前是在系统g0栈 _g_ := getg() // _g_ = g0 if goroutineProfile.active { // Make sure that gp has had its stack written out to the goroutine // profile, exactly as it was when the goroutine profiler first stopped // the world. tryRecordGoroutineProfile(gp, osyield) } // Assign gp.m before entering _Grunning so running Gs have an // M. // // 在输入_Grunning之前指定gp.m，以便运行Gs具有m。 _g_.m.curg = gp // m.curg = gp gp.m = _g_.m // gp.m = m // _Grunnable：它当前没有执行用户代码。 // _Grunning：表示这个goroutine可以执行用户代码。 casgstatus(gp, _Grunnable, _Grunning) // 修改当前g的状态为运行中 gp.waitsince = 0 // 设置g被阻塞的大约时间 // 抢占信号，重复stackguard0 = stackpreempt gp.preempt = false // const _StackGuard = 928; // 设置当前g栈扩容阈值点。 gp.stackguard0 = gp.stack.lo + _StackGuard // 是否继承当前时间片。具体的抢占在sysmon监控线程中。 if !inheritTime { // 不继承上一个时间片时，调度次数会加一 _g_.m.p.ptr().schedtick++ // 调度次数加一 } // Check whether the profiler needs to be turned on or off. // // 检查分析器是否需要打开或关闭 hz := sched.profilehz // sched.profilehz：用来设置性能分析的采样频率。 if _g_.m.profilehz != hz { setThreadCPUProfiler(hz) } if trace.enabled { // GoSysExit has to happen when we have a P, but before GoStart. // So we emit it here. if gp.syscallsp != 0 \u0026amp;\u0026amp; gp.sysblocktraced { traceGoSysExit(gp.sysexitticks) } traceGoStart() } // gogo完成从g0到gp真正的切换 gogo(\u0026amp;gp.sched) } gogo() gogo()函数完成从g0到gp的的切换：CPU执行权的转让以及栈的切换。 函数原型：func gogo(buf *gobuf)。 参数buf *gobuf：需要切换的goroutine的调度信息。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 # func gogo(buf *gobuf) # restore state from Gobuf; longjmp TEXT runtime·gogo(SB), NOSPLIT, $0-8 # 1) 取出gobuf信息，里面包含需要调度的信息 # 取出需要调度的goroutine，gp.sched.g，判断这个goroutine不为nil # execute函数在调用gogo时把gp的sched成员的地址作为实参（型参buf）传递了过来 # 该参数位于FP寄存器所指的位置，所以第一条指令是获取参数 # buf = \u0026amp;gp.sched; BX = *gobuf MOVQ buf+0(FP), BX # *gobuf # 把buf的值也就是gp.sched的地址放在了BX寄存器之中 # 这样便于后面的指令依靠BX寄存器来存取gp.sched的成员 # 注意这里是间接寻址方式 # gobuf-\u0026gt;g --\u0026gt; dx register MOVQ gobuf_g(BX), DX\t# DX = gp.sched.g; *g # 下面这行代码没有实质作用，检查gp.sched.g是否是nil，如果是nil进程会crash死掉 # 如果DX为空使用0(DX)形式简介寻址会报错。确保 g 不是 nil。 MOVQ 0(DX), CX # make sure g != nil # 2) 使用JMP指令跳转到gogo函数 JMP gogo\u0026lt;\u0026gt;(SB) # 注意这里使用的是JMP 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 TEXT gogo\u0026lt;\u0026gt;(SB), NOSPLIT, $0 # 3) 把gp放入TLS中和R14寄存器中 # 获取当前工作线程M的fs段基址，前面把fs段基址设置成了\u0026amp;m.tls[1]的地址 get_tls(CX) # CX = \u0026amp;m.tls[1] = TLS # 把DX值也就是需要运行的goroutine的指针写入线程本地存储之中 # 运行这条指令之前，线程本地存储存放的是g0的地址 MOVQ DX, g(CX) # TLS = gp.sched.g # 在g1.17和1.18版本中 R14寄存器被用来指向当前goroutine的runtime.g结构 # R14 = gp.sched.g MOVQ DX, R14 # set the g register # 4) 设置栈顶SP寄存器，切gp的栈，切换栈 # 把CPU的SP寄存器设置为sched.sp，完成了栈的切换，gp.sched.sp记录着g的栈顶位置 # 设置CPU的栈顶寄存器SP为gp.sched.sp，这条指令完成了栈的切换，从g0的栈切换到了gp的栈 # rsp = gp.sched.sp MOVQ gobuf_sp(BX), SP # restore SP # 5) 设置 AX = gp.sched.ret # 设置 DX = gp.sched.ctxt 闭包上下文 # 设置 BP = BP = gp.sched.bp 栈底寄存器 # 下面三条同样是恢复调度上下文到CPU相关寄存器 # 需要返回的地址 MOVQ gobuf_ret(BX), AX # AX = gp.sched.ret\t# 上下文环境，也就是当前注册函数的闭包捕获层，funcval地址处 MOVQ gobuf_ctxt(BX), DX # DX = gp.sched.ctxt\t# 设置栈基地址 MOVQ gobuf_bp(BX), BP # BP = gp.sched.bp\t# 6) 清空gp的gobuf.sp、gobuf.ret、gobuf.ctxt、gobuf.bp # 清空gp.sched中不再需要的值，因为我们已把相关值放入CPU对应的寄存器了 # clear to help garbage collector MOVQ $0, gobuf_sp(BX) # g.gobuf.sp = 0 MOVQ $0, gobuf_ret(BX) # g.gobuf.ret = 0 MOVQ $0, gobuf_ctxt(BX) # g.gobuf.ctxt = 0 MOVQ $0, gobuf_bp(BX) # g.gobuf.bp = 0 # 7) 跳转到g.gobuf.pc执行gp的相关代码 # 注意：从g0切换的gp过程中，并没有保存g0的相关栈信息 # gp.sched.pc 记录着注册函数开始的代码地址 # 把gp.sched.pc的值读取到BX寄存器，这个pc值是gp这个goroutine马上需要执行的第一条指令的地址 # 对于runtime.main这个场景来说它现在就是runtime.main函数的第一条指令，现在这条指令的地址就放在BX寄存器里面 # DX寄存器作为上下文，记录着闭包函数的相关捕获变量 MOVQ gobuf_pc(BX), BX # BX = g.gobuf.pc # 这里的JMP BX指令把BX寄存器里面的指令地址放入CPU的rip寄存器 # 于是，CPU就会跳转到该地址继续执行属于gp这个goroutine的代码，这样就完成了goroutine的切换 # 还需要注意的是：DX寄存器的值 gp.sched.ctxt 存储的是闭包的上下文信息，如果闭包捕获了变量则会使用它。 JMP BX # 跳转到注册的goroutine去执行了 总结： execute()函数完成从系统栈g0切换到普通goroutine的过程（这里是参数gp）。 该函数将工作线程m与gp相互绑定，然后切换gp的状态并设置栈溢出相关参数，以及设置调度次数， 接着调用gogo()函数把栈从g0切换成gp的栈，并把gp的调度信息保存在相关寄存器中，然后切换到gp开始执行相关代码。 这里需要注意的是，从g0切换到gp过程中并没有保存g0的相关栈顶SP相关信息，因此g0栈总是从一个固定的开始的位置开始的。 其他相关函数 checkTimers() 该函数是唤醒time.Sleep、time.Timer等的相关函数，查看runtime.timer文档。 文件位置：go1.19.3/src/runtime/proc.go。 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335 3336 3337 3338 3339 3340 3341 3342 3343 3344 // checkTimers runs any timers for the P that are ready. // If now is not 0 it is the current time. // It returns the passed time or the current time if now was passed as 0. // and the time when the next timer should run or 0 if there is no next timer, // and reports whether it ran any timers. // If the time when the next timer should run is not 0, // it is always larger than the returned time. // We pass now in and out to avoid extra calls of nanotime. // //go:yeswritebarrierrec func checkTimers(pp *p, now int64) (rnow, pollUntil int64, ran bool) { // If it\u0026#39;s not yet time for the first timer, or the first adjusted // timer, then there is nothing to do. next := int64(atomic.Load64(\u0026amp;pp.timer0When)) nextAdj := int64(atomic.Load64(\u0026amp;pp.timerModifiedEarliest)) if next == 0 || (nextAdj != 0 \u0026amp;\u0026amp; nextAdj \u0026lt; next) { next = nextAdj } if next == 0 { // No timers to run or adjust. // 无需运行或调整计时器 return now, 0, false } if now == 0 { now = nanotime() } if now \u0026lt; next { // Next timer is not ready to run, but keep going // if we would clear deleted timers. // This corresponds to the condition below where // we decide whether to call clearDeletedTimers. if pp != getg().m.p.ptr() || int(atomic.Load(\u0026amp;pp.deletedTimers)) \u0026lt;= int(atomic.Load(\u0026amp;pp.numTimers)/4) { return now, next, false } } lock(\u0026amp;pp.timersLock) // 如果当前P的timers存在数据 if len(pp.timers) \u0026gt; 0 {\t// pp.timers记录着当前P中所有相关的timer // adjusttimers 在当前 P 的堆中查找任何已修改为更早运行的定时器，并将它们放在堆中的正确位置 // 在查找这些计时器时，它还会移动已修改为稍后运行的计时器，并删除已删除的计时器 // 调用者必须锁定 pp 的计时器 adjusttimers(pp, now) for len(pp.timers) \u0026gt; 0 { // Note that runtimer may temporarily unlock // pp.timersLock. // 请注意，runtimer 可能会暂时解锁 pp.timersLock // runtimer函数 // runtimer 检查timers中的第一个timer。 如果它基于now准备好，它会运行timer并删除或更新它 // 如果它运行了一个timer，则返回 0，如果没有更多的timer，则返回 -1，或者第一个timer应该运行的时间 if tw := runtimer(pp, now); tw != 0 { if tw \u0026gt; 0 { pollUntil = tw } break } ran = true } } // If this is the local P, and there are a lot of deleted timers, // clear them out. We only do this for the local P to reduce // lock contention on timersLock. // 如果当前P是当前工作线程绑定的P，并且有很多被删除的timer，清除它们 // 我们只对本地 P 这样做，以减少 timersLock 上的锁争用 if pp == getg().m.p.ptr() \u0026amp;\u0026amp; int(atomic.Load(\u0026amp;pp.deletedTimers)) \u0026gt; len(pp.timers)/4 { clearDeletedTimers(pp) } unlock(\u0026amp;pp.timersLock) return now, pollUntil, ran } checkdead() 检查死锁情况。检查基于正在运行的M的数量，如果0 -\u0026gt; deadlock。 sched.lock必须被持有。 文件位置：go1.19.3/src/runtime/proc.go。 5017 5018 5019 5020 5021 5022 5023 5024 5025 5026 5027 5028 5029 5030 5031 5032 5033 5034 5035 5036 5037 5038 5039 5040 5041 5042 5043 5044 5045 5046 5047 5048 5049 5050 5051 5052 5053 5054 5055 5056 5057 5058 5059 5060 5061 5062 5063 5064 5065 5066 5067 5068 5069 5070 5071 5072 5073 5074 5075 5076 5077 5078 5079 5080 5081 5082 5083 5084 5085 5086 5087 5088 5089 5090 5091 5092 5093 5094 5095 5096 5097 5098 5099 5100 5101 5102 5103 5104 5105 5106 5107 5108 5109 5110 5111 5112 5113 5114 5115 5116 5117 5118 5119 5120 5121 5122 5123 5124 5125 5126 // Check for deadlock situation. // The check is based on number of running M\u0026#39;s, if 0 -\u0026gt; deadlock. // sched.lock must be held. func checkdead() { // sched.lock 必须被持有 assertLockHeld(\u0026amp;sched.lock) // For -buildmode=c-shared or -buildmode=c-archive it\u0026#39;s OK if // there are no running goroutines. The calling program is // assumed to be running. if islibrary || isarchive { return } // If we are dying because of a signal caught on an already idle thread, // freezetheworld will cause all running threads to block. // And runtime will essentially enter into deadlock state, // except that there is a thread that will call exit soon. if panicking.Load() \u0026gt; 0 { return } // If we are not running under cgo, but we have an extra M then account // for it. (It is possible to have an extra M on Windows without cgo to // accommodate callbacks created by syscall.NewCallback. See issue #6751 // for details.) var run0 int32 if !iscgo \u0026amp;\u0026amp; cgoHasExtraM { mp := lockextra(true) haveExtraM := extraMCount \u0026gt; 0 unlockextra(mp) if haveExtraM { run0 = 1 } } //func mcount() int32 { // return int32(sched.mnext - sched.nmfreed) //} run := mcount() - sched.nmidle - sched.nmidlelocked - sched.nmsys if run \u0026gt; run0 { return } if run \u0026lt; 0 { print(\u0026#34;runtime: checkdead: nmidle=\u0026#34;, sched.nmidle, \u0026#34; nmidlelocked=\u0026#34;, sched.nmidlelocked, \u0026#34; mcount=\u0026#34;, mcount(), \u0026#34; nmsys=\u0026#34;, sched.nmsys, \u0026#34;\\n\u0026#34;) throw(\u0026#34;checkdead: inconsistent counts\u0026#34;) } grunning := 0 forEachG(func(gp *g) { if isSystemGoroutine(gp, false) { return } s := readgstatus(gp) switch s \u0026amp;^ _Gscan { case _Gwaiting, _Gpreempted: grunning++ case _Grunnable, _Grunning, _Gsyscall: print(\u0026#34;runtime: checkdead: find g \u0026#34;, gp.goid, \u0026#34; in status \u0026#34;, s, \u0026#34;\\n\u0026#34;) throw(\u0026#34;checkdead: runnable g\u0026#34;) } }) if grunning == 0 { // possible if main goroutine calls runtime·Goexit() unlock(\u0026amp;sched.lock) // unlock so that GODEBUG=scheddetail=1 doesn\u0026#39;t hang fatal(\u0026#34;no goroutines (main called runtime.Goexit) - deadlock!\u0026#34;) } // Maybe jump time forward for playground. if faketime != 0 { if when := timeSleepUntil(); when \u0026lt; maxWhen { faketime = when // Start an M to steal the timer. pp, _ := pidleget(faketime) if pp == nil { // There should always be a free P since // nothing is running. throw(\u0026#34;checkdead: no p for timer\u0026#34;) } mp := mget() if mp == nil { // There should always be a free M since // nothing is running. throw(\u0026#34;checkdead: no m for timer\u0026#34;) } // M must be spinning to steal. We set this to be // explicit, but since this is the only M it would // become spinning on its own anyways. sched.nmspinning.Add(1) mp.spinning = true mp.nextp.set(pp) notewakeup(\u0026amp;mp.park) return } } // There are no goroutines running, so we can look at the P\u0026#39;s. for _, pp := range allp { // 当某个P中存在timer，即使全部P都睡眠了也不会报错 if len(pp.timers) \u0026gt; 0 { return } } unlock(\u0026amp;sched.lock) // unlock so that GODEBUG=scheddetail=1 doesn\u0026#39;t hang fatal(\u0026#34;all goroutines are asleep - deadlock!\u0026#34;) } ","permalink":"https://heliu.site/posts/golang/goroutine/mstart/","summary":"Golang GMP调度模型介绍。","title":"GMP 调度模型"},{"content":"runtime.main 监控线程在runtime.main中被创建。 func main() { // ... if GOARCH != \u0026#34;wasm\u0026#34; { // no threads on wasm yet, so no sysmon // systemstack()函数切换到g0栈去运行闭包函数 systemstack(func() { // newm新创建一个线程，从sysmon入口函数开始执行 newm(sysmon, nil, -1) // 监控线程sysmon不需要P就能运行 }) } // ... } variables // forcegcperiod is the maximum time in nanoseconds between garbage // collections. If we go this long without a garbage collection, one // is forced to run. // // This is a variable for testing purposes. It normally doesn\u0026#39;t change. // // forceegcperiod是两次垃圾回收之间的最大时间，单位为纳秒。 // 如果这么长时间都没有垃圾收集，那么垃圾收集将被迫运行。 // 这是一个用于测试的变量。它通常不会改变。 var forcegcperiod int64 = 2 * 60 * 1e9 // 2min sysmon() 前面创建监控线程可以看出，监控线程是没有绑定P的。 这个监控线程是一个独立的线程，无需P即可运行，sysmon每20us ~ 10ms运行一次。 timer在每次调度器调度和窃取其他g的时候触发，这种具有一定的随机性和不确定性，系统监控线程触发依然是一个兜底保障。 监控线程主要职责： 最长10ms间隔执行一次网络轮询（保证I/O轮询）。因为netpoll是随机的，不是定时间段的。 抢占超过时间片的G。 超过预定时间，发起一轮GC。 总是在没有P的情况下运行，因此不允许写屏障。 文件位置：go1.19.3/src/runtime/proc.go。 5131 5132 5133 5134 5135 5136 5137 5138 5139 5140 5141 5142 5143 5144 5145 5146 5147 5148 5149 5150 5151 5152 5153 5154 5155 5156 5157 5158 5159 5160 5161 5162 5163 5164 5165 5166 5167 5168 5169 5170 5171 5172 5173 5174 5175 5176 5177 5178 5179 5180 5181 5182 5183 5184 5185 5186 5187 5188 5189 5190 5191 5192 5193 5194 5195 5196 5197 5198 5199 5200 5201 5202 5203 5204 5205 5206 5207 5208 5209 5210 5211 5212 5213 5214 5215 5216 5217 5218 5219 5220 5221 5222 5223 5224 5225 5226 5227 5228 5229 5230 5231 5232 5233 5234 5235 5236 5237 5238 5239 5240 5241 5242 5243 5244 5245 5246 5247 5248 5249 5250 5251 5252 5253 5254 5255 5256 5257 5258 5259 5260 5261 5262 5263 5264 5265 5266 5267 5268 5269 5270 5271 5272 5273 5274 5275 5276 5277 5278 5279 5280 5281 5282 5283 5284 5285 5286 5287 5288 5289 5290 5291 5292 5293 5294 5295 5296 5297 5298 5299 5300 5301 5302 5303 5304 5305 5306 5307 5308 5309 5310 5311 5312 5313 5314 5315 5316 5317 5318 5319 5320 5321 5322 5323 5324 5325 5326 5327 5328 5329 5330 5331 5332 5333 5334 5335 5336 5337 5338 5339 5340 5341 5342 5343 5344 5345 5346 5347 5348 5349 5350 5351 5352 5353 5354 5355 5356 5357 5358 5359 5360 5361 5362 5363 5364 5365 5366 5367 5368 5369 5370 5371 5372 5373 5374 5375 5376 5377 5378 5379 // Always runs without a P, so write barriers are not allowed. // //go:nowritebarrierrec func sysmon() { lock(\u0026amp;sched.lock) sched.nmsys++ // 系统M数量 checkdead() // 检查死锁 unlock(\u0026amp;sched.lock) lasttrace := int64(0) // 最后跟踪时间 // idle：在以下两种情况下才会重置为0 // 1. 有陷入系统调度的P需要被抢占时。 // 2. sysmon从深度睡眠中醒来时。 // 进入深度睡眠在这两种条件下： // 1. STW期间，sysmon可以进入深度睡眠。 // 2. 在所有P都空闲时(可能都陷入系统调用)。 // 其他情况idle会累加，因此sysmon的调度间隔会趋向于10ms。这一个goroutine运行的时间片时间值。 idle := 0 // how many cycles in succession we had not wokeup somebody // 下次sysmon运行的时间间隔，微秒。根据idle计算而来。 delay := uint32(0) for { // 1) 计算下次运行时间间隔 // 1. 默认20us。(20微秒)。 // 2. 连续50个周期无事可做则翻倍时间，后面依次翻倍。 // 3. 最高10ms。(10毫秒)。 if idle == 0 { // start with 20us sleep... delay = 20 } else if idle \u0026gt; 50 { // start doubling the sleep after 1ms... delay *= 2\t} if delay \u0026gt; 10*1000 { // up to 10ms delay = 10 * 1000\t} // 系统调用sleep delay微秒 usleep(delay) // sysmon should not enter deep sleep if schedtrace is enabled so that // it can print that information at the right time. // // It should also not enter deep sleep if there are any active P\u0026#39;s so // that it can retake P\u0026#39;s from syscalls, preempt long running G\u0026#39;s, and // poll the network if all P\u0026#39;s are busy for long stretches. // // It should wakeup from deep sleep if any P\u0026#39;s become active either due // to exiting a syscall or waking up due to a timer expiring so that it // can resume performing those duties. If it wakes from a syscall it // resets idle and delay as a bet that since it had retaken a P from a // syscall before, it may need to do it again shortly after the // application starts work again. It does not reset idle when waking // from a timer to avoid adding system load to applications that spend // most of their time sleeping. // // 如果启用了 schedtrace，sysmon 不应进入深度睡眠，以便它可以在正确的时间打印该信息 // 如果有任何活动的P，它也不应该进入深度睡眠，以便它可以从系统调用中重新获取P， // 抢占长时间运行的G，并在所有P长时间忙碌时轮询网络 // 如果任何 P 由于退出系统调用或由于计时器到期而唤醒， // 它应该从深度睡眠中唤醒，以便它可以恢复执行这些职责 // 果它从系统调用中唤醒，它会重置空闲和延迟作为赌注，因为它之前已经从系统调用中重新获得了P， // 它可能需要在应用程序再次开始工作后不久再次这样做 // 它不会在从计时器唤醒时重置空闲，以避免将系统负载添加到大部分时间都在休眠的应用程序 now := nanotime() // 当前时间 // 2) 满足以下条件工作线程会进入深度睡眠： // 1. STW正在等待其他P停下来，这段时间sysmon线程可以深度睡眠，在start the world时会唤醒sysmon。 // 2. 全部P都处于空闲，这段时间sysmon线程可以深度睡眠，这可能是处于系统调用中时，系统调用返回时会唤醒sysmon。 if debug.schedtrace \u0026lt;= 0 \u0026amp;\u0026amp; (sched.gcwaiting != 0 || atomic.Load(\u0026amp;sched.npidle) == uint32(gomaxprocs)) { lock(\u0026amp;sched.lock) // mutex lock // 加锁后，再次判断一次原因是获取锁这段时间可能条件不成立了。 if atomic.Load(\u0026amp;sched.gcwaiting) != 0 || atomic.Load(\u0026amp;sched.npidle) == uint32(gomaxprocs) { syscallWake := false // 系统调用唤醒? // 2.1) 最近一次timer的触发时间点或没有timer时都应该sleep。 // timeSleepUntil函数只会在sysmon和checkdead函数中被调用： // 1. next表示最先触发timer的时间点，timeSleepUntil函数会遍历所有的P取选择最小的timer触发时间点。 // 2. 返回 maxWhen = 1\u0026lt;\u0026lt;63 - 1，表示没有定时器。 next, _ := timeSleepUntil() // 2.2) 还未到触发timer的时间点时或没有timer，这段时间可以sleep。 if next \u0026gt; now {\tatomic.Store(\u0026amp;sched.sysmonwait, 1) // sched.sysmonwait = 1 unlock(\u0026amp;sched.lock)\t// Make wake-up period small enough // for the sampling to be correct. // // 使唤醒周期足够小，以保证取样正确。 // 2.3) 计算睡眠时间间隔最大值1分钟。 sleep := forcegcperiod / 2 // 1min if next-now \u0026lt; sleep { sleep = next - now } // osRelaxMinNS 表示如果下一个计时器从现在开始少于 60 毫秒，则 sysmon 不应该 osRelax // 由于 osRelaxing 可能会将计时器分辨率降低到 15.6 毫秒，这将计时器错误保持在大约 4 分之一以下 // const osRelaxMinNS = 0 shouldRelax := sleep \u0026gt;= osRelaxMinNS if shouldRelax { // osRelax 在与所有空闲的 P 之间转换时由调度程序调用 // 在 linux amd64 下该函数为空 osRelax(true)\t} // 2.4) 在sched.sysmonnote上睡眠sleep纳秒。 // 睡眠 sleep ns 时间，睡眠在 sched.sysmonnote 上。 // 最长情况会睡眠1min，也就是全部P都无事可做时。 // sleep时间后，也就是最新的timer需要触发的时间点，唤醒监控线程。 // 当 STW 正在进行时，这里会把监控线程sleep 1min，在start the world时会唤醒 // 在sched.sysmonnote上的监控线程。 // 当系统调用返回，在runtime_exitsyscall()函数中会响应的唤醒 // 在sched.sysmonnote上的监控线程。 // syscallWake = true。 syscallWake = notetsleep(\u0026amp;sched.sysmonnote, sleep) if shouldRelax { osRelax(false) } lock(\u0026amp;sched.lock) // sched.sysmonwait = 0;sched.sysmonnote.key = 0; atomic.Store(\u0026amp;sched.sysmonwait, 0) noteclear(\u0026amp;sched.sysmonnote) } // 由系统调用醒来或触发timer时间点已经过了，重置计时。 if syscallWake { idle = 0 delay = 20 } } unlock(\u0026amp;sched.lock) } lock(\u0026amp;sched.sysmonlock) // Update now in case we blocked on sysmonnote or spent a long time // blocked on schedlock or sysmonlock above. // // 如果我们在sysmonnote上被阻塞，或者在上面的schedlock或sysmonlock上花了很长时间阻塞，现在更新。 now = nanotime() // trigger libc interceptors if needed if *cgo_yield != nil { asmcgocall(*cgo_yield, nil) } // 3) network poll; 网络轮询。 // 网络轮询的时间间隔设置为10ms。 // poll network if not polled for more than 10ms // // 超过10ms没有进行网络轮询，则进行网络轮询。 // sched.lastpoll：记录的是上次执行netpoll的时间。 // 1. 如果等于0，则表示某个线程正在阻塞式地执行netpoll。 // 2. 大于0，则是上次执行时间点。 lastpoll := int64(atomic.Load64(\u0026amp;sched.lastpoll)) // 以下三种情况不会轮询网络： // 1. 没有初始化 netpoll 时。 // 2. 其他线程阻塞式访问 netpoll 时。 // 3. 上次轮询时间还没到 10ms 时。 // 需要查看network：已初始化 \u0026amp;\u0026amp; 没有其他线程在阻塞调用epoll \u0026amp;\u0026amp; 上次epoll已超过10ms了 if netpollinited() \u0026amp;\u0026amp; lastpoll != 0 \u0026amp;\u0026amp; lastpoll+10*1000*1000 \u0026lt; now { // CAS更新 sched.lastpoll 时间。 atomic.Cas64(\u0026amp;sched.lastpoll, uint64(lastpoll), uint64(now)) // 3.1) 轮询 poll。参数0立即返回。 // network poll是否有就绪的事件。 // 传递参数0表示epoll轮询wait等待函数立即返回。 // 非阻塞式轮询，返回就绪的goroutine列表。 list := netpoll(0) // non-blocking - returns list of goroutines // 存在就绪的 goroutine。 if !list.empty() { // Need to decrement number of idle locked M\u0026#39;s // (pretending that one more is running) before injectglist. // Otherwise it can lead to the following situation: // injectglist grabs all P\u0026#39;s but before it starts M\u0026#39;s to run the P\u0026#39;s, // another M returns from syscall, finishes running its G, // observes that there is no work to do and no other running M\u0026#39;s // and reports deadlock. // // 设置 sched.nmidlelocked += -1 incidlelocked(-1) // 处理准备好的goroutine // 该函数在调度循环函数中有详细注解。 injectglist(\u0026amp;list) incidlelocked(1) } } // 在 linux amd64 下不会触发。 if GOOS == \u0026#34;netbsd\u0026#34; \u0026amp;\u0026amp; needSysmonWorkaround { // netpoll is responsible for waiting for timer // expiration, so we typically don\u0026#39;t have to worry // about starting an M to service timers. (Note that // sleep for timeSleepUntil above simply ensures sysmon // starts running again when that timer expiration may // cause Go code to run again). // // However, netbsd has a kernel bug that sometimes // misses netpollBreak wake-ups, which can lead to // unbounded delays servicing timers. If we detect this // overrun, then startm to get something to handle the // timer. // // See issue 42515 and // https://gnats.netbsd.org/cgi-bin/query-pr-single.pl?number=50094. if next, _ := timeSleepUntil(); next \u0026lt; now { startm(nil, false) } } if atomic.Load(\u0026amp;scavenge.sysmonWake) != 0 { // Kick the scavenger awake if someone requested it. wakeScavenger() } // 4) 检查所有的P查看是否存在运行时间太长的G需要设置抢占请求。 // 1. goroutine运行时间超过10ms时需要抢占。 // 2. goroutine陷入系统调用，运行时间超过10ms或在第二轮来是sysmon系统调用还没返回时。 // 陷入系统调用而抢占P的情况： // 1. 运行时间超过10ms，可能一开始就陷入系统调用，或中途陷入系统调用。不论那种情况都应该抢占。 // 2. 运行时间没到10ms，但是两轮sysmon了还是在系统调用中，需要抢占P。这时候时间间隔在(0, 20ms)这个范围。 // retake P\u0026#39;s blocked in syscalls // and preempt long running G\u0026#39;s // // 重新获取在系统调用中阻塞的 P 并抢占长时间运行的 G // retake函数返回值，陷入系统调用的需要抢占的P的数量。 if retake(now) != 0 { // 为什么陷入系统调度的P需要重置监控频率？ // 原因是陷入系统调度的P，把时间调回20us，下轮监控线程来时判断是否还在系统调用中。 idle = 0 } else { idle++ } // 5) GC相关，定时检查GC是否该触发了 // check if we need to force a GC // t.test()：判断是否满足定时GC间隔2分钟的条件 // forcegc.idle.Load()：当前定时GC是空闲的 if t := (gcTrigger{kind: gcTriggerTime, now: now}); t.test() \u0026amp;\u0026amp; atomic.Load(\u0026amp;forcegc.idle) != 0 { lock(\u0026amp;forcegc.lock) // 获取互斥锁 forcegc.idle = 0 // 标记本轮定时GC开始了 var list gList // goroutine的列表，最后会把里面的goroutine放入P的本地队列 list.push(forcegc.g)// forcegchelper goroutine 加入本地队列，去触发goroutine injectglist(\u0026amp;list) // list 加入P的本地队列等待M调用，等待forcegchelper()函数继续运行吧 unlock(\u0026amp;forcegc.lock)// 解锁 } if debug.schedtrace \u0026gt; 0 \u0026amp;\u0026amp; lasttrace+int64(debug.schedtrace)*1000000 \u0026lt;= now { lasttrace = now schedtrace(debug.scheddetail \u0026gt; 0) } unlock(\u0026amp;sched.sysmonlock) } } ","permalink":"https://heliu.site/posts/golang/goroutine/sysmon/","summary":"Golang sysmon监控线程介绍。","title":"sysmon 监控线程"},{"content":"唤醒工作线程 去尝试唤醒工作线程条件：atomic.Load(\u0026amp;sched.npidle) != 0 \u0026amp;\u0026amp; atomic.Load(\u0026amp;sched.nmspinning) == 0。 atomic.Load(\u0026amp;sched.npidle) != 0：有空闲的P。 atomic.Load(\u0026amp;sched.nmspinning) == 0：没有工作线程正在尝试从其他工作线程的本地队列偷取goroutine。(就是没有spinning自旋的goroutine时) 唤醒空闲的P和M由wakep()函数完成。 wakep() 尝试添加一个P来执行G。当G是可运行时调用(newproc, ready)。 wakep()函数被调用的地方：【创建g时候，在newproc()函数中，就是go关键字】，【g放回P的时候，在ready()函数中】。 newproc()函数中，也就是go关键字时，runtime.main已启动时。（这种情况发生在go关键字时） ready()函数中，该函数通过把需要唤醒的goroutine放入运行队列来唤醒它。（这种情况在g被挂在了其他地方时需要恢复到P中时） 也就是只要g被放入本地队列中，准备运行时都需要调用wakep()函数尝试利用空闲的M和P来运行它。 文件位置：go1.19.3/src/runtime/proc.go。 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 // Tries to add one more P to execute G\u0026#39;s. // Called when a G is made runnable (newproc, ready). func wakep() { // 没有空闲的P，直接返回。当前所有的P都在工作。因为P的数量是固定的。 if atomic.Load(\u0026amp;sched.npidle) == 0 { return } // be conservative about spinning threads // // 对自旋的线程持保守态度： // 1. sched.nmspinning != 0：有其他线程正在自旋（就是在其他线程中去偷取g） // 2. !atomic.Cas(\u0026amp;sched.nmspinning, 0, 1)：通过cas操作再次确认是否有其他工作线程处于spinning状态 // 从进入wakep()判断到真正启动工作线程之前的这一段时间之内，如果已经有工作线程进入了spinning状态而在四处寻找需要运行的goroutine // 这样的话我们就没有必要再启动一个多余的工作线程出来了 // 如果cas操作成功，则继续调用startm创建一个新的或唤醒一个处于睡眠状态的工作线程出来工作 // // 1. atomic.Load(\u0026amp;sched.nmspinning) != 0 成立：有其他工作线程正在自旋，直接return退出 // 2. atomic.Load(\u0026amp;sched.nmspinning) == 0 成立：当前没有忙碌的工作线程 // atomic.Cas(\u0026amp;sched.nmspinning, 0, 1) == true：当前没有忙碌的工作线程，当前可以创建工作线程，并标记sched.nmspinning=1阻止后来者 // atomic.Cas(\u0026amp;sched.nmspinning, 0, 1) == false：当前有其他忙碌的工作线程，直接return退出 if atomic.Load(\u0026amp;sched.nmspinning) != 0 || !atomic.Cas(\u0026amp;sched.nmspinning, 0, 1) { return } // 程序执行到这里说明：sched.nmspinning一定被标记为1了。 startm(nil, true) } startm() 调度一些M来运行p(如果需要，创建一个M)。 如果p==nil，尝试得到一个空闲的p，如果没有空闲的p什么都不做。 可以使用m.p==nil运行，因此不允许写入障碍。 如果设置了spinning，则调用者增加了nmspinning，而startm将减少nmspinning或在新启动的M中设置m.spinning。 传递nil的P的调用方必须从不可抢占的上下文中调用。见下面对acquirem。 必须没有写障碍，因为这个可能没有P。 go:nowritebarrierrec：不允许编译器插入写屏障相关代码。 在抢占系统调用的P的时候该函数会被调用，并传入空闲的P和false参数。 参数： _p_ *p：nil表示没有指定P，否则指定P。 spinning bool：true.sched.nmspinning的值在前面被加一了。false.没有加一。 文件位置：go1.19.3/src/runtime/proc.go。 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 // Schedules some M to run the p (creates an M if necessary). // If p==nil, tries to get an idle P, if no idle P\u0026#39;s does nothing. // May run with m.p==nil, so write barriers are not allowed. // If spinning is set, the caller has incremented nmspinning and startm will // either decrement nmspinning or set m.spinning in the newly started M. // // Callers passing a non-nil P must call from a non-preemptible context. See // comment on acquirem below. // // Must not have write barriers because this may be called without a P. // //go:nowritebarrierrec func startm(_p_ *p, spinning bool) { // Disable preemption. // // Every owned P must have an owner that will eventually stop it in the // event of a GC stop request. startm takes transient ownership of a P // (either from argument or pidleget below) and transfers ownership to // a started M, which will be responsible for performing the stop. // // Preemption must be disabled during this transient ownership, // otherwise the P this is running on may enter GC stop while still // holding the transient P, leaving that P in limbo and deadlocking the // STW. // // Callers passing a non-nil P must already be in non-preemptible // context, otherwise such preemption could occur on function entry to // startm. Callers passing a nil P may be preemptible, so we must // disable preemption before acquiring a P from pidleget below. mp := acquirem() // 禁止当前M被抢占 lock(\u0026amp;sched.lock) // 锁住全局sched // 有空闲的p才会去唤醒线程 if _p_ == nil { // 如果没有指定P，则需要从P的空闲列表中获取一个P _p_ = pidleget(0) // 从P的空闲队列中获取空闲的P // 没有空闲的P，意味着所有的P都很忙不需要唤醒 if _p_ == nil {\tunlock(\u0026amp;sched.lock) // 之前的Cas把nmspinning加一，这里需要减回来 if spinning {\t// The caller incremented nmspinning, but there are no idle Ps, // so it\u0026#39;s okay to just undo the increment and give up. // // 正常逻辑这里不应该减成负数，否则是系统逻辑存在错误 if int32(atomic.Xadd(\u0026amp;sched.nmspinning, -1)) \u0026lt; 0 { throw(\u0026#34;startm: negative nmspinning\u0026#34;) } } // 与acquirem函数呼应，并检查是否有抢占请求发生 releasem(mp)\treturn // 没有空闲的P直接返回 } } // 尝试从m空闲队列中获取正处于睡眠之中的工作线程 // 所有处于睡眠状态的m都在此队列中 nmp := mget() // 没有处于睡眠状态的工作线程，这种情况需要去创建线程 if nmp == nil {\t// No M is available, we must drop sched.lock and call newm. // However, we already own a P to assign to the M. // // Once sched.lock is released, another G (e.g., in a syscall), // could find no idle P while checkdead finds a runnable G but // no running M\u0026#39;s because this new M hasn\u0026#39;t started yet, thus // throwing in an apparent deadlock. // // Avoid this situation by pre-allocating the ID for the new M, // thus marking it as \u0026#39;running\u0026#39; before we drop sched.lock. This // new M will eventually run the scheduler to execute any // queued G\u0026#39;s. // // 这里是为需要新创建的工作线程准备工作 id := mReserveID() // 给需要创建的工作线程分配ID unlock(\u0026amp;sched.lock) // 初始化fn函数，该函数在工作线程刚启动时会被调用 var fn func() // nil if spinning { // 如果需要标记当前工作线程是自旋状态 // The caller incremented nmspinning, so set m.spinning in the new M. // // mspinning函数就一行代码 \u0026#39;getg().m.spinning = true\u0026#39; 标记当前工作线程是自旋状态 // 因为全局的sched.nmspinning已经加一了，因此需要标记m的spinning fn = mspinning\t} newm(fn, _p_, id) // 创建新的工作线程 // Ownership transfer of _p_ committed by start in newm. // Preemption is now safe. releasem(mp) return } // 到这里说明有正在处于睡眠的工作线程 unlock(\u0026amp;sched.lock) // 从空闲的线程队列中拿出来的 spinning 标志位存在，说明sleep时有问题 if nmp.spinning { // 系统逻辑存在问题 throw(\u0026#34;startm: m is spinning\u0026#34;) } // 工作线程还与其他P有关，说明有问题 if nmp.nextp != 0 { // 系统逻辑存在问题 throw(\u0026#34;startm: m has p\u0026#34;) } // 空闲的P中不应该存在g，系统逻辑存在问题 if spinning \u0026amp;\u0026amp; !runqempty(_p_) {\tthrow(\u0026#34;startm: p has runnable gs\u0026#34;) } // The caller incremented nmspinning, so set m.spinning in the new M. // // 调用者增加nmspinning，因此将m.spinning设置为新的M。因此当前这个M就是这个自旋的M nmp.spinning = spinning // 标记当前需要唤醒的工作线程 自旋的状态 // 当前M的P暂时放在nextp上 // 这里也就是为什么新创建的工作线程直接在nextp去取P，原因在这里关联的 // 因为_p_只在这里存在，因此不会存在其他工作线程使用该P。 nmp.nextp.set(_p_)\t// 唤醒工作线程，工作线程睡眠在 nmp.park 上面 notewakeup(\u0026amp;nmp.park)\t// Ownership transfer of _p_ committed by wakeup. Preemption is now // safe. // // 唤醒提交的_p_的所有权转移。 抢占现在是安全的 // 与acquirem函数呼应，并检查是否有抢占请求发生 releasem(mp) } acquirem() m加锁禁止抢占当前m。 文件位置：go1.19.3/src/runtime/runtime1.go。 473 474 475 476 477 478 //go:nosplit func acquirem() *m { _g_ := getg() _g_.m.locks++ return _g_.m } releasem() 文件位置：go1.19.3/src/runtime/runtime1.go。 482 483 484 485 486 487 488 489 490 func releasem(mp *m) { _g_ := getg() mp.locks-- // 当前M没有锁，并且G需要被抢占 if mp.locks == 0 \u0026amp;\u0026amp; _g_.preempt { // restore the preemption request in case we\u0026#39;ve cleared it in newstack _g_.stackguard0 = stackPreempt // 设置抢占标志 } } pidleget() 从sched.pidle中尝试获取一个空闲的P。 参数now int64：0则取当前时间点。 返回值： *p：返回一个空闲的P，否则为nil没有空闲的P。 int64：传入now的时间值，0则是当前时间值。 文件位置：go1.19.3/src/runtime/proc.go。 5727 5728 5729 5730 5731 5732 5733 5734 5735 5736 5737 5738 5739 5740 5741 5742 5743 5744 5745 5746 5747 5748 5749 5750 5751 5752 5753 5754 5755 5756 // pidleget tries to get a p from the _Pidle list, acquiring ownership. // // sched.lock must be held. // // May run during STW, so write barriers are not allowed. // //go:nowritebarrierrec func pidleget(now int64) (*p, int64) { // sched.lock 必须被持有 assertLockHeld(\u0026amp;sched.lock) // 从sched.pidle上获取空闲的P _p_ := sched.pidle.ptr() if _p_ != nil { // Timer may get added at any time now. if now == 0 { now = nanotime() } // 设置timerpMask和idlepMask timerpMask.set(_p_.id) idlepMask.clear(_p_.id) // 从全局空闲的P中移除_p_ sched.pidle = _p_.link // 全局的空闲P的次数减一 atomic.Xadd(\u0026amp;sched.npidle, -1) // limiterEvent跟踪GC CPU限制器的事件。 _p_.limiterEvent.stop(limiterEventIdle, now) } return _p_, now } mget() 尝试从sched.midle获取一个空闲的工作线程m，起来绑定P运行。 文件位置：go1.19.3/src/runtime/proc.go。 5547 5548 5549 5550 5551 5552 5553 5554 5555 5556 5557 5558 5559 5560 5561 5562 5563 5564 // Try to get an m from midle list. // sched.lock must be held. // May run during STW, so write barriers are not allowed. // //go:nowritebarrierrec func mget() *m { assertLockHeld(\u0026amp;sched.lock) // 空闲的m在sched.midle上 mp := sched.midle.ptr() if mp != nil { // 从sched.midle上移除mp sched.midle = mp.schedlink // 空闲的m数量减一 sched.nmidle-- } return mp } mReserveID() 给新创建的工作线程分配唯一的ID。 文件位置：go1.19.3/src/runtime/proc.go。 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 // mReserveID returns the next ID to use for a new m. This new m is immediately // considered \u0026#39;running\u0026#39; by checkdead. // // sched.lock must be held. func mReserveID() int64 { // sched.lock锁必须被持有 assertLockHeld(\u0026amp;sched.lock) // 分配的ID溢出了 if sched.mnext+1 \u0026lt; sched.mnext { throw(\u0026#34;runtime: thread ID overflow\u0026#34;) } id := sched.mnext // 分配的ID sched.mnext++ // 下一个ID // 检查sched.mnext - sched.nmfreed \u0026gt; sched.maxmcount // sched.maxmcount 在 runtime.main 中被设置为 10000 // sched.mnext 下一个分配的ID，该值是累加的 // sched.nmfreed 已经释放的工作线程数量 // 因此这里是检查当前已经创建的工作线程数量不能大于最大值 checkmcount() return id } notewakeup() 首先使用atomic.Xchg设置note.key值为1。 这是为了使被唤醒的线程可以通过查看该值是否等于1来确定是被其它线程唤醒还是意外从睡眠中苏醒了过来， 如果该值为1则表示是被唤醒的，可以继续工作了。 但如果该值为0则表示是意外苏醒，需要再次进入睡眠， 工作线程苏醒之后的处理逻辑我们已经在notesleep()函数中见过，所以这里略过。 文件位置：go1.19.3/src/runtime/lock_futex.go。 139 140 141 142 143 144 145 146 147 func notewakeup(n *note) { // 设置n.key = 1, 被唤醒的线程通过查看该值是否等于1来确定是被其它线程唤醒还是意外从睡眠中苏醒 old := atomic.Xchg(key32(\u0026amp;n.key), 1) if old != 0 { // 如果旧值不是0说明系统逻辑有问题 print(\u0026#34;notewakeup - double wakeup (\u0026#34;, old, \u0026#34;)\\n\u0026#34;) throw(\u0026#34;notewakeup - double wakeup\u0026#34;) } futexwakeup(key32(\u0026amp;n.key), 1) // 调用futexwakeup唤醒 } futexwakeup() 对于Linux平台来说，工作线程通过note睡眠其实是通过futex系统调用睡眠在内核之中， 所以唤醒处于睡眠状态的线程也需要通过futex系统调用进入内核来唤醒。 所以这里的futexwakeup()又继续调用包装了futex系统调用的futex()函数来实现唤醒睡眠在内核中的工作线程。 文件位置：go1.19.3/src/runtime/os_linux.go。 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 // If any procs are sleeping on addr, wake up at most cnt. //go:nosplit func futexwakeup(addr *uint32, cnt uint32) { // 调用futex函数唤醒工作线程 ret := futex(unsafe.Pointer(addr), _FUTEX_WAKE_PRIVATE, cnt, nil, nil, 0) if ret \u0026gt;= 0 {\t// 调用成功是这里直接返回 return } // I don\u0026#39;t know that futex wakeup can return // EAGAIN or EINTR, but if it does, it would be // safe to loop and call futex again. systemstack(func() { print(\u0026#34;futexwakeup addr=\u0026#34;, addr, \u0026#34; returned \u0026#34;, ret, \u0026#34;\\n\u0026#34;) }) // 程序不会到这里来，即使到这里来了，向一个未知地址写入数据直接宕机 *(*int32)(unsafe.Pointer(uintptr(0x1006))) = 0x1006 } futex() futex()函数由汇编代码写成，前面的几条指令都在为futex系统调用准备参数， 参数准备完成之后则通过SYSCALL指令进入操作系统内核完成线程的唤醒功能。 内核在完成唤醒工作之后当前工作线程则从内核返回到futex()函数继续执行SYSCALL指令之后的代码并按函数调用链原路返回。 继续执行其它代码，而被唤醒的工作线程则由内核负责在适当的时候调度到CPU上运行。 陷入系统调用太长时间的工作线程会在监控线程中剥离P和G，具体的参看监控线程相关代码。这里没有标记工作线程陷入系统调用的标志。 应该是当前函数调用不会形成阻塞。 文件位置：go1.19.3/src/runtime/sys_linux_amd64.s。 549 550 551 552 553 554 555 556 557 558 559 560 561 562 # int64 futex(int32 *uaddr, int32 op, int32 val, # struct timespec *timeout, int32 *uaddr2, int32 val2); TEXT runtime·futex(SB),NOSPLIT,$0 #这6条指令在为futex系统调用准备参数 MOVQ addr+0(FP), DI MOVL op+8(FP), SI MOVL val+12(FP), DX MOVQ ts+16(FP), R10 MOVQ addr2+24(FP), R8 MOVL val3+32(FP), R9 MOVL $SYS_futex, AX # futex系统调用编号放入AX寄存器 SYSCALL # 系统调用，进入内核 MOVL AX, ret+40(FP) # 系统调用通过AX寄存器返回返回值，这里把返回值保存到内存之中 RET 创建工作线程 如果没有正处于休眠状态的工作线程，则需要调用newm()函数新建一个工作线程。 newm() 创建调度线程和监控线程都是通过该函数，执行该函数时都会把栈切换到g0栈，因为g0栈比较大。 该函数在以下两种情况下使用： newm(sysmon, nil, -1)：创建【监控线程】。 sysmon工作线程开始执行时首先调用的函数。（不是入口函数，newm()创建的入口函数都是固定的mstart()函数） nil表示不需要绑定P。 -1系统会自动分配一个递增的数字。（全局唯一的ID） newm(fn, _p_, id)：创建【调度线程】。 fn工作线程开始执行时首先调用的函数。（不是入口函数，newm()创建的入口函数都是固定的mstart()函数） _p_线程启动时需要绑定的P。 创建工作线程的唯一ID。 创建一个新的m。它将从对fn或调度器的调用开始。fn需要是静态的，而不是一个堆分配闭包。可以使用 m.p==nil运行，因此不允许写入障碍。 id是可选的，预分配的M的id。通过传递-1来省略。 go:nowritebarrierrec：告诉编译器该函数及里面所调用的函数都不插入写屏障代码。 参数： fn func()：新创建的工作线程启动后需要执行的函数，不能是一个堆分配的闭包，必须是一个静态的函数。 也就是所有创建的线程入口函数都是mstart()函数是线程的入口函数数，参看newosproc()函数。 _p_ *p：新创建的工作线程需要绑定的P，该值可以为 nil，表示不绑定P。 id int64：新创建的工作线程的ID值，该值可以是-1，表示系统自动分配一个递增的ID数值。 文件位置：go1.19.3/src/runtime/proc.go。 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 // Create a new m. It will start off with a call to fn, or else the scheduler. // fn needs to be static and not a heap allocated closure. // May run with m.p==nil, so write barriers are not allowed. // // id is optional pre-allocated m ID. Omit by passing -1. // //go:nowritebarrierrec func newm(fn func(), _p_ *p, id int64) { // allocm adds a new M to allm, but they do not start until created by // the OS in newm1 or the template thread. // // doAllThreadsSyscall requires that every M in allm will eventually // start and be signal-able, even with a STW. // // Disable preemption here until we start the thread to ensure that // newm is not preempted between allocm and starting the new thread, // ensuring that anything added to allm is guaranteed to eventually // start. // // allocm将一个新的M添加到allm中，但是直到操作系统在newm1或模板线程中创建它们才开始。 // doAllThreadsSyscall 要求allm中的每个M最终都将启动并可发送信号，即使是STW。 // 在这里禁用抢占，直到我们启动线程，以确保newm在allocm和启动新线程之间不被抢占，确保添加到allm的任何内容最终都能启动。 acquirem()\t// 禁止当前工作线程被抢占 // allocm从堆上分配一个m结构体，并绑定M与其他相关例如allp等 mp := allocm(_p_, fn, id) mp.nextp.set(_p_)\t// 设置当前M需要用到的P mp.sigmask = initSigmask if gp := getg(); gp != nil \u0026amp;\u0026amp; gp.m != nil \u0026amp;\u0026amp; (gp.m.lockedExt != 0 || gp.m.incgo) \u0026amp;\u0026amp; GOOS != \u0026#34;plan9\u0026#34; { // We\u0026#39;re on a locked M or a thread that may have been // started by C. The kernel state of this thread may // be strange (the user may have locked it for that // purpose). We don\u0026#39;t want to clone that into another // thread. Instead, ask a known-good thread to create // the thread for us. // // This is disabled on Plan 9. See golang.org/issue/22227. // // TODO: This may be unnecessary on Windows, which // doesn\u0026#39;t model thread creation off fork. lock(\u0026amp;newmHandoff.lock) if newmHandoff.haveTemplateThread == 0 { throw(\u0026#34;on a locked thread with no template thread\u0026#34;) } mp.schedlink = newmHandoff.newm newmHandoff.newm.set(mp) if newmHandoff.waiting { newmHandoff.waiting = false notewakeup(\u0026amp;newmHandoff.wake) } unlock(\u0026amp;newmHandoff.lock) // The M has not started yet, but the template thread does not // participate in STW, so it will always process queued Ms and // it is safe to releasem. releasem(getg().m) return } newm1(mp) releasem(getg().m) } acquirem() 文件位置：go1.19.3/src/runtime/runtime1.go。 473 474 475 476 477 478 //go:nosplit func acquirem() *m { _g_ := getg() _g_.m.locks++ return _g_.m } allocm() 分配一个不与任何线程关联的新m。如果需要，可以使用p作为分配上下文。 fn被记录为新m的m.mstartfn。id是可选的，预分配的m的id。通过传递-1来省略。 这个函数允许有写障碍，即使调用者没有，因为它借用了_p_。 go:yeswritebarrierrec：允许编译器插入写屏障相关代码，因为调用者使用的是go:nowritebarrierrec。 文件位置：go1.19.3/src/runtime/proc.go。 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 // Allocate a new m unassociated with any thread. // Can use p for allocation context if needed. // fn is recorded as the new m\u0026#39;s m.mstartfn. // id is optional pre-allocated m ID. Omit by passing -1. // // This function is allowed to have write barriers even if the caller // isn\u0026#39;t because it borrows _p_. // //go:yeswritebarrierrec func allocm(_p_ *p, fn func(), id int64) *m { allocmLock.rlock() // 读加锁 // The caller owns _p_, but we may borrow (i.e., acquirep) it. We must // disable preemption to ensure it is not stolen, which would make the // caller lose ownership. acquirem() // 禁止当前M被抢占 _g_ := getg() // 当前g // 注意这里是正在执行的工作线程,在此函数中为 malloc 临时借用 p if _g_.m.p == 0 { // 如果当前M没有绑定P，则去绑定一个P // 在这个函数中暂时借用p来代替mallocs // 当前这个工作线程没有绑定p需要临时借用这个_p_，这种情况可能是sysmon线程中来的。 acquirep(_p_) // temporarily borrow p for mallocs in this function } // Release the free M list. We need to do this somewhere and // this may free up a stack we can use. // // sched.freem 存储的是等待释放的m的链表 if sched.freem != nil { // 释放需要释放的M列表 lock(\u0026amp;sched.lock) var newList *m // freem 是一组已经运行结束的M构成的链表（不是空闲的）。 for freem := sched.freem; freem != nil; { // freeWait 释放g0和删除m是否安全(freeMRef, freeMStack, freeMWait中的一个) if freem.freeWait != 0 { next := freem.freelink freem.freelink = newList newList = freem freem = next continue } // stackfree must be on the system stack, but allocm is // reachable off the system stack transitively from // startm. // // stackfree 必须在系统栈上，但allocm从startm开始在系统栈之外是可访问的。 systemstack(func() { stackfree(freem.g0.stack) // 释放栈 }) freem = freem.freelink } sched.freem = newList unlock(\u0026amp;sched.lock) } // 堆分配一个m mp := new(m)\t// M开始前需要执行的函数，不是M的入口函数，是执行mstart后会调用的函数。 // 1. 如果是调度线下这里存储的是mspinning()函数 // 2. 如果是监控线程存储的是sysmon()函数 mp.mstartfn = fn\t// 初始化M，主要是把m加入到allm中，m记录allm地址等 // 该函数在程序初始化过程中也被调用过 mcommoninit(mp, id)\t// In case of cgo or Solaris or illumos or Darwin, pthread_create will make us a stack. // Windows and Plan 9 will layout sched stack on OS stack. if iscgo || mStackIsSystemAllocated() { mp.g0 = malg(-1) } else { // runtime 的g0栈分配的是64kb左右大小，其他的g0栈分配的是8kb左右大小 // 关于malg函数，是来自栈相关 mp.g0 = malg(8192 * sys.StackGuardMultiplier) // 分配一个大概8Kb左右的g0作为系统栈 } mp.g0.m = mp\t// g0与m关联 if _p_ == _g_.m.p.ptr() { // 如果前面临时借用了P，这里需要还出来 releasep() // 解绑当前工作线程M和P的关联 } releasem(_g_.m) // 判断当前g是否需要被抢占，设置抢占标志 allocmLock.runlock() return mp } acquirep() 把p和当前m联系起来。 这个函数允许有写障碍，即使调用者没有，因为它立即获得_p_。 go:yeswritebarrierrec：允许编译器插入写屏障相关代码。 文件位置：go1.19.3/src/runtime/proc.go。 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951 4952 4953 4954 4955 4956 4957 4958 4959 // Associate p and the current m. // // This function is allowed to have write barriers even if the caller // isn\u0026#39;t because it immediately acquires _p_. // //go:yeswritebarrierrec func acquirep(_p_ *p) { // Do the part that isn\u0026#39;t allowed to have write barriers. wirep(_p_)\t// 把 P 与 M 绑定起来 // Have p; write barriers now allowed. // 现在有p了；现在允许写屏障。 // Perform deferred mcache flush before this P can allocate // from a potentially stale mcache. // 在此P可以从可能不新鲜的mcache分配之前，执行延迟的mcache刷新。 _p_.mcache.prepareForSweep() if trace.enabled { traceProcStart() } } wirep是acquirep的第一步，它实际上将当前M关联到_p_。 因为我们还没有P，所以我们可以在这部分不允许写障碍。 go:nowritebarrierrec：不允许编译器插入写屏障相关代码。 文件位置：go1.19.3/src/runtime/proc.go。 4959 4960 4961 4962 4963 4964 4965 4966 4967 4968 4969 4970 4971 4972 4973 4974 4975 4976 4977 4978 4979 4980 4981 4982 4983 4984 4985 // wirep is the first step of acquirep, which actually associates the // current M to _p_. This is broken out so we can disallow write // barriers for this part, since we don\u0026#39;t yet have a P. // //go:nowritebarrierrec //go:nosplit func wirep(_p_ *p) { _g_ := getg() // g // 这里来的m一定需要是没绑定p的。 if _g_.m.p != 0 { throw(\u0026#34;wirep: already in go\u0026#34;) } // 当前p也是不能绑定m的，并且当前p的状态不能是 _Pidle if _p_.m != 0 || _p_.status != _Pidle { id := int64(0) if _p_.m != 0 { id = _p_.m.ptr().id } print(\u0026#34;wirep: p-\u0026gt;m=\u0026#34;, _p_.m, \u0026#34;(\u0026#34;, id, \u0026#34;) p-\u0026gt;status=\u0026#34;, _p_.status, \u0026#34;\\n\u0026#34;) throw(\u0026#34;wirep: invalid p state\u0026#34;) } // p 与 m 相互绑定 _g_.m.p.set(_p_) // m.p = _p_ _p_.m.set(_g_.m) // _p_.m = m _p_.status = _Prunning // 设置p的状态为运行中 } mcommoninit() 预分配的ID可以作为'ID'传递，也可以通过传递-1来省略。 文件位置：go1.19.3/src/runtime/proc.go。 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 // Pre-allocated ID may be passed as \u0026#39;id\u0026#39;, or omitted by passing -1. func mcommoninit(mp *m, id int64) { _g_ := getg() // g // g0 stack won\u0026#39;t make sense for user (and is not necessary unwindable). if _g_ != _g_.m.g0 { // 不能是g0栈 callers(1, mp.createstack[:]) } lock(\u0026amp;sched.lock) if id \u0026gt;= 0 { mp.id = id } else { mp.id = mReserveID() } lo := uint32(int64Hash(uint64(mp.id), fastrandseed)) hi := uint32(int64Hash(uint64(cputicks()), ^fastrandseed)) if lo|hi == 0 { hi = 1 } // Same behavior as for 1.17. // TODO: Simplify ths. if goarch.BigEndian { mp.fastrand = uint64(lo)\u0026lt;\u0026lt;32 | uint64(hi) } else { mp.fastrand = uint64(hi)\u0026lt;\u0026lt;32 | uint64(lo) } mpreinit(mp) // 信号相关 if mp.gsignal != nil { mp.gsignal.stackguard1 = mp.gsignal.stack.lo + _StackGuard } // Add to allm so garbage collector doesn\u0026#39;t free g-\u0026gt;m // when it is just in a register or thread-local storage. mp.alllink = allm // 记录当前m.alllink的全局allm地址 // NumCgoCall() iterates over allm w/o schedlock, // so we need to publish it safely. atomicstorep(unsafe.Pointer(\u0026amp;allm), unsafe.Pointer(mp))\t// 把m添加到全局allm中 unlock(\u0026amp;sched.lock) // Allocate memory to hold a cgo traceback if the cgo call crashes. if iscgo || GOOS == \u0026#34;solaris\u0026#34; || GOOS == \u0026#34;illumos\u0026#34; || GOOS == \u0026#34;windows\u0026#34; { mp.cgoCallers = new(cgoCallers) } } newm1() 文件位置：go1.19.3/src/runtime/proc.go。 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 func newm1(mp *m) { if iscgo { // cgo相关代码 var ts cgothreadstart if _cgo_thread_start == nil { throw(\u0026#34;_cgo_thread_start missing\u0026#34;) } ts.g.set(mp.g0) ts.tls = (*uint64)(unsafe.Pointer(\u0026amp;mp.tls[0])) ts.fn = unsafe.Pointer(abi.FuncPCABI0(mstart)) if msanenabled { msanwrite(unsafe.Pointer(\u0026amp;ts), unsafe.Sizeof(ts)) } if asanenabled { asanwrite(unsafe.Pointer(\u0026amp;ts), unsafe.Sizeof(ts)) } execLock.rlock() // Prevent process clone. asmcgocall(_cgo_thread_start, unsafe.Pointer(\u0026amp;ts)) execLock.runlock() return } execLock.rlock() // Prevent process clone. // newosproc函数 调用clone函数创建一个系统线程 // 新建的这个系统线程将从mstart()函数开始运行。 newosproc(mp) execLock.runlock() } newosproc() 可以m.p==nil 运行，因此不允许写屏障。 文件位置：go1.19.3/src/runtime/os_linux.go。 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 // May run with m.p==nil, so write barriers are not allowed. // //go:nowritebarrier func newosproc(mp *m) { stk := unsafe.Pointer(mp.g0.stack.hi) // 获取当前新创建的M的g0栈栈顶位置 /* * note: strace gets confused if we use CLONE_PTRACE here. */ if false { print(\u0026#34;newosproc stk=\u0026#34;, stk, \u0026#34; m=\u0026#34;, mp, \u0026#34; g=\u0026#34;, mp.g0, \u0026#34; clone=\u0026#34;, abi.FuncPCABI0(clone), \u0026#34; id=\u0026#34;, mp.id, \u0026#34; ostk=\u0026#34;, \u0026amp;mp, \u0026#34;\\n\u0026#34;) } // Disable signals during clone, so that the new thread starts // with signals disabled. It will enable them in minit. // // 在克隆期间禁用信号，以便新线程以禁用信号开始。 它将在minit中启用它们。 var oset sigset sigprocmask(_SIG_SETMASK, \u0026amp;sigset_all, \u0026amp;oset) // cloneFlags = _CLONE_VM | /* share memory */ // 指定父子线程共享进程地址空间 // _CLONE_FS | /* share cwd, etc */ // _CLONE_FILES | /* share fd table */ // _CLONE_SIGHAND | /* share sig handler table */ // _CLONE_SYSVSEM | /* share SysV semaphore undo lists (see issue #20763) */ // _CLONE_THREAD /* revisit - okay for now */ // 创建子线程而不是子进程 // 程序的入口都是【mstart()】函数开始 ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(abi.FuncPCABI0(mstart))) sigprocmask(_SIG_SETMASK, \u0026amp;oset, nil) // 怎么也应该出现 ret 小于0的情况 if ret \u0026lt; 0 { print(\u0026#34;runtime: failed to create new OS thread (have \u0026#34;, mcount(), \u0026#34; already; errno=\u0026#34;, -ret, \u0026#34;)\\n\u0026#34;) if ret == -_EAGAIN { println(\u0026#34;runtime: may need to increase max user processes (ulimit -u)\u0026#34;) } throw(\u0026#34;newosproc\u0026#34;) } } clone() C函数原型：int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void))\nint32 flags：指定内核创建线程时需要的选项。 void *stk：新线程应该使用的栈： 因为即将被创建的线程与当前线程共享同一个进程地址空间，所以这里必须为子线程指定其使用的栈，否则父子线程会共享同一个栈从而造成混乱。 从上面的newosproc()函数可以看出，新线程使用的栈为m.g0.stack.lo～m.g0.stack.hi这段内存，而这段内存是newm()函数在创建m结构体对象时从进程的堆上分配而来的。 M *mp：工作线程 M 的信息记录。 G *gp：g0栈信息记录。 void (*fn)(void)：子线程程序入口函数。 上面三个参数（M *mp、G *gp、void (*fn)(void)）保存到寄存器（R13、R9、R12）中： 之所以需要在系统调用之前保存这几个参数，原因在于这几个参数目前还位于父线程的栈之中。 一旦通过系统调用把子线程创建出来之后，子线程将会使用我们在clone系统调用时给它指定的栈。 所以这里需要把这几个参数先保存到寄存器，等子线程从系统调用返回后直接在寄存器中获取这几个参数。 这里要注意的是虽然这个几个参数值保存在了父线程的寄存器之中，但创建子线程时，操作系统内核会把父线程的所有寄存器帮我们复制一份给子线程，所以当子线程开始运行时就能拿到父线程保存在寄存器中的值，从而拿到这几个参数。 文件位置：go1.19.3/src/runtime/sys_linux_amd64.s。 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 # int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void)); TEXT runtime·clone(SB),NOSPLIT,$0 # 1) 接受参数分蘖放入 DI、SI、R13、R9、R12寄存器中 # 清除 DX、R10、D8寄存器的值 # 第一个参数 flags，clone需要的参数 MOVL flags+0(FP), DI # DI = flags # 第二个参数 stk，g0栈空间 MOVQ stk+8(FP), SI # SI = stk MOVQ $0, DX # 清除DX寄存器 MOVQ $0, R10 # 清除R10寄存器 MOVQ $0, R8 # 清除R8寄存器 # Copy mp, gp, fn off parent stack for use by child. # Careful: Linux system call clobbers CX and R11. # # 从父堆栈中复制 mp、gp、fn 以供子级使用 # 小心：Linux系统调用clobbers CX和R11 # 第三个参数 mp # 在clone后子线程开始运行时，R13、R9、R12的值会被拷贝给子线程 MOVQ mp+16(FP), R13 # R13 = mp # 第四个参数 gp，这里是 g0 MOVQ gp+24(FP), R9 # R9 = gp # 第五个参数 fn，mstart()函数 MOVQ fn+32(FP), R12 # R12 = fn # 2) 判断 mp 和 gp 的值是为 nil # 判断mp==nil和g0=nil # m 如果R13为0则跳转 CMPQ R13, $0 JEQ\tnog1 # g\t如果R9为0则跳转 CMPQ R9, $0 JEQ\tnog1 # 3) 找到需要设置TLS的地址值，也就是\u0026amp;m.tls[1] # 调用系统SYS_clone函数克隆线程 # 把m.tls地址存入R8寄存器 LEAQ m_tls(R13), R8 # R8 = TLS #ifdef GOOS_android # Android stores the TLS offset in runtime·tls_g. SUBQ runtime·tls_g(SB), R8 #else # R8 = -8(FS); R8=\u0026amp;m.tls[1]处地址 ADDQ $8, R8\t# ELF wants to use -8(FS) #endif # 添加CLONE_SETTLS标志 ORQ $0x00080000, DI #add flag CLONE_SETTLS(0x00080000) to call clone nog1: MOVL $SYS_clone, AX # 写入clone函数标志，然后调用系统函数 # 系统调用约定寄存器 DI SI DX R10 R8 R9 参数传参 # DI = flags # SI = stk # DX = 0 # R10 = 0 # R8 = R8=\u0026amp;m.tls[1] # R9 = gp SYSCALL # 4) 系统调用后，新创建的子线程和当前线程都会从系统调用中返回然后执行后面的代码 # # 那么从系统调用返回之后我们怎么知道哪个是父线程哪个是子线程，从而来决定它们的执行流程？ # 使用过fork系统调用的读者应该知道，我们需要通过返回值来判断父子线程： # 1. 系统调用的返回值如果是0则表示这是子线程 # 2. 不为0则表示这个是父线程 # 4.1) 父线程的处理逻辑 # In parent, return. # # 在父线程中，直接返回。 # 判断系统调用SYS_clone的返回值AX与0比较 CMPQ AX, $0 # JEQ 表示AX是0则执行 3(PC)跳过3条指令 JEQ\t3(PC) #跳转到子线程部分 # 这里是父线程直接把返回值写入栈，然后退出函数 MOVL AX, ret+40(FP)\tRET\t# 4.2) 子线程的处理逻辑，设置SP，判断mp和gp，设置mp.procid # In child, on new stack. # # 在子线程中，在new栈上。 # 新创建的子线程从这里开始，注意一下代码是在子线程中，寄存器也是子线程的 # 设置CPU栈顶寄存器指向子线程的栈顶，这条指令看起来是多余的？内核应该已经把SP设置好了 MOVQ SI, SP # If g or m are nil, skip Go-related setup. # # 如果 g 或 m 为 nil，跳过 Go-related 设置。 # m\t新创建的m结构体对象的地址，由父线程保存在R13寄存器中的值被复制到了子线程 CMPQ R13, $0 # R13 = mp JEQ\tnog2 # R13 为 0 时跳转 # g\tm.g0的地址，由父线程保存在R9寄存器中的值被复制到了子线程 CMPQ R9, $0 # R9 = gp JEQ\tnog2 # R9 为 0 时跳转 # Initialize m-\u0026gt;procid to Linux tid # # 将m-\u0026gt;procid初始化为Linux tid。 MOVL $SYS_gettid, AX\t# 通过gettid()系统调用获取线程ID（tid） SYSCALL MOVQ AX, m_procid(R13) # m.procid = tid # Set FS to point at m-\u0026gt;tls. # # 新线程刚刚创建出来，还未设置线程本地存储，即m结构体对象还未与工作线程关联起来， # 下面的指令负责设置新线程的TLS，把m对象和工作线程关联起来 # 这两行代码在go1.18中消失了，原因在于CLONE_SETTLS配合参数和R8寄存器在clone中被设置了 # LEAQ m_tls(R13), DI # 取m.tls字段的地址\t# CALL runtime·settls(SB) # In child, set up new stack get_tls(CX)\t# CX=\u0026amp;m.tls[1]; CX=TLS MOVQ R13, g_m(R9) # g0.m = m MOVQ R9, g(CX) # m.tls[0]=\u0026amp;g0 # R14=\u0026amp;g0 R14寄存器主要存储当前正在运行的goroutine MOVQ R9, R14 # set g register CALL runtime·stackcheck(SB) # 检查 SP 是否在 [g-\u0026gt;stack.lo, g-\u0026gt;stack.hi) 范围内 nog2: # Call fn. This is the PC of an ABI0 function. # # 调用mstart()函数开始调度循环 CALL R12\t# 永不返回 # It shouldn\u0026#39;t return. If it does, exit that thread. MOVL $111, DI MOVL $SYS_exit, AX SYSCALL JMP\t-3(PC) // keep exiting stackcheck() 检查SP是否在[g-\u0026gt;stack.lo, g-\u0026gt;stack.hi)范围内。 文件位置：go1.19.3/src/runtime/sys_linux_amd64.s。 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 # check that SP is in range [g-\u0026gt;stack.lo, g-\u0026gt;stack.hi) TEXT runtime·stackcheck(SB), NOSPLIT, $0-0 get_tls(CX) # CX=TLS MOVQ g(CX), AX # AX=g0 # g0.stack.hi 与 SP 比较 CMPQ (g_stack+stack_hi)(AX), SP JHI\t2(PC) CALL runtime·abort(SB) # g0.stack.lo 与 SP 比较 CMPQ SP, (g_stack+stack_lo)(AX) JHI\t2(PC) CALL runtime·abort(SB) RET ","permalink":"https://heliu.site/posts/golang/goroutine/newm/","summary":"Golang wakep()和newm()函数介绍。","title":"工作线程的唤醒和创建"},{"content":" goroutine的主动调度是指当前正在运行的goroutine通过直接调用runtime.Gosched()函数暂时放弃运行而发生的调度。 主动调度完全是【用户代码】自己控制的，我们根据代码就可以预见什么地方一定会发生调度。 使用示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package main import ( \u0026#34;runtime\u0026#34; \u0026#34;sync\u0026#34; ) const N = 1 func main() { var wg sync.WaitGroup wg.Add(N) for i := 0; i \u0026lt; N; i++ { go start(\u0026amp;wg) } wg.Wait() } func start(wg *sync.WaitGroup) { for i := 0; i \u0026lt; 1000; i++ { runtime.Gosched() // 这里会让出调度 } wg.Done() } Gosched() Gosched放弃当前CPU运行权限，允许其他goroutine运行。 它会挂起当前的goroutine，因此执行会自动恢复。 文件位置：go1.19.3/src/runtime/proc.go。 314 315 316 317 318 319 320 321 322 323 324 325 // Gosched yields the processor, allowing other goroutines to run. It does not // suspend the current goroutine, so execution resumes automatically. func Gosched() { // amd64 linux平台是空函数 checkTimeouts()\t// mcall 函数在 user goroutine 中已分析，切换到g0栈调用 gosched_m 函数。 // 相关 user goroutine 寄存器信息在 mcall 函数中被保存了。 mcall(gosched_m) // goroutine 再次被调度起来则从这里开始运行 } gosched_m() 根据mcall()函数知道这里的gp *g是user goroutine，不是g0。 但是当前已经切换到g0栈了。 文件位置：go1.19.3/src/runtime/proc.go。 3381 3382 3383 3384 3385 3386 3387 3388 3389 // Gosched continuation on g0. func gosched_m(gp *g) { // traceback 不关注 if trace.enabled {\ttraceGoSched() } // gp is user goroutine goschedImpl(gp) } goschedImpl() user goroutine修改状态后与M解绑，加入全局队列池中，开启下一轮调度循环。 文件位置：go1.19.3/src/runtime/proc.go。 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 func goschedImpl(gp *g) { // readgstatus(gp) -\u0026gt; atomic.Load(\u0026amp;gp.atomicstatus) // 原子获取 user goroutine 的状态 status := readgstatus(gp) // 判断 user goroutine 状态 if status\u0026amp;^_Gscan != _Grunning { dumpgstatus(gp) throw(\u0026#34;bad g status\u0026#34;) } // 当前 user goroutine 即将被挂起，需要修改状态 // _Grunning： goroutine可能正在运行用户代码，它的栈归自己所有。 // _Grunnable：goroutine应该在某个runq中，当前并没有在运行用户代码，它的栈不归自己所有。 casgstatus(gp, _Grunning, _Grunnable) // 设置当前m.curg = nil, gp.m = nil 解除m与g之前的绑定关系 dropg()\tlock(\u0026amp;sched.lock) // 把gp放入sched的全局运行队列runq globrunqput(gp)\tunlock(\u0026amp;sched.lock) // 在schedule函数中会判断 m.locks != 0 判断 // 因此当前M还存在锁情况下不要让出 schedule() // 进入新一轮调度 } drop() dropg去除m和当前goroutine m-\u0026gt;curg(简称gp)之间的关联。 通常，调用者会将gp的状态设置为不运行状态，然后立即调用dropg完成工作。调用者还负责安排gp在适当的时间使用ready重新启动。 在调用dropg并安排稍后准备好gp之后，调用者可以做其他工作，但最终应该调用schedule来重新启动这个m上的goroutine的调度。 文件位置：go1.19.3/src/runtime/proc.go。 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 // dropg removes the association between m and the current goroutine m-\u0026gt;curg (gp for short). // Typically a caller sets gp\u0026#39;s status away from Grunning and then // immediately calls dropg to finish the job. The caller is also responsible // for arranging that gp will be restarted using ready at an // appropriate time. After calling dropg and arranging for gp to be // readied later, the caller can do other work but eventually should // call schedule to restart the scheduling of goroutines on this m. func dropg() { _g_ := getg() // g0 // gp.m = nil setMNoWB(\u0026amp;_g_.m.curg.m, nil) // m.curg = nil setGNoWB(\u0026amp;_g_.m.curg, nil) } setMNoWB() 文件位置：go1.19.3/src/runtime/runtime2.go。 307 308 309 310 311 312 313 314 // setMNoWB performs *mp = new without a write barrier. // For times when it\u0026#39;s impractical to use an muintptr. // //go:nosplit //go:nowritebarrier func setMNoWB(mp **m, new *m) { (*muintptr)(unsafe.Pointer(mp)).set(new) // *mp = new } setGNoWB() 文件位置：go1.19.3/src/runtime/runtime2.go。 273 274 275 276 277 278 279 280 // setGNoWB performs *gp = new without a write barrier. // For times when it\u0026#39;s impractical to use a guintptr. // //go:nosplit //go:nowritebarrier func setGNoWB(gp **g, new *g) { (*guintptr)(unsafe.Pointer(gp)).set(new) // *gp = new } globrunqput() 把gp放到全局可运行队列中。sched.lock必须被持有。 可能在STW期间运行，因此不允许写屏障。 文件位置：go1.19.3/src/runtime/proc.go。 5563 5564 5565 5566 5567 5568 5569 5570 5571 5572 5573 5574 5575 // Put gp on the global runnable queue. // sched.lock must be held. // May run during STW, so write barriers are not allowed. // //go:nowritebarrierrec func globrunqput(gp *g) { // sched.lock 锁必须被持有 assertLockHeld(\u0026amp;sched.lock) // gp 加入全局队列中 sched.runq.pushBack(gp) sched.runqsize++ } ","permalink":"https://heliu.site/posts/golang/goroutine/gosched/","summary":"Golang runtime.Gosched()函数主动让出CPU介绍。","title":"主动让出调度"},{"content":" 抢占调度（goroutine因运行时间过长）。 抢占调度：因goroutine运行时间过长而发生的。 goroutine因读写channel等阻塞而导致的被动调度，以及通过调用Gosched()函数发起的主动调度。 抢占标识 retake() _Prunning，表示对应的goroutine正在运行，如果其运行时间超过了10毫秒则对需要抢占。 _Psyscall，表示对应的goroutine正在内核执行系统调用，此时需要根据多个条件来判断是否需要抢占。 该函数只在sysmon监控线程中被调用。 参数now int64：当前时间。 返回值uint32：处于系统调用中需要抢占P的数量。 文件位置：go1.19.3/src/runtime/proc.go。 // forcePreemptNS is the time slice given to a G before it is // preempted. // // forcePreemptNS 是在G被抢占之前给它的时间片。 const forcePreemptNS = 10 * 1000 * 1000 // 10ms 5285 5286 5287 5288 5289 5290 5291 5292 5293 5294 5295 5296 5297 5298 5299 5300 5301 5302 5303 5304 5305 5306 5307 5308 5309 5310 5311 5312 5313 5314 5315 5316 5317 5318 5319 5320 5321 5322 5323 5324 5325 5326 5327 5328 5329 5330 5331 5332 5333 5334 5335 5336 5337 5338 5339 5340 5341 5342 5343 5344 5345 5346 5347 5348 5349 5350 5351 5352 5353 5354 5355 5356 5357 5358 5359 5360 5361 5362 5363 5364 5365 5366 5367 5368 5369 5370 5371 5372 5373 5374 5375 5376 5377 5378 5379 5380 5381 5382 5383 5384 5385 5386 5387 5388 5389 5390 5391 5392 5393 5394 5395 5396 5397 5398 5399 5400 5401 5402 5403 5404 5405 5406 5407 5408 5409 5410 5411 5412 5413 5414 5415 5416 5417 5418 5419 5420 5421 5422 5423 5424 5425 5426 5427 5428 5429 5430 5431 5432 5433 5434 5435 5436 5437 5438 5439 5440 5441 5442 5443 5444 5445 // 检查所有的P查看是否存在运行时间太长的G需要设置抢占请求。 // 1. goroutine运行时间超过10ms时需要抢占。 // 2. goroutine陷入系统调用，运行时间超过10ms或在第二轮来是sysmon系统调用还没返回时。 // 陷入系统调用而抢占P的情况： // 1. 运行时间超过10ms，可能一开始就陷入系统调用，或中途陷入系统调用。不论那种情况都应该抢占。 // 2. 运行时间没到10ms，但是两轮sysmon了还是在系统调用中，需要抢占P。 func retake(now int64) uint32 { n := 0 // 1) 锁住 allp，现在需要遍历所有的P查看是否存在运行时间过长而需要抢占的G。 // Prevent allp slice changes. This lock will be completely // uncontended unless we\u0026#39;re already stopping the world. // // 防止 allp 切片更改。 除非我们已经STW，否则这把锁将是完全无人争夺的 lock(\u0026amp;allpLock) // allp加锁 // 2) 遍历所有的P，根据运行时间是否设置抢占标志。 // We can\u0026#39;t use a range loop over allp because we may // temporarily drop the allpLock. Hence, we need to re-fetch // allp each time around the loop. // // 我们不能使用range来遍历allp，因为我们可能会暂时放弃allpLock锁（会暂时解锁）。 // 因此，我们需要在每次循环中重新获取allp。 // range会拷贝，因此增长或缩小了allp不会实时变化。 for i := 0; i \u0026lt; len(allp); i++ { // 遍历所有的P _p_ := allp[i] // 2.1) 未初始化的P跳过。可能正在增长P。 if _p_ == nil { // This can happen if procresize has grown // allp but not yet created new Ps. // // 如果procresize已经增长了所有p，但还没有创建新的p，则可能发生这种情况。 continue } // 2.2) 判断是否运行时间过长 // _p_.sysmontick用于sysmon线程记录被监控p的系统调用时间和运行时间 // type sysmontick struct { // schedtick uint32 // 调度器调度次数 // schedwhen int64 // 上次调度时间 // // syscalltick uint32 // 系统调用次数 // syscallwhen int64 // 上次调度时间 // } pd := \u0026amp;_p_.sysmontick // 与sysmon线程相关 // _Prunning：对应的goroutine正在运行 // _Psyscall：对应的goroutine正在内核执行系统调用 s := _p_.status // P当前所处状态 _Prunning，_Psyscall // 标记当前P是否已设置抢占请求 // false.未设置 true.已设置 sysretake := false // 2.3) 先判断 schedtick 和 schedwhen 时间是否运行时间过长。 // G的运行时间是包括系统调用的时间的。 if s == _Prunning || s == _Psyscall { // Preempt G if it\u0026#39;s running for too long.\t// // 如果G运行太久，就抢占它。 // _p_.schedtick调度次数，该值是在P上的，记录当前的调度次数。 // 注意区别sysmontick上的schedtick t := int64(_p_.schedtick) // _p_.schedtick：每发生一次调度，调度器++该值 // pd.schedtick == t说明(pd.schedwhen～now)这段时间未发生过调度（这种情况也就是我们要处理的抢占情况）， // 所以这段时间是同一个goroutine一直在运行，下面检查一直运行是否超过了10毫秒，否则则是发生过调度 if int64(pd.schedtick) != t { // 如果不相等说明是一次新的调度 // 监控线程监控到一次新的调度，所以重置跟sysmon相关的schedtick和schedwhen变量 // 2.4) 检测到下次调度，更新调度时间 pd.schedtick = uint32(t) pd.schedwhen = now } else if pd.schedwhen+forcePreemptNS \u0026lt;= now { // 2.4) 本次调度已超过 10ms，设置抢占标识。 // 从某goroutine第一次被sysmon线程监控到正在运行一直运行到现在超过了10毫秒 // 抢占用户代码的goroutine时是需要判断是否能抢占的条件的。 preemptone(_p_) // 设置抢占请求，非系统调用时在这里后就结束了。 // In case of syscall, preemptone() doesn\u0026#39;t // work, because there is no M wired to P. // // 在系统调用的情况下，preemptone()不起作用，因为M没有连接到P。此时已经陷入到系统调度中，不会响应请求。 sysretake = true // 已标记了抢占 } // 2.4) 本地调度运行时间还未到10ms。 } // 2.5) P处于系统调用之中时。 if s == _Psyscall { // Retake P from syscall if it\u0026#39;s there for more than 1 sysmon tick (at least 20us). // // 如果P存在超过1个sysmon tick(至少20us)，则从sycall中重新取P。 // _p_.syscalltick用于记录系统调用的次数，主要由工作线程在完成系统调用之后++ t := int64(_p_.syscalltick)\t// sysretake = false：前面没有设置抢占标志。 // 1. 本轮调度G还没到达10ms。 // 2. 新的一轮调度，已经重置了。 // int64(pd.syscalltick) != t：新的一轮系统调度了。 if !sysretake \u0026amp;\u0026amp; int64(pd.syscalltick) != t { pd.syscalltick = uint32(t) // update syscalltick pd.syscallwhen = now // update syscallwhen continue } // 2.6) sysretake == true || (sysretake == false \u0026amp;\u0026amp; int64(pd.syscalltick) == t) // 1. sysretake == true：前面已经设置了抢占请求，G运行时间超过了10ms，现在处于系统调用中。 // 2. (sysretake == false \u0026amp;\u0026amp; int64(pd.syscalltick) == t)： // goroutine没有超过10ms，但是监控先到第二轮了，现在处于系统调用中。 // 因此这种情况取决于监控线程的调度时间间隔。 // On the one hand we don\u0026#39;t want to retake Ps if there is no other work to do, // but on the other hand we want to retake them eventually // because they can prevent the sysmon thread from deep sleep. // // 一方面我们不想在没有其他工作的情况下重新获取 Ps， // 另一方面我们希望最终重新获取它们，因为它们可以防止 sysmon 线程深度睡眠。 // 只要满足下面三个条件中的任意一个，则抢占该p，否则不抢占 // 1. p的运行队列里面有等待运行的goroutine。（有需要运行的goroutine，需要抢占P） // 2. 没有无所事事的p，也就是没有自旋的P或空闲的P。（系统很忙，需要抢占P） // 3. 从上一次监控线程观察到p对应的m处于系统调用之中到现在已经超过10了毫秒。（系统调用时间太长，需要抢占P） if runqempty(_p_) \u0026amp;\u0026amp; atomic.Load(\u0026amp;sched.nmspinning)+atomic.Load(\u0026amp;sched.npidle) \u0026gt; 0 \u0026amp;\u0026amp; pd.syscallwhen+10*1000*1000 \u0026gt; now { // 不需要抢占：_p_本地队列为空 \u0026amp;\u0026amp; 存在自旋或空闲的P（系统不忙） \u0026amp;\u0026amp; 系统调用时间还没有超过了10ms continue } // Drop allpLock so we can take sched.lock. // // 这里是前面不能有for range的原因，解锁这段时间可能allp会发生变化。 unlock(\u0026amp;allpLock) // 解锁 allpLock // Need to decrement number of idle locked M\u0026#39;s // (pretending that one more is running) before the CAS. // Otherwise the M from which we retake can exit the syscall, // increment nmidle and report deadlock. // // 需要在CAS之前减少空闲锁定M的数量(假装还有一个正在运行)。 // 否则，我们重新获取的M可以退出系统调用，增加nmid并报告死锁。 incidlelocked(-1) // sched.nmidlelocked += -1 // 这里使用Cas修改P的使用权，原因是此时此刻正好存在系统调用返回了，也正在获取P的使用权 // 如果使用权获取成功则调用handoffp()寻找新的工作线程来接管这个p // _Pidle：空闲状态。此时的P没有被用来执行用户代码或调度器代码，通常位于空闲链表中，能够被调度器获取， // 它的状态可能正在由空闲转变成其他状态。P的所有权归空闲链表或某个正在改变它状态的线程所有，本地runq为空。 if atomic.Cas(\u0026amp;_p_.status, s, _Pidle) { if trace.enabled { traceGoSysBlock(_p_) traceProcStop(_p_) } n++ _p_.syscalltick++ // 系统调度次数加一 // 尝试寻找一个新的m出来接管P // 抢占陷入系统调用的P时，没有多余的条件 handoffp(_p_)\t} incidlelocked(1) lock(\u0026amp;allpLock) } } unlock(\u0026amp;allpLock) return uint32(n) } incidlelocked() 文件位置：go1.19.3/src/runtime/proc.go。 5505 5506 5507 5508 5509 5510 5511 5512 5513 5514 func incidlelocked(v int32) { lock(\u0026amp;sched.lock) // nmidlelocked 锁定等待工作的M的数量 // 只会在该函数中加减，在checkdead()函数中判断 sched.nmidlelocked += v if v \u0026gt; 0 { checkdead() } unlock(\u0026amp;sched.lock) } preemptone() sysmon线程如果监控到某个goroutine连续运行超过了10毫秒，则会调用preemptone()函数向该goroutine发出抢占请求。 告诉在处理器P上运行的goroutine停止。 这个函数只是尽了最大努力。它可能会错误地没有通知goroutine。也可能会通知错误的goroutine。 即使它通知了正确的goroutine，如果goroutine同时执行newstack，它可能会忽略请求。 不需要锁。如果发出抢占请求，则返回true。 实际的抢占将在未来的某个时间点发生，并且将由gp-\u0026gt;status不再是Grunning表示。设置抢占请求。 该函数会在retake()函数中调用，GC期间调用。 可以看出，preemptone函数只是简单的设置了被抢占goroutine对应的g结构体中的 preempt成员为true和stackguard0成员为stackPreempt（stackPreempt是一个常量0xfffffffffffffade，是非常大的一个数）就返回了，并未真正强制被抢占的goroutine暂停下来。 既然设置了一些抢占标志，那么就一定需要对这些标志进行处理，下面我们就来分析被抢占的goroutine如何处理这些标志去响应监控线程提出的抢占请求。 文件位置：go1.19.3/src/runtime/proc.go。 5378 5379 5380 5381 5382 5383 5384 5385 5386 5387 5388 5389 5390 5391 5392 5393 5394 5395 5396 5397 5398 5399 5400 5401 5402 5403 5404 5405 5406 5407 5408 5409 5410 5411 5412 5413 5414 5415 5416 5417 5418 5419 5420 5421 5422 5423 5424 5425 5426 5427 5428 5429 5430 5431 5432 5433 5434 5435 // Tell the goroutine running on processor P to stop. // This function is purely best-effort. It can incorrectly fail to inform the // goroutine. It can inform the wrong goroutine. Even if it informs the // correct goroutine, that goroutine might ignore the request if it is // simultaneously executing newstack. // No lock needs to be held. // Returns true if preemption request was issued. // The actual preemption will happen at some point in the future // and will be indicated by the gp-\u0026gt;status no longer being // Grunning func preemptone(_p_ *p) bool { // 1) 抢占P的关联的m mp := _p_.m.ptr() // mp := m // 2) 抢占的P没有绑定M，或抢占的P的M与当前运行G的M一致【不设置抢占标志】 // 1. mp == nil：可能来自sysmon抢占空闲的P的时候，这时候P是没有绑定M的。 // 2. mp == getg().m：抢占的是自己，很大可能这种情况来自GC在等待其他P停下来的时候。 if mp == nil || mp == getg().m { return false } // 3) 抢占的工作线程刚好处理完goroutine，或抢占的工作线程正在g0中【不设置抢占标志】 gp := mp.curg // mp工作线程上正在运行的goroutine // 1. gp == nil：当前工作线程正在执行的goroutine刚好运行完被调离M时。 // 2. gp == mp.g0：当前正在g0上，可能在执行调度代码。 if gp == nil || gp == mp.g0 { return false } gp.preempt = true // 标记正在运行的P的g设置抢占标志 // Every call in a goroutine checks for stack overflow by // comparing the current stack pointer to gp-\u0026gt;stackguard0. // Setting gp-\u0026gt;stackguard0 to StackPreempt folds // preemption into the normal stack overflow check. // // goroutine中的每个调用都通过将当前堆栈指针与gp-\u0026gt;stackguard0进行比较来检查堆栈溢出。 // 设置gp-\u0026gt;stackguard0为StackPreempt将抢占转换为正常的栈溢出检查。 // stackPreempt是一个常量0xfffffffffffffade，是非常大的一个数。 gp.stackguard0 = stackPreempt // 设置stackguard0使被抢占的goroutine去处理抢占请求 // Request an async preemption of this P. // // 请求这个P的异步抢占。这种情况是对于没有调用任何函数的goroutine，没有抢占机会的情况下。 // 1. preemptMSupported：其中的 preemptMSupported 是个常量，因为受硬件特性的限制， // 在某些平台上是无法支持这种抢占的。 // 2. debug.asyncpreemptoff：则是让用户可以通过 GODEBUG 环境变量来禁用异步抢占， // 默认情况下是被启用的。 if preemptMSupported \u0026amp;\u0026amp; debug.asyncpreemptoff == 0 { // 在P的数据结构中也新增了一个preempt字段，这里会把它设置为true。 _p_.preempt = true // 实际上抢占操作是由 preemptM 函数完成的。 preemptM(mp)\t// 该函数发起异步抢占给MP发送抢占信号 } return true } handoffp() 从系统调用中关闭P或锁定M。总是在没有P的情况下运行，因此不允许有写屏障。 handoffp()函数主要任务是通过各种条件判断是否需要启动工作线程来接管_p_，如果不需要则把_p_放入P的全局空闲队列。 _p_的本地运行队列或全局运行队列里面有待运行的goroutine。 需要帮助gc完成标记工作。 系统比较忙，所有其它_p_都在运行goroutine，需要帮忙。 所有其它P都已经处于空闲状态，如果需要监控网络连接读写事件，则需要启动新的m来poll网络连接。 文件位置：go1.19.3/src/runtime/proc.go。 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 // Hands off P from syscall or locked M. // Always runs without a P, so write barriers are not allowed. // //go:nowritebarrierrec func handoffp(_p_ *p) { // handoffp must start an M in any situation where // findrunnable would return a G to run on _p_. // // 在findrunnable返回G并在_p_上运行的任何情况下，handffp必须开始一个M。 // if it has local work, start it straight away // // 如果它有本地工作，需要启动m来接管 if !runqempty(_p_) || sched.runqsize != 0 { startm(_p_, false) // 创建M来接管P return } // if there\u0026#39;s trace work to do, start it straight away if (trace.enabled || trace.shutdown) \u0026amp;\u0026amp; traceReaderAvailable() { startm(_p_, false) return } // if it has GC work, start it straight away // // GC正在工作，也需要启动m来接管 if gcBlackenEnabled != 0 \u0026amp;\u0026amp; gcMarkWorkAvailable(_p_) { startm(_p_, false) return } // no local work, check that there are no spinning/idle M\u0026#39;s, // otherwise our help is not required // // 没有本地工作，检查是否有 spinning/idle 的M，否则不需要我们的帮助。 // 1. atomic.Load(\u0026amp;sched.nmspinning)+atomic.Load(\u0026amp;sched.npidle) == 0：没有自旋的M和空闲的P时。 // 2. atomic.Cas(\u0026amp;sched.nmspinning, 0, 1)：sched.nmspinning = 1。 if atomic.Load(\u0026amp;sched.nmspinning)+atomic.Load(\u0026amp;sched.npidle) == 0 \u0026amp;\u0026amp; atomic.Cas(\u0026amp;sched.nmspinning, 0, 1) { // TODO: fast atomic startm(_p_, true) // 这时候启动的M绑定P可以起去其他P中偷取任务，如果存在空闲的P则表示其他P不忙 return } lock(\u0026amp;sched.lock) // GC正在STW等待时。 if sched.gcwaiting != 0 { _p_.status = _Pgcstop // 修改状态为GC而停下 sched.stopwait-- // 因为GC而停下来 // 当前STW要求的P全部停下来时，就可以唤醒等待在sched.stopnote上的发起STW的线程了。 if sched.stopwait == 0 { notewakeup(\u0026amp;sched.stopnote) } unlock(\u0026amp;sched.lock) return } if _p_.runSafePointFn != 0 \u0026amp;\u0026amp; atomic.Cas(\u0026amp;_p_.runSafePointFn, 1, 0) { sched.safePointFn(_p_) sched.safePointWait-- if sched.safePointWait == 0 { notewakeup(\u0026amp;sched.safePointNote) } } // 全局队列池有G需要处理时。 if sched.runqsize != 0 { unlock(\u0026amp;sched.lock) startm(_p_, false) return } // If this is the last running P and nobody is polling network, // need to wakeup another M to poll network. // // 如果这是最后一个运行的P并且没有其他线程在阻塞式等待netpoll，需要唤醒一个M来处理netpoll。 // 1. sched.npidle == uint32(gomaxprocs-1)：当前是最后一个空闲P // 2. atomic.Load64(\u0026amp;sched.lastpoll) != 0：没有其他线程在阻塞式访问netpoll。 if sched.npidle == uint32(gomaxprocs-1) \u0026amp;\u0026amp; atomic.Load64(\u0026amp;sched.lastpoll) != 0 { unlock(\u0026amp;sched.lock) startm(_p_, false) return } // The scheduler lock cannot be held when calling wakeNetPoller below // because wakeNetPoller may call wakep which may call startm. // // 当调用wakeNetPoller时，调度器锁不能保持，因为wakeNetPoller可能会调用wakeep，而后者可能会调用startm。 when := nobarrierWakeTime(_p_) // 最新timer触发时间点 pidleput(_p_, 0) //无事可做，把p放入全局空闲队列 unlock(\u0026amp;sched.lock) if when != 0 { wakeNetPoller(when) } // 走到这里不会抢占P } 响应抢占请求 抢占的相关函数调用链morestack_noctxt()-\u0026gt;morestack()-\u0026gt;newstack()。 从源代码中morestack()函数的注释可以知道，该函数会被编译器自动插入到函数 序言(prologue) 中。 morestack_noctxt() 文件位置：go1.19.3/src/runtime/asm_amd64.s。 574 575 576 577 # morestack but not preserving ctxt. TEXT runtime·morestack_noctxt(SB),NOSPLIT,$0 MOVL $0, DX # DX = 0，DX寄存器被用作函数调用的隐藏传值 JMP\truntime·morestack(SB) # 注意这里使用的是JMP不是CALL因此不是函数调用 我们假设是在main.main函数序言中调用了morestack_noctxt()函数，则函数的栈帧结构如下： // +10 | // ---------------------------- runtime.main SP // +08 | runtime.main callback // ---------------------------- main.main SP // +00 | main.main callback // ---------------------------- morestack_noctxt SP // // runtime·morestack(SB)是通过JMP调用的，所以没有重新分配栈帧 morestack() 当需要更多栈时，在函数prolog期间调用。 回溯例程将g0上的morestack视为栈的顶部(例如，morestack调用newstack调用调度器调用newm调用gc)， 因此我们必须记录参数大小。为此，它没有参数。 文件位置：go1.19.3/src/runtime/asm_amd64.s。 该函数，保护调用者信息，切换到g0栈调用runtime·newstack方法。 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 # Called during function prolog when more stack is needed. # # The traceback routines see morestack on a g0 as being # the top of a stack (for example, morestack calling newstack # calling the scheduler calling newm calling gc), so we must # record an argument size. For that purpose, it has no arguments. TEXT runtime·morestack(SB),NOSPLIT,$0-0 # Cannot grow scheduler stack (m-\u0026gt;g0). get_tls(CX) # CX = \u0026amp;m.tls[1] MOVQ g(CX), BX # BX = m.tls[0] = g MOVQ g_m(BX), BX # BX = g.m MOVQ m_g0(BX), SI # SI = m.g0 CMPQ g(CX), SI # 比较当前g是否是g0 JNE\t3(PC) # 判断不为零时则跳转 # runtime·badmorestackg0 错误信息 \u0026#34;morestack()函数在g0栈上被调用\u0026#34; CALL runtime·badmorestackg0(SB) # int 3 进入中断指令，这是一个调试指令 CALL runtime·abort(SB) # Cannot grow signal stack (m-\u0026gt;gsignal). MOVQ m_gsignal(BX), SI # SI = m.gsignal CMPQ g(CX), SI JNE\t3(PC) # 判断不为零时则跳转 # runtime·badmorestackgsignal 错误信息 \u0026#34;morestack()函数在gsignal上被调用\u0026#34; CALL runtime·badmorestackgsignal(SB) CALL runtime·abort(SB) # Called from f. # Set m-\u0026gt;morebuf to f\u0026#39;s caller. # # 从f调用。设置m-\u0026gt;morebuf为f的调用者。 # NOP SP 指令意义： # 1. NOP SP指令不做任何操作。具体来说，它会将堆栈指针(SP)向后移动0个字节，这实际上是没有任何效果的。 # 2. 在 Go 的汇编语言中，有时需要使用 \u0026#34;NOP SP\u0026#34; 这条指令来进行指令对齐，但这也可能会导致 vet 工具产生误报，因为它会认为这会导致堆栈偏移量的改变。 # \u0026#34;# tell vet SP changed - stop checking offsets\u0026#34; 这行注释的意义： # 1. 为了避免这种情况，程序员可以添加这个注释来告诉vet工具，实际上没有对堆栈偏移量进行任何更改，因此vet工具可以停止检查堆栈偏移量。 # 2. 这句话的意思是，程序员在添加NOP SP指令时遇到了vet工具的误报问题，为了解决这个问题，他们添加了这个注释，告诉vet工具不需要继续检查堆栈偏移量。 # 指令对齐：是指将指令地址对齐到一定的边界上，使得指令的执行效率更高。 # 1. 在计算机系统中，CPU 通常需要从内存中读取指令并执行它们，这是一个非常耗时的过程。 # 2. 为了提高执行效率，CPU 需要在访问内存时保持一定的对齐方式，以便更快地读取指令并进行处理。 # 3. 在指令对齐中，指令地址通常被要求对齐到一个特定的边界，通常是2的幂次方，如2、4、8等。 # 4. 这意味着指令地址的低位必须是0，这使得 CPU 可以更快地读取指令并进行处理，从而提高程序的执行效率。 # 5. 在编写汇编语言程序时，程序员通常需要手动对指令进行对齐。这可以通过添加一些无操作指令，如NOP指令，来实现。 # 6. 这些指令不会对程序的执行产生任何影响，只是用来填充指令流中的空隙，以确保指令地址对齐。 # 7. 这些操作可以帮助 CPU 更快地读取指令并提高程序的执行效率。 NOP\tSP\t# tell vet SP changed - stop checking offsets # 以下代码保存调用者信息，比如在main.main的序言中调了morestack_noctxt()-\u0026gt;morestack()函数，需要保存的是main.main的信息 # 8(SP)：main函数在调用morestack_noctxt之前的rsp寄存器 # 通过上面函数栈帧的分配 8(SP) 是runtime.main函数的返回地址，注意这里是保存在m上的，m-\u0026gt;morebuf # 保存到m-\u0026gt;morebuf用于提供给接下来的newstack()函数使用 MOVQ 8(SP), AX\t# f\u0026#39;s caller\u0026#39;s PC; MOVQ AX, (m_morebuf+gobuf_pc)(BX) # m.morebuf.gobuf.pc=AX # 16(SP)：调用者函数的SP，也就是runtime.main的SP寄存器地址，注意这里是 LEAQ 指令 LEAQ 16(SP), AX\t# f\u0026#39;s caller\u0026#39;s SP # AX = 16(SP); 该值是runtime.main函数的rsp寄存器存储的地址 MOVQ AX, (m_morebuf+gobuf_sp)(BX) # m.morebuf.gobuf.sp=AX get_tls(CX) # CX = \u0026amp;m.tls[1] MOVQ g(CX), SI # SI = m.tls[0] = g; 这里是g，不是g0 MOVQ SI, (m_morebuf+gobuf_g)(BX) # m.morebuf.gobuf.g = g # 到这里我们已经在m-\u0026gt;morebuf保存好了调用者runtime.main的rip、rsp、g相关信息 # Set g-\u0026gt;sched to context in f. # # 将 g-\u0026gt;sched 设置为f的上下文，这才是需要恢复的现场数据 # SP栈顶寄存器现在指向的是morestack_noctxt函数的返回地址，注意下面都是保存在g上的，g-\u0026gt;sched不是g0上 # 0(SP)：通过上面函数栈帧的分配 0(SP) 是main.main函数的返回地址，也就是rip中的值就是main.main的下条代码地址 MOVQ 0(SP), AX # f\u0026#39;s PC # g.sched.gobuf.pc = AX MOVQ AX, (g_sched+gobuf_pc)(SI) # 执行完morestack_noctxt函数之后应该返回去继续执行指令的地址 AX # 8(SP)：调用者函数的SP，也就是main.main的SP寄存器地址，这个地址是没有压入rip指令数据前的地址，注意这里是 LEAQ 指令 LEAQ 8(SP), AX # f\u0026#39;s SP; MOVQ AX, (g_sched+gobuf_sp)(SI) # g.sched.gobuf.sp = AX # 由于BP寄存器的值一致没有变，所以这里BP寄存器还是指向main.main的栈底 MOVQ BP, (g_sched+gobuf_bp)(SI) # g.sched.gobuf.bp = BP # DX寄存器被设置为了0，在runtime·morestack_noctxt()函数中 MOVQ DX, (g_sched+gobuf_ctxt)(SI)# g.sched.gobuf.ctxt = DX; # 到这里当前g-\u0026gt;sched已保存好了恢复到main.main的现场，包括rip、rsp、rbp、rdx # Call newstack on m-\u0026gt;g0\u0026#39;s stack. # 切换到g0栈，并设置tls的g为g0 MOVQ m_g0(BX), BX # BX = g0 # 设置TLS中的g为g0 MOVQ BX, g(CX) # m.tls[0] = g0 # 把g0栈的栈顶寄存器的值恢复到CPU的寄存器，达到切换栈的目的，下面这一条指令执行之前， # CPU还是使用的调用此函数的g的栈，执行之后CPU就开始使用g0的栈了 MOVQ (g_sched+gobuf_sp)(BX), SP # rsp = g0.sched.gobuf.sp CALL runtime·newstack(SB) # 调用 newstack() 函数 CALL runtime·abort(SB) # crash if newstack returns RET 汇编语言\u0026quot;int 3\u0026quot;是一个中断指令，它向操作系统发出一个调试信号，要求在程序的当前位置停止执行并进入调试器。 通常，调试器会在此处暂停程序的执行，并允许程序员检查程序状态、变量值和程序流程等信息，以帮助他们调试程序。 TEXT runtime·abort(SB),NOSPLIT,$0-0 INT\t$3 loop: JMP\tloop newstack() 该函数主要有两个职责：一个是【扩栈】，另一个是响应sysmon提出的【抢占请求】。 newstack()函数首先检查g.stackguard0是否被设置为stackPreempt，如果是则表示sysmon已经发现我们运行得太久了并对我们发起了抢占请求。 当需要更多堆栈时从runtime·morestack调用。分配更大的堆栈并重新定位到新堆栈。对于固定的平摊代价，堆栈增长是乘法的。 g-\u0026gt;atomicstatus将在进入时进行Grunning或Gscanrunning。调度程序试图停止这个g，然后它将设置preemptStop。 这必须是nowritebarrierrec，因为它可以作为堆栈增长的一部分从其他nowritebarrierrec函数调用，但编译器不会检查这一点。 go:nowritebarrierrec：编译器不插入写屏障相关代码，包括当前函数以及调用的任何函数中。 文件位置：go1.19.3/src/runtime/stack.go。 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 // Called from runtime·morestack when more stack is needed. // Allocate larger stack and relocate to new stack. // Stack growth is multiplicative, for constant amortized cost. // // g-\u0026gt;atomicstatus will be Grunning or Gscanrunning upon entry. // If the scheduler is trying to stop this g, then it will set preemptStop. // // This must be nowritebarrierrec because it can be called as part of // stack growth from other nowritebarrierrec functions, but the // compiler doesn\u0026#39;t check this. // //go:nowritebarrierrec func newstack() { thisg := getg() // thisg = g0; 根据morestack()函数的相关代码 // TODO: double check all gp. shouldn\u0026#39;t be getg(). // // 根据morestack()函数的相关代码，这里thisg.m.morebuf.g.ptr()是g不是g0 if thisg.m.morebuf.g.ptr().stackguard0 == stackFork { throw(\u0026#34;stack growth after fork\u0026#34;) } // m-\u0026gt;curg 是当前m上正在运行的g if thisg.m.morebuf.g.ptr() != thisg.m.curg { print(\u0026#34;runtime: newstack called from g=\u0026#34;, hex(thisg.m.morebuf.g), \u0026#34;\\n\u0026#34;+\u0026#34;\\tm=\u0026#34;, thisg.m, \u0026#34; m-\u0026gt;curg=\u0026#34;, thisg.m.curg, \u0026#34; m-\u0026gt;g0=\u0026#34;, thisg.m.g0, \u0026#34; m-\u0026gt;gsignal=\u0026#34;, thisg.m.gsignal, \u0026#34;\\n\u0026#34;) morebuf := thisg.m.morebuf traceback(morebuf.pc, morebuf.sp, morebuf.lr, morebuf.g.ptr()) throw(\u0026#34;runtime: wrong goroutine in newstack\u0026#34;) } gp := thisg.m.curg // gp 在这里例子是runtime.main的goroutine // g.throwsplit 在系统调用前会被设置为true或其他地方。因此g出现在这里不合适。 if thisg.m.curg.throwsplit { // Update syscallsp, syscallpc in case traceback uses them. morebuf := thisg.m.morebuf gp.syscallsp = morebuf.sp gp.syscallpc = morebuf.pc pcname, pcoff := \u0026#34;(unknown)\u0026#34;, uintptr(0) f := findfunc(gp.sched.pc) if f.valid() { pcname = funcname(f) pcoff = gp.sched.pc - f.entry() } print(\u0026#34;runtime: newstack at \u0026#34;, pcname, \u0026#34;+\u0026#34;, hex(pcoff), \u0026#34; sp=\u0026#34;, hex(gp.sched.sp), \u0026#34; stack=[\u0026#34;, hex(gp.stack.lo), \u0026#34;, \u0026#34;, hex(gp.stack.hi), \u0026#34;]\\n\u0026#34;, \u0026#34;\\tmorebuf={pc:\u0026#34;, hex(morebuf.pc), \u0026#34; sp:\u0026#34;, hex(morebuf.sp), \u0026#34; lr:\u0026#34;, hex(morebuf.lr), \u0026#34;}\\n\u0026#34;, \u0026#34;\\tsched={pc:\u0026#34;, hex(gp.sched.pc), \u0026#34; sp:\u0026#34;, hex(gp.sched.sp), \u0026#34; lr:\u0026#34;, hex(gp.sched.lr), \u0026#34; ctxt:\u0026#34;, gp.sched.ctxt, \u0026#34;}\\n\u0026#34;) thisg.m.traceback = 2 // Include runtime frames traceback(morebuf.pc, morebuf.sp, morebuf.lr, gp) throw(\u0026#34;runtime: stack split at bad time\u0026#34;) } // m.morebuf 在上面的morestack函数中被设置为调用函数的相关信息。 morebuf := thisg.m.morebuf thisg.m.morebuf.pc = 0 thisg.m.morebuf.lr = 0 thisg.m.morebuf.sp = 0 thisg.m.morebuf.g = 0 // NOTE: stackguard0 may change underfoot, if another thread // is about to try to preempt gp. Read it just once and use that same // value now and below. // // 注意：如果另一个线程即将尝试抢占gp，stackguard0可能会在脚下发生变化。 // 只需阅读一次并在现在和下面使用相同的值 stackguard0 := atomic.Loaduintptr(\u0026amp;gp.stackguard0) // 获取gp.stackguard0 // Be conservative about where we preempt. // We are interested in preempting user Go code, not runtime code. // If we\u0026#39;re holding locks, mallocing, or preemption is disabled, don\u0026#39;t // preempt. // This check is very early in newstack so that even the status change // from Grunning to Gwaiting and back doesn\u0026#39;t happen in this case. // That status change by itself can be viewed as a small preemption, // because the GC might change Gwaiting to Gscanwaiting, and then // this goroutine has to wait for the GC to finish before continuing. // If the GC is in some way dependent on this goroutine (for example, // it needs a lock held by the goroutine), that small preemption turns // into a real deadlock. preempt := stackguard0 == stackPreempt // 判断当前是否真需要被抢占 if preempt { // canPreemptM -\u0026gt; mp.locks == 0 \u0026amp;\u0026amp; mp.mallocing == 0 \u0026amp;\u0026amp; mp.preemptoff == \u0026#34;\u0026#34; \u0026amp;\u0026amp; mp.p.ptr().status == _Prunning if !canPreemptM(thisg.m) { // canPreemptM(thisg.m); true.可以抢占; false.不允许抢占 // 以下是【不允许】抢占时，再次恢复gp。 // Let the goroutine keep running for now. // gp-\u0026gt;preempt is set, so it will be preempted next time. // // 现在让goroutine继续运行。gp-\u0026gt;preempt已设置，因此下次将被抢占。 // (gp-\u0026gt;preempt在前面已被设置为true) // 还原stackguard0为正常值，表示我们已经处理过抢占请求了 gp.stackguard0 = gp.stack.lo + _StackGuard // 恢复gp，这里永远不会返回 gogo(\u0026amp;gp.sched) // never return } } if gp.stack.lo == 0 { throw(\u0026#34;missing stack in newstack\u0026#34;) } sp := gp.sched.sp if goarch.ArchFamily == goarch.AMD64 || goarch.ArchFamily == goarch.I386 || goarch.ArchFamily == goarch.WASM { // The call to morestack cost a word. sp -= goarch.PtrSize } if stackDebug \u0026gt;= 1 || sp \u0026lt; gp.stack.lo { print(\u0026#34;runtime: newstack sp=\u0026#34;, hex(sp), \u0026#34; stack=[\u0026#34;, hex(gp.stack.lo), \u0026#34;, \u0026#34;, hex(gp.stack.hi), \u0026#34;]\\n\u0026#34;, \u0026#34;\\tmorebuf={pc:\u0026#34;, hex(morebuf.pc), \u0026#34; sp:\u0026#34;, hex(morebuf.sp), \u0026#34; lr:\u0026#34;, hex(morebuf.lr), \u0026#34;}\\n\u0026#34;, \u0026#34;\\tsched={pc:\u0026#34;, hex(gp.sched.pc), \u0026#34; sp:\u0026#34;, hex(gp.sched.sp), \u0026#34; lr:\u0026#34;, hex(gp.sched.lr), \u0026#34; ctxt:\u0026#34;, gp.sched.ctxt, \u0026#34;}\\n\u0026#34;) } if sp \u0026lt; gp.stack.lo { print(\u0026#34;runtime: gp=\u0026#34;, gp, \u0026#34;, goid=\u0026#34;, gp.goid, \u0026#34;, gp-\u0026gt;status=\u0026#34;, hex(readgstatus(gp)), \u0026#34;\\n \u0026#34;) print(\u0026#34;runtime: split stack overflow: \u0026#34;, hex(sp), \u0026#34; \u0026lt; \u0026#34;, hex(gp.stack.lo), \u0026#34;\\n\u0026#34;) throw(\u0026#34;runtime: split stack overflow\u0026#34;) } // 判断抢占，发起抢占 if preempt { if gp == thisg.m.g0 { throw(\u0026#34;runtime: preempt g0\u0026#34;) } if thisg.m.p == 0 \u0026amp;\u0026amp; thisg.m.locks == 0 { throw(\u0026#34;runtime: g is running but p is not\u0026#34;) } if gp.preemptShrink { // We\u0026#39;re at a synchronous safe point now, so // do the pending stack shrink. gp.preemptShrink = false shrinkstack(gp) } // 停止抢占，开启下一次调度循环,makeroot期间改值会被设置为true。 if gp.preemptStop {\tpreemptPark(gp) // never returns } // Act like goroutine called runtime.Gosched. // // 像调用 runtime.Gosched 的 goroutine 一样 // 调用gopreempt_m把gp切换出去，抢占这个goroutine成功了 gopreempt_m(gp) // never return } // 下面代码是扩大栈相关代码 // Allocate a bigger segment and move the stack. oldsize := gp.stack.hi - gp.stack.lo newsize := oldsize * 2 // 扩大为原来的2倍 // Make sure we grow at least as much as needed to fit the new frame. // (This is just an optimization - the caller of morestack will // recheck the bounds on return.) if f := findfunc(gp.sched.pc); f.valid() { max := uintptr(funcMaxSPDelta(f)) needed := max + _StackGuard used := gp.stack.hi - gp.sched.sp for newsize-used \u0026lt; needed { newsize *= 2 } } if stackguard0 == stackForceMove { // Forced stack movement used for debugging. // Don\u0026#39;t double the stack (or we may quickly run out // if this is done repeatedly). newsize = oldsize } if newsize \u0026gt; maxstacksize || newsize \u0026gt; maxstackceiling { if maxstacksize \u0026lt; maxstackceiling { print(\u0026#34;runtime: goroutine stack exceeds \u0026#34;, maxstacksize, \u0026#34;-byte limit\\n\u0026#34;) } else { print(\u0026#34;runtime: goroutine stack exceeds \u0026#34;, maxstackceiling, \u0026#34;-byte limit\\n\u0026#34;) } print(\u0026#34;runtime: sp=\u0026#34;, hex(sp), \u0026#34; stack=[\u0026#34;, hex(gp.stack.lo), \u0026#34;, \u0026#34;, hex(gp.stack.hi), \u0026#34;]\\n\u0026#34;) throw(\u0026#34;stack overflow\u0026#34;) } // The goroutine must be executing in order to call newstack, // so it must be Grunning (or Gscanrunning). casgstatus(gp, _Grunning, _Gcopystack) // The concurrent GC will not scan the stack while we are doing the copy since // the gp is in a Gcopystack status. copystack(gp, newsize) if stackDebug \u0026gt;= 1 { print(\u0026#34;stack grow done\\n\u0026#34;) } casgstatus(gp, _Gcopystack, _Grunning) gogo(\u0026amp;gp.sched) // 再次恢复这个goroutine } canPreemptM canPreemptM报告mp是否处于可以安全抢占的状态。 它是nosplit因为它有nosplit的调用者。 go:nosplit：告诉编译器不要在当前函数中插入任何栈扩展代码，这样可以确保当前函数不会导致栈的大小发生变化。 在Go语言中，每个goroutine都有一个固定的栈大小，当栈的大小不足以容纳当前函数的执行时，就会发生栈溢出错误。 因此，使用\u0026quot;go:nosplit\u0026quot;指令可以确保函数的执行不会导致栈的大小发生变化，从而避免栈溢出错误的发生。这个指令通常用于一些关键性的函数中，比如垃圾回收器和调度器等。 需要注意的是，使用\u0026quot;go:nosplit\u0026quot;指令可能会影响程序的性能。因为不再插入栈扩展代码，这意味着在执行函数时，栈的大小不会动态调整。因此，程序员需要在使用\u0026quot;go:nosplit\u0026quot;指令时仔细考虑性能和栈溢出错误之间的权衡。 文件位置：go1.19.3/src/runtime/preempt.go。 282 283 284 285 286 287 288 289 290 291 292 293 294 295 // canPreemptM reports whether mp is in a state that is safe to preempt. // // It is nosplit because it has nosplit callers. // //go:nosplit func canPreemptM(mp *m) bool { // 能否抢占条件：true.能抢占，false.不能抢占。 // 1. mp.locks == 0：表示当前goroutine持有的互斥锁数量，没到0时，不应该被抢占。 // 2. mp.mallocing == 0：当前goroutine正在分配内存，不应该被抢占。 // 3. mp.preemptoff：如果该值被设置为非空字符串，则表示当前goroutine不应该被抢占。 // 4. mp.p.ptr().status == _Prunning：当前P正在运行中。 // 满足以上条件则能抢占g。该函数也会在信号抢占函数isAsyncPreempt()函数中调用，用于判断是否允许抢占 return mp.locks == 0 \u0026amp;\u0026amp; mp.mallocing == 0 \u0026amp;\u0026amp; mp.preemptoff == \u0026#34;\u0026#34; \u0026amp;\u0026amp; mp.p.ptr().status == _Prunning } gopreempt_m 抢占调度，后逻辑和runtime.Gosched一样。 文件位置：go1.19.3/src/runtime/proc.go。 3402 3403 3404 3405 3406 3407 func gopreempt_m(gp *g) { if trace.enabled { traceGoPreempt() } goschedImpl(gp) } 系统调用前后 handoffp()，对正在进行系统调用的goroutine的抢占实质上是剥夺与其对应的工作线程所绑定的p。 虽然说处于系统调用之中的工作线程并不需要p，但一旦从操作系统内核返回到用户空间之后就必须绑定一个p才能运行go代码。 系统调用 Syscall6() 系统调用时最终会调用该汇编函数。 文件位置：go1.19.3/src/syscall/asm_unix_amd64.s。 函数原型：func Syscall6(num, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2, errno uintptr)。 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 TEXT ·Syscall6(SB),NOSPLIT,$0-80 # 调用 runtime.entersyscall 函数，保存现场解除绑定关系 CALL runtime·entersyscall\u0026lt;ABIInternal\u0026gt;(SB) # 系统调用参数，按照linux系统约定寄存器并调用SYSCALL执行进入内核。 # 系统调用编号放入AX。 MOVQ trap+0(FP), AX # syscall entry MOVQ a1+8(FP), DI MOVQ a2+16(FP), SI MOVQ a3+24(FP), DX MOVQ a4+32(FP), R10 MOVQ a5+40(FP), R8 MOVQ a6+48(FP), R9 SYSCALL # 进入内核 # 从内核返回，判断标识是否跳转 JCC\tok6 MOVQ $-1, r1+56(FP) # r1 MOVQ $0, r2+64(FP) # r2 MOVQ AX, err+72(FP) # errno CALL runtime·exitsyscall\u0026lt;ABIInternal\u0026gt;(SB) RET ok6: # 系统调用返回的值保存栈 MOVQ AX, r1+56(FP) # r1 MOVQ DX, r2+64(FP) # r2 MOVQ $0, err+72(FP) # errno CALL runtime·exitsyscall\u0026lt;ABIInternal\u0026gt;(SB) RET 系统调用前 entersyscall() go系统调用库和普通cgo调用使用的标准系统调用项。 这是通过syscall包和x/sys中的链接名导出到程序集的。 文件位置：go1.19.3/src/runtime/proc.go。 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681 3682 // Standard syscall entry used by the go syscall library and normal cgo calls. // // This is exported via linkname to assembly in the syscall package and x/sys. // //go:nosplit //go:linkname entersyscall func entersyscall() { // getcallerpc()：调用者当前PC值。 // getcallersp()：调用者当前SP值。 reentersyscall(getcallerpc(), getcallersp()) } reentersyscall() 文件位置：go1.19.3/src/runtime/proc.go。 3575 3576 3577 3578 3579 3580 3581 3582 3583 3584 3585 3586 3587 3588 3589 3590 3591 3592 3593 3594 3595 3596 3597 3598 3599 3600 3601 3602 3603 3604 3605 3606 3607 3608 3609 3610 3611 3612 3613 3614 3615 3616 3617 3618 3619 3620 3621 3622 3623 3624 3625 3626 3627 3628 3629 3630 3631 3632 3633 3634 3635 3636 3637 3638 3639 3640 3641 3642 3643 3644 3645 3646 3647 3648 3649 3650 3651 3652 3653 3654 3655 3656 3657 3658 3659 3660 3661 3662 3663 3664 3665 3666 3667 3668 3669 3670 3671 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681 3682 3683 3684 3685 3686 3687 3688 // The goroutine g is about to enter a system call. // Record that it\u0026#39;s not using the cpu anymore. // This is called only from the go syscall library and cgocall, // not from the low-level system calls used by the runtime. // // Entersyscall cannot split the stack: the save must // make g-\u0026gt;sched refer to the caller\u0026#39;s stack segment, because // entersyscall is going to return immediately after. // // Nothing entersyscall calls can split the stack either. // We cannot safely move the stack during an active call to syscall, // because we do not know which of the uintptr arguments are // really pointers (back into the stack). // In practice, this means that we make the fast path run through // entersyscall doing no-split things, and the slow path has to use systemstack // to run bigger things on the system stack. // // reentersyscall is the entry point used by cgo callbacks, where explicitly // saved SP and PC are restored. This is needed when exitsyscall will be called // from a function further up in the call stack than the parent, as g-\u0026gt;syscallsp // must always point to a valid stack frame. entersyscall below is the normal // entry point for syscalls, which obtains the SP and PC from the caller. // // Syscall tracing: // At the start of a syscall we emit traceGoSysCall to capture the stack trace. // If the syscall does not block, that is it, we do not emit any other events. // If the syscall blocks (that is, P is retaken), retaker emits traceGoSysBlock; // when syscall returns we emit traceGoSysExit and when the goroutine starts running // (potentially instantly, if exitsyscallfast returns true) we emit traceGoStart. // To ensure that traceGoSysExit is emitted strictly after traceGoSysBlock, // we remember current value of syscalltick in m (_g_.m.syscalltick = _g_.m.p.ptr().syscalltick), // whoever emits traceGoSysBlock increments p.syscalltick afterwards; // and we wait for the increment before emitting traceGoSysExit. // Note that the increment is done even if tracing is not enabled, // because tracing can be enabled in the middle of syscall. We don\u0026#39;t want the wait to hang. // //go:nosplit func reentersyscall(pc, sp uintptr) { // user goroutine _g_ := getg() // 执行系统调用的goroutine // Disable preemption because during this function g is in Gsyscall status, // but can have inconsistent g-\u0026gt;sched, do not let GC observe it. // // 禁用抢占，因为在这个功能期间g处于Gsyscall状态，但可能有不一致的g-\u0026gt;sched，不要让GC观察它。 _g_.m.locks++ // Entersyscall must not call any function that might split/grow the stack. // (See details in comment above.) // Catch calls that might, by replacing the stack guard with something that // will trip any stack check and leaving a flag to tell newstack to die. _g_.stackguard0 = stackPreempt // 设置抢占，在调用返回时会修改回来 // 不能扩展栈，在调用返回时会修改回来 _g_.throwsplit = true // Leave SP around for GC and traceback. save(pc, sp) // 保存g的现场信息，rsp，rbp，rip等 _g_.syscallsp = sp _g_.syscallpc = pc // 监控线程依赖_Gsyscall状态实施系统调用时的抢占 casgstatus(_g_, _Grunning, _Gsyscall) // 切换g状态为系统调用中 // SP是否在goroutine的栈范围内 if _g_.syscallsp \u0026lt; _g_.stack.lo || _g_.stack.hi \u0026lt; _g_.syscallsp { systemstack(func() { print(\u0026#34;entersyscall inconsistent \u0026#34;, hex(_g_.syscallsp), \u0026#34; [\u0026#34;, hex(_g_.stack.lo), \u0026#34;,\u0026#34;, hex(_g_.stack.hi), \u0026#34;]\\n\u0026#34;) throw(\u0026#34;entersyscall\u0026#34;) }) } if trace.enabled { systemstack(traceGoSysCall) // systemstack itself clobbers g.sched.{pc,sp} and we might // need them later when the G is genuinely blocked in a // syscall save(pc, sp) } // sysmon 监控线程正挂起在 sched.sysmonwait if atomic.Load(\u0026amp;sched.sysmonwait) != 0 { // 切换到g0栈调用 entersyscall_sysmon 函数 // entersyscall_sysmon 函数唤醒 sysmon 监控线程 systemstack(entersyscall_sysmon) save(pc, sp) } if _g_.m.p.ptr().runSafePointFn != 0 { // runSafePointFn may stack split if run on this stack systemstack(runSafePointFn) save(pc, sp) } // 把P的调用次数拷贝给M _g_.m.syscalltick = _g_.m.p.ptr().syscalltick _g_.sysblocktraced = true // M和P相互解除关联，并把P暂存与m.oldp中， // 等待系统调用完后使用 // 解除p.m关联的m pp := _g_.m.p.ptr() // pp = p pp.m = 0 // m.oldp = pp _g_.m.oldp.set(pp) // 解除 m.p 的关系 p _g_.m.p = 0 atomic.Store(\u0026amp;pp.status, _Psyscall) // pp.status = _Psyscall // STW正在等待时 if sched.gcwaiting != 0 { // 切换到g0栈调用entersyscall_gcwait函数 // entersyscall_gcwait函数，将P状态设置为 _Pgcstop，如果STW已完成则唤醒在sched.stopnote上等待的STW发起的线程。 systemstack(entersyscall_gcwait) save(pc, sp) } _g_.m.locks-- } save() 保存goroutine现场。 文件位置：go1.19.3/src/runtime/proc.go。 3543 3544 3545 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555 3556 3557 3558 3559 3560 3561 3562 3563 3564 3565 3566 3567 3568 3569 3570 3571 3572 3573 // save updates getg().sched to refer to pc and sp so that a following // gogo will restore pc and sp. // // save must not have write barriers because invoking a write barrier // can clobber getg().sched. // //go:nosplit //go:nowritebarrierrec func save(pc, sp uintptr) { gp := getg() if gp == gp.m.g0 || gp == gp.m.gsignal { // m.g0.sched is special and must describe the context // for exiting the thread. mstart1 writes to it directly. // m.gsignal.sched should not be used at all. // This check makes sure save calls do not accidentally // run in contexts where they\u0026#39;d write to system g\u0026#39;s. throw(\u0026#34;save on system g not allowed\u0026#34;) } gp.sched.pc = pc gp.sched.sp = sp gp.sched.lr = 0 gp.sched.ret = 0 // We need to ensure ctxt is zero, but can\u0026#39;t have a write // barrier here. However, it should always already be zero. // Assert that. if gp.sched.ctxt != nil { badctxt() } } 系统调用后 exitsyscall() 这个goroutine g退出系统调用。安排它再次在cpu上运行。 这仅从go系统调用库中调用，而不是从运行时使用的低级系统调用中调用。 写屏障是不被允许的，因为我们的P可能被偷了。 文件位置：go1.19.3/src/runtime/proc.go。 3761 3762 3763 3764 3765 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819 3820 3821 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 // The goroutine g exited its system call. // Arrange for it to run on a cpu again. // This is called only from the go syscall library, not // from the low-level system calls used by the runtime. // // Write barriers are not allowed because our P may have been stolen. // // This is exported via linkname to assembly in the syscall package. // //go:nosplit //go:nowritebarrierrec //go:linkname exitsyscall func exitsyscall() { // user goroutine _g_ := getg() // goroutine g _g_.m.locks++ // see comment in entersyscall if getcallersp() \u0026gt; _g_.syscallsp { throw(\u0026#34;exitsyscall: syscall frame is no longer valid\u0026#34;) } // g.waitsince，g被阻塞的大约时间 _g_.waitsince = 0 // 进入系统调用之前所绑定的p oldp := _g_.m.oldp.ptr() _g_.m.oldp = 0 // exitsyscallfast 尝试绑定P，成功返回true，失败返回false。 if exitsyscallfast(oldp) { // When exitsyscallfast returns success, we have a P so can now use // write barriers if goroutineProfile.active { // Make sure that gp has had its stack written out to the goroutine // profile, exactly as it was when the goroutine profiler first // stopped the world. systemstack(func() { tryRecordGoroutineProfileWB(_g_) }) } if trace.enabled { if oldp != _g_.m.p.ptr() || _g_.m.syscalltick != _g_.m.p.ptr().syscalltick { systemstack(traceGoStart) } } // There\u0026#39;s a cpu for us, so we can run. _g_.m.p.ptr().syscalltick++ // We need to cas the status and scan before resuming... casgstatus(_g_, _Gsyscall, _Grunning) // Garbage collector isn\u0026#39;t running (since we are), // so okay to clear syscallsp. _g_.syscallsp = 0 _g_.m.locks-- if _g_.preempt { // restore the preemption request in case we\u0026#39;ve cleared it in newstack // 恢复抢占请求，以防我们在newstack中清除了它 _g_.stackguard0 = stackPreempt } else { // otherwise restore the real _StackGuard, we\u0026#39;ve spoiled it in entersyscall/entersyscallblock // 否则恢复真正的_StackGuard，我们已经在entersyscall/entersyscallblock中破坏了它 _g_.stackguard0 = _g_.stack.lo + _StackGuard } _g_.throwsplit = false // sched.disable.user == true，用户goroutine被禁止运行 // schedEnabled判断g是否是系统goroutine if sched.disable.user \u0026amp;\u0026amp; !schedEnabled(_g_) { // Scheduling of this goroutine is disabled. Gosched() // 让出CPU，当前goroutine。 } return } // M绑定P没有成功时。 _g_.sysexitticks = 0 if trace.enabled { // Wait till traceGoSysBlock event is emitted. // This ensures consistency of the trace (the goroutine is started after it is blocked). for oldp != nil \u0026amp;\u0026amp; oldp.syscalltick == _g_.m.syscalltick { osyield() } // We can\u0026#39;t trace syscall exit right now because we don\u0026#39;t have a P. // Tracing code can invoke write barriers that cannot run without a P. // So instead we remember the syscall exit time and emit the event // in execute when we have a P. _g_.sysexitticks = cputicks() } _g_.m.locks-- // Call the scheduler. // // 没有绑定到p，调用mcall切换到g0栈执行exitsyscall0函数 mcall(exitsyscall0) // mcall函数会保存现场，切换g0调用exitsyscall0函数 // Scheduler returned, so we\u0026#39;re allowed to run now. // Delete the syscallsp information that we left for // the garbage collector during the system call. // Must wait until now because until gosched returns // we don\u0026#39;t know for sure that the garbage collector // is not running. _g_.syscallsp = 0 _g_.m.p.ptr().syscalltick++ _g_.throwsplit = false } exitsyscallfast() 尝试绑定一个空闲的P。true.绑定成功，false.绑定失败。 文件位置：go1.19.3/src/runtime/proc.go。 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881 3882 3883 3884 3885 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903 3904 //go:nosplit func exitsyscallfast(oldp *p) bool { _g_ := getg() // g // Freezetheworld sets stopwait but does not retake P\u0026#39;s. // // Freezetheworld 设置停止等待，但不重新获取P。 // const freezeStopWait int = 0x7fffffff if sched.stopwait == freezeStopWait { return false } // Try to re-acquire the last P. // // 试着重新获取last P。 if oldp != nil \u0026amp;\u0026amp; oldp.status == _Psyscall \u0026amp;\u0026amp; atomic.Cas(\u0026amp;oldp.status, _Psyscall, _Pidle) { // There\u0026#39;s a cpu for us, so we can run. // 我们有cpu，所以我们可以运行。 wirep(oldp) // 绑定P exitsyscallfast_reacquired() // 处理P的syscalltick字段 return true } // Try to get any other idle P. // // 尝试获取一个空闲的P。 if sched.pidle != 0 { var ok bool // 切换到g0栈 systemstack(func() { // 从全局队列中寻找空闲的p，需要加锁，比较慢 ok = exitsyscallfast_pidle() // 搬到成功返回true，绑定失败返回false。 if ok \u0026amp;\u0026amp; trace.enabled { if oldp != nil { // Wait till traceGoSysBlock event is emitted. // This ensures consistency of the trace (the goroutine is started after it is blocked). for oldp.syscalltick == _g_.m.syscalltick { osyield() } } traceGoSysExit(0) } }) if ok { return true } } return false } exitsyscallfast_pidle() 文件位置：go1.19.3/src/runtime/proc.go。 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923 3924 3925 3926 3927 func exitsyscallfast_pidle() bool { lock(\u0026amp;sched.lock) _p_, _ := pidleget(0) // 处理sysmon，因为在陷入到系统调用是sysmon可能自己把自己挂起，所以需要恢复 if _p_ != nil \u0026amp;\u0026amp; atomic.Load(\u0026amp;sched.sysmonwait) != 0 { atomic.Store(\u0026amp;sched.sysmonwait, 0) notewakeup(\u0026amp;sched.sysmonnote) } unlock(\u0026amp;sched.lock) if _p_ != nil { acquirep(_p_) // 绑定P如果有的话 return true } return false } exitsyscall0() exitsyscall在g0上的慢路径。获取P失败将gp放入可运行队列中。 通过mcall()调用，gp是从这个M调用g。 文件位置：go1.19.3/src/runtime/proc.go。 3934 3935 3936 3937 3938 3939 3940 3941 3942 3943 3944 3945 3946 3947 3948 3949 3950 3951 3952 3953 3954 3955 3956 3957 3958 3959 3960 3961 3962 3963 3964 3965 3966 3967 3968 3969 3970 3971 3972 3973 3974 3975 3976 3977 3978 3979 3980 3981 3982 3983 3984 3985 3986 3987 // exitsyscall slow path on g0. // Failed to acquire P, enqueue gp as runnable. // // Called via mcall, so gp is the calling g from this M. // //go:nowritebarrierrec func exitsyscall0(gp *g) { // 修改gp状态为_Grunnable casgstatus(gp, _Gsyscall, _Grunnable) dropg() // 解除g关联关系 lock(\u0026amp;sched.lock) var _p_ *p // 判断gp是否是系统goroutine，如果是的话再次尝试获取P。 if schedEnabled(gp) { _p_, _ = pidleget(0) } var locked bool if _p_ == nil { globrunqput(gp) // gp加入全局可运行队列 // Below, we stoplockedm if gp is locked. globrunqput releases // ownership of gp, so we must check if gp is locked prior to // committing the release by unlocking sched.lock, otherwise we // could race with another M transitioning gp from unlocked to // locked. // // 下面，如果gp被锁定，我们将停止阻塞。 // globrunqput释放了gp的所有权，所以我们必须在释放之前通过解锁sched.lock检查gp是否被锁定，否则我们可以与另一个M转换gp从解锁到锁定。 locked = gp.lockedm != 0 } else if atomic.Load(\u0026amp;sched.sysmonwait) != 0 { // 尝试唤醒sysmon，如果有 atomic.Store(\u0026amp;sched.sysmonwait, 0) notewakeup(\u0026amp;sched.sysmonnote) } unlock(\u0026amp;sched.lock) if _p_ != nil { acquirep(_p_) // 绑定P // gp 被调度起来运行 execute(gp, false) // Never returns. } if locked { // Wait until another thread schedules gp and so m again. // // N.B. lockedm must be this M, as this g was running on this M // before entersyscall. // // 等待另一个线程调度gp，然后再调度m。 // 注意，lockedm一定是这个M，因为这个g在entersyscall之前是在这个M上运行的。 stoplockedm() execute(gp, false) // Never returns. } stopm() // 当前工作线程被挂起，等待被唤醒获取P然后运行起来 // 调度循环开始 schedule() // Never returns. } 信号形式发送抢占 preemptM() preemptM向mp发送抢占请求。该请求可以异步处理，并且可以与对M的其他请求合并。 当接收到请求时，如果正在运行的G或P被标记为抢占，并且goroutine处于异步安全点，则它将抢占 goroutine。 它总是在处理抢占请求后自动递增mp.preemptGen。 通过runtime.signalM()函数向执行M发送sigPreempt信号。 至于signalM()函数，就是调用操作系统的信号相关系统调用，将指定信号发送给目标线程。 至此，异步抢占逻辑的主要工作就算完成了前一半。 preemptM这个函数会调用signalM将在初始化的安装的_SIGURG信号发送到指定的M上。 使用 preemptM 发送抢占信号的地方主要有下面几个： Go 后台监控 runtime.sysmon 检测超时发送抢占信号； Go GC 栈扫描发送抢占信号； Go GC STW 的时候调用 preemptall 抢占所有 P，让其暂停； 文件位置：go1.19.3/src/runtime/signal_unix.go。 参数mp *m：被抢占的P关联的M。 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 // preemptM sends a preemption request to mp. This request may be // handled asynchronously and may be coalesced with other requests to // the M. When the request is received, if the running G or P are // marked for preemption and the goroutine is at an asynchronous // safe-point, it will preempt the goroutine. It always atomically // increments mp.preemptGen after handling a preemption request. func preemptM(mp *m) { // On Darwin, don\u0026#39;t try to preempt threads during exec. // Issue #41702. if GOOS == \u0026#34;darwin\u0026#34; || GOOS == \u0026#34;ios\u0026#34; { execLock.rlock() } // mp.signalPending: 这个M上是否有一个待处理的抢占信号。原子操作。 if atomic.Cas(\u0026amp;mp.signalPending, 0, 1) { if GOOS == \u0026#34;darwin\u0026#34; || GOOS == \u0026#34;ios\u0026#34; { atomic.Xadd(\u0026amp;pendingPreemptSignals, 1) } // If multiple threads are preempting the same M, it may send many // signals to the same M such that it hardly make progress, causing // live-lock problem. Apparently this could happen on darwin. See // issue #37741. // Only send a signal if there isn\u0026#39;t already one pending. // // 如果多个线程抢占同一个M，它可能会向同一个M发送许多信号， // 使其几乎无法取得进展，从而导致实时锁定问题。 // 显然这可能发生在darwin身上。只有在还没有挂起的情况下才发送信号。 // const sigPreempt int = _SIGURG // const _SIGURG = 0x17 signalM(mp, sigPreempt) } if GOOS == \u0026#34;darwin\u0026#34; || GOOS == \u0026#34;ios\u0026#34; { execLock.runlock() } } signalM() signalM向mp发送信号。 文件位置：go1.19.3/src/runtime/os_linux.go。 551 552 553 554 555 556 557 558 559 560 561 562 // signalM sends a signal to mp. func signalM(mp *m, sig int) { // 将信号sig发送到线程组tgid中具有线程ID tid的线程。 // int tgkill(int tgid, int tid, int sig); // 1. tgid：为线程组中主线程的线程ID，或者称为进程号。 // 其实它能起到保护的作用，防止向错误的线程发送信号。 // 比如向线程ID为1234的线程发送信号时，很可能线程1234早就退出了， // 而线程ID 1234恰好被内核分配给了另一个不相干的进程。 // 2. tid：线程ID。 // 3. sig：信号值。sigPreempt = _SIGURG = 0x17。 tgkill(getpid(), int(mp.procid), sig) } tgkill() 系统调用 tgkill() 函数向进程内的线程发送信号。 文件位置：go1.19.3/src/runtime/sys_linux_amd64.s。 176 177 178 179 180 181 182 TEXT ·tgkill(SB),NOSPLIT,$0 MOVQ tgid+0(FP), DI MOVQ tid+8(FP), SI MOVQ sig+16(FP), DX MOVL $SYS_tgkill, AX SYSCALL # 进入系统调用 RET 全局信号处理注册 mstart1() 主线程启动运行到mstart()-\u0026gt;mstart0()-\u0026gt;mstart1()函数内时。 文件位置：go1.19.3/src/runtime/proc.go。 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 // The go:noinline is to guarantee the getcallerpc/getcallersp below are safe, // so that we can set up g0.sched to return to the call of mstart1 above. // //go:noinline func mstart1() { // ... asminit() minit() // Install signal handlers; after minit so that minit can // prepare the thread to be able to handle the signals. // // 安装信号处理程序;在minit之后，以便minit可以准备线程，以便能够处理信号。 if gp.m == \u0026amp;m0 { mstartm0() } // ... } mstartm0() initsig(false)则是注册信号处理相关。 文件位置：go1.19.3/src/runtime/proc.go。 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 // mstartm0 implements part of mstart1 that only runs on the m0. // // Write barriers are allowed here because we know the GC can\u0026#39;t be // running yet, so they\u0026#39;ll be no-ops. // //go:yeswritebarrierrec func mstartm0() { // Create an extra M for callbacks on threads not created by Go. // An extra M is also needed on Windows for callbacks created by // syscall.NewCallback. See issue #6751 for details. if (iscgo || GOOS == \u0026#34;windows\u0026#34;) \u0026amp;\u0026amp; !cgoHasExtraM { cgoHasExtraM = true newextram() } initsig(false) } initsig() 信号注册。 文件位置：go1.19.3/src/runtime/signal_unix.go。 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 // Initialize signals. // Called by libpreinit so runtime may not be initialized. // //go:nosplit //go:nowritebarrierrec func initsig(preinit bool) { if !preinit { // It\u0026#39;s now OK for signal handlers to run. // // 现在可以运行信号处理程序了。 signalsOK = true } // For c-archive/c-shared this is called by libpreinit with // preinit == true. if (isarchive || islibrary) \u0026amp;\u0026amp; !preinit { return } // 遍历信号数组 // const _NSIG int = 65; for i := uint32(0); i \u0026lt; _NSIG; i++ { // sigtable 全局变量存储的是所有信号及描述 t := \u0026amp;sigtable[i] // const _SigDefault int = 16; // 如果信号没有被显式请求，就不要监视它 // 略过信号，SIGKILL、SIGSTOP、SIGTSTP、SIGCONT、SIGTTIN、SIGTTOU if t.flags == 0 || t.flags\u0026amp;_SigDefault != 0 { continue } // We don\u0026#39;t need to use atomic operations here because // there shouldn\u0026#39;t be any other goroutines running yet. fwdSig[i] = getsig(i) if !sigInstallGoHandler(i) { // Even if we are not installing a signal handler, // set SA_ONSTACK if necessary. if fwdSig[i] != _SIG_DFL \u0026amp;\u0026amp; fwdSig[i] != _SIG_IGN { setsigstack(i) } else if fwdSig[i] == _SIG_IGN { sigInitIgnored(i) } continue } handlingSig[i] = 1 setsig(i, abi.FuncPCABIInternal(sighandler)) } } setsig() 这里需要注意的是，当 fn 等于 sighandler 的时候，调用的函数会被替换成 sigtramp。 sigaction 函数在 Linux 下会调用系统调用函数 sys_signal 以及 sys_rt_sigaction 实现安装信号。 文件位置：go1.19.3/src/runtime/os_linux.go。 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 //go:nosplit //go:nowritebarrierrec func setsig(i uint32, fn uintptr) { var sa sigactiont sa.sa_flags = _SA_SIGINFO | _SA_ONSTACK | _SA_RESTORER | _SA_RESTART sigfillset(\u0026amp;sa.sa_mask) // Although Linux manpage says \u0026#34;sa_restorer element is obsolete and // should not be used\u0026#34;. x86_64 kernel requires it. Only use it on // x86. if GOARCH == \u0026#34;386\u0026#34; || GOARCH == \u0026#34;amd64\u0026#34; { sa.sa_restorer = abi.FuncPCABI0(sigreturn) } if fn == abi.FuncPCABIInternal(sighandler) { // abi.FuncPCABIInternal(sighandler) matches the callers in signal_unix.go if iscgo { fn = abi.FuncPCABI0(cgoSigtramp) } else { // 替换为调用 sigtramp fn = abi.FuncPCABI0(sigtramp) } } sa.sa_handler = fn sigaction(i, \u0026amp;sa, nil) } 信号形式响应抢占 sigtramp() 函数原型：func sigtramp()。 sigtramp()实际上是真正的信号处理函数，进程从内核态收到信号回到用户态调用的处理函数就是它。 注释中表明这个函数以C语言的调用惯例被调用，Go在这里通过PUSH_REGS_HOST_TO_ABI0保存go自己调用惯例用的寄存器后， 转换成自己的调用规范，等函数调用完毕之后，再通过POP_REGS_HOST_TO_ABI0恢复这些寄存器的值。 调度路径sigtramp()-\u0026gt;sigtrampgo()-\u0026gt;sighandler()-\u0026gt;doSigPreempt()。 这里会被调用说明信号已经发送响应了，runtime·sigtramp会进行信号的处理。 runtime·sigtramp会继续调用runtime·sigtrampgo。 文件位置：go1.19.3/src/runtime/sys_linux_amd64.s。 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 # Called using C ABI. TEXT runtime·sigtramp(SB),NOSPLIT|TOPFRAME,$0 # Transition from C ABI to Go ABI. PUSH_REGS_HOST_TO_ABI0() # Set up ABIInternal environment: g in R14, cleared X15. get_tls(R12) # TLS MOVQ g(R12), R14 # R14 = g PXOR X15, X15 # Reserve space for spill slots. NOP SP # disable vet stack checking ADJSP $24 # Call into the Go signal handler # # 内核修改用户态寄存器时设置的 rdi、rsi、rdx # 三个寄存器的值就是内核模仿调用sigtramp时传入的参数 MOVQ DI, AX\t# sig MOVQ SI, BX\t# info MOVQ DX, CX\t# ctx CALL ·sigtrampgo\u0026lt;ABIInternal\u0026gt;(SB) ADJSP $-24 POP_REGS_HOST_TO_ABI0() RET sigtrampgo() 文件位置：go1.19.3/src/runtime/signal_unix.go。 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 // sigtrampgo is called from the signal handler function, sigtramp, // written in assembly code. // This is called by the signal handler, and the world may be stopped. // // It must be nosplit because getg() is still the G that was running // (if any) when the signal was delivered, but it\u0026#39;s (usually) called // on the gsignal stack. Until this switches the G to gsignal, the // stack bounds check won\u0026#39;t work. // //go:nosplit //go:nowritebarrierrec func sigtrampgo(sig uint32, info *siginfo, ctx unsafe.Pointer) { if sigfwdgo(sig, info, ctx) { return } c := \u0026amp;sigctxt{info, ctx} gp := sigFetchG(c) // g setg(gp) if gp == nil { if sig == _SIGPROF { // Some platforms (Linux) have per-thread timers, which we use in // combination with the process-wide timer. Avoid double-counting. if validSIGPROF(nil, c) { sigprofNonGoPC(c.sigpc()) } return } if sig == sigPreempt \u0026amp;\u0026amp; preemptMSupported \u0026amp;\u0026amp; debug.asyncpreemptoff == 0 { // This is probably a signal from preemptM sent // while executing Go code but received while // executing non-Go code. // We got past sigfwdgo, so we know that there is // no non-Go signal handler for sigPreempt. // The default behavior for sigPreempt is to ignore // the signal, so badsignal will be a no-op anyway. if GOOS == \u0026#34;darwin\u0026#34; || GOOS == \u0026#34;ios\u0026#34; { pendingPreemptSignals.Add(-1) } return } c.fixsigcode(sig) badsignal(uintptr(sig), c) return } setg(gp.m.gsignal) // If some non-Go code called sigaltstack, adjust. var gsignalStack gsignalStack setStack := adjustSignalStack(sig, gp.m, \u0026amp;gsignalStack) if setStack { gp.m.gsignal.stktopsp = getcallersp() } if gp.stackguard0 == stackFork { signalDuringFork(sig) } c.fixsigcode(sig) sighandler(sig, info, ctx, gp) setg(gp) if setStack { restoreGsignalStack(\u0026amp;gsignalStack) } } sighander() 响应抢占。调度路径sigtramp()-\u0026gt;sigtrampgo()-\u0026gt;sighandler()-\u0026gt;doSigPreempt()。 文件位置：go1.19.3/src/runtime/signal_unix.go。 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 // sighandler is invoked when a signal occurs. The global g will be // set to a gsignal goroutine and we will be running on the alternate // signal stack. The parameter g will be the value of the global g // when the signal occurred. The sig, info, and ctxt parameters are // from the system signal handler: they are the parameters passed when // the SA is passed to the sigaction system call. // // The garbage collector may have stopped the world, so write barriers // are not allowed. // //go:nowritebarrierrec func sighandler(sig uint32, info *siginfo, ctxt unsafe.Pointer, gp *g) { // ... ... // sig == sigPreempt：抢占信号 // debug.asyncpreemptoff == 0：没有禁止抢占 // delayedSignal：延迟信号? if sig == sigPreempt \u0026amp;\u0026amp; debug.asyncpreemptoff == 0 \u0026amp;\u0026amp; !delayedSignal { // Might be a preemption signal. // 可能是一个抢占信号。 doSigPreempt(gp, c) // Even if this was definitely a preemption signal, it // may have been coalesced with another signal, so we // still let it through to the application. // 即使这确实是一个抢占信号，它可能已经与另一个信号合并，所以我们仍然让它通过应用程序。 } // ... ... } doSigPreempt() doSigPreempt处理gp上的抢占信号。 调用到doSigPreempt时，会将ctx这个参数传入，其中包含了进程用户态硬件上下文 ctxt的类型为*sigctxt，指向的是用户态堆栈中存放内核态堆栈内容的地址。 然后信号处理程序通过isAsyncSafePoint来判断抢占位置是否安全，并返回安全的抢占地址。 如果确认抢占没有问题，接着会调用pushCall方法来修改ctxt中的用户态硬件上下文， 用于稍后再一次从内核态返回用户态时模拟出一个用户态程序调用asyncPreempt的假象。 文件位置：go1.19.3/src/runtime/signal_unix.go。 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 // doSigPreempt handles a preemption signal on gp. func doSigPreempt(gp *g, ctxt *sigctxt) { // Check if this G wants to be preempted and is safe to // preempt. // 检查这个G是否希望被抢占，并且抢占是安全的。 // 通过 wantAsyncPreempt 函数确认runtime确实想要对指定的G实施异步抢占 if wantAsyncPreempt(gp) { // 通过isAsyncSafePoint函数确认G当前执行上下文是能够安全地进行异步抢占的。 if ok, newpc := isAsyncSafePoint(gp, ctxt.sigpc(), ctxt.sigsp(), ctxt.siglr()); ok { // Adjust the PC and inject a call to asyncPreempt. // 以上两个函数都确认无误后，才通过pushCall向G的执行上下文中注入一个函数调用， // 要调用的目标函数是 runtime.asyncPreempt 函数。这是一个汇编函数，它会先把各个寄存器的值保存在栈上， // 也就是将现场保存在栈上，然后调用 runtime.asyncPreempt2函数。 ctxt.pushCall(abi.FuncPCABI0(asyncPreempt), newpc) // 就是向当前运行的goroutine注册加入asyncPreempt函数 } } // Acknowledge the preemption. atomic.Xadd(\u0026amp;gp.m.preemptGen, 1) atomic.Store(\u0026amp;gp.m.signalPending, 0) if GOOS == \u0026#34;darwin\u0026#34; || GOOS == \u0026#34;ios\u0026#34; { atomic.Xadd(\u0026amp;pendingPreemptSignals, -1) } } wantAsyncPreempt() wantAsyncPreempt返回异步抢占是否为gp排队。 文件位置：go1.19.3/src/runtime/preempt.go。 340 341 342 343 344 345 346 347 348 349 350 // wantAsyncPreempt returns whether an asynchronous preemption is // queued for gp. func wantAsyncPreempt(gp *g) bool { // Check both the G and the P. // 同时检查G和P的preempt字段，并且G当前需要处于_Grunning状态。 // 在每轮调度循环中，P和G的preempt字段都会被置为false，所以这个检测能够避免刚刚切换至一个新的G后马上又被抢占。 // gp.preempt || gp.m.p != 0 \u0026amp;\u0026amp; gp.m.p.ptr().preempt：判断G或P的preempt抢占标识位。 // readgstatus(gp)\u0026amp;^_Gscan == _Grunning：当前G正在运行状态。 // 确认是否设置了抢占标志 return (gp.preempt || gp.m.p != 0 \u0026amp;\u0026amp; gp.m.p.ptr().preempt) \u0026amp;\u0026amp; readgstatus(gp)\u0026amp;^_Gscan == _Grunning } isAsyncSafePoint() 它从以下几个方面来保证在当前位置进行异步抢占是安全的。 可以挂起G并安全的扫描它的栈和寄存器，没有潜在的隐藏指针，而且当前并没有打断一个写屏障。 G还有足够的栈空间来注入一个对asyncPreempt()函数的调用。 可以安全地和 runtime 进行交互，例如未持有 runtime 相关的锁，因此在尝试获得锁时不会造成死锁。 isAsyncSafePoint报告指令PC上的gp是否是异步安全点。这表明： 暂停gp并保守地扫描它的堆栈和寄存器是安全的。它没有潜在的隐藏指针值，也不像写屏障那样位于原子序列的中间。 gp有足够的堆栈空间注入asyncPreempt调用。 通常情况下，与运行时交互是安全的，即使我们在信号处理程序中就停在这里。例如，没有持有运行时锁，因此获取运行时锁不会自死锁。 在某些情况下，PC是安全的异步抢占，但它也需要调整恢复PC。新的PC在第二个结果中返回。 文件位置：go1.19.3/src/runtime/preempt.go。 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 // isAsyncSafePoint reports whether gp at instruction PC is an // asynchronous safe point. This indicates that: // // 1. It\u0026#39;s safe to suspend gp and conservatively scan its stack and // registers. There are no potentially hidden pointer values and it\u0026#39;s // not in the middle of an atomic sequence like a write barrier. // // 2. gp has enough stack space to inject the asyncPreempt call. // // 3. It\u0026#39;s generally safe to interact with the runtime, even if we\u0026#39;re // in a signal handler stopped here. For example, there are no runtime // locks held, so acquiring a runtime lock won\u0026#39;t self-deadlock. // // In some cases the PC is safe for asynchronous preemption but it // also needs to adjust the resumption PC. The new PC is returned in // the second result. func isAsyncSafePoint(gp *g, pc, sp, lr uintptr) (bool, uintptr) { mp := gp.m // Only user Gs can have safe-points. We check this first // because it\u0026#39;s extremely common that we\u0026#39;ll catch mp in the // scheduler processing this G preemption. // // 只有用户Gs可以有安全点。我们首先检查这个，因为在处理G抢占的调度器中捕获mp是非常常见的。 if mp.curg != gp { return false, 0 } // Check M state. // 检查M状态。 // canPreemptM(mp) -\u0026gt; mp.locks == 0 \u0026amp;\u0026amp; mp.mallocing == 0 \u0026amp;\u0026amp; mp.preemptoff == \u0026#34;\u0026#34; \u0026amp;\u0026amp; mp.p.ptr().status == _Prunning if mp.p == 0 || !canPreemptM(mp) { return false, 0 } // Check stack space. // 检查栈空间。 // asyncPreemptStack是注入一个asyncPreempt调用所需的栈空间的字节。 if sp \u0026lt; gp.stack.lo || sp-gp.stack.lo \u0026lt; asyncPreemptStack { return false, 0 } // Check if PC is an unsafe-point. // 检查PC是否为不安全点。 f := findfunc(pc) if !f.valid() { // Not Go code. return false, 0 } if (GOARCH == \u0026#34;mips\u0026#34; || GOARCH == \u0026#34;mipsle\u0026#34; || GOARCH == \u0026#34;mips64\u0026#34; || GOARCH == \u0026#34;mips64le\u0026#34;) \u0026amp;\u0026amp; lr == pc+8 \u0026amp;\u0026amp; funcspdelta(f, pc, nil) == 0 { // We probably stopped at a half-executed CALL instruction, // where the LR is updated but the PC has not. If we preempt // here we\u0026#39;ll see a seemingly self-recursive call, which is in // fact not. // This is normally ok, as we use the return address saved on // stack for unwinding, not the LR value. But if this is a // call to morestack, we haven\u0026#39;t created the frame, and we\u0026#39;ll // use the LR for unwinding, which will be bad. return false, 0 } up, startpc := pcdatavalue2(f, _PCDATA_UnsafePoint, pc) if up == _PCDATA_UnsafePointUnsafe { // Unsafe-point marked by compiler. This includes // atomic sequences (e.g., write barrier) and nosplit // functions (except at calls). return false, 0 } if fd := funcdata(f, _FUNCDATA_LocalsPointerMaps); fd == nil || f.flag\u0026amp;funcFlag_ASM != 0 { // This is assembly code. Don\u0026#39;t assume it\u0026#39;s well-formed. // TODO: Empirically we still need the fd == nil check. Why? // // TODO: Are there cases that are safe but don\u0026#39;t have a // locals pointer map, like empty frame functions? // It might be possible to preempt any assembly functions // except the ones that have funcFlag_SPWRITE set in f.flag. return false, 0 } name := funcname(f) if inldata := funcdata(f, _FUNCDATA_InlTree); inldata != nil { inltree := (*[1 \u0026lt;\u0026lt; 20]inlinedCall)(inldata) ix := pcdatavalue(f, _PCDATA_InlTreeIndex, pc, nil) if ix \u0026gt;= 0 { name = funcnameFromNameoff(f, inltree[ix].func_) } } if hasPrefix(name, \u0026#34;runtime.\u0026#34;) || hasPrefix(name, \u0026#34;runtime/internal/\u0026#34;) || hasPrefix(name, \u0026#34;reflect.\u0026#34;) { // For now we never async preempt the runtime or // anything closely tied to the runtime. Known issues // include: various points in the scheduler (\u0026#34;don\u0026#39;t // preempt between here and here\u0026#34;), much of the defer // implementation (untyped info on stack), bulk write // barriers (write barrier check), // reflect.{makeFuncStub,methodValueCall}. // // TODO(austin): We should improve this, or opt things // in incrementally. return false, 0 } switch up { case _PCDATA_Restart1, _PCDATA_Restart2: // Restartable instruction sequence. Back off PC to // the start PC. if startpc == 0 || startpc \u0026gt; pc || pc-startpc \u0026gt; 20 { throw(\u0026#34;bad restart PC\u0026#34;) } return true, startpc case _PCDATA_RestartAtEntry: // Restart from the function entry at resumption. return true, f.entry() } return true, pc } pushCall() pushCall干了两件事： 修改程序计数器的指向为asyncPreempt函数的地址。 修改栈顶指针，将当前 goroutine 的原本中断地址放入堆栈。 文件位置：go1.19.3/src/runtime/signal_amd64.go。 先把SP向下移动一个指针大小的位置，把PC的值存入栈上SP指向的位置，然后将PC的值更新为targetPC。 这样就模拟了一条CALL指令的效果，栈上存入的PC的旧值就相当于返回地址。 此时整个执行上下文的状态就像是goroutine在被信号打断的位置额外执行了一条CALL targetPC指令。 由于执行流程刚刚跳转到targetPC地址处，所以还没来得及执行目标地址处的指令。 当sighandler()函数处理完信号并返回后，被打断的goroutine得以继续执行，会立即调用被注入的asyncPreempt()函数。经过一连串的函数调用，最终执行到schedule()函数。 参数： targetPC uintptr：asyncPreempt 函数的执行入口地址。 resumePC uintptr：其实就是发生中断前当前goroutine的下一指令地址，也就是PC的值。 80 81 82 83 84 85 86 87 88 89 func (c *sigctxt) pushCall(targetPC, resumePC uintptr) { // Make it look like we called target at resumePC. // 让它看起来像我们在resumePC上调用了target。 sp := uintptr(c.rsp()) // 当前goroutine的SP sp -= goarch.PtrSize *(*uintptr)(unsafe.Pointer(sp)) = resumePC // 设置当前中断保存的上下文信息，因为中断结束后从这里恢复。 c.set_rsp(uint64(sp)) // 修改中断保存的上下文SP c.set_rip(uint64(targetPC)) // 修改中断保存的上下文PC } asyncPreempt() 中断信号函数处理完后，goroutine得到运行，继续从嵌入的本函数开始执行。 文件位置：go1.19.3/src/runtime/preempt_amd64.s。 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 TEXT ·asyncPreempt(SB),NOSPLIT|NOFRAME,$0-0 PUSHQ BP # BP入栈 MOVQ SP, BP # BP = SP # Save flags before clobbering them PUSHFQ # obj doesn\u0026#39;t understand ADD/SUB on SP, but does understand ADJSP ADJSP $368 # But vet doesn\u0026#39;t know ADJSP, so suppress vet stack checking NOP SP MOVQ AX, 0(SP) MOVQ CX, 8(SP) MOVQ DX, 16(SP) MOVQ BX, 24(SP) MOVQ SI, 32(SP) MOVQ DI, 40(SP) MOVQ R8, 48(SP) MOVQ R9, 56(SP) MOVQ R10, 64(SP) MOVQ R11, 72(SP) MOVQ R12, 80(SP) MOVQ R13, 88(SP) MOVQ R14, 96(SP) MOVQ R15, 104(SP) #ifdef GOOS_darwin CMPB internal∕cpu·X86+const_offsetX86HasAVX(SB), $0 JE 2(PC) VZEROUPPER #endif MOVUPS X0, 112(SP) MOVUPS X1, 128(SP) MOVUPS X2, 144(SP) MOVUPS X3, 160(SP) MOVUPS X4, 176(SP) MOVUPS X5, 192(SP) MOVUPS X6, 208(SP) MOVUPS X7, 224(SP) MOVUPS X8, 240(SP) MOVUPS X9, 256(SP) MOVUPS X10, 272(SP) MOVUPS X11, 288(SP) MOVUPS X12, 304(SP) MOVUPS X13, 320(SP) MOVUPS X14, 336(SP) MOVUPS X15, 352(SP) CALL ·asyncPreempt2(SB) # 调用asyncPreempt2 # 下次goroutine再度被运行起来时，从这里恢复。 MOVUPS 352(SP), X15 MOVUPS 336(SP), X14 MOVUPS 320(SP), X13 MOVUPS 304(SP), X12 MOVUPS 288(SP), X11 MOVUPS 272(SP), X10 MOVUPS 256(SP), X9 MOVUPS 240(SP), X8 MOVUPS 224(SP), X7 MOVUPS 208(SP), X6 MOVUPS 192(SP), X5 MOVUPS 176(SP), X4 MOVUPS 160(SP), X3 MOVUPS 144(SP), X2 MOVUPS 128(SP), X1 MOVUPS 112(SP), X0 MOVQ 104(SP), R15 MOVQ 96(SP), R14 MOVQ 88(SP), R13 MOVQ 80(SP), R12 MOVQ 72(SP), R11 MOVQ 64(SP), R10 MOVQ 56(SP), R9 MOVQ 48(SP), R8 MOVQ 40(SP), DI MOVQ 32(SP), SI MOVQ 24(SP), BX MOVQ 16(SP), DX MOVQ 8(SP), CX MOVQ 0(SP), AX ADJSP $-368 POPFQ POPQ BP RET # 返回继续去执行原来的goroutine代码 asyncPreempt2() 文件位置：go1.19.3/src/runtime/preempt.go。 301 302 303 304 305 306 307 308 309 310 311 312 313 314 //go:nosplit func asyncPreempt2() { gp := getg() gp.asyncSafePoint = true // preemptStop 主要在GC标记期间被用来挂起运行中的 goroutine if gp.preemptStop { // preemptPark会把当前g切换至_Gpreempted状态，然后调用schedule函数 mcall(preemptPark) } else { // 通过preemptone函数发起的异步抢占会调用gopreempt_m函数，它最终也会调用schedule函数 mcall(gopreempt_m) } gp.asyncSafePoint = false } gopreempt_m() 文件位置：go1.19.3/src/runtime/proc.go。 3402 3403 3404 3405 3406 3407 func gopreempt_m(gp *g) { if trace.enabled { traceGoPreempt() } goschedImpl(gp) } goschedImpl() G加入全局队列，解除G与M的关系，再次发起调度循环。 文件位置：go1.19.3/src/runtime/proc.go。 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377 3378 3379 3380 func goschedImpl(gp *g) { status := readgstatus(gp) // 获取G状态 if status\u0026amp;^_Gscan != _Grunning { dumpgstatus(gp) throw(\u0026#34;bad g status\u0026#34;) } // 修改G状态 _Grunnable casgstatus(gp, _Grunning, _Grunnable) dropg() // 解除绑定关系 lock(\u0026amp;sched.lock) globrunqput(gp) // 加入全局链表 unlock(\u0026amp;sched.lock) schedule() // 调度循环 } ","permalink":"https://heliu.site/posts/golang/goroutine/retake/","summary":"Golang 抢占长时间运行的goroutine。","title":"被动让出调度"},{"content":"type g struct 每一个实例对象代表一个goroutine。 该结构体保存CPU寄存器的值以及goroutine的所有信息，包括栈，gobuf结构体和其它的一些状态信息。 调度器代码可以通过g对象来对goroutine进行调度： 当goroutine被调离CPU时，调度器代码负责把CPU寄存器的值保存在g对象的成员变量之中。 当goroutine被调度起来运行时，调度器代码又负责把g对象的成员变量所保存的寄存器的值恢复到CPU的寄存器。 type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). // // goroutine栈以及栈扩容相关信息 // 记录该goroutine使用的栈信息，[lo,hi) stack stack // offset known to runtime/cgo // 被正常的goroutine使用，编译器安插在函数头部的栈增长代码，用它来和SP比较，按需进行栈增长。 // 它的值一般是 stcak.lo + StackGuard，也可能被设置成 StackPreempt，以触发一次抢占。 // const _StackGuard = 928; linux amd64 // const stackPreempt = 0xfffffade; ((1\u0026lt;\u0026lt;64) - 1) \u0026amp; -1314 stackguard0 uintptr // offset known to liblink // 原理和 stackguard0 差不多，只不过是被 g0 和 gsignal 中的C代码使用。 stackguard1 uintptr // offset known to liblink // _panic 和 _defer 在defer和panic中被使用 // panic链表，记录当前goroutine触发的panic链表 _panic *_panic // innermost panic - offset known to liblink // defer链表，记录整个调用链函数中注册的defer函数链表 _defer *_defer // innermost defer // 关联到正在执行当前G的工作线程M，也就是 type m struct 结构体指针 m *m // current m; offset known to arm liblink // 保存调度信息，主要是几个寄存器的值，g被调离前CPU以及寄存器信息保存在这里，恢复后从这里保存的信息开始 // 被调度器，用来保存 goroutine 的执行上下文。 sched gobuf // 档期前goroutine被调度或者被保存是CPU相关信息存储在这里 // 系统调用进入调用前，保存SP寄存器和IP寄存器的值 syscallsp uintptr// if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr// if status==Gsyscall, syscallpc = sched.pc to use during gc // 应为堆栈顶部的sp，用于回溯 stktopsp uintptr// expected sp at top of stack, to check in traceback // param is a generic pointer parameter field used to pass // values in particular contexts where other storage for the // parameter would be difficult to find. It is currently used // in three ways: // 1. When a channel operation wakes up a blocked goroutine, it sets param to // point to the sudog of the completed blocking operation. // 2. By gcAssistAlloc1 to signal back to its caller that the goroutine completed // the GC cycle. It is unsafe to do so in any other way, because the goroutine\u0026#39;s // stack may have moved in the meantime. // 3. By debugCallWrap to pass parameters to a new goroutine because allocating a // closure in the runtime is forbidden. // // param是一个通用的指针参数字段，用于在很难找到参数的其他存储的特定上下文中传递值。它目前有三种使用方式： // 1.当通道操作唤醒被阻塞的goroutine时，它将param设置为指向已完成阻塞操作的sudog。 // 2.通过gcAssistAlloc1向其调用方发出信号，表明goroutine完成了GC循环。 // 以任何其他方式这样做都是不安全的，因为goroutine的堆栈可能在此期间发生了移动。 // 3.通过debugCallWrap将参数传递给新的goroutine，因为禁止在运行时分配闭包。 param unsafe.Pointer // passed parameter on wakeup // 用来表示当前G的状态。 atomicstatus uint32 // 记录当前G的状态 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus // 当前 goroutine 的全局唯一 ID。 goid int64 // schedlink字段指向全局运行队列中的下一个g // 所有位于全局运行队列中的g形成一个链表 // 被调度器用于实现内部链表、队列，对应的 guintptr 类型从逻辑上将等于 *g， // 而底层类型却是个 uintptr，这样是为了避免写屏障。 schedlink guintptr waitsince int64 // g被阻塞的大约时间 waitreason waitReason // if status==Gwaiting // 抢占调度标志，如果需要抢占调度，设置preempt为true // 抢占信号，重复 stackguard0 = stackpreempt // 为true时，调度器会在合适的时机触发一次抢占 preempt bool // preemption signal, duplicates stackguard0 = stackpreempt preemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule preemptShrink bool // shrink stack at synchronous safe point\t在同步安全点收缩堆栈 // asyncSafePoint is set if g is stopped at an asynchronous // safe point. This means there are frames on the stack // without precise pointer information. asyncSafePoint bool paniconfault bool // panic (instead of crash) on unexpected fault address gcscandone bool // g has scanned stack; protected by _Gscan bit in status // 不能扩展栈，该值在系统调用前被设置为true，在系统调用返回是设置为false。 throwsplit bool // must not split stack // activeStackChans indicates that there are unlocked channels // pointing into this goroutine\u0026#39;s stack. If true, stack // copying needs to acquire channel locks to protect these // areas of the stack. // activeStackChans 表示有未锁定的通道指向这个 goroutines 堆栈 // 如果为true，堆栈复制需要获取通道锁来保护堆栈的这些区域 activeStackChans bool // parkingOnChan indicates that the goroutine is about to // park on a chansend or chanrecv. Used to signal an unsafe point // for stack shrinking. It\u0026#39;s a boolean value, but is updated atomically. parkingOnChan uint8\t// 赋值1，表示当前goroutine正在chan上 raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine tracking bool // whether we\u0026#39;re tracking this G for sched latency statistics trackingSeq uint8// used to decide whether to track this G runnableStamp int64// timestamp of when the G last became runnable, only used when tracking runnableTime int64// the amount of time spent runnable, cleared when running, only used when tracking sysexitticks int64// cputicks when syscall has returned (for tracing) traceseq uint64// trace event sequencer tracelastp puintptr// last P emitted an event for this goroutine // 关联到与当前G绑定的M，可以参考下 LockOSThread。 lockedm muintptr sig uint32 writebuf []byte // sigcode0 和 sigcode1 用于临时传参记录 sigcode0 uintptr\t// 记录当前需要跳转的SP地址，比如panic中即将跳转goexit sigcode1 uintptr\t// 记录当前需要跳转的PC地址，比如panic中即将跳转goexit sigpc uintptr // 在创建goroutine时候被保存 gopc uintptr // pc of go statement that created this goroutine // 创建此goroutine的祖先信息goroutine（仅在debug.traceback祖先时使用），在创建goroutin时候被保存 ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) // goroutine函数的pc。在创建goroutin时候被保存 startpc uintptr // pc of goroutine function racectx uintptr // 标记当前goroutine 0表示主goroutine // 记录让当前goroutine等待的sudog，sudog是chan的等待队列，等待被读，c\u0026lt;-1操作引起当前，该参数在当前goroutine被恢复时判断使用 // Sudog结构这个g正在等待(有一个有效的elem指针);按锁定顺序。 // 主要用于实现 channel 中的等待队列。 waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr// cgo traceback context labels unsafe.Pointer // profiler labels // 缓存 timer 由于 time.Sleep。 timer *timer // cached timer for time.Sleep // selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G\u0026#39;s GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 // GC信用值 } type stack struct Stack描述了Go的执行栈。栈的边界正好是[lo, hi)，两边都没有隐式的数据结构。 注意栈是向下生长的。 // Stack describes a Go execution stack. // The bounds of the stack are exactly [lo, hi), // with no implicit data structures on either side. type stack struct { lo uintptr // 栈顶，指向内存【低地址】 hi uintptr // 栈底，指向内存【高地址】 } type gobuf struct 保存goroutine的调度信息，应用场景在这goroutine被选中调度起来去执行，或当前goroutine被抢占需要保存CPU信息然后下次接到从此处执行。 用来存储goroutine执行上下文的sched字段需要格外注意，它与goroutine协程切换的底层实现相关。 type gobuf struct { // sp字段存储的是栈指针，rsp寄存器的值 sp uintptr // 保存CPU的SP寄存器的值，存储的是被抢占或调度时CPU信息 // pc字段存储的是指令指针，rip寄存器的值 pc uintptr // 保存CPU的IP寄存器的值 // g字段用来反向关联到对应的G。 g guintptr // 记录当前这个gobuf对象属于那个goroutine // ctxt字段指向闭包对象，也就是说用go关键字创建协程的时候传递的是一个闭包 // 这里会存储闭包对象的地址。rdx寄存器的值 ctxt unsafe.Pointer // 上下文信息 // 保存系统调用的返回值，因为从系统调用返回之后如果p被其他工作线程抢占 // 则这个goroutine会被放入全局运行队列被其他工作线程调度，其他线程需要知道系统调用的返回值 // ret字段用来存储返回值，实际上是利用AX寄存器实现类似C函数的返回值，目前只发现panic-recover机制用到了该字段。 ret sys.Uintreg // lr字段在arm等架构上用来存储返地址，x86没有用到该字段。 lr uintptr // bp字段用来存储栈帧基地址。rbp寄存器的值 bp uintptr // 对于支持帧指针的架构 } G Status // defined constants const ( // goroutine 开始创建的状态，此时尚未初始化完成； _Gidle = iota // 0 // goroutine 在待执行队列中，等待被执行； _Grunnable // 1 // goroutine 正在执行，同一时刻一个P中只有一个g处于此状态； _Grunning // 2 // goroutine 正在执行系统调用； _Gsyscall // 3 // goroutine 处于挂起状态，需要等待被唤醒。gc、channel 或者锁操作时经常会进入这种状态； _Gwaiting // 4 // _Gmoribund_unused is currently unused, but hardcoded in gdb // scripts. _Gmoribund_unused // 5 // goroutine 刚初始化完成或者已经被销毁，会处于此状态； _Gdead // 6 // _Genqueue_unused is currently unused. _Genqueue_unused // 7 // goroutine 正在栈扩容流程中； _Gcopystack // 8 // goroutine 被抢占后的状态 _Gpreempted // 9 // _Gscan与前面的一些状态组合。 // 除了_Gscanrunning外，其他的组合状态都表示GC正在扫描goroutine的栈，goroutine没有在执行用户代码， // 栈的所有权归设置了_Gscan标志位的goroutine所有。 _Gscan = 0x1000 _Gscanrunnable = _Gscan + _Grunnable // 0x1001 // _Gscanrunning在GC通知G扫描栈的时候，它被用来短暂的阻止状态变换，其他方面和_Grunning一样。 // 栈扫描完成后，goroutine将会切换回原来的状态，移除_Gscan标志位。 _Gscanrunning = _Gscan + _Grunning // 0x1002 _Gscansyscall = _Gscan + _Gsyscall // 0x1003 _Gscanwaiting = _Gscan + _Gwaiting // 0x1004 _Gscanpreempted = _Gscan + _Gpreempted // 0x1009 ) type m struct m结构体用来代表工作线程，它保存了m自身使用的栈信息。 当前正在运行的goroutine以及与m绑定的p等信息。 每个工作线程都有唯一的一个m结构体的实例对象与之对应，m结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的goroutine以及是否空闲等等状态信息之外，还通过指针维持着与p结构体的实例对象之间的绑定关系。 于是，通过m既可以找到与之对应的工作线程正在运行的goroutine，又可以找到工作线程的局部运行队列等资源。 只要每个工作线程拥有了各自私有的m结构体全局变量，我们就能在不同的工作线程中使用相同的全局变量名来访问不同的m结构体对象。 type m struct { // 并不是一个真正的goroutine，它的栈是由操作系统分配的， // 初始大小比普通goroutine的栈要大，被用作调度器执行的栈。 // 程序刚初始化启动时第一个g0栈大概有64KB大小，后面的工作线程的g0栈有8KB大小 g0 *g // goroutine with scheduling stack // 记录被调用者信息，在抢占调度中被设置 morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. // 线程ID，该值在`go1.19.3/src/runtime/os_linux.go:minit`被调用，该方法在mstart函数线程刚启动时初始化。 // 该值默认是一个自增的ID procid uint64 // for debuggers, but offset not hard-coded // 本质上是用来处理信号的栈，因为一些UNIX系统支持为信号处理器配置独立的栈。 gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask // 通过TLS实现m结构体对象与工作线程之前的绑定 // 线程本地存储，存储内容只对当前线程可见。线程本地存储的时m.tls的地址，m.tls[0]存储的是当前运行的g， // 因此线程可以通过g找到当前的m、p、g0等信息。 tls [6]uintptr // thread-local storage (for x86 extern register) mstartfn func() // 工作线程启动后需要执行的函数 // 指向工作线程正在运行的goroutine的g结构体对象，该参数的作用是在切换到g0栈后清除之前的g， // 记录在这里指向的是M当前正在执行的G。 curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal // 记录与当前工作线程绑定的p结构体对象 // GMP中的P，即关联到当前M上的处理器。 p puintptr // attached p for executing go code (nil if not executing go code) // 用来将P传递给M，调度器一般是在M阻塞时为m.nextp赋值，等到M开始运行后会尝试从nextp处获取P进行关联。 nextp puintptr // 用来暂存执行系统调用之前关联的P。 oldp puintptr // the p that was attached before executing a syscall // M的唯一id。 id int64 // 当前线程的ID，根据schedt.mnext记录的工作线程个数而设置的 // mallocing = 1，当前goroutine正在分配内存 mallocing int32 throwing int32 // 不为空时表示要关闭对curg的抢占，字符串内容给出了相关的原因。 // 用于控制当前 goroutine 是否可被抢占。 //\t1. 当一个 goroutine 执行一些关键操作时（如获取锁、执行系统调用等），它可能需要暂时关闭抢占，以避免在关键操作期间被抢占导致死锁或竞争条件的发生。 // 2. 程序员可以通过使用 runtime.LockOSThread() 函数来将当前 goroutine 绑定到一个 OS 线程上，从而避免抢占的发生。 // 3. 如果在执行关键操作时需要暂时关闭抢占，可以使用 runtime.LockOSThread() 函数将当前 goroutine 绑定到一个 OS 线程上，并在操作完成后调用 runtime.UnlockOSThread() 函数将其解绑。 preemptoff string // if != \u0026#34;\u0026#34;, keep curg running on this m // 记录当前M持有锁的数量，不为0时能够阻止抢占发生。 // 用来记录当前 goroutine 持有的互斥锁数量的 // 1. 当 goroutine 持有一个互斥锁时，它不能被抢占，因为如果被抢占了，其他 goroutine 就无法获取该锁。 // 2. 为了避免这种情况的发生，Go 语言的调度器会在检查是否应该抢占当前 goroutine 之前，先检查它是否持有互斥锁。 // 3. 如果当前 goroutine 持有互斥锁，则调度器会暂时将其标记为不可抢占状态，直到该 goroutine 释放锁为止。 // 4. 因此，m.locks 字段是用来辅助调度器实现这一机制的。 // 5. 当一个 goroutine 获取一个互斥锁时，m.locks 字段会被更新，标记该 goroutine 持有相应的互斥锁。 // 6. 当 goroutine 释放锁时，m.locks 字段也会被更新，清除相应的标记。 // 7. 调度器在决定是否应该抢占一个 goroutine 时，会检查该 goroutine 是否持有互斥锁，以此来避免因抢占导致的锁竞争和死锁问题。 locks int32\t// 尝试获取锁的次数，在lock中加一，在unlock减一 dying int32 profilehz int32 // spining状态：表示当前工作线程正在试图从其他工作线程的本地运行队列偷取goroutine // 表示当前M正处于自旋状态。 spinning bool // m is out of work and is actively looking for work\tblocked bool // m is blocked on a note m在note上被屏蔽，表示当前M正在休眠中 newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait atomic.Uint32 // Whether it is safe to free g0 and delete m (one of freeMRef, freeMStack, freeMWait) // fastrand 用于在一些随机值的使用需要 fastrand uint64 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call doesPark bool // non-P running threads: sysmon and newmHandoff never use .park // 没有goroutine需要运行时，工作线程睡眠在这个park成员上 // 其他线程通过这个park唤醒该工作线程 // 用来支持M的sleep和wakeup，可以很方便地实现每个M单独sleep和wakeup。 park note // 记录所有工作线程的一个链表 // 把所有的M连起来，构成allm链表。 alllink *m // on allm // 被调度器用于实现链表，如空闲M链表。 schedlink muintptr // 关联到与当前M绑定的G，可参考LockOSThread。 lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 // 用来把已经退出运行的M连起来，构成sched.freem链表，方便下次分配时复用。 freelink *m // on sched.freem // mFixup is used to synchronize OS related m state (credentials etc) // use mutex to access. mFixup struct { lock mutex fn func(bool) bool } // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call // preemptGen counts the number of completed preemption // signals. This is used to detect when a preemption is // requested, but fails. Accessed atomically. preemptGen uint32 // Whether this is a pending preemption signal on this M. // Accessed atomically. // // 这个M上是否有一个待处理的抢占信号。原子操作。 // 该参数在 preemptM 函数中从0设置为1。 signalPending uint32 dlogPerM mOS // Up to 10 locks held by this m, maintained by the lock ranking code. locksHeldLen int locksHeld [10]heldLockInfo } type p struct p结构体用于保存工作线程执行go代码时所必需的资源。 比如goroutine的运行队列，内存分配用到的缓存，局部goroutien运行队列等等。 type p struct { // P的位移ID，等于当前P在allp数组中的下标。 id int32 // 当前P所处状态，也就是当前P上的g的状态 status uint32 // one of pidle/prunning/... // link是一个没有写屏障的指针，被调度器用来构造链表 link puintptr // 在每次调度器调用时递增，记录当前P的调度次数 // 记录调度发生的次数，实际上在每发生一次goroutine切换且不继承时间片的情况下，该字段会加一。 schedtick uint32 // incremented on every scheduler call // 在每次系统调用时递增，记录当前P的系统调用次数 // 发生每一次系统调用就会加一。 syscalltick uint32 // incremented on every system call // sysmon观察到的最后一个时钟信号 // 该值被用于sysmon线程记录被监控p的系统调用时间和运行时间，注意这里是与sysmon相关的 // type sysmontick struct { //\tschedtick uint32 //\tschedwhen int64 //\tsyscalltick uint32 //\tsyscallwhen int64 // } // 被监控线程用来存储上一次检查时的调度器时钟滴答，用于实现时间片算法。 sysmontick sysmontick // last tick observed by sysmon // 本质上是个指针，反向关联到当前P绑定的M。 m muintptr // back-link to associated m (nil if idle) mcache *mcache\t// p的内存模块管理 pcache pageCache raceprocctx uintptr // 用于缓存*_defer接口，避免频繁堆分配 deferpool []*_defer // pool of available defer structs of different sizes (see panic.go) // 根据源码中 pp.deferpool = pp.deferpoolbuf[:0] 可知，deferpoolbuf只是作为deferpool的内存地址在使用 deferpoolbuf [32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. // 用来从全局sched,goidgen处生气goid分配区间，批量申请以减少全局范围的锁竞争用。 goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. // 本地goroutine运行队列 // 当前P的就绪队列，用一个数组和一头一尾两个下标实现了一个环型队列。 runqhead uint32\t// 队列头 runqtail uint32\t// 队列尾 runq [256]guintptr // 使用数组实现的循环队列 // runnext, if non-nil, is a runnable G that was ready\u0026#39;d by // the current G and should be run next instead of what\u0026#39;s in // runq if there\u0026#39;s time remaining in the running G\u0026#39;s time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready\u0026#39;d // goroutines to the end of the run queue. // // 如果不为nil，则指向一个被当前G准备好(就绪)的G，接下来将会继承当前G的时间片开始运行。 // 该字段存在的意义在于，假如有一组goroutine中有生产者和消费者，它们在一个channel上频繁的等待、唤醒， // 那么调度器会把它们作为一个单元来调度。每次使用runnext比添加到本地runq尾部能大幅减少延迟。 runnext guintptr\t// 记录着下一个将要执行的goroutine // Available G\u0026#39;s (status == Gdead) // 记录着所有状态为Gdead的空闲的goroutine链表 // go关键字配的时候优先从这里获取，goroutine执行完时保存在这里 // 用来缓存已经退出运行的G，方便再次分配时进行复用。 gFree struct { gList\t// type gList struct {head guintptr}\tguintptr是uintputr的自定义类型 n int32\t// 记录着当前空闲的g的数量 } sudogcache []*sudog sudogbuf [128]*sudog // Cache of mspan objects from the heap. mspancache struct { // We need an explicit length here because this field is used // in allocation codepaths where write barriers are not allowed, // and eliminating the write barrier/keeping it eliminated from // slice updates is tricky, moreso than just managing the length // ourselves. len int buf [128]*mspan } tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex // 用于下面字段对齐 _ uint32 // Alignment for atomic fields below // 以下timer0When和timerModifiedEarliest字段维护这这个P的执行时间，也是用于抢断判断依据 // The when field of the first entry on the timer heap. // This is updated using atomic functions. // This is 0 if the timer heap is empty. // timer 堆上第一个条目的 when 字段。 // 这是使用原子函数更新的 // 如果 timer 堆为空，则为 0 timer0When uint64\t// 堆顶元素什么时候执行 // The earliest known nextwhen field of a timer with // timerModifiedEarlier status. Because the timer may have been // modified again, there need not be any timer with this value. // This is updated using atomic functions. // This is 0 if the value is unknown. // 具有 timerModifiedEarlier 状态的定时器的最早已知 nextwhen 字段。 // 因为定时器可能已经被再次修改，所以不需要任何具有该值的timer // 这是使用原子函数更新的 // 如果没有 timerModifiedEarlier 计时器，则为 0 timerModifiedEarliest uint64\t// 如果有timer修改为更早执行时间了，将执行时间更新到当更早时间 // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) // gcMarkWorkerMode is the mode for the next mark worker to run in. // That is, this is used to communicate with the worker goroutine // selected for immediate execution by // gcController.findRunnableGCWorker. When scheduling other goroutines, // this field must be set to gcMarkWorkerNotWorker. gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which the most recent // mark worker started. gcMarkWorkerStartTime int64 // gcw is this P\u0026#39;s GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P\u0026#39;s GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point // statsSeq is a counter indicating whether this P is currently // writing any stats. Its value is even when not, odd when it is. statsSeq uint32 // Lock for timers. We normally access the timers while running // on this P, but the scheduler can also do it from a different P. // 锁定timers。我们通常在此P上运行时访问timers，但调度程序也可以从不同的P上执行此操作 timersLock mutex\t// 操作timer的互斥锁 // Actions to take at some time. This is used to implement the // standard library\u0026#39;s time package. // Must hold timersLock to access. // 必须持有 timersLock 才能访问 // 当前关于P的timer，可能出现当前P中很多goroutine被挂在不同的timer上 timers []*timer\t// 该P上的所有timer，必须加锁去操作这个字段，因为不同的P操作这个字段会有竞争 // Number of timers in P\u0026#39;s heap. // Modified using atomic instructions. // P 堆中的timers数量，使用原子指令修改 numTimers uint32\t// P堆上所有的timer数量 // Number of timerModifiedEarlier timers on P\u0026#39;s heap. // This should only be modified while holding timersLock, // or while the timer status is in a transient state // such as timerModifying. // P 的堆上 timerModifiedEarlier 计时器的数量 // 这只应在持有 timersLock 时修改，或者当定时器状态处于诸如 timerModifying 之类的瞬态状态时进行修改 adjustTimers uint32 // Number of timerDeleted timers in P\u0026#39;s heap. // Modified using atomic instructions. // P 的堆中 timerDeleted timers的数量 // 使用原子指令修改 deletedTimers uint32\t// 被标记为删除的timer，要么是我们调用stop，要么是timer自己触发后过期导致的删除 // Race context used while executing timer functions. timerRaceCtx uintptr // preempt is set to indicate that this P should be enter the // scheduler ASAP (regardless of what G is running on it). // preempt 设置为指示该 P 应尽快进入调度程序（无论 G 在其上运行什么） // 在GO1.14版本被引入，以支持新的异步抢占机制。 preempt bool pad cpu.CacheLinePad } P Status const ( // P status // _Pidle means a P is not being used to run user code or the // scheduler. Typically, it\u0026#39;s on the idle P list and available // to the scheduler, but it may just be transitioning between // other states. // // The P is owned by the idle list or by whatever is // transitioning its state. Its run queue is empty. // // 空闲状态。此时的P没有被用来执行用户代码或调度器代码，通常位于空闲链表中，能够被调度器获取， // 它的状态可能正在由空闲转变成其他状态。P的所有权归空闲链表或某个正在改变它状态的线程所有，本地runq为空。 _Pidle = iota // 空闲状态 // _Prunning means a P is owned by an M and is being used to // run user code or the scheduler. Only the M that owns this P // is allowed to change the P\u0026#39;s status from _Prunning. The M // may transition the P to _Pidle (if it has no more work to // do), _Psyscall (when entering a syscall), or _Pgcstop (to // halt for the GC). The M may also hand ownership of the P // off directly to another M (e.g., to schedule a locked G). // // 运行中状态。当前P正被某个M持有，并且用于执行用户代码或调度器代码。 // 只有持有P所有权的M，才被允许将P的状态从_Prunning转变为其他状态。 // 在任务都执行完以后，M会把P设置为_Pidle状态。在进入系统调用时，M会把P设置为_Psyscall状态。 // 挂起以执行GC时，会设置为_Pgcstop状态。某些情况下，M还可能会直接把P的所有权交给另一个M。 _Prunning // 运行中状态 // _Psyscall means a P is not running user code. It has // affinity to an M in a syscall but is not owned by it and // may be stolen by another M. This is similar to _Pidle but // uses lightweight transitions and maintains M affinity. // // Leaving _Psyscall must be done with a CAS, either to steal // or retake the P. Note that there\u0026#39;s an ABA hazard: even if // an M successfully CASes its original P back to _Prunning // after a syscall, it must understand the P may have been // used by another M in the interim. // // 系统调用状态。此时的P没有执行用户代码，它和一个处于syscall中的M间存在弱关联关系，可能会被另外一个M窃取走。 _Psyscall // 系统调用中状态 // _Pgcstop means a P is halted for STW and owned by the M // that stopped the world. The M that stopped the world // continues to use its P, even in _Pgcstop. Transitioning // from _Prunning to _Pgcstop causes an M to release its P and // park. // // The P retains its run queue and startTheWorld will restart // the scheduler on Ps with non-empty run queues. // // GC停止状态。P被STW挂起以执行GC，所有权归执行STW的M所有，执行STW的M会继续使用处于_Pgcstop状态的P。 // 当P的状态从_Prunning转变成_Pgcstop时，会造成关联的M释放P的所有权，然后进入阻塞状态。 // P会保留它的本地runq，然后Start The World会从新启动这些本地runq不为空的P。 _Pgcstop // GC停止状态 // _Pdead means a P is no longer used (GOMAXPROCS shrank). We // reuse Ps if GOMAXPROCS increases. A dead P is mostly // stripped of its resources, though a few things remain // (e.g., trace buffers). // // 停用状态。因为GOMAXPROCS收缩，会造成多余的P被停用，当GOMAXPROCS再次增大时还会被复用。 // 一个停用的P，大部分资源被剥夺，只有很少量保留。 _Pdead // 停用状态 ) type schedt struct schedt结构体用来保存调度器的状态信息和(可运行或空闲的)goroutine的容器以及保存goroutine的运行队列 每个Go程序中只有一个调度器，多以每个Go程序中schedt结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量 这样每个工作线程都可以访问它以及它所拥有的goroutine运行队列，我们称这个运行队列为全局goroutine运行队列 全局运行队列是每个工作线程都可以读写的，因此访问它需要加锁，然而在一个繁忙的系统中，加锁会导致严重的性能问题 于是又为每个工作线程引入一个私有的局部goroutine运行队列，工作线程优先使用自己的局部运行队列，只有必要时才会去访问全局运行队列 这大大减少了锁冲突，提高了工作线程的并发性 在Go调度器源代码中，局部运行队列被包含在p结构体的实例对象之中，每一个运行着go代码的工作线程都会与一个p结构体的实例对象关联在一起 type schedt struct { // accessed atomically. keep at top to ensure alignment on 32-bit systems. // 用作全局的goid分配器，以保证goid的唯一性。 // P中的goidcache就是从这里批量分配获取goid的。 goidgen uint64 // 以下两个字段可以在IO轮询时判断是否有需要的timer已到时间需要去执行 // 上次网络轮询的时间点，如果当前轮询，则为 0 // 记录的是上次执行netpoll的时间，如果等于0，则表示某个线程正在阻塞式地执行netpoll。 lastpoll uint64 // time of last network poll, 0 if currently polling // 下次timer应该被唤醒时间点，来自timer四叉数中的时间 // 表示阻塞式地netpoll将在何时被唤醒。GO1.14版本重构了Timer，引入了该字段，唤醒netpoller以处理Timer。 pollUntil uint64 // time to which current poll is sleeping // 全局范围的调度器锁，访问sched中的很多字段需要提前获得该锁。 lock mutex // When increasing nmidle, nmidlelocked, nmsys, or nmfreed, be // sure to call checkdead(). // 有空闲的工作线程M组成的链表 // 空闲M链表的链表头，nmidle记录的是空闲M的数量，即链表的长度。 midle muintptr // idle m\u0026#39;s waiting for work // 空闲的工作线程数量 nmidle int32 // number of idle m\u0026#39;s waiting for work // 统计的是与G绑定(LockOSThread)且处于空闲状态的M，绑定的G没有在运行，相应的M不能用来运行其他G，只能挂起，以便进入空闲状态。 nmidlelocked int32 // number of locked m\u0026#39;s waiting for work // 下一个工作线程M的ID值 // 记录了共创建了多少个M，同时也被用作下一个M的ID。 mnext int64 // number of m\u0026#39;s that have been created and next M ID // 最多只能创建maxmcount个工作线程M，初始化时该值为10000，schedinit()中被设置。 // 限制了最多允许的M的个数，除去那些已经释放的。 maxmcount int32 // maximum number of m\u0026#39;s allowed (or die) // 统计的是系统M的个数。比如监控线程sysmon启动时会 nmsys++。 nmsys int32 // number of system m\u0026#39;s not counted for deadlock // 统计的是累计已经释放了所少M。 nmfreed int64 // cumulative number of freed m\u0026#39;s // 记录的是系统goroutine的数量，会被原子性的更新。 ngsys uint32 // 系统 goroutine 的数量； 原子更新 // 由空闲的p结构体对象组成的链表 // 空闲P链表的表头，npidle记录了空闲P的个数，也就是链表的长度。 pidle puintptr // idle p\u0026#39;s // 空闲的p结构体对象的数量 npidle uint32 // 正在自旋的M的数量 // 记录的是处于自旋状态的M的数量。 nmspinning uint32 // See \u0026#34;Worker thread parking/unparking\u0026#34; comment in proc.go. // Global runnable queue. // goroutine全局运行队列，全局的就绪队列。 runq gQueue // 记录的是全局就绪队列的长度。也就是全局队列goroutine的个数。 runqsize int32 // disable controls selective disabling of the scheduler. // // Use schedEnableUser to control this. // // disable is protected by sched.lock. // // 用来禁止调度用户goroutine，其中的user变量被置为true后，调度器将不在调度执行用户goroutine， // 系统goroutine不受影响。期间就绪的用户gouroutine会被临时存储放到disable.runnable队列中，变量n记录了队列长度。 // GC期间。 disable struct { // user disables scheduling of user goroutines. user bool runnable gQueue // pending runnable Gs n int32 // length of runnable } // Global cache of dead G\u0026#39;s. // gFree是所有已退出的goroutine对应的g结构体对象组成的链表 // 用于缓存g结构体对象，避免每次创建gouroutine时都重新分配内存 // 用来存储已经退出运行的G，lock是本结构单独的锁，避免争用sched.lock。stack和noStack这两个列表分别用来存储有栈的G，因为在 // G结束运行被回收的时候，如果栈大小超过了标准大小，就会被释放，所以有一部分G是没有栈的。变量n是两个列表之和，也就是总缓存了多少个G。 gFree struct { lock mutex stack gList // Gs with stacks noStack gList // Gs without stacks n int32 } // Central cache of sudog structs. // 构成了 sudog 结构的中央缓存，供各个P存储。 sudoglock mutex sudogcache *sudog // Central pool of available defer structs of different sizes. // 构成了 _defer 结构的中央缓存。 deferlock mutex deferpool [5]*_defer // freem is the list of m\u0026#39;s waiting to be freed when their // m.exited is set. Linked through m.freelink. // freem 是设置 m.exited 时等待释放的 m 的列表。 通过 m.freelink 链接。 // 一组已经结束运行的M构成的链表头，通过m.freem链接到下一个项，链表中的内容在分配新的M时会被复用。 freem *m // 表示GC正在等待运行，和stopwait、stopnote一同被用于实现STW。 // stopwait记录了STW需要停止的P的数量，发起STW的线程会先把GOMAXPROCS赋值给stopwait，也就是需要停止所有的P。 // 再把gcwaiting置为1，然后再stopnote上睡眠等待被唤醒。其他正在运行的M检测到gcwaiting后会释放关联P的所有权，并把P的状态 // 置为_Pgcstop，再把stopwait的值减1，然后M把自己挂起。M在自我挂起之前如果检测到stopwait==0，也就是所有P都已经停止了， // 就会通过stopnote唤醒发起STW的线程。 gcwaiting uint32 // gc is waiting to run; GC是否正在处于等待 stopwait int32 stopnote note // sysmonwait的值为0或1，表示sysmon线程是否sleep。 // 1. 0时，sysmon没有sleep。 // 2. 1时，sysmon在sysmonnote上sleep。 // 当STW时sysmon可能会挂在sysmonnote上，在STW退出时会唤醒sysmon。 // 当所有P都空闲(可能是陷入系统调用中)，sysmon可能会挂在 sysmonwait uint32 sysmonnote note // While true, sysmon not ready for mFixup calls. // Accessed atomically. // 表示主线程已经创建了监控线程sysmon，但是后者尚未开始运行，某些操作需要等到sysmon启动之后才能进行。 sysmonStarting uint32 // safepointFn should be called on each P at the next GC // safepoint if p.runSafePointFn is set. // 如果设置了 p.runSafePointFn，则应该在下一个 GC 安全点对每个 P 调用 safepointFn // 是一个Function Value.safePointWait 和 Value.safePointNote的左右类似stopwait和stopnone，被runtime.forEachP用来确保每个P都在 // 下一个GC安全点执行了 safePointFn。 safePointFn func(*p) safePointWait int32 safePointNote note // 用来设置性能分析的采样频率。 profilehz int32 // cpu profiling rate // 最后一次改变gomaxprocs的时间，参看procresize()函数 // 统计了改变GOMAXPROCS所花费的时间。 procresizetime int64 // nanotime() of last change to gomaxprocs totaltime int64 // ∫gomaxprocs dt up to procresizetime // sysmonlock protects sysmon\u0026#39;s actions on the runtime. // // Acquire and hold this mutex to block sysmon from interacting // with the rest of the runtime. // 监控线程sysmon访问runtime数据时会加上的锁，其他线程可以通过它和监控线程进行同步。 sysmonlock mutex } 重要的全局变量 var ( allgs []*g\t// 保存所有的g allm *m // 所有的m构成的一个链表，包括下面的m0 allp []*p // 保存所有的p，len(allp) == gomaxprocs ncpu int32 // 系统中cpu核的数量，程序启动时由runtime代码初始化 gomaxprocs int32 // p的最大值，默认等于ncpu，但可以通过GOMAXPROCS修改 sched schedt // 调度器结构体对象，记录了调度器的工作状态 m0 m // 代表进程的主线程 g0 g // m0的g0，也是m0.g0 = \u0026amp;g0 // Information about what cpu features are available. // Packages outside the runtime should not use these // as they are not an external api. // Set on startup in asm_{386,amd64}.s processorVersionInfo uint32 // CPU厂商信息，能根据该标识找到对应厂商 isIntel bool // true.当前处理器信息是英特，false.不是英特处理器 ) ","permalink":"https://heliu.site/posts/golang/goroutine/struct/","summary":"Golang GMP相关结构简介。","title":"runtime中重要的结构体"},{"content":" Go 通过通信来共享内存，而不是共享内存来通信。 channel 单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。 虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。 Go语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。 如果说goroutine是Go程序并发的执行体，channel就是它们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 Go 语言中的通道（channel）是一种特殊的类型。 通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。 每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。 通道是类型相关的，一个通道只能传递（发送或接收）一种类型的值，这个类型需要在声明通道时指定。 channel 类型 channel是一种类型，一种引用类型。声明通道类型的格式如下： 1 var identily chan type 1 2 3 var ch1 chan int // 声明一个传递整型的通道 nil var ch2 chan bool // 声明一个传递布尔型的通道 nil var ch3 chan []int // 声明一个传递int切片的通道 nil 创建 channel 通道是引用类型，通道类型的空值是nil。 1 2 var ch chan in // 默认值 nil fmt.Println(ch) // nil make() 函数创建通道。 1 make(chan type, [缓冲大小]) 1 2 3 ch4 := make(chan int) ch5 := make(chan bool) ch6 := make(chan []int) 1 2 3 4 // 无缓冲 var channel1 chan int = make(chan int) // 通道大小默认值为0 channel2 := make(chan int) // 通道大小默认值为0 channel3 := make(chan int, 1) // 有缓冲 Go 通道有三种：发送（send）、接收（receive）、同时发送和接收。 chan\u0026lt;-：表示数据进入通道，要把数据写进通道，对于调用者就是发送 send，chan \u0026lt;- int。 \u0026lt;-chan：表示数据从通道出来，对于调用者就是得到通道的数据，当然就是接收 recv，\u0026lt;-chan int。 1 2 3 receive_only := make(\u0026lt;-chan int) // 定义接收的channel send_only := make(chan\u0026lt;- int) // 定义发送的channel send_receive := make(chan int) // 定义同时发送接收 channel 操作 通道有发送（send）、接收(receive）和关闭（close）三种操作。发送和接收都使用 \u0026lt;- 符号。 定义通道，无缓冲通道。 1 ch := make(chan int) // size默认等于0 发送：将一个值发送到通道中。 1 ch \u0026lt;- 10 // 把10发送到ch中 接收：从一个通道中接收值。 1 2 x := \u0026lt;- ch // 从ch中接收值并赋值给变量x \u0026lt;-ch // 从ch中接收值，忽略结果 关闭：通过调用内置的close函数来关闭通道。 1 close(ch) 关于关闭通道需要注意的事情是： 只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。 通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的。 在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。 关闭后的通道有以下特点： 对一个关闭的通道再发送值就会导致panic。 对一个关闭的通道进行接收会一直获取值直到通道为空。 对一个关闭的并且没有值得通道执行接收操作会得到对应类型的零值。 关闭一个已关闭的通道会导致panic。 无缓冲的通道 无缓冲的通道又称为阻塞的通道。 1 2 3 4 5 6 7 8 9 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int) ch \u0026lt;- 10 fmt.Println(\u0026#34;发送成功\u0026#34;) } 上面这段代码能够通过编译，但是执行的时候会出现以下错误： fatal error: all goroutines are asleep - deadlock! 所有的goroutine都睡眠 - 死锁 goroutine 1 [chan send]: main.main() D:/True-False/WWW/GoLang/src/xuexi/channel1.go:7 +0x5b exit status 2 为什么会出现deadlock错误呢？ 因为我们使用ch := make(chan int)创建的是无缓冲的通道。 无缓冲的通道只有在有人接收值的时候才能发送值。无缓冲的通道必须有接收才能发送。 上面的代码会阻塞在ch \u0026lt;- 10这一行代码形成死锁，那如何解决这个问题呢？ 一种方法是启用一个goroutine去接收值，例如： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int) go recv(ch) ch \u0026lt;- 10 fmt.Println(\u0026#34;发送成功\u0026#34;) // Output: // 10 // 发送成功 } func recv(c chan int) { recv := \u0026lt;- c fmt.Println(recv) } 无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作。 这时值才能发送成功，两个goroutine将继续执行。 相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。 使用无缓冲通道进行通信将导致发送和接收的goroutine同步化，因此，无缓冲通道也被称为同步通道。 有缓冲的通道 解决上面问题的方法还有一种就是使用有缓冲区的通道。 我们可以在使用make函数初始化通道的时候为其指定通道的容量。 1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int, 1) ch \u0026lt;- 10 fmt.Println(\u0026#34;发送成功\u0026#34;) // Output: // 发送成功 } 只要通道的容量大于零，那么该通道就是有缓冲的通道，通道的容量表示通道中能存放元素的数量。 我们可以使用内置的len函数获取通道内元素的数量，使用cap函数获取通道的容量，虽然我们很少会这么做。 len(chan) 获取通道内的元素个数。 cap(chan) 获取通道容量。 关闭通道 可以通过内置的close()函数关闭channel，如果你的管道不往里存值或者取值的时候一定记得关闭管道。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package main import \u0026#34;fmt\u0026#34; func main() { c := make(chan int) go func() { for i := 0; i \u0026lt; 5; i++ { c \u0026lt;- i } close(c)\t// 关闭通道 }() for { if data, ok := \u0026lt;- c; ok { fmt.Println(data) } else { break } } /* for v := range c { fmt.Println(v) } */ fmt.Println(\u0026#34;main结束\u0026#34;) // Output: // 0 // 1 // 2 // 3 // 4 // main结束 } 从通道循环取值 当通过通道发送有限的数据时，我们可以通过close函数关闭通道来告知从该通道接收值的goroutine停止等待，使用close关闭通道，会触发那些在等待中的goroutine。 当通道被关闭时，往该通道发送值会引发panic，从该通道里接收的值一直都是类型零值。 那如何判断一个通道是否被关闭了呢？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package main import \u0026#34;fmt\u0026#34; func main() { ch1 := make(chan int) ch2 := make(chan int) go func() { for i := 0; i \u0026lt; 10; i++ { ch1 \u0026lt;- i } close(ch1) }() go func() { for { i, ok := \u0026lt;-ch1 // 通道关闭后再取值 ok = false if !ok { // 通道关闭时退出循环 break } ch2 \u0026lt;- i * i } close(ch2) }() // 打印ch2中值，通道关闭后会退出for range循环 for i := range ch2 { fmt.Println(i) } // Output: // 0 // 1 // 4 // 9 // 16 // 25 // 36 // 49 // 64 // 81 } 从上面的例子中我们看到有两种方式在接收值的时候判断通道是否被关闭，我们通常使用的是for range的方式。 单向通道 有的时候我们会将通道作为参数在多个任务函数间传递，很多时候我们在不同的任务函数中使用通道都会对其进行限制，比如限制通道在函数中只能发送或只能接收。 Go语言中提供了单向通道来处理这种情况。例如，我们把上面的例子改造如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import \u0026#34;fmt\u0026#34; func main() { ch1 := make(chan int) ch2 := make(chan int) go counter(ch1) go squarer(ch2, ch1) printer(ch2) // Output: // 100 // 121 // 144 // 169 // 196 // 225 // 256 // 289 // 324 // 361 } func counter(out chan \u0026lt;- int) { for i := 10; i \u0026lt; 20; i++ { out \u0026lt;- i } close(out) } func squarer(out chan \u0026lt;- int, in \u0026lt;- chan int) { for i := range in { out \u0026lt;- i * i } close(out) } func printer(in \u0026lt;- chan int) { for i := range in { fmt.Println(i) } } 其中，chan \u0026lt;- int 是一个只能发送的通道，可以发送但是不能接收。\u0026lt;- chan int 是一个只能接收的通道，可以接收但是不能发送。 在函数传参及任何赋值操作中将双向通道转换为单向通道是可以的，但反过来是不可以的。 总结 关闭已经关闭的channel也会引发panic。 channel nil 非空 空的 满了 没满 接收 panic 接收值 阻塞 接收值 接收值 发送 panic 发送值 发送值 阻塞 发送值 关闭 panic 关闭成功，读完数据后返回零值 关闭成功，返回零值 关闭成功，读完数据后返回零值 关闭成功，读完数据后返回零值值 select select 多路复用 某些场景下我们需要同时从多个通道接收数据，通道在接收数据时，如果没有数据可以接收将会发生阻塞。 你也许会写出如下代码使用遍历的方式来实现： 1 2 3 4 5 6 7 for { // 尝试从 ch1 接收值 data, ok := \u0026lt;-ch1 // 尝试从 ch2 接收值 data, ok := \u0026lt;-ch2 // ... } 这种方式虽然可以实现从多个通道接收值的需求，但是运行性能会差很多。为了应对这种场景，Go内置了select关键字，可以同时响应多个通道的操作。 select的使用类似于switch语句，它有一系列case分支和一个默认的分支。 每个case会对应一个通道的通信（接收或发送）过程。 select会一直等待，直到某个case的通信操作完成时，就会执行case分支对应的语句。 具体格式如下： 1 2 3 4 5 6 7 8 select { case \u0026lt;- chan1: // 如果chan1成功读到数据，则进行该case处理语句 case chan \u0026lt;- 1: // 如果成功向chan2写入数据，则进行该case处理语句 default: // 如果上面都没有成功，则进入default处理流程 } select 可以同时监听一个或多个channel，直到其中一个channel ready。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package main import ( \u0026#34;fmt\u0026#34; ) func test11(ch chan string) { ch \u0026lt;- \u0026#34;test1\u0026#34; } func test21(ch chan string) { ch \u0026lt;- \u0026#34;test2\u0026#34; } func main() { // 创建2个通道 output1 := make(chan string) output2 := make(chan string) // 跑2个子协程，写数据 go test11(output1) go test21(output2) // 由于select只能选择其中一个执行，因此上面两个goroutine至少有一个要阻塞 // 因此在case里面添读取另外一个goroutine，防止goroutine被一直挂起。 select { case s1 := \u0026lt;-output1: // recv \u0026lt;-output2 fmt.Println(\u0026#34;s1=\u0026#34;, s1) case s2 := \u0026lt;-output2: // recv \u0026lt;-output1 fmt.Println(\u0026#34;s2=\u0026#34;, s2) } // Output: // s2= test2 } 如果多个channel同时ready，则随机选择一个执行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;fmt\u0026#34; ) func main() { // 创建2个通道 intChan := make(chan int, 1) stringChan := make(chan string, 1) go func() { intChan \u0026lt;- 1 }() go func() { stringChan \u0026lt;- \u0026#34;hello\u0026#34; }() select { case value := \u0026lt;- intChan: fmt.Println(\u0026#34;int:\u0026#34;, value) case value := \u0026lt;- stringChan: fmt.Println(\u0026#34;string:\u0026#34;, value) } fmt.Println(\u0026#34;main结束\u0026#34;) // Output: // string: hello // main结束 } 可以用于判断通道是否存满。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 创建通道 output1 := make(chan string, 10) // 字协程写数据 go write(output1) // 取数据 for s := range output1 { fmt.Println(\u0026#34;res:\u0026#34;, s) // 延迟数据读取 time.Sleep(time.Second) } // Output: // write hello // res: hello // write hello // write hello // res: hello // write hello // res: hello // write hello // write hello // ... } func write(ch chan string) { for { select { case ch \u0026lt;- \u0026#34;hello\u0026#34;: fmt.Println(\u0026#34;write hello\u0026#34;) default: fmt.Println(\u0026#34;channel full\u0026#34;) } // 延迟 等到数据被取出 不然一直在执行default条件语句 time.Sleep(500 * time.Millisecond) } } 参考 https://www.topgoer.com ","permalink":"https://heliu.site/posts/golang/channel/use/","summary":"Golang channel使用介绍。","title":"Channel(使用)"},{"content":"包解释：\n该文件包含 Go channels 的实现。 c.sendq 和 c.recvq 中至少有一个是空的，除了使用 select 语句发送和接收的无缓冲 chan 上阻止了单个 goroutine 的情况外，在这种情况下，c.sendq 和c.recvq 的长度仅受 select 语句的大小限制。 select 同时操作单个无缓冲 chan 的读和写这种情况下可能存在 c.sendq 和 c.recvq 都不为空（这种情况下 select不能有 default 分支）。 对于缓冲 channels，也是: c.qcount \u0026gt; 0 表示 c.recvq 为空。缓存区有值则 c.recvq 一定为空。 c.qcount \u0026lt; c.dataqsiz 意味着 c.sendq 是空的。缓存区没有满则 c.sendq 一定为空。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 package runtime // This file contains the implementation of Go channels. // Invariants: // At least one of c.sendq and c.recvq is empty, // except for the case of an unbuffered channel with a single goroutine // blocked on it for both sending and receiving using a select statement, // in which case the length of c.sendq and c.recvq is limited only by the // size of the select statement. // // For buffered channels, also: // c.qcount \u0026gt; 0 implies that c.recvq is empty. // c.qcount \u0026lt; c.dataqsiz implies that c.sendq is empty. type hchan struct hchan 结构其实就是一个【有缓冲】和【双向链表】组成的队列。 这个队列维护着通信的数据，以及挂起等待的 goroutine。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 type hchan struct { // 已有元素个数（也就是通道中元素个数）len(chan) // 缓存区元素个数，不包括sendq上面的goroutine数量(如果存在) qcount uint // total data in the queue // 数组容量（也就是chan容量）cap(chan)\t// 也就是 make(chan int, size) 这里的size dataqsiz uint // size of the circular queue // 有缓冲数组地址指针，这里是根据 dataqsiz*elemsize 计算分配的内存数组大小 buf unsafe.Pointer // points to an array of dataqsiz elements // 元素大小，比如int这里存储的就是8，string的话这里存储的就是16 elemsize uint16 // 通道是否被关闭 1.被关闭 0.正常 closed uint32 // chan元素类型，指向类型元数据，比如chan int这里记录的就是int的元类型 elemtype *_type // element type // 当前索引（记录下一次send下标），下一次写取位置。 sendx uint // send index // 当前索引（记录下一次recv下标），下一次读入位置。 recvx uint // receive index // 等待写的队列，是一个双向的goroutine链表 recvq waitq // list of recv waiters // 等待读的队列，是一个双向的goroutine链表 sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. // // lock保护hchan中的所有字段，以及sudogs中的一些字段在这个通道上被阻塞。 // 在持有该锁时，不要改变另一个G的状态(特别是不要准备一个G)，因为这可能会导致栈收缩死锁。 lock mutex\t// runtime.mutex 为了应对并发的读写chan，参看runtime.mutex相关文档 } hchan 缓存区内存布局图（如果存在缓存区时） raceaddr() 该函数主要用于 make() 函数中，当申请总内存为0时，返回当前buf字段地址作为 buf 的值。形成指针指向闭环。 1 2 3 4 5 6 7 8 9 10 11 func (c *hchan) raceaddr() unsafe.Pointer { // Treat read-like and write-like operations on the channel to // happen at this address. Avoid using the address of qcount // or dataqsiz, because the len() and cap() builtins read // those addresses, and we don\u0026#39;t want them racing with // operations like close(). // // 将channel上的read-like和write-like操作视为在此地址发生。 // 避免使用qcount或dataqsiz的地址，因为len()和cap()内置函数会读取这些地址，我们不希望它们与close()等操作竞争。 return unsafe.Pointer(\u0026amp;c.buf) } sortkey() 该函数在 goselect() 函数中使用，用于返回 chan 地址升序排序 channels。 select 中相关用到的函数。在后面介绍select时，会被使用。 1 2 3 func (c *hchan) sortkey() uintptr { return uintptr(unsafe.Pointer(c)) } Constant 1 2 3 4 5 6 7 8 9 10 11 const ( // 最大对齐字节数，主要用于下面的定义。 maxAlign = 8 // hchan 占用内存大小字节，使 hchan 按照 maxAlign 大小对齐 // 比如 hchan 是 12byte，那么 hchanSize 则是 16byte // 为什么要使 hchan 对齐 maxAlign？原因是 hchan 后接着是 chan 元素的内存空间块(如果是有缓冲情况下) // 这种情况是为了兼容32位，因为在64位下hchan就是8字节对齐的，该字段用于make函数中申请 chan 内存需要。 hchanSize = unsafe.Sizeof(hchan{}) + uintptr(-int(unsafe.Sizeof(hchan{}))\u0026amp;(maxAlign-1)) debugChan = false\t// debug ) type waitq struct waitq 根据 sudog 形成一个双向链表。 其实就是一个队列的功能，元素【从 last 处添加】，【从 first 处取出】。 1 2 3 4 type waitq struct { first *sudog // 指向链表的首个 *sudog last *sudog // 指向链表的尾部 *sudog } dequeue() 从 first 中取出一个 *sudog。相当于从队列头（first）取出一个 *sudog。 调用该方法时 chan lock 锁一定是被持有的。下面函数中需要 for {} 的原因是最后一个 if 条件的 CAS 操作。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 func (q *waitq) dequeue() *sudog { for { sgp := q.first // 从first处取一个 *sudog if sgp == nil { return nil } y := sgp.next if y == nil { // 最后一个 *sudog q.first = nil q.last = nil } else { y.prev = nil q.first = y // 标记已删除（参看 dequeueSudoG） sgp.next = nil // mark as removed (see dequeueSudoG) } // 为什么需要下面的判断条件？ // 1. select 语句中阻塞了一组 chan 时，所有 channels 的 lock 锁都已被持有。 // 2. 当前执行select语句的goroutine会被封装到多个*sudog中通过waitlink字段形成链表，然后把各个*sudog的isSelect字段标记为true。 // 3. 把各个*sudog分别挂在各自的sendq或recvq链表中。等待goroutine被唤醒。 // 4. 某一时刻*sudog被选中唤醒，则一定会执行当前函数 *sudog.isSelect 是 true，并且通过 CAS 把 g.selectDone 从0标记为1。 // 5. 注意此时唤醒的goroutine可能在多个channel上面等待。此时可能会出现在其他chan上这个goroutine也被选中了，也在执行当前函数。 // 6. 则这里会直接跳过。因为当前goroutine已被唤醒，后续会在唤醒的goroutine移除这里goroutine的goselect函数中。 // 7. goroutine 唤醒后会获取所有的 channels lock，然后把selectDone设置为0，此时因为所有的channel lock已被持有所以能立即修改selectDone。 // if a goroutine was put on this queue because of a // select, there is a small window between the goroutine // being woken up by a different case and it grabbing the // channel locks. Once it has the lock // it removes itself from the queue, so we won\u0026#39;t see it after that. // We use a flag in the G struct to tell us when someone // else has won the race to signal this goroutine but the goroutine // hasn\u0026#39;t removed itself from the queue yet. // // 如果一个goroutine因为select被放到这个队列上，那么在goroutine被不同的情况唤醒和它获取通道锁之间有一个小窗口。 // 一旦它有了锁，它就会从队列中移除自己，所以在那之后我们就看不到它了。 // 我们在G结构体中使用一个标志来告诉我们，当有其他人赢得比赛时，向这个goroutine发出信号，但该goroutine还没有从队列中删除自己。 if sgp.isSelect \u0026amp;\u0026amp; !atomic.Cas(\u0026amp;sgp.g.selectDone, 0, 1) { continue } return sgp } } enqueue() 从 last 放入 *sudog。相当于从队列尾（last）添加元素。 调用该方法时 chan lock 已被持有。 1 2 3 4 5 6 7 8 9 10 11 12 13 func (q *waitq) enqueue(sgp *sudog) { sgp.next = nil x := q.last if x == nil { // waitq 是空的 sgp.prev = nil q.first = sgp q.last = sgp return } sgp.prev = x x.next = sgp q.last = sgp } dequeueSudoG() 在 selectgo() 函数中被用到，用于将指定的 *sudog 取出。 因为 select 不能立即完成时会挂在所有的 channel，当有 channel 就绪后其他 recvq、sendq 上的需要调用这个函数剔除掉。 调用该函数是相关的 channel lock 已被持有。 参数：sgp *sudog 是通过 waitlink 字段组成的 *sudog 链表。 该函数也是在 go1.19.3/src/runtime/select.go 文件中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 func (q *waitq) dequeueSudoG(sgp *sudog) { // 当前 sgp 可能处在链表的任何位置，或者不在链表中。 x := sgp.prev y := sgp.next if x != nil { if y != nil { // middle of queue // // 在 queue 的中间 x.next = y y.prev = x sgp.next = nil sgp.prev = nil return } // end of queue // // 在 queue 的最后 x.next = nil q.last = x sgp.prev = nil return } if y != nil { // start of queue // // 在queue开头 y.prev = nil q.first = y sgp.next = nil return } // x==y==nil. Either sgp is the only element in the queue, // or it has already been removed. Use q.first to disambiguate. // // x==y==nil。 // 要么 sgp 是队列中唯一的成员，要么它已经被删除。使用 q.first 来消除歧义。 if q.first == sgp { q.first = nil q.last = nil } } type sudog struct sudog 表示等待列表中的 g，例如用于在 channel 上 sending/receiving 。 sudog 是必要的，因为 g↔synchronization 对象关系是多对多的。 一个 g 可能会出现在许多等待列表中，所以一个g可能会有许多 sudog; 并且许多 g 可能在同一个 same 对象上等待，因此一个对象可能有许多 sudog。 sudog 是从一个特殊的池中分配的。使用 acquireSudog 和 releaseSudog 来分配和释放它们。 文件位置：go1.19.3/src/runtime2.go。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 // sudog represents a g in a wait list, such as for sending/receiving // on a channel. // // sudog is necessary because the g ↔ synchronization object relation // is many-to-many. A g can be on many wait lists, so there may be // many sudogs for one g; and many gs may be waiting on the same // synchronization object, so there may be many sudogs for one object. // // sudogs are allocated from a special pool. Use acquireSudog and // releaseSudog to allocate and free them. type sudog struct { // The following fields are protected by the hchan.lock of the // channel this sudog is blocking on. shrinkstack depends on // this for sudogs involved in channel ops. g *g // 等待的goroutine next *sudog // 链接下一个*sudog 对于二叉树就是left prev *sudog // 链接前一个*sudog 对于二叉树就是right // seampher中：保存来自信号量的地址；比如在sync.Mutex中则是\u0026amp;sync.Mutex.sema该字段的地址。 // channels中：则是保存需要传递的值的地址。（需要交换的数据地址） elem unsafe.Pointer // data element (may point to stack) // The following fields are never accessed concurrently. // For channels, waitlink is only accessed by g. // For semaphores, all fields (including the ones above) // are only accessed when holding a semaRoot lock. // // 以下字段永远不会并发访问。 // 对于 channels，waitlink 只能由 g 访问。 // 对于 semaphores，所有字段(包括上面的字段)只有在持有 semaRoot 锁时才能访问。 // 以下时间都是为了分析 sudog acquiretime int64 // 获得 sudog 的时间 releasetime int64 // 释放时间\t// ticket 用于形成最小堆，从root往下按照 s.ticket \u0026lt;= both s.prev.ticket AND s.next.ticket; 最小堆就是一种完全二叉树 // 1. ticket 在 semaRoot.queue 函数中作为二叉树枝干情况下被初始化为 s.ticket = fastrand() | 1; s.ticket \u0026gt;= 0 // 2. ticket 在 semaRoot.dequeue 函数中返回 sudog 时，被重置为0 // 3. ticket 在 sync_runtime_SemacquireMutex 函数中 如果是饥饿模式则标记为1 // 最小堆百度百科：https://baike.baidu.com/item/%E6%9C%80%E5%B0%8F%E5%A0%86/9139372 ticket uint32 // isSelect indicates g is participating in a select, so // g.selectDone must be CAS\u0026#39;d to win the wake-up race. // // isSelect 表示 g 正在参与一个 select，因此 g.selectDone 必须经过 CAS 处理才能赢得唤醒竞赛。 // 具体参考 goselect() 函数。当前是因为 select 语句被挂起时，该字段会被设置为 true。 isSelect bool // 在select结构中被使用 // success indicates whether communication over channel c // succeeded. It is true if the goroutine was awoken because a // value was delivered over channel c, and false if awoken // because c was closed. // // success c 通道通信是否成功。 // 如果 goroutine 因为通过通道 c 传递值而被唤醒，则为 true，如果因为通道 c 被关闭而被唤醒，则为 false。 success bool // 在chan中被使用，用于判断本次通信是否成功 // semaRoot的二叉树 parent *sudog // semaRoot binary tree // g.waiting 列表或 semaRoot 的等待链表，指向链表的头。 // 在 goselect() 函数中，挂起的 goroutine 组装的 *sudog 通过 waitlink 字段形成链表。 // waitlink 只在 semapher 或 select 语句中被用来形成链表。 waitlink *sudog // g.waiting list or semaRoot // 等待尾部 semaRoot，指向链表的尾部 waittail *sudog // semaRoot // 当前sudog所属*hchan，select不能就绪要被挂起时用到。 c *hchan // channel } make() 初始化 channel。\nmakechan() 函数原型：make(chan Type, size int) 参数： t *chantype：chan 元类型结构。 size int：chan 大小，默认0无缓冲 chan；\u0026gt;=1 都是有缓冲 chan。 type chantype struct { typ _type // chan元类型 elem *_type // chan 元素元类型 dir uintptr // 通道方向 } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 func makechan(t *chantype, size int) *hchan { elem := t.elem // chan元素元类型 // compiler checks this but be safe. // // 编译器会检查这一点，但这是安全的。 if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { // chan元素类型内存 \u0026gt;= 1\u0026lt;\u0026lt;16时不适合chan throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } // hchan 是否对齐 maxAlign if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } // mem = elem.size * uintptr(size) mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { // 内存溢出 panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. // // 当存储在buf中的元素不包含指针时，hchan不包含GC感兴趣的指针。 // (因此可直接在无指针内存块分配)。buf指向相同的内存分配，elemtype是持久的。 // Sudog 是在它们自己的线程中引用的，所以它们无法被收集。 // TODO(dvyukov,rlh):重新考虑收集器何时可以移动已分配的对象。 var c *hchan // nil switch { // 【make(chan struct{}, n)】 OR 【make(chan int, 0)】 形式 case mem == 0: // channel 内存为零 // Queue or element size is zero. // // Queue 或 element 的大小为0。 // 注意这里申请的内存规格块是无指针的，具体原因前面注释有解释 c = (*hchan)(mallocgc(hchanSize, nil, true)) // 申请hchan需要的内存空间 // Race detector uses this location for synchronization. // // 竞态检测器使用此位置进行同步。 c.buf = c.raceaddr() // c.buf = \u0026amp;c.buf case elem.ptrdata == 0: // channel 内存不为零，元素不包含指针 // Elements do not contain pointers. // Allocate hchan and buf in one call. // // 元素不包含指针。一次调用即可分配 hchan 和 buf。 // hchanSize 主要是为了这里的对齐。注意这里申请的内存规格块是无指针的，具体原因前面注释有解释 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) // 申请【hchan + buf】需要内存块 c.buf = add(unsafe.Pointer(c), hchanSize) // 可见申请的是一整块内存空间 default: // channel 内存不为零，元素包含指针 // Elements contain pointers. // // 元素包含指针。 c = new(hchan) // 申请元素需要的内存块 // 注意这里申请的是有指针内存规格块，具体原因是chan元素类型有指针可能存在多级指针引用，需要GC帮助 c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) // chan 元素大小 c.elemtype = elem // chan元素元类型 c.dataqsiz = uint(size) // 有缓存容量，一旦初始化就是确定的值 // 初始化 runtime.mutex，主要是初始化锁排名 lockInit(\u0026amp;c.lock, lockRankHchan)\tif debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c } makechan64() 1 2 3 4 5 6 7 func makechan64(t *chantype, size int64) *hchan { if int64(int(size)) != size { // 如果在32位系统下这里会报错 panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } return makechan(t, int(size)) } c \u0026lt;- ep ep 发送到 c 中。\nchansend1() 编译后代码中 c \u0026lt;- x 的入口点。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // // c \u0026lt;- ep // // as // // chansend1(c, \u0026amp;ep) // // entry point for c \u0026lt;- x from compiled code // //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } chansend() 通用单通道 send/recv，如果 block 不是 nil，那么协议将不会进入睡眠状态，如果无法完成则返回。 当涉及 sleep 的通道被关闭时，sleep 可以使用 g.param == nil 唤醒。循环并重新运行操作是最简单的;我们会看到它现在已经关闭了。 参数： c *hchan：hchan 结构体的指针。指向要来用 send 数据的 channel。 ep unsafe.Pointer：ep 是 c \u0026lt;- ep 需要发送到 chan 的数据地址。 是一个指针，指向要被送入通道 c 的数据，数据类型要和 c 的元素类型一致。 block bool：false.不能立即完成时不阻塞。 true.不能立即完成时阻塞。 表示如果 send 操作不能立即完成，是否想要阻塞等待。 block bool 参数 false 状态用于 select{case: default:} 形式中。true 状态用于 c \u0026lt;- ep 情况下。 callerpc uintptr：是 c \u0026lt;- ep 的下一条代码指令地址。用于进行race相关检测。 返回值： bool：true.数据 send 完成。false.表示目前不能发送，但因为不想阻塞(block为false)而返回。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 /* * generic single channel send/recv * If block is not nil, * then the protocol will not * sleep but return if it could * not complete. * * sleep can wake up with g.param == nil * when a channel involved in the sleep has * been closed. it is easiest to loop and re-run * the operation; we\u0026#39;ll see that it\u0026#39;s now closed. */ func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { // 1) chan没有初始化，比如 var c chan int形式 if c == nil { if !block { // select{case: default:} 块 return false // 返回false，表示未发送数据。 } // nil \u0026lt;- x：如果block为true，就让当前协程永久地阻塞在这个nil通道上。 // 处理相关goroutine然后再次进行新一轮调度。 // 注意：这里的goroutine将永久丢失，因为这个goroutine没有被放入队列中等待被调度， // 还有就是c \u0026lt;- x这行代码后的所有代码都不会在被执行。 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } if debugChan { // debug print(\u0026#34;chansend: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } if raceenabled { racereadpc(c.raceaddr(), callerpc, abi.FuncPCABIInternal(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from \u0026#39;ready for sending\u0026#39; to // \u0026#39;not ready for sending\u0026#39;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn\u0026#39;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread\u0026#39;s view of c.closed and full(). // // Fast path: 在未获得锁的情况下检查失败的非阻塞操作。 // 在观察到通道没有关闭之后，我们观察到通道还没有准备好发送。每个观察值都是单个word-sized的读取(第一个是c.closed，第二个是full())。 // 因为一个封闭的通道不能从\u0026#39;ready for sending\u0026#39;过渡到\u0026#39;not ready for sending\u0026#39;，即使在两次观测之间通道是关闭的， // 它们也意味着在两次观测之间通道既没有关闭也没有准备好发送的时刻。 // 我们的行为就像我们当时观察到通道一样，并报告发送无法继续。 // 在这里，如果读操作被重新排序是可以的:如果我们观察到通道还没有准备好发送，然后又观察到它没有关闭，这意味着在第一次观察期间通道没有关闭。 // 然而，这里没有任何东西能保证取得进展。我们依赖chanrecv()和closechan()中锁释放的副作用来更新这个线程的c.closed和full()视图。 if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { // select块中 \u0026amp;\u0026amp; chan未关闭 \u0026amp;\u0026amp; c已满 // 如果block为false且closed为0，也就是在不想阻塞且通道未关闭的前提下，如果通道满了（无缓冲且recvq为空，或者有缓存且缓冲已用尽）， // 则直接返回false。 // 本步判断是在不加锁的情况下进行的，目的是让非阻塞send在无法立即完成时能真正不阻塞（加锁操作可能阻塞）。 return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // 2) 尝试获取 runtime.mutex 互斥锁 // 对hchan加锁，如果closed不为0，即通道已经关闭，则先解锁，然后panic。因为不允许用已关闭的通道进行send。 lock(\u0026amp;c.lock) // 3) 向已关闭的chan 发送数据直接panic // 这里存在获取runtime.mutex期间其他协程已经把c关闭的情况，这里会直接panic // 因此chan的关闭是要确保所有的send操作已完成后再进行 if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } // 4) 从 recvq 中去找出一个正在等待的 *sudog // 如果 recvq 不为空，隐含了缓冲区为空，就从中取出第1个排队的协程，将数据传给这个协程，并将该协程置为ready状态 //（放入run queue，进而得到调度），然后解锁，然后返回true。 if sg := c.recvq.dequeue(); sg != nil { // 存在等待的 goroutine 直接交换数据即可 // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). // // 找到了一个等待的接收器。我们将想要直接发送的值传递给接收器，绕过通道缓冲区(如果有的话)。 send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } // 5) 缓冲区还有空间，直接把数据放入即可 // 通过比较 qcount 和 dataqsiz 判断缓存区是否还有剩余空间，在这里无缓冲的通道被视为没有剩余空间。 // 如果有剩余空间，将数据追加到缓冲区中，相应地移动 sendx，增加 qcount，然后解锁，返回值为 true。 if c.qcount \u0026lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. // // 通道缓冲区中有可用空间。对要发送的元素进行排队。 qp := chanbuf(c, c.sendx) // 下一个空闲插槽地址 if raceenabled { racenotify(c, c.sendx, nil) } // 把c \u0026lt;- ep这里的ep值复制到qp这个地址中，实现把ep放入buf中 typedmemmove(c.elemtype, qp, ep) // 如果元素大小为0不会有任何操作 c.sendx++ // 下一次空闲位置 if c.sendx == c.dataqsiz { // 到达最大索引 c.sendx = 0 } c.qcount++ // 已存储的数量加一 unlock(\u0026amp;c.lock) return true } // 6) 如果上面4和5都不满足，并且是在select中，那么就直接返回false，表示当前分支不会选中 // 运行到这里表明通道已满，如果block为false，即不想阻塞，则解锁，返回值为false。 if !block { unlock(\u0026amp;c.lock) return false } // 7) 下面是 c \u0026lt;- x 写操作需要阻塞的情况 // Block on the channel. Some receiver will complete our operation for us. // // 在通道上阻塞。有人会替我们完成我们的操作。 gp := getg() // goroutine // 获取一个空闲的 *sudog mysg := acquireSudog()\tmysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. // // 在分配elem和在gp上排队mysg之间没有堆栈分裂。在拷贝堆能找到的地方等待。 mysg.elem = ep // waitlink 只在 semapher 或 select 语句中被使用到。 // 用来链接多个 sudog mysg.waitlink = nil mysg.g = gp // 标记当前 sudog 不是来自select语句 mysg.isSelect = false mysg.c = c // 标记goroutine正在*sudog这中等待（一个有效的elem ptr）; in lock order gp.waiting = mysg gp.param = nil // 放入 sendq queue 中等待 c.sendq.enqueue(mysg)\t// Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. // // 向任何试图缩小堆栈的人发出信号，我们即将停在一个channel上。 // 当G的状态改变和我们设置gp之间的窗口。activeStackChans 对堆栈收缩不安全。 // goroutine.parkingOnChan表示该goroutine即将停在一个chansend或chanrecv上。 // 用于指示堆栈收缩的不安全点。它是一个布尔值，但会自动更新。 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) // 表示这段时间chan正在parking中 // gopark—\u0026gt;mcall-\u0026gt;park_m-\u0026gt;schedule() gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2)\t// 调离当前g进入调度循环 // 当前g被再次调度起来时，继续这里执行 // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren\u0026#39;t considered as roots of the // stack tracer. // // 确保正在发送的值在接收方复制出来之前都是有效的。 // sudog有一个指向栈对象的指针，但sudogs不被认为是栈跟踪器的roots。 // https://zhuanlan.zhihu.com/p/213744309 KeepAlive(ep) // 保持ep是活跃的，因为ep来自用户端可能ep会被回收 // someone woke us up. // // 有人把我们叫醒了，可能是正常 \u0026lt;-c 或者 close() 函数 if mysg != gp.waiting {\t// 当前 gp 是否等待在 mysq 上 throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil // activeStackChans表示有未锁定的通道指向这个goroutine的堆栈。 // 如果为true，堆栈复制需要获得通道锁来保护堆栈的这些区域。 // activeStackChans 字段在 gopark 中 chanparkcommit 函数中被设置为true，因此是go被调离CPU时候设置为true，在唤醒后设置为false。 // 具体参看栈 runtime.copystack 函数。 gp.activeStackChans = false // 来自close()函数唤醒时，closed为true。 closed := !mysg.success // 如果是有close唤醒的这里success为false并closed为1 gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg)\t// 回收*sudog // 这里也解释了关闭channel需要谨慎操作。 // 一个goroutine正在send，而另外一个goroutine却close了，这里就会panic。 if closed { // 来自close()函数唤醒时closed字段应该为1。 if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) // chansend 虚假唤醒 } // c.closed == 1时，还存在send的g却关闭了chan报错 // 因此 close() 函数不要在还有send未完成时调用。 panic(plainError(\u0026#34;send on closed channel\u0026#34;)) // send 在关闭的 channel 上 } return true } full() full() 报告在 c 上的发送是否会阻塞(即通道已满)。 它使用了一个可变状态的word-sized的读取，因此尽管答案立即为true，但在调用函数收到返回值时，正确的答案可能已经改变了。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // full reports whether a send on c would block (that is, the channel is full). // It uses a single word-sized read of mutable state, so although // the answer is instantaneously true, the correct answer may have changed // by the time the calling function receives the return value. func full(c *hchan) bool { // c.dataqsiz is immutable (never written after the channel is created) // so it is safe to read at any time during channel operation. // // c.dataqsiz是不可变的(在通道创建后永不写入)，因此在通道操作期间的任何时候读取都是安全的。 if c.dataqsiz == 0 { // Assumes that a pointer read is relaxed-atomic. // // 假定指针读取是relaxed-atomic的。 return c.recvq.first == nil } // Assumes that a uint read is relaxed-atomic. // // 假设uint read是relax-atomic。 return c.qcount == c.dataqsiz } send() 交换数据，并调用goready把等待的G放入p中等待调度。 send 处理空通道 c 上的发送操作。 发送端发送的值 ep 被复制到接收端sg。然后，接收者被唤醒，继续它的快乐之路。 通道c必须是空的并被锁定。用unlockf发送解锁c。sg必须已经从c中退出队列。 ep必须是非空值，并且指向堆或调用者的堆栈。 参数： c *hchan：hchan 结构体指针。 sg *sudog：是等待 ep \u0026lt;- c 的 g。 ep unsafe.Pointer：是 c \u0026lt;- ep 的数据地址。 unlockf func()：闭包函数解锁 c.lock。 skip int：skip 跳过步骤。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // send processes a send operation on an empty channel c. // The value ep sent by the sender is copied to the receiver sg. // The receiver is then woken up to go on its merry way. // Channel c must be empty and locked. send unlocks c with unlockf. // sg must already be dequeued from c. // ep must be non-nil and point to the heap or the caller\u0026#39;s stack. func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { if raceenabled { if c.dataqsiz == 0 { racesync(c, sg) } else { // Pretend we go through the buffer, even though // we copy directly. Note that we need to increment // the head/tail locations only when raceenabled. racenotify(c, c.recvx, nil) racenotify(c, c.recvx, sg) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } } // sg.elem 是等待读的地址，也就是ep \u0026lt;- c这里的ep地址 if sg.elem != nil { // 把ep复制到sg.elem中，这样就完成了chan的数据交换 sendDirect(c.elemtype, sg, ep) sg.elem = nil } gp := sg.g // 取出准备恢复的g // 把 hchan 解锁。 unlockf() // 唤醒时传递的参数。主要用与 select 语句唤醒后使用。 // select 拿着这个参数的值做比对，是哪个 case 就绪了。 gp.param = unsafe.Pointer(sg) // g.param = *sudog // 把sg.success标记为true表示数据已经交换成功 sg.success = true if sg.releasetime != 0 { sg.releasetime = cputicks() } goready(gp, skip+1) } sendDirect() 从 src -\u0026gt; sg.elem。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src is on our stack, dst is a slot on another stack. // // src在我们的堆栈上，dst是另一个堆栈上的插槽。 // Once we read sg.elem out of sg, it will no longer // be updated if the destination\u0026#39;s stack gets copied (shrunk). // So make sure that no preemption points can happen between read \u0026amp; use. // // 一旦我们从sg中读入sg.elem，如果目标堆栈被复制(收缩)，它将不再被更新。 // 因此，请确保在读取和使用之间不会发生抢占点。 dst := sg.elem // typeBitsBulkBarrier对memmove使用类型位图定位指针槽将[src, src+size)复制到[dst, dst+size)的每个指针执行写屏障。 // 类型typ必须精确对应于[src, src+size)和[dst, dst+size)。dst、src和size必须是指针对齐的。 typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // No need for cgo write barrier checks because dst is always // Go memory. // // 不需要cgo写屏障检查，因为dst总是Go内存。 memmove(dst, src, t.size)\t// src -\u0026gt; dst } goready() 恢复gp也就是goroutine前进行栈切换到g0栈。 1 2 3 4 5 func goready(gp *g, traceskip int) { systemstack(func() {\t// 切换到g0栈 ready(gp, traceskip, true) }) } ready() 恢复gp也就是这个goroutine相关的状态，然后放入P中等待被调度。 标记 gp 准备运行。 参数： gp *g：当前需要恢复的goroutine traceskip int：检查跳过步骤 next bool：next为true时，则将gp放入到_p_.runnext中 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Mark gp ready to run. func ready(gp *g, traceskip int, next bool) { if trace.enabled { traceGoUnpark(gp, traceskip) } // 获取当前gp这个goroutine的状态 status := readgstatus(gp) // Mark runnable. _g_ := getg() // 当前正在运行的g这里是g0 // 禁用抢占，因为它可以在本地变量中持有p mp := acquirem() // disable preemption because it can be holding p in a local var if status\u0026amp;^_Gscan != _Gwaiting { dumpgstatus(gp) throw(\u0026#34;bad g-\u0026gt;status in ready\u0026#34;) } // status is Gwaiting or Gscanwaiting, make Grunnable and put on runq casgstatus(gp, _Gwaiting, _Grunnable) // 切换gp的状态 // gp放入p的本地队列，这里next是true时，会放入next字段会优先调度起来 runqput(_g_.m.p.ptr(), gp, next) // 因为有goroutine放入队列中，尝试唤醒其他工作线程起来工作 wakep() // 有goroutine被放回队列该函数就会紧接着被调用 releasem(mp) } chanbuf() chanbuf(c, i) 是指向缓冲区第 i 个槽的指针。 1 2 3 4 // chanbuf(c, i) is pointer to the i\u0026#39;th slot in the buffer. func chanbuf(c *hchan, i uint) unsafe.Pointer { return add(c.buf, uintptr(i)*uintptr(c.elemsize)) } ep \u0026lt;- c 从 c 中读取数据。 编译后代码中 \u0026lt;- c 的入口点。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // // ep \u0026lt;- c // // as // // chanrecv1(c, \u0026amp;ep) // // entry points for \u0026lt;- c from compiled code // //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } chanrecv() chanrecv 在通道 c 接收数据，并将接收到的数据写入 ep。 ep可以是nil，在这种情况下接收到的数据将被忽略。 如果block == false且没有元素可用，则返回(false, false)。否则，如果c是关闭的，则*ep设置成零值并返回(true, false)。否则，用一个元素填充*ep并返回(true, true)。 非nil的ep必须指向堆或调用者的堆栈。 参数： c *hchan：hchan结构体指针，也就是 ep \u0026lt;- c 中 c 的结构体指针。指向要从recv数据的channel。 ep unsafe.Pointer：接收变量地址，也就是 ep \u0026lt;- c 中ep变量的地址。是一个指针，指向用来接收数据的内存，数据类型要和c的元素类型一致。 block bool：true.表示如果recv操作不能立即完成，是否想要阻塞等待。true.不能立即完成则阻塞，false.不能立即完成不阻塞，用于select{case: default:}形式。 返回值：这两个参数都是用于 select{case: default:}形式的。selected表示当前case被选中。received表示数据有没交换成功。 selected bool：true.表示操作完成（可能因为通道已经关闭）。false.表示目前不能立即完成recv，但因为不想阻塞（block为false）而返回。 received bool：true.表示数据确实是从通道中接收的，不是因为通道关闭而得到的零值。false.可能是因为通道关闭而得到的零值（selected为true），或者因为不想阻塞而返回（selected为false）。 返回值的组成： (true, true)：操作已完成，确实是从channel中接收的（不是因为channel关闭而得到的零值）。（当前分支被选中，数据也交换成功了） (false, false)：目前不能立即完成，因为不想阻塞而返回。（当前分支没被选中，走default吧） (true, false)：操作已完成，因为通道关闭而返回零值。（当前分支被选中，因close而返回默认零值） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 // chanrecv receives on channel c and writes the received data to ep. // ep may be nil, in which case received data is ignored. // If block == false and no elements are available, returns (false, false). // Otherwise, if c is closed, zeros *ep and returns (true, false). // Otherwise, fills in *ep with an element and returns (true, true). // A non-nil ep must point to the heap or the caller\u0026#39;s stack. func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don\u0026#39;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. // // Raceenabled:不需要检查ep，因为它总是在堆栈上或由reflect分配新的内存。 if debugChan { // debug print(\u0026#34;chanrecv: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } // 1) chan未初始化时，比如 var c chan int if c == nil { if !block { // 来自select{case: default:}块 return // false, false } // \u0026lt;- nil // 这里在nil的chan中读取数据，直接切换到调度循环进行新一轮调度 // 这个G后面的代码将不会得到执行，应该当前G既没有加入到P中等待调度，也没有在chan中，永久丢失了 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } // 2) Fast path：在未加锁下，判断block为false时，send为空时。 // Fast path: check for failed non-blocking operation without acquiring the lock. // // Fast path: 检查未获得锁的失败的非阻塞操作。 if !block \u0026amp;\u0026amp; empty(c) { // select{case: default:}块，c为空 // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate \u0026#34;open and empty\u0026#34;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. // // 在观察到通道还没有准备好接收之后，我们观察通道是否关闭。 // // 在与close竞争时，这些检查的重新排序可能会导致错误的行为。 // 例如，如果channel是打开的且不是空的，被关闭，然后全部取出，重新排序的读数可能会错误地指示\u0026#34;open and empty\u0026#34;。 // 为了防止重新排序，我们对这两种检查都使用了原子加载，并依赖于在同一锁下的不同临界区中进行清空和关闭操作。 // 当以阻塞的发送方式关闭无缓冲的通道时，这个假设就失败了，但无论如何这都是一个错误条件。 if atomic.Load(\u0026amp;c.closed) == 0 { // send为空 并 closed 未关闭，返回 (false, false) // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. // // 因为channel不能重新打开，所以后来观察到的channel没有关闭意味着在第一次观察的时候它也没有关闭。 // 我们的行为就像我们当时观察到了channel，并报告说接收无法继续。 return } // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. // // channel是不可逆关闭的。重新检查信道是否有待处理的数据要接收，这些数据可能是在上面的空检查和关闭检查之间到达的。 // 当使用这样的发送方式比赛时，顺序的一致性也是必需的。 if empty(c) { // send为空 并且 closed 已关闭，返回 (true, false) // The channel is irreversibly closed and empty. if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // 3) 加锁情况下去判断 send 和 sendq 是否有等待 send 的数据。 lock(\u0026amp;c.lock) // 获取runtime.mutex // channel 已关闭 if c.closed != 0 {\t// send buf缓冲区没数据 if c.qcount == 0 {\tif raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026amp;c.lock) // 拷贝对应类型的零值 if ep != nil { // Typedmemclr清除类型为typ的ptr的类型化内存。 typedmemclr(c.elemtype, ep) // ep 赋值chan元素类型的默认值 } return true, false } // The channel has been closed, but the channel\u0026#39;s buffer have data. // // channel 已经关闭，但通道的缓冲区有数据。 } else { // channel 未关闭 // Just found waiting sender with not closed. // // 刚刚发现等待send未关闭。取出first上的第一个*sudog，这个需要处理 // 这里隐含了 buf 缓存区为空的情况。 if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender\u0026#39;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). // // 发现一个等待发送者。如果缓冲区大小是0，接收值直接从发送方。 // 否则，从队列的头部接收并将发送方的值添加到队列的尾部(两者映射到相同的缓冲槽，因为队列已满)。 recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } } // buf 缓冲区有数据 if c.qcount \u0026gt; 0 { // Receive directly from queue // 直接从缓存区队列中接收数据 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } // 交换数据 if ep != nil { typedmemmove(c.elemtype, ep, qp) // ep = qp } typedmemclr(c.elemtype, qp) // 清除 qp c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- // 缓存区元素个数 unlock(\u0026amp;c.lock) return true, true } // 下面代码是需要被阻塞的情况，当前goroutine被动执行调度到c.sendq中去等待 // block 为 false，不想阻塞而返回。 if !block { unlock(\u0026amp;c.lock) return false, false } // 4) send buf取没有数据或sendq中没有等待的goroutine时。 // no sender available: block on this channel. // 没有可用的发送者:在此通道上阻塞。 gp := getg() // g mysg := acquireSudog() // 获取一个空闲的 *sudog mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. // 在分配elem和在gp.waiting上对mysg进行排队之间没有栈拆分，因为在gp.waiting上copystack可以找到它。 mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false // 标记不是在select块中来的 mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // 加入 recvq 队列中 // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. // 向任何试图缩小堆栈的人发出信号，我们即将停在一个channel上。 // 当G的状态改变和我们设置gp之间的窗口。activeStackChans 对堆栈收缩不安全。 // goroutine.parkingOnChan表示该goroutine即将停在一个chansend或chanrecv上。用于指示堆栈收缩的不安全点。它是一个布尔值，但会自动更新。 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) // gopark 保存当前goroutine线程; 调用 releasem(mp) 解除当前m和P的绑定 // 调用mcall(park_m) mcall切换栈到g0 park_m 解除m和g的关联 调用schedule再次开启调度循环 gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) // 回收 sudog return true, success } empty() Empty报告从c读取数据是否会阻塞(即channel是空的)。它使用单个原子读取可变状态。 1 2 3 4 5 6 7 8 9 10 11 12 13 // empty reports whether a read from c would block (that is, the channel is // empty). It uses a single atomic read of mutable state. func empty(c *hchan) bool { // c.dataqsiz is immutable. // // c.dataqsiz 是不可变的 if c.dataqsiz == 0 { // 是否有等待 send 的 goroutine return atomic.Loadp(unsafe.Pointer(\u0026amp;c.sendq.first)) == nil } // 缓存区是否有数据 return atomic.Loaduint(\u0026amp;c.qcount) == 0 } recv() recv 在一个满的缓存区的channel c上处理接收操作 有以下两部分： 发送放sg发送的值被放入channel，发送方被唤醒 接收端接收到的值(当前G)被写入ep 对于同步channel，这两个值是相同的 对于异步channel，接收方从通道缓冲区获取数据，发送方的数据放在通道缓冲区中。 通道c必须已满且已锁定。recv用unlockf解锁c。sg必须已经从c中退出队列。 非nil的ep必须指向堆或调用者的堆栈。 参数： c *hchan：当前 chan sg *sudog：从 recvq 中的first取出的第一个 *sudog ep unsafe.Pointer：v \u0026lt;- c 中的v地址 unlockf func()：解锁 runtime.mutex 的闭包函数 skip int：调试相关 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 // recv processes a receive operation on a full channel c. // There are 2 parts: // 1. The value sent by the sender sg is put into the channel // and the sender is woken up to go on its merry way. // 2. The value received by the receiver (the current G) is // written to ep. // // For synchronous channels, both values are the same. // For asynchronous channels, the receiver gets its data from // the channel buffer and the sender\u0026#39;s data is put in the // channel buffer. // Channel c must be full and locked. recv unlocks c with unlockf. // sg must already be dequeued from c. // A non-nil ep must point to the heap or the caller\u0026#39;s stack. func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { if c.dataqsiz == 0 { // 无缓冲 chan if raceenabled { racesync(c, sg) } if ep != nil { // copy data from sender // 从发送方复制数据 recvDirect(c.elemtype, sg, ep) // ep = sg } } else { // 有缓冲 chan // Queue is full. Take the item at the // head of the queue. Make the sender enqueue // its item at the tail of the queue. Since the // queue is full, those are both the same slot. // 队列已满。以队列最前面的项为例。 // 让发送方在队列的尾部将其项目入队。 // 因为队列已经满了，所以它们是同一个槽。 // 以上意思是从sendq.first取出的*sudog需要恢复这个g并把数据放入缓存区，从缓存区取出下一个数据交换 qp := chanbuf(c, c.recvx) // 数据区的下一个需要交换的数据 if raceenabled { racenotify(c, c.recvx, nil) racenotify(c, c.recvx, sg) } // copy data from queue to receiver // 将数据从队列复制到接收器 if ep != nil { typedmemmove(c.elemtype, ep, qp) // ep = qp } // copy data from sender to queue // 从发送端复制数据到队列 typedmemmove(c.elemtype, qp, sg.elem) // qp = sg.elem c.recvx++\t// 下一次recv数据索引 if c.recvx == c.dataqsiz {\t// 如果超过最大重置为0 c.recvx = 0 } // 设置缓存区是满的，因为这种情况缓存区一定是full // 此时需要调整 sendx 的值，因为之前就是满的 说明之前 c.sendx == c.recvx c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } // sg 中的 *sudog 的g需要被恢复让其从新被调度 sg.elem = nil // 数据已被放入缓存区，情况即可 gp := sg.g // 需要恢复的g unlockf() // runtime.mutex 解锁 // 当一个channel操作唤醒一个被阻塞的goroutine时，它将param设置为指向已完成阻塞操作的sudog。 // select 拿着这个参数的值做比对，是哪个 case 就绪了。 gp.param = unsafe.Pointer(sg) // 主要用与 select 语句唤醒后使用。 sg.success = true // success 标记了 true，交换数据成功 if sg.releasetime != 0 { sg.releasetime = cputicks() } goready(gp, skip+1)\t// 放入队列中等待唤醒g } goready() 恢复gp也就是goroutine前进行栈切换到g0栈。 1 2 3 4 5 func goready(gp *g, traceskip int) { systemstack(func() { // 切换到 g0 栈 ready(gp, traceskip, true) }) } ready() 标记gp准备运行。 参数： gp *g：准备恢复的 goroutine traceskip int：测试相关 next bool：true.下次调度优先调度当前goroutine 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // Mark gp ready to run. func ready(gp *g, traceskip int, next bool) { if trace.enabled { traceGoUnpark(gp, traceskip) } // goroutine 状态 status := readgstatus(gp) // Mark runnable. _g_ := getg() // 当前g0 // 禁止当前m被抢占，因为即将把gp放入m关联的本地P中去 mp := acquirem() // disable preemption because it can be holding p in a local var // 如果当前gp状态处理后不等于_Gwaiting等待中，那说明这个gp是有问题的 if status\u0026amp;^_Gscan != _Gwaiting { dumpgstatus(gp) throw(\u0026#34;bad g-\u0026gt;status in ready\u0026#34;) } // status is Gwaiting or Gscanwaiting, make Grunnable and put on runq // 把当前gp这个goroutine状态从_Gwaiting等待中修改为_Grunnable可以运行的状态 casgstatus(gp, _Gwaiting, _Grunnable) // 然后把gp放入m的本地关联P中，next为true表示放入前面 runqput(_g_.m.p.ptr(), gp, next) wakep() // 尝试唤醒其他线程 releasem(mp) // 解除前面的 acquirem() 函数的抢占，并判断是否有抢占发生 } runqput() runqput 试图将g放到本地可运行队列上。 如果 next 为 false, runqput 将 g 添加到可运行队列的尾部。 如果 next 为 true, runqput 将 g 放入_p_.runnext位置。 如果就绪队列已满，runnext 将 g 放置到全局队列中。 仅由所有者P执行。 参数： _p_ *p：当前工作线程绑定的 P gp *g：需要处理的 goroutine next bool：true.下次调度优先调度当前goroutine 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // runqput tries to put g on the local runnable queue. // If next is false, runqput adds g to the tail of the runnable queue. // If next is true, runqput puts g in the _p_.runnext slot. // If the run queue is full, runnext puts g on the global queue. // Executed only by the owner P. func runqput(_p_ *p, gp *g, next bool) { // 这里是为了测试用例增加随机性的代码 // randomizeScheduler在测试代码中这里会设置为true，正常是false if randomizeScheduler \u0026amp;\u0026amp; next \u0026amp;\u0026amp; fastrandn(2) == 0 { next = false } // next=true，将gp添加到_p_.runnext中。_p_.runnext 如果是非nil，是一个可运行的G // 如果在运行 G 的时间片中有剩余时间，那么应该运行下一个而不是 runq 中的内容 if next { retryNext: oldnext := _p_.runnext // 原子交换 if !_p_.runnext.cas(oldnext, guintptr(unsafe.Pointer(gp))) { goto retryNext } if oldnext == 0 { return } // Kick the old runnext out to the regular run queue. // 把旧的runnext踢到常规的run队列。 gp = oldnext.ptr() } retry: // _p_的runq是一个256大小的循环数组，runqhead指向开始，runqtail指向尾部 h := atomic.LoadAcq(\u0026amp;_p_.runqhead) // load-acquire, synchronize with consumers t := _p_.runqtail // 这里之所以没有使用锁，是由于这个runqtail在其他地方不会被修改 // 如果t-h小于总runq的大小，说明还没有存满 if t-h \u0026lt; uint32(len(_p_.runq)) { // 这里使用t%uint32(len(_p_.runq))是由于可能出现h \u0026gt; t的情况，那么需要始终放在t的后面 _p_.runq[t%uint32(len(_p_.runq))].set(gp) atomic.StoreRel(\u0026amp;_p_.runqtail, t+1) // store-release, makes the item available for consumption return } // 如果本地P已经存满，那么需要去全局里面存数据 if runqputslow(_p_, gp, h, t) { return } // the queue is not full, now the put above must succeed // 如果上面都没有存储成功，那么跳转到retry标签继续存储数据，直到成功 goto retry } runqputslow() 把gp及_p_中的一半的G尝试加入全局G中去 将g和一批来自本地可运行队列的工作放到全局队列上。 仅由所有者P执行。 参数： _p_ *p：当前工作线程绑定的P gp *g：当前需要处理的 goroutine h, t uint32：_p_的runq是一个256大小的循环数组，runqhead指向开始，runqtail指向尾部 返回值： bool：true.放入成功，false.放入失败 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // Put g and a batch of work from local runnable queue on global queue. // Executed only by the owner P. func runqputslow(_p_ *p, gp *g, h, t uint32) bool { // 首先定义batch数组，这是需要取出的G放入的数组 // 这里的len(_p_.runq)/2 + 1是把gp放入这个+1这里算在一起的 var batch [len(_p_.runq)/2 + 1]*g // 临时容器 // First, grab a batch from local queue. // 首先，从本地队列中获取一个批。 n := t - h n = n / 2 // 取一半 if n != uint32(len(_p_.runq)/2) { throw(\u0026#34;runqputslow: queue is not full\u0026#34;) } // 取出一半放入容器 for i := uint32(0); i \u0026lt; n; i++ { batch[i] = _p_.runq[(h+i)%uint32(len(_p_.runq))].ptr() } // 原子交换head索引值 if !atomic.CasRel(\u0026amp;_p_.runqhead, h, h+n) { // cas-release, commits consume return false } batch[n] = gp // gp 放入最后一位 // 这里如果开始起了随机性，那么会把batch顺序打乱 if randomizeScheduler { for i := uint32(1); i \u0026lt;= n; i++ { j := fastrandn(i + 1) // fastrand() % (i+1) batch[i], batch[j] = batch[j], batch[i] } } // Link the goroutines. // 把batch中的所有G形成一个链表链接起来 for i := uint32(0); i \u0026lt; n; i++ { batch[i].schedlink.set(batch[i+1]) } // 是一个双向链表，head和tail分别表示正序和倒叙 var q gQueue q.head.set(batch[0]) // 把batch[0]指向q.head q.tail.set(batch[n]) // 把batch[n]指向q.tail // Now put the batch on global queue. // 现在将batch放到全局队列中。 lock(\u0026amp;sched.lock) // 获取 sched 上的 runtime.mutex // 把设置好的G链表链接拿到shced.runq上去 globrunqputbatch(\u0026amp;q, int32(n+1)) unlock(\u0026amp;sched.lock) // 解锁 return true } globrunqputbatch() 把设置好的G链表链接拿到shced.runq上去 将一批可运行的 goroutines 放到全局可运行队列中。清除 *batch。 sched.lock 必须被持有。. 可能在STW期间运行，因此不允许写入障碍。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Put a batch of runnable goroutines on the global runnable queue. // This clears *batch. // sched.lock must be held. // May run during STW, so write barriers are not allowed. // //go:nowritebarrierrec func globrunqputbatch(batch *gQueue, n int32) { // 判断 sched.lock 锁是否持有 assertLockHeld(\u0026amp;sched.lock) // 把设置好的G链表链接到sched.runq上去 sched.runq.pushBackAll(*batch) sched.runqsize += n // 把全局链表总数量加上n *batch = gQueue{} // 清空这个batch，减轻GC压力 } v, ok := \u0026lt;-c 编译后是通过调用 chanrecv2 函数。 ok：true.确实从channel中接收的值（不是因为channel关闭而得到的零值）。false.因为channel关闭而返回的零值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 通过编译后： // // if v, ok := \u0026lt;-c; ok { // ... foo // } // // as // // if _, ok = chanrecv2(c, \u0026amp;v); ok { // ... foo // } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { // 1. (_, true)：数据交换成功，得到对应交换的数据。 // 2. (_, false)：因close导致获取到了零值数据。 _, received = chanrecv(c, elem, true) return } gopark() 将当前例程置于等待状态并调用系统堆栈上的 unlock。 如果 unlock 返回 false，则继续执行该 goroutine。 unlockf 不能访问这个 G 的堆栈，因为它可能在调用 gopark 和调用 unlockf 之间移动。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // Puts the current goroutine into a waiting state and calls unlockf on the // system stack. // // If unlockf returns false, the goroutine is resumed. // // unlockf must not access this G\u0026#39;s stack, as it may be moved between // the call to gopark and the call to unlockf. // // Note that because unlockf is called after putting the G into a waiting // state, the G may have already been readied by the time unlockf is called // unless there is external synchronization preventing the G from being // readied. If unlockf returns false, it must guarantee that the G cannot be // externally readied. // // Reason explains why the goroutine has been parked. It is displayed in stack // traces and heap dumps. Reasons should be unique and descriptive. Do not // re-use reasons, add new ones. func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) { // const waitReasonSleep = 19 // 等待原因不是因为sleep时，按需调用checkTimeouts()，检查timer。 if reason != waitReasonSleep { // timeouts 可能会在两个goroutine使调度程序繁忙时过期。 // 检查 p.timers 在调度循环时或 goroutine 被调离CPU 或 sysmon 监控线程中都会轮询查看。 checkTimeouts() // timeouts may expire while two goroutines keep the scheduler busy } mp := acquirem() gp := mp.curg // 当前gp status := readgstatus(gp) // 获取状态 if status != _Grunning \u0026amp;\u0026amp; status != _Gscanrunning { throw(\u0026#34;gopark: bad g status\u0026#34;) } mp.waitlock = lock // 等待的锁，unlockf的第二个参数 mp.waitunlockf = unlockf// 调离前需要执行的闭包 gp.waitreason = reason mp.waittraceev = traceEv mp.waittraceskip = traceskip releasem(mp) // can\u0026#39;t do anything that might move the G between Ms here. mcall(park_m) // mcall保存现场并切换g0调用park_m函数。 } park_m() 该函数在g0上。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // park continuation on g0. func park_m(gp *g) { mp := getg().m if trace.enabled { traceGoPark(mp.waittraceev, mp.waittraceskip) } // N.B. Not using casGToWaiting here because the waitreason is // set by park_m\u0026#39;s caller. casgstatus(gp, _Grunning, _Gwaiting) // 切换gp的状态 dropg() // 解除m与gp的绑定 if fn := mp.waitunlockf; fn != nil { ok := fn(gp, mp.waitlock) // 调用waitunlockf mp.waitunlockf = nil mp.waitlock = nil // 返回false时，再次运行gp if !ok { if trace.enabled { traceGoUnpark(gp, 2) } casgstatus(gp, _Gwaiting, _Grunnable) execute(gp, true) // Schedule it back, never returns. } } schedule() // 调度循环 } close() 关闭 hchan。 几种关闭 channel 的情况： close 关闭时，sendq 上有等待的 goroutine，会 panic。【\u0026ldquo;panic: send on closed channel\u0026rdquo;】。 close 关闭时，再有 send 操作，会 panic。【\u0026ldquo;panic: send on closed channel\u0026rdquo;】。 close 关闭时，buf 中有数据，不会 panic，recv 可以读取它们。 向 nil 的 channel，send 或 recv 时当前 goroutine 会panic。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 func closechan(c *hchan) { // 1) nil 的 chan 是不允许被 close 的 if c == nil {\tpanic(plainError(\u0026#34;close of nil channel\u0026#34;)) } lock(\u0026amp;c.lock) // 尝试获取 runtime.mutex // 2) 已经关闭的 chan 不能再次关闭 if c.closed != 0 {\tunlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, abi.FuncPCABIInternal(closechan)) racerelease(c.raceaddr()) } // 3) 获取到互斥锁后首先标记closed字段 c.closed = 1 // 标记chan状态为关闭 0.未关闭 1.已关闭 // gList是一个goroutine的链表 // 当前要关闭的c还未处理的goroutine var glist gList // 4) 处理 recvq 上的 goroutine // release all readers for { // 如果同一个goroutine在多个channel上时（这种情况发生在goselect时） // dequeue() 函数有相关的排重，CAS操作。 sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g // 主要用与 select 语句唤醒后使用。 gp.param = unsafe.Pointer(sg) // g.param = *sudog sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // 5) 处理 sendq 上的 goroutine，这些goroutine得到运行后会 panic。 // 因为不能向close的channel有send操作，其中一种情况体现在这里。 // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g // 主要用与 select 语句唤醒后使用。 gp.param = unsafe.Pointer(sg) // g.param = *sudog sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) // 6) 将这些 goroutine 放回等待队列中 // Ready all Gs now that we\u0026#39;ve dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 // 将gp放入本地P的队列中 goready(gp, 3) } } type guintptr uintptr 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // A guintptr holds a goroutine pointer, but typed as a uintptr // to bypass write barriers. It is used in the Gobuf goroutine state // and in scheduling lists that are manipulated without a P. // // The Gobuf.g goroutine pointer is almost always updated by assembly code. // In one of the few places it is updated by Go code - func save - it must be // treated as a uintptr to avoid a write barrier being emitted at a bad time. // Instead of figuring out how to emit the write barriers missing in the // assembly manipulation, we change the type of the field to uintptr, // so that it does not require write barriers at all. // // Goroutine structs are published in the allg list and never freed. // That will keep the goroutine structs from being collected. // There is never a time that Gobuf.g\u0026#39;s contain the only references // to a goroutine: the publishing of the goroutine in allg comes first. // Goroutine pointers are also kept in non-GC-visible places like TLS, // so I can\u0026#39;t see them ever moving. If we did want to start moving data // in the GC, we\u0026#39;d need to allocate the goroutine structs from an // alternate arena. Using guintptr doesn\u0026#39;t make that problem any worse. // Note that pollDesc.rg, pollDesc.wg also store g in uintptr form, // so they would need to be updated too if g\u0026#39;s start moving. type guintptr uintptr //go:nosplit func (gp guintptr) ptr() *g { return (*g)(unsafe.Pointer(gp)) } //go:nosplit func (gp *guintptr) set(g *g) { *gp = guintptr(unsafe.Pointer(g)) } //go:nosplit func (gp *guintptr) cas(old, new guintptr) bool { return atomic.Casuintptr((*uintptr)(unsafe.Pointer(gp)), uintptr(old), uintptr(new)) } type gList struct 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // A gList is a list of Gs linked through g.schedlink. A G can only be // on one gQueue or gList at a time. type gList struct { head guintptr } // empty reports whether l is empty. func (l *gList) empty() bool { return l.head == 0 } // push adds gp to the head of l. func (l *gList) push(gp *g) { gp.schedlink = l.head l.head.set(gp) } // pushAll prepends all Gs in q to l. func (l *gList) pushAll(q gQueue) { if !q.empty() { q.tail.ptr().schedlink = l.head l.head = q.head } } // pop removes and returns the head of l. If l is empty, it returns nil. func (l *gList) pop() *g { gp := l.head.ptr() if gp != nil { l.head = gp.schedlink } return gp } len() 获取 chan 的元素个数。（获取的是缓存区的个数，没有挂在链表中的数量） 1 2 3 4 5 6 7 //go:linkname reflect_chanlen reflect.chanlen func reflect_chanlen(c *hchan) int { if c == nil { return 0 } return int(c.qcount) } 1 2 3 4 5 6 7 //go:linkname reflectlite_chanlen internal/reflectlite.chanlen func reflectlite_chanlen(c *hchan) int { if c == nil { return 0 } return int(c.qcount) } cap() 返回值和len()函数一致。 1 2 3 4 5 6 7 //go:linkname reflect_chancap reflect.chancap func reflect_chancap(c *hchan) int { if c == nil { return 0 } return int(c.dataqsiz) } select default 以下是存在 default 默认分支情况。意思类似于 tryLock 函数，尝试一次。 以下只是特例，编译器不采用 goselect() 函数时。都是 select {case: default:} 这种形式。 select 中 c \u0026lt;- v 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // compiler implements // //\tselect { //\tcase c \u0026lt;- v: //\t... foo //\tdefault: //\t... bar //\t} // // as // //\tif selectnbsend(c, v) { //\t... foo //\t} else { //\t... bar //\t} func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { // true. 数据send完成。 // false. 表示目前不能发送，因为不想阻塞(block为false)而返回。 // false只在这里被传入使用。 return chansend(c, elem, false, getcallerpc()) } 验证上面代码。 1 2 3 4 5 6 7 8 9 10 11 func chanTs() { ch := make(chan int) a, b := 1, 2 select { case ch \u0026lt;- a: a = b default: b = a } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 TEXT main.chanTs(SB) G:/workspace/hello/main.go func chanTs() { 0x490ae0 493b6610 CMPQ 0x10(R14), SP 0x490ae4 0f8685000000 JBE 0x490b6f 0x490aea 4883ec40 SUBQ $0x40, SP 0x490aee 48896c2438 MOVQ BP, 0x38(SP) 0x490af3 488d6c2438 LEAQ 0x38(SP), BP ch := make(chan int) 0x490af8 488d05419b0000 LEAQ runtime.rodata+30272(SB), AX 0x490aff 31db XORL BX, BX 0x490b01 e8da3cf7ff CALL runtime.makechan(SB) 0x490b06 4889442428 MOVQ AX, 0x28(SP) a, b := 1, 2 0x490b0b 48c744241801000000 MOVQ $0x1, 0x18(SP) 0x490b14 48c744241002000000 MOVQ $0x2, 0x10(SP) case ch \u0026lt;- a: 0x490b1d 488b4c2428 MOVQ 0x28(SP), CX 0x490b22 48894c2430 MOVQ CX, 0x30(SP) 0x490b27 488b4c2418 MOVQ 0x18(SP), CX 0x490b2c 48894c2420 MOVQ CX, 0x20(SP) 0x490b31 488b442430 MOVQ 0x30(SP), AX # 参数 c 0x490b36 488d5c2420 LEAQ 0x20(SP), BX # 参数 elem 0x490b3b 0f1f440000 NOPL 0(AX)(AX*1) 0x490b40 e89b55f7ff CALL runtime.selectnbsend(SB) # 调用selectnbsend 0x490b45 84c0 TESTL AL, AL 0x490b47 7502 JNE 0x490b4b 0x490b49 eb0c JMP 0x490b57 a = b 0x490b4b 488b442410 MOVQ 0x10(SP), AX 0x490b50 4889442418 MOVQ AX, 0x18(SP) 0x490b55 eb0c JMP 0x490b63 b = a 0x490b57 488b442418 MOVQ 0x18(SP), AX 0x490b5c 4889442410 MOVQ AX, 0x10(SP) 0x490b61 eb00 JMP 0x490b63 case ch \u0026lt;- a: 0x490b63 eb00 JMP 0x490b65 } 0x490b65 488b6c2438 MOVQ 0x38(SP), BP 0x490b6a 4883c440 ADDQ $0x40, SP 0x490b6e c3 RET func chanTs() { 0x490b6f e8ecb4fcff CALL runtime.morestack_noctxt.abi0(SB) 0x490b74 e967ffffff JMP main.chanTs(SB) 0x490b79 cc INT $0x3 0x490b7a cc INT $0x3 0x490b7b cc INT $0x3 0x490b7c cc INT $0x3 0x490b7d cc INT $0x3 0x490b7e cc INT $0x3 0x490b7f cc INT $0x3 select 中 v \u0026lt;- c 在 go1.18版本前。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // compiler implements // // select { // case v = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if selectnbrecv(\u0026amp;v, c) { // ... foo // } else { // ... bar // } // func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { // selected：表示当前分支是否选中 selected, _ = chanrecv(c, elem, false) return } select 中 v, ok = \u0026lt;- c 在 go1.18版本前。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // compiler implements // // select { // case v, ok = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if c != nil \u0026amp;\u0026amp; selectnbrecv2(\u0026amp;v, \u0026amp;ok, c) { // ... foo // } else { // ... bar // } // func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. // selected：表示当前分支是否选中 // received：表示当前是否因为 close 而关闭的零值 selected, *received = chanrecv(c, elem, false) return } 其他版本 在go1.19.3中，\u0026lt;-c 有所改变但是原理都一样。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // compiler implements // // select { // case v, ok = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if selected, ok = selectnbrecv(\u0026amp;v, c); selected { // ... foo // } else { // ... bar // } func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected, received bool) { // selected：表示当前分支是否选中 // received：表示当前是否因为 close 而关闭的零值 return chanrecv(c, elem, false) } // // select { // case v = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if selected, _ = selectnbrecv(\u0026amp;v, c); selected { // ... foo // } else { // ... bar // } 验证上面代码。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func chanTs() { ch := make(chan int) a, b := 1, 2 var ok bool select { case a, ok = \u0026lt;-ch: b = a if ok { b = 100 } default: a = b } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 TEXT main.chanTs(SB) G:/workspace/hello/main.go func chanTs() { 0x490ae0 493b6610 CMPQ 0x10(R14), SP 0x490ae4 0f86aa000000 JBE 0x490b94 0x490aea 4883ec48 SUBQ $0x48, SP 0x490aee 48896c2440 MOVQ BP, 0x40(SP) 0x490af3 488d6c2440 LEAQ 0x40(SP), BP ch := make(chan int) 0x490af8 488d05419b0000 LEAQ runtime.rodata+30272(SB), AX 0x490aff 31db XORL BX, BX 0x490b01 e8da3cf7ff CALL runtime.makechan(SB) 0x490b06 4889442430 MOVQ AX, 0x30(SP) a, b := 1, 2 0x490b0b 48c744242001000000 MOVQ $0x1, 0x20(SP) 0x490b14 48c744241802000000 MOVQ $0x2, 0x18(SP) var ok bool 0x490b1d c644241500 MOVB $0x0, 0x15(SP) case a, ok = \u0026lt;-ch: 0x490b22 488b5c2430 MOVQ 0x30(SP), BX 0x490b27 48895c2438 MOVQ BX, 0x38(SP) 0x490b2c 488d442428 LEAQ 0x28(SP), AX 0x490b31 e8aa55f7ff CALL runtime.selectnbrecv(SB) # selectnbrecv 0x490b36 88442416 MOVB AL, 0x16(SP) 0x490b3a 885c2417 MOVB BL, 0x17(SP) 0x490b3e 807c241600 CMPB $0x0, 0x16(SP) if ok { 0x490b64 807c241500 CMPB $0x0, 0x15(SP) 0x490b69 7502 JNE 0x490b6d 0x490b6b eb0b JMP 0x490b78 b = 100 0x490b6d 48c744241864000000 MOVQ $0x64, 0x18(SP) 0x490b76 eb02 JMP 0x490b7a if ok { 0x490b78 eb00 JMP 0x490b7a case a, ok = \u0026lt;-ch: 0x490b7a eb0c JMP 0x490b88 a = b 0x490b7c 488b442418 MOVQ 0x18(SP), AX 0x490b81 4889442420 MOVQ AX, 0x20(SP) 0x490b86 eb00 JMP 0x490b88 case a, ok = \u0026lt;-ch: 0x490b88 eb00 JMP 0x490b8a } 0x490b8a 488b6c2440 MOVQ 0x40(SP), BP 0x490b8f 4883c448 ADDQ $0x48, SP 0x490b93 c3 RET func chanTs() { 0x490b94 e8c7b4fcff CALL runtime.morestack_noctxt.abi0(SB) 0x490b99 e942ffffff JMP main.chanTs(SB) 0x490b9e cc INT $0x3 0x490b9f cc INT $0x3 for range 参考 流程控制(range迭代)。 总结 向(没在select块中) nil 的 channel 中 send、recv 会 panic。在select块中 nil 的 channel 会被丢弃。 send 总是先判断的 close（panic），再判断的数据能否交换(select中的也一样)。recv 也是先判断 close 但是不会panic，再判断 buf 有没数据，有则取出，不会去 sendq 中查看挂起的 sudog。 nil 的 channel 不允许 close 操作，会 panic。close 已经 close 的 channel 会 panic。 参考 https://mp.weixin.qq.com/s/6ZEGtXRGKm2qP5b-rGLyVg https://mp.weixin.qq.com/s?__biz=Mzg5NjIwNzIxNQ==\u0026mid=2247484471\u0026idx=2\u0026sn=49af599b9c3796857459a14d040586fd\u0026scene=19#wechat_redirect ","permalink":"https://heliu.site/posts/golang/channel/theory/","summary":"Golang channel源码走读。","title":"Channel(原理)"},{"content":" 文件位置：go1.19.3/src/runtime/select.go。 select 的使用文档参考 select(使用)。 Constants const debugSelect = false // 调试模式 Variables 1 2 3 4 5 var ( // 函数chansend的PC入口 chansendpc = abi.FuncPCABIInternal(chansend) chanrecvpc = abi.FuncPCABIInternal(chanrecv) ) type scase struct Select case 描述符。编译器已知。 这里修改必须去 src/cmd/compile/internal/walk/select.go\u0026rsquo;s scasetype。 scase 结构是一个 case 的 channel 结构。 1 2 3 4 5 6 7 // Select case descriptor. // Known to compiler. // Changes here must also be made in src/cmd/compile/internal/walk/select.go\u0026#39;s scasetype. type scase struct { c *hchan // chan elem unsafe.Pointer // data element } select关键字 selectgo 实现了 select 语句。 cas0 指向类型为 [ncases]scase 的数组，order0 指向类型为 [2*ncases]uint16 的数组，其中 ncases 必须 \u0026lt;= 65536。 两者都存在于 goroutine 的栈中（不管 selectgo 中的任何转义）。 对于 race 的构建，pc0 指向一个类型为 [ncases]uintptr 的数组（也在这个栈上）；对于其他构建，它被设置为nil。 selectgo 返回所选分支的索引，它与各自的 select{recv,send,default} 调用的顺序位置匹配。 此外，如果选择的 scase 是一个 receive 接收类型操作，它会报告是否收到了值。 参数： cas0 *scase：指向一个数组，数组里装的是select中所有的case分支，按照send在前recv在后的顺序。不包含default分支。 order0 *uint16：指向一个大小等于case分支数量两倍的uint16数组(2*(nsends+nrecvs))，实际上是作为两个大小相等的数组来用的。前一个用来对所有case中channel的轮询进行乱序，后一个用来对所有case中channel的加锁操作进行排序。 pc0 *uintptr：race 相关。 nsends int：send 操作的分支数量。 nrecvs int：recv 操作的分支数量。 block bool：表示是否想要阻塞等待。有default分支的不阻塞，反之则会阻塞。 返回值： int：表示最终哪个case分支被执行了，对应case0数组的下标。如果因为不想阻塞而返回，则这个值为-1。 bool：表示在对应的case分支执行的是recv操作时，用来表示实际接收到一个值，而不是因为通道关闭得到的零值。 selectgo() 函数流程： 先随机打乱cas0集用于轮询遍历。在按照channel地址升序排序用于全部的channel加锁和解锁。 all channel lock后遍历打乱的case集检查是否能立即完成，如果可以则交换数据后全部解锁。否则判断block是否需要阻塞。 全部需要阻塞时，将当前goroutine封装成sudog形成一个链表挂在所有的channel上去等待。 当再次触发时，先获取清all channel lock，除挂在这些上面的sudog，解锁后返回。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 // selectgo implements the select statement. // // cas0 points to an array of type [ncases]scase, and order0 points to // an array of type [2*ncases]uint16 where ncases must be \u0026lt;= 65536. // Both reside on the goroutine\u0026#39;s stack (regardless of any escaping in // selectgo). // // For race detector builds, pc0 points to an array of type // [ncases]uintptr (also on the stack); for other builds, it\u0026#39;s set to // nil. // // selectgo returns the index of the chosen scase, which matches the // ordinal position of its respective select{recv,send,default} call. // Also, if the chosen scase was a receive operation, it reports whether // a value was received. func selectgo(cas0 *scase, order0 *uint16, pc0 *uintptr, nsends, nrecvs int, block bool) (int, bool) { if debugSelect { print(\u0026#34;select: cas0=\u0026#34;, cas0, \u0026#34;\\n\u0026#34;) } // NOTE: In order to maintain a lean stack size, the number of scases // is capped at 65536. cas1 := (*[1 \u0026lt;\u0026lt; 16]scase)(unsafe.Pointer(cas0)) order1 := (*[1 \u0026lt;\u0026lt; 17]uint16)(unsafe.Pointer(order0)) // send + recv 数量和 ncases := nsends + nrecvs // cases 集，按照 send + recv 顺序组成的 scases := cas1[:ncases:ncases] // select case集 // 轮询集,记录的是scases的下标,现在是空的。后面乱序填入 pollorder := order1[:ncases:ncases] // lockorder 用于按channel地址升序排序，所以方便Lock channel的作用。 lockorder := order1[ncases:][:ncases:ncases] // lock集,现在是空的 // NOTE: pollorder/lockorder\u0026#39;s underlying array was not zero-initialized by compiler. // Even when raceenabled is true, there might be select // statements in packages compiled without -race (e.g., // ensureSigM in runtime/signal_unix.go). var pcs []uintptr if raceenabled \u0026amp;\u0026amp; pc0 != nil { pc1 := (*[1 \u0026lt;\u0026lt; 16]uintptr)(unsafe.Pointer(pc0)) pcs = pc1[:ncases:ncases] } casePC := func(casi int) uintptr { if pcs == nil { return 0 } return pcs[casi] } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // The compiler rewrites selects that statically have // only 0 or 1 cases plus default into simpler constructs. // The only way we can end up with such small sel.ncase // values here is for a larger select in which most channels // have been nilled out. The general code handles those // cases correctly, and they are rare enough not to bother // optimizing (and needing to test). // 1) 乱序 pollorder，为后面select的随机性左准备 // generate permuted order // // 生成排列的 order。 norder := 0 // 有效的数量 // 随机打乱 scases 并把打乱结果下标存入 pollorder 中。 // 参看下面的【图一】 for i := range scases { cas := \u0026amp;scases[i] // Omit cases without channels from the poll and lock orders. // // 从 poll 和 lock orders 中省略没有 channels 的情况。 // nil 的 channel 会被丢弃。 if cas.c == nil { cas.elem = nil // allow GC continue } // 生成随机数 [0, norder + 1] j := fastrandn(uint32(norder + 1)) pollorder[norder] = pollorder[j] pollorder[j] = uint16(i) norder++ } pollorder = pollorder[:norder] // 此时pollorder是打乱的轮询集 lockorder = lockorder[:norder] // 2) lockorder 按 channel 地址排序，为了后面 all lock 准备 // 按照地址升序排序有助于判断同一个channel在多个 case 中的情况 // sort the cases by Hchan address to get the locking order. // simple heap sort, to guarantee n log n time and constant stack footprint. // // 将cases按照Hchan地址排序得到 locking order。 // 简单的堆排序，保证 n log n 时间和恒定的栈占用。 // 参看下面的【图一】 for i := range lockorder { // 按照channel地址排序并记录在lockorder中升序。 j := i // Start with the pollorder to permute cases on the same channel. c := scases[pollorder[i]].c // 按照 channel 的地址排序 for j \u0026gt; 0 \u0026amp;\u0026amp; scases[lockorder[(j-1)/2]].c.sortkey() \u0026lt; c.sortkey() { k := (j - 1) / 2 lockorder[j] = lockorder[k] j = k } lockorder[j] = pollorder[i] } for i := len(lockorder) - 1; i \u0026gt;= 0; i-- { o := lockorder[i] c := scases[o].c lockorder[i] = lockorder[0] j := 0 for { k := j*2 + 1 if k \u0026gt;= i { break } if k+1 \u0026lt; i \u0026amp;\u0026amp; scases[lockorder[k]].c.sortkey() \u0026lt; scases[lockorder[k+1]].c.sortkey() { k++ } if c.sortkey() \u0026lt; scases[lockorder[k]].c.sortkey() { lockorder[j] = lockorder[k] j = k continue } break } lockorder[j] = o } if debugSelect { for i := 0; i+1 \u0026lt; len(lockorder); i++ { if scases[lockorder[i]].c.sortkey() \u0026gt; scases[lockorder[i+1]].c.sortkey() { print(\u0026#34;i=\u0026#34;, i, \u0026#34; x=\u0026#34;, lockorder[i], \u0026#34; y=\u0026#34;, lockorder[i+1], \u0026#34;\\n\u0026#34;) throw(\u0026#34;select: broken sort\u0026#34;) } } } // 3) 所有的 send、recv 获取 lock // lock all the channels involved in the select // // 锁定select中涉及的所有channels。 sellock(scases, lockorder) // lock channel var ( gp *g // 找到的goroutine sg *sudog c *hchan // channel k *scase sglist *sudog sgnext *sudog qp unsafe.Pointer nextp **sudog ) // pass 1 - look for something already waiting // pass 1 - 寻找已经在等待的 var casi int var cas *scase\tvar caseSuccess bool var caseReleaseTime int64 = -1 var recvOK bool // 轮序 order for _, casei := range pollorder { casi = int(casei) // 选中下标 cas = \u0026amp;scases[casi] c = cas.c // channel // recv 操作 if casi \u0026gt;= nsends { // 注意 recv 先判断的能否成功，再判断的 close sg = c.sendq.dequeue() // sendq中寻找 if sg != nil { goto recv // 找到，去recv } // send buf 中有数据，去bufrecv if c.qcount \u0026gt; 0 { goto bufrecv } // 当前recv操作没完成，close关闭了，去rclose if c.closed != 0 { goto rclose } } else { // send 操作。注意 send 先判断的 close，再判断能否成功 if raceenabled { racereadpc(c.raceaddr(), casePC(casi), chansendpc) } // channel 已经关闭 if c.closed != 0 { goto sclose } sg = c.recvq.dequeue() // recvq中寻找 if sg != nil { goto send } // buf 中还有容量 if c.qcount \u0026lt; c.dataqsiz { goto bufsend } } } // 4) 以上都没有能立即完成时。可以走default分支不？ // block 为false时存在default分支，不想阻塞。 // block 为true时不存在default分支，阻塞。 if !block { selunlock(scases, lockorder) // all channel unlock casi = -1 // -1 没找到 goto retc } // 5) 把当前 goroutine 挂在所有 channel 等待。 // pass 2 - enqueue on all chans // pass 2 - 对所有chan进行排队 gp = getg() // g if gp.waiting != nil { throw(\u0026#34;gp.waiting != nil\u0026#34;) } nextp = \u0026amp;gp.waiting // 遍历 lockorder，这里当前goroutine被加入到多个channel中 for _, casei := range lockorder { casi = int(casei) cas = \u0026amp;scases[casi] c = cas.c // channel sg := acquireSudog() // 寻找一个*sudog sg.g = gp // 记录当前goroutine sg.isSelect = true // 标记是在select // No stack splits between assigning elem and enqueuing // sg on gp.waiting where copystack can find it. sg.elem = cas.elem sg.releasetime = 0 if t0 != 0 { sg.releasetime = -1 } sg.c = c // Construct waiting list in lock order. // 所有的 sudog 组成个链表，有两个作用：【参看下面图片】 // 1. 后续selparkcommit函数通过sudog.c解锁所有的 channel。 // 2. 就绪后用于判断是那个 case 就绪了。 *nextp = sg // 通过 waitlink 链接 nextp = \u0026amp;sg.waitlink // 加入队列中 if casi \u0026lt; nsends { c.sendq.enqueue(sg) } else { c.recvq.enqueue(sg) } } // wait for someone to wake us up // 等着有人叫醒我们 gp.param = nil // 在被唤醒时会给param参数上赋值 // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. // 参看 channel 文档 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) // parkingOnChan = 1 // 挂起，进入调度循环。 gopark(selparkcommit, nil, waitReasonSelect, traceEvGoBlockSelect, 1) // 6) 再次被唤醒时，... ... gp.activeStackChans = false // 全部channels锁住 sellock(scases, lockorder) // all channel lock // 标记为0，表示select已完成。此时所有的channels都锁住了。 gp.selectDone = 0 // 被唤醒的goroutine的*sudog放在param上 // 直接获取使用，关于 gp.param 的部分赋值代码在 chan send和recv上 sg = (*sudog)(gp.param) gp.param = nil // pass 3 - dequeue from unsuccessful chans // otherwise they stack up on quiet channels // record the successful case, if any. // We singly-linked up the SudoGs in lock order. casi = -1 cas = nil caseSuccess = false // 在 waiting 上等待着很多goroutine sglist = gp.waiting // Clear all elem before unlinking from gp.waiting. // 在从gp.waiting断开连接前清除所有elem。 for sg1 := gp.waiting; sg1 != nil; sg1 = sg1.waitlink { sg1.isSelect = false sg1.elem = nil sg1.c = nil } gp.waiting = nil // 7) 遍历 lockorder，寻找是哪个case就绪了 for _, casei := range lockorder { k = \u0026amp;scases[casei] if sg == sglist { // 找到就绪的 case // sg has already been dequeued by the G that woke us up. casi = int(casei) // 找到就绪的 case cas = k caseSuccess = sglist.success if sglist.releasetime \u0026gt; 0 { caseReleaseTime = sglist.releasetime } } else { // 移除没就绪的 c = k.c // 从 channel 中移除 sglist // 因为其他 channel 中还挂起的呢，要移除 if int(casei) \u0026lt; nsends { c.sendq.dequeueSudoG(sglist) } else { c.recvq.dequeueSudoG(sglist) } } sgnext = sglist.waitlink // 换下一个 sglist.waitlink = nil releaseSudog(sglist) // 回收*sudog sglist = sgnext } if cas == nil { throw(\u0026#34;selectgo: bad wakeup\u0026#34;) } c = cas.c // channel if debugSelect { print(\u0026#34;wait-return: cas0=\u0026#34;, cas0, \u0026#34; c=\u0026#34;, c, \u0026#34; cas=\u0026#34;, cas, \u0026#34; send=\u0026#34;, casi \u0026lt; nsends, \u0026#34;\\n\u0026#34;) } // send 操作 if casi \u0026lt; nsends { // caseSuccess = true成功，false由于closed函数关闭触发。 if !caseSuccess { goto sclose } } else { // recv 操作 recvOK = caseSuccess } if raceenabled { if casi \u0026lt; nsends { raceReadObjectPC(c.elemtype, cas.elem, casePC(casi), chansendpc) } else if cas.elem != nil { raceWriteObjectPC(c.elemtype, cas.elem, casePC(casi), chanrecvpc) } } if msanenabled { if casi \u0026lt; nsends { msanread(cas.elem, c.elemtype.size) } else if cas.elem != nil { msanwrite(cas.elem, c.elemtype.size) } } if asanenabled { if casi \u0026lt; nsends { asanread(cas.elem, c.elemtype.size) } else if cas.elem != nil { asanwrite(cas.elem, c.elemtype.size) } } selunlock(scases, lockorder) // all channel unlock goto retc bufrecv: // buf 中有数据, recv操作【ep \u0026lt;- c】 // can receive from buffer if raceenabled { if cas.elem != nil { raceWriteObjectPC(c.elemtype, cas.elem, casePC(casi), chanrecvpc) } racenotify(c, c.recvx, nil) } if msanenabled \u0026amp;\u0026amp; cas.elem != nil { msanwrite(cas.elem, c.elemtype.size) } if asanenabled \u0026amp;\u0026amp; cas.elem != nil { asanwrite(cas.elem, c.elemtype.size) } recvOK = true // 数据交换成功标识 qp = chanbuf(c, c.recvx) if cas.elem != nil { // 数据给到等待的变量 typedmemmove(c.elemtype, cas.elem, qp) } typedmemclr(c.elemtype, qp) // 处理 buf 的下标 c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- selunlock(scases, lockorder) // all channel unlock goto retc bufsend: // buf 中还有容量，send操作【c \u0026lt;- ep】 // can send to buffer if raceenabled { racenotify(c, c.sendx, nil) raceReadObjectPC(c.elemtype, cas.elem, casePC(casi), chansendpc) } if msanenabled { msanread(cas.elem, c.elemtype.size) } if asanenabled { asanread(cas.elem, c.elemtype.size) } // 数据迁移 typedmemmove(c.elemtype, chanbuf(c, c.sendx), cas.elem) // 处理下标 c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ selunlock(scases, lockorder) goto retc recv: // sendq 中获取到 sg goroutine // can receive from sleeping sender (sg) // 数据在挂起的 send 的 goroutine 里面，调用recv取交换数据。 recv(c, sg, cas.elem, func() { selunlock(scases, lockorder) }, 2) // 恢复并解锁all channel if debugSelect { print(\u0026#34;syncrecv: cas0=\u0026#34;, cas0, \u0026#34; c=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } recvOK = true // recv操作成功 goto retc rclose: // channel 已经关闭, recv 操作时 // read at end of closed channel selunlock(scases, lockorder) // all channel unlock recvOK = false // channel 关闭的 recv if cas.elem != nil { // 接受值设置成默认零值，因为close了 typedmemclr(c.elemtype, cas.elem) } if raceenabled { raceacquire(c.raceaddr()) } goto retc send: // recvq 中有等待 sg goroutine。 // can send to a sleeping receiver (sg) if raceenabled { raceReadObjectPC(c.elemtype, cas.elem, casePC(casi), chansendpc) } if msanenabled { msanread(cas.elem, c.elemtype.size) } if asanenabled { asanread(cas.elem, c.elemtype.size) } // 数据在挂起的 recv 的 goroutine 里面，调用 send 去交换数据。 send(c, sg, cas.elem, func() { selunlock(scases, lockorder) }, 2) if debugSelect { print(\u0026#34;syncsend: cas0=\u0026#34;, cas0, \u0026#34; c=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } goto retc retc: if caseReleaseTime \u0026gt; 0 { blockevent(caseReleaseTime-t0, 1) } return casi, recvOK sclose: // channel 已经关闭，send 操作时 // send on closed channel selunlock(scases, lockorder) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } sellock() 所有 case 的 send、recv 操作的获取 hmap.lock 互斥锁。 1 2 3 4 5 6 7 8 9 10 11 func sellock(scases []scase, lockorder []uint16) { var c *hchan // 按照lockorder遍历，因为是升序，所以相同的channel在一起 for _, o := range lockorder { c0 := scases[o].c if c0 != c { // 如果是同一个 channel 跳过它 c = c0 lock(\u0026amp;c.lock) // mutex lock } } } selunlock() 所有 case 的 send、recv 操作的释放 hmap.lock 互斥锁。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func selunlock(scases []scase, lockorder []uint16) { // We must be very careful here to not touch sel after we have unlocked // the last lock, because sel can be freed right after the last unlock. // Consider the following situation. // First M calls runtime·park() in runtime·selectgo() passing the sel. // Once runtime·park() has unlocked the last lock, another M makes // the G that calls select runnable again and schedules it for execution. // When the G runs on another M, it locks all the locks and frees sel. // Now if the first M touches sel, it will access freed memory. for i := len(lockorder) - 1; i \u0026gt;= 0; i-- { c := scases[lockorder[i]].c // 如果是同一个 channel 跳过它 if i \u0026gt; 0 \u0026amp;\u0026amp; c == scases[lockorder[i-1]].c { continue // will unlock it on the next iteration } unlock(\u0026amp;c.lock) } } selparkcommit() 当前 select 没有就绪 case 导致当前 goroutine 被挂起前执行的函数。 func selparkcommit(gp *g, _ unsafe.Pointer) bool { // There are unlocked sudogs that point into gp\u0026#39;s stack. Stack // copying must lock the channels of those sudogs. // Set activeStackChans here instead of before we try parking // because we could self-deadlock in stack growth on a // channel lock. gp.activeStackChans = true // 参看channel文档 // Mark that it\u0026#39;s safe for stack shrinking to occur now, // because any thread acquiring this G\u0026#39;s stack for shrinking // is guaranteed to observe activeStackChans after this store. atomic.Store8(\u0026amp;gp.parkingOnChan, 0) // 参看channel文档 // Make sure we unlock after setting activeStackChans and // unsetting parkingOnChan. The moment we unlock any of the // channel locks we risk gp getting readied by a channel operation // and so gp could continue running before everything before the // unlock is visible (even to gp itself). // This must not access gp\u0026#39;s stack (see gopark). In // particular, it must not access the *hselect. That\u0026#39;s okay, // because by the time this is called, gp.waiting has all // channels in lock order. var lastc *hchan // 依次channel解锁 for sg := gp.waiting; sg != nil; sg = sg.waitlink { if sg.c != lastc \u0026amp;\u0026amp; lastc != nil { // As soon as we unlock the channel, fields in // any sudog with that channel may change, // including c and waitlink. Since multiple // sudogs may have the same channel, we unlock // only after we\u0026#39;ve passed the last instance // of a channel. unlock(\u0026amp;lastc.lock) } lastc = sg.c } if lastc != nil { unlock(\u0026amp;lastc.lock) } return true } selectgo 参数组成 以下都是介绍selectgo()参数的组成，对于理解goselect增加帮助。\ntype runtimeSelect struct runtimeSelect 是传递给 rselect 的一个 case。 必须匹配 ../reflect/value.go:/runtimeSelect。 该结构理解为select case中的所有case组成的集合。 1 2 3 4 5 6 7 8 9 10 11 // A runtimeSelect is a single case passed to rselect. // This must match ../reflect/value.go:/runtimeSelect type runtimeSelect struct { // channel 类型，包含：send、recv、default 三种 dir selectDir typ unsafe.Pointer // channel type (not used here) // 当前 case 操作所属的 channel ch *hchan // channel // send 或 recv 操作时数据的地址 val unsafe.Pointer // ptr to data (SendDir) or ptr to receive buffer (RecvDir) } type selectDir int 1 2 3 4 5 6 7 8 9 // These values must match ../reflect/value.go:/SelectDir. type selectDir int const ( _ selectDir = iota selectSend // case Chan \u0026lt;- Send selectRecv // case \u0026lt;-Chan: selectDefault // default ) reflect_rselect() reflect_rselect是select关键字相关代码。 对于代码select {}，当前goroutine会丢失再也不会被调度。 参数cases []runtimeSelect：select的所有分支数据信息。 返回值int：返回选中的分支下标。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 //go:linkname reflect_rselect reflect.rselect func reflect_rselect(cases []runtimeSelect) (int, bool) { // 没有 case 分支 // 对于 `select {}` 当前goroutine会直接丢失 if len(cases) == 0 { block() // gopark } // len(cases) = send + recv + default sel := make([]scase, len(cases)) // scase 集 orig := make([]int, len(cases)) // sel下标和cases的对应关系 // 临时变量用于保存 send 和 recv nsends, nrecvs := 0, 0 // send And recv // 标记select中默认default分支下标 dflt := -1 // 默认值-1表示没有默认default分支 // 遍历select的所有case，包括default分支 // 使用 dflt 标记 default 分支的下标 // sel 整理存储为 send + recv // orig 存储sel和cases的映射关系【参看上面\u0026#34;图一\u0026#34;】 for i, rc := range cases { // 临时变量，用于计算当前case应该放入的位置 var j int switch rc.dir { // default分支 case selectDefault: dflt = i continue // send 分支：c \u0026lt;- ep case selectSend: // 从前向后，依次放入 j = nsends nsends++ // recv 分支：\u0026lt;- c case selectRecv: // 从后向前，依次放入 nrecvs++ j = len(cases) - nrecvs } // 保存对应关系 sel[j] = scase{c: rc.ch, elem: rc.val} orig[j] = i } // for range 完后，sel 保存 send + recv // orig 保存 sel 和 cases 对应关系 // Only a default case. // // 仅仅只有一个 default case。 // 因为如果一个分支都没有，最前面就返回了 // select {default:} if nsends+nrecvs == 0 { return dflt, false } // Compact sel and orig if necessary. // // 如果有必要使sel 和 orig紧凑。【参看上面\u0026#34;图二\u0026#34;】 if nsends+nrecvs \u0026lt; len(cases) { // 存在defult时 copy(sel[nsends:], sel[len(cases)-nrecvs:]) copy(orig[nsends:], orig[len(cases)-nrecvs:]) } // order 长度是 2*(nsends+nrecvs) order := make([]uint16, 2*(nsends+nrecvs)) var pc0 *uintptr if raceenabled { pcs := make([]uintptr, nsends+nrecvs) for i := range pcs { selectsetpc(\u0026amp;pcs[i]) } pc0 = \u0026amp;pcs[0] } // \u0026amp;sel[0]：是send+recv // \u0026amp;order[0]：是空的，dflt true.不存在defalut分支 false.存在default分支 // chosen：表示选择的case下标，如果为-1时为默认default分支 // recvOK：表示数据是否交换成功，true.成功 false.失败 // 从case分支中选择一个就绪的channel chosen, recvOK := selectgo(\u0026amp;sel[0], \u0026amp;order[0], pc0, nsends, nrecvs, dflt == -1) // Translate chosen back to caller\u0026#39;s ordering. // // chosen \u0026lt; 0 选中默认分支 if chosen \u0026lt; 0 { chosen = dflt // 默认default } else { chosen = orig[chosen] // case } return chosen, recvOK } block() 1 2 3 4 func block() { // 注意：这里第一和第二个参数都为nil，表明当前goroutine被丢弃了。 gopark(nil, nil, waitReasonSelectNoCases, traceEvGoStop, 1) // forever } 汇编验证 1 2 3 4 5 6 7 8 9 10 11 12 13 package main func main() { ch1 := make(chan int) ch2 := make(chan int) select { case v := \u0026lt;-ch1: println(v) case ch2 \u0026lt;- 10: default: } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 TEXT main.main(SB) /mnt/GoProject/small/tt1.go func main() { 0x459580 4c8d6424c8 LEAQ -0x38(SP), R12 0x459585 4d3b6610 CMPQ 0x10(R14), R12 0x459589 0f8632010000 JBE 0x4596c1 0x45958f 4881ecb8000000 SUBQ $0xb8, SP 0x459596 4889ac24b0000000 MOVQ BP, 0xb0(SP) 0x45959e 488dac24b0000000 LEAQ 0xb0(SP), BP ch1 := make(chan int) 0x4595a6 488d0513490000 LEAQ 0x4913(IP), AX 0x4595ad 31db XORL BX, BX 0x4595af e8eca6faff CALL runtime.makechan(SB) 0x4595b4 4889442468 MOVQ AX, 0x68(SP) ch2 := make(chan int) 0x4595b9 488d0500490000 LEAQ 0x4900(IP), AX 0x4595c0 31db XORL BX, BX 0x4595c2 e8d9a6faff CALL runtime.makechan(SB) 0x4595c7 4889442460 MOVQ AX, 0x60(SP) case v := \u0026lt;-ch1: 0x4595cc 488b4c2468 MOVQ 0x68(SP), CX #CX=\u0026amp;ch1 0x4595d1 48894c2478 MOVQ CX, 0x78(SP) case ch2 \u0026lt;- 10: 0x4595d6 488b4c2460 MOVQ 0x60(SP), CX 0x4595db 48894c2470 MOVQ CX, 0x70(SP) 0x4595e0 48c74424500a000000 MOVQ $0xa, 0x50(SP) select { 0x4595e9 440f11bc2490000000 MOVUPS X15, 0x90(SP) 0x4595f2 440f11bc24a0000000 MOVUPS X15, 0xa0(SP) case v := \u0026lt;-ch1: 0x4595fb 488b4c2478 MOVQ 0x78(SP), CX 0x459600 48898c24a0000000 MOVQ CX, 0xa0(SP) 0x459608 488d4c2458 LEAQ 0x58(SP), CX 0x45960d 48898c24a8000000 MOVQ CX, 0xa8(SP) case ch2 \u0026lt;- 10: 0x459615 488b4c2470 MOVQ 0x70(SP), CX 0x45961a 48898c2490000000 MOVQ CX, 0x90(SP) 0x459622 488d4c2450 LEAQ 0x50(SP), CX 0x459627 48898c2498000000 MOVQ CX, 0x98(SP) select { 0x45962f 488d8c2490000000 LEAQ 0x90(SP), CX 0x459637 48898c2488000000 MOVQ CX, 0x88(SP) 0x45963f 488d5c2448 LEAQ 0x48(SP), BX 0x459644 48899c2480000000 MOVQ BX, 0x80(SP) 0x45964c 488b842488000000 MOVQ 0x88(SP), AX 0x459654 31c9 XORL CX, CX 0x459656 bf01000000 MOVL $0x1, DI 0x45965b 4889fe MOVQ DI, SI 0x45965e 4531c0 XORL R8, R8 0x459661 e89a57feff CALL runtime.selectgo(SB) 0x459666 4889442440 MOVQ AX, 0x40(SP) 0x45966b 885c2437 MOVB BL, 0x37(SP) default: 0x45966f 48837c244000 CMPQ $0x0, 0x40(SP) 0x459675 7c02 JL 0x459679 0x459677 eb02 JMP 0x45967b 0x459679 eb36 JMP 0x4596b1 case ch2 \u0026lt;- 10: 0x45967b 48837c244000 CMPQ $0x0, 0x40(SP) 0x459681 7402 JE 0x459685 0x459683 eb02 JMP 0x459687 0x459685 eb2a JMP 0x4596b1 case v := \u0026lt;-ch1: 0x459687 488b442458 MOVQ 0x58(SP), AX 0x45968c 4889442438 MOVQ AX, 0x38(SP) println(v) 0x459691 e86a5cfdff CALL runtime.printlock(SB) 0x459696 488b442438 MOVQ 0x38(SP), AX 0x45969b 0f1f440000 NOPL 0(AX)(AX*1) 0x4596a0 e85b63fdff CALL runtime.printint(SB) 0x4596a5 e8b65efdff CALL runtime.printnl(SB) 0x4596aa e8d15cfdff CALL runtime.printunlock(SB) case v := \u0026lt;-ch1: 0x4596af eb00 JMP 0x4596b1 } 0x4596b1 488bac24b0000000 MOVQ 0xb0(SP), BP 0x4596b9 4881c4b8000000 ADDQ $0xb8, SP 0x4596c0 c3 RET func main() { 0x4596c1 e8dacbffff CALL runtime.morestack_noctxt.abi0(SB) 0x4596c6 e9b5feffff JMP main.main(SB) 总结 select {} 会导致当前 goroutine 直接丢弃，再也不会被调用。 select {default:} 直接跳过什么都不会做。 select case 中存在 channel 为 nil，该 case 会被丢弃。 select 中也一样，向关闭的channel，send会panic，recv会得到默认的零值。 select 中，向 nil 的 channel，send 或 recv 不会 panic（channel会被丢弃）。而没在 select 中全部都会 panic。 注意：在 select 中 close 的 channel 情况： recv 先判断的能否成功，再判断的 close。 send 先判断的 close，再判断能否成功。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main import ( \u0026#34;fmt\u0026#34; ) func main() { c := make(chan int, 2) c \u0026lt;- 1 close(c) select { case v, ok := \u0026lt;-c: fmt.Printf(\u0026#34;received %d, ok = %v\\n\u0026#34;, v, ok) default: fmt.Printf(\u0026#34;default\u0026#34;) } // Output: // received 1, ok = true } ","permalink":"https://heliu.site/posts/golang/channel/select/","summary":"Golang select关键字介绍。","title":"select(原理)"},{"content":"epoll描述 适用范围：连接数量多，但活动连接较少的情况。 epoll高效的奥秘：epoll精巧的使用3个方法实现select方法要做的事： epoll_create()：创建一个epoll文件描述符。 执行一次epoll_create()函数就会创建一个epoll池，因此初始化执行一次即可。 epoll_create函数会返回一个epoll文件描述符。 epoll_ctrl()：添加/修改/删除需要侦听的文件描述符及其事件。 一个socket只需调用该函数一次注册当前文件描述符。 该函数注册时可以添加具体的侦听的事件和用户数据，当前事件触发时可以根据epoll_wait函数获取事件。 返回注册成功和失败结果。 epoll_wait()：接收发生在被侦听的描述符上的，用户感兴趣的IO事件，返回已就绪的事件集。 查询系统最大支持FD数目：cat /proc/sys/fs/file-max。 理解epoll的关键要素：红黑树、链表。 红黑树：存储epoll所监听的套接字。epoll在实现上采用红黑树去存储所有套接字，当添加或者删除一个套接字时（epoll_ctl），都在红黑树上去处理，红黑树本身插入和删除性能比较好，时间复杂度O(logN)。 通过epoll_ctl函数添加进来的事件都会被放在红黑树的某个节点内，所以重复添加是没有用的。当把事件添加进来的时候时候会完成关键的一步，那就是该事件都会与相应的设备（网卡）驱动程序建立回调关系，当相应的事件发生后，就会调用这个回调函数，该回调函数在内核中被称为：ep_poll_callback，这个回调函数其实就所把这个事件添加到rdllist这个双向链表中。一旦有事件发生，epoll就会将该事件添加到双向链表中。那么当我们调用epoll_wait时，epoll_wait只需要检查rdlist双向链表中是否有存在注册的事件，效率非常可观。这里也需要将发生了的事件复制到用户态内存中即可。中断程序还有一个重要作用是将阻塞的进程唤醒起来执行。 总结： 红黑树的作用：当有事件发生时，可以快速根据fd查找epitem（找到得epiterm会组成链表传递给用户空间做进一步处理），比遍历链表快多了！ 内核中链表适用的场景：用来做队列或栈，存储的每个节点都要处理（说白了就是需要遍历），不存在查找的需求场景！ epoll事件底层最终是中断触发的：当网卡收到数据后，通过中断通知操作系统来取数据，进而触发epoll事件！ epoll_create() 在epoll早期的实现中，对于监控文件描述符的组织并不是使用红黑树，而是hash表。所以在epoll_create的参数size没有什么意义。 epoll_create：该函数初始化时只执行一次。 1 2 3 4 5 6 7 // 创建一个epoll句柄 // 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，在红黑树中该参数size无效 int epoll_create(int size);\t// 返回值： //\tEINVAL 大小不是正数。 // ENFILE 已达到系统对打开文件总数的限制。 // ENOMEM 没有足够的内存来创建内核对象。 epoll_ctl() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 添加文件描述符到红黑树中 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // epfd：为epoll_create创建的fd // op：指定操作类型 // EPOLL_CTL_ADD：\t将目标文件描述符fd添加到epoll描述符epfd中，并将事件event与fd链接的内部文件关联起来。 // EPOLL_CTL_MOD：\t更改与目标文件描述符fd关联的事件event。 // EPOLL_CTL_DEL：\t从epoll文件描述符epfd中删除目标文件描述符fd。该事件被忽略，可以为NULL。 // fd：要操作的文件描述符，也就是我们要加入的fd，可以是创建的socket或其他文件句柄。 // event：指定事件，它是epoll_event结构指针类型 // epoll_event 定义： // events：描述事件类型，和poll支持的事件类型基本相同（两个额外的事件：EPOLLET和EPOLLONESHOT，高效运作的关键） // events可以是以下几个宏的集合： // EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）。关联文件描述符的read()操作 // EPOLLOUT：表示对应的文件描述 符可以写，关联文件描述符的write()操作。 // EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来） // EPOLLERR：描述符产生错误时触发，默认检测事件 // EPOLLHUP：本端描述符产生一个挂断事件，默认监测事件 // EPOLLRDHUP：对端描述符产生一个挂断事件 // EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的 // EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 // data：存储用户数据，该字段是一个指针类型因此在wait函数中我们可以拿到该数据进行相关操作 // event是我们所关心的事件类型，注意只有我们注册的事件才会在epoll_wait被唤醒后传递到用户空间，否则虽然内核可以收到但不会传递 epoll_wait() 1 2 3 4 5 6 7 8 9 10 11 // 成功时返回就绪的文件描述符的个数，失败时返回-1并设置errno int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); // timeout：指定epoll的超时时间，单位是毫秒 // 当timeout为-1时，epoll_wait调用将永久阻塞，直到某个事件发生 // 当timeout为0时，epoll_wait调用将立即返回 // 当timeout大于0时，epoll_wait阻塞timeout事件后返回 // maxevents：指定最多监听多少个事件，意思是一次返回最大的就绪事件数量 // events：检测到事件，将所有就绪的事件从内核事件表中复制到它的第二个参数events指向的数组中 // 该参数获取从内核得到的事件的集合，拿到前面函数注册的用户数据进行标记 // 返回值int，表示需要处理的事件数目，如果返回0表示已超时 select、poll、epoll 系统调用 select poll epoll 事件集合 通过传入3个参数可读、可写、异常事件内核通过对这些参数在线修改来反馈其中的就绪事件，这使得用户每次调用select都要重置这3个参数 统一处理所有事件类型，因此只需要一个事件集参数。用户通过pollfd.events传入感兴趣的事件，内核通过修改pollfd.revents反馈其中就绪的事件 内核通过一个事件表直接管理用户感兴趣的所有事件。因此每次调用epoll_wait时，无需反复传入用户感兴趣的事件。epoll_wait系统调用的参数events仅用来反馈就绪的事件 应用程序索引就绪文件描述符的时间复杂度 O(n) O(n) O(1) 最大支持文件描述符数 一般有最大值限制 65535 65535 工作模式 LT LT 支持ET高效模式 内核实现和工作效率 采用轮询方式检测就绪事件，时间复杂度：O(n) 采用轮询方式检测就绪事件，时间复杂度：O(n) 采用回调方式检测就绪事件，时间复杂度：O(1) socket() 创建一个socket，为一个socket数据结构分配存储空间。 两个网络程序之间的一个网络连接包括五种信息：【通信协议】、【本地协议地址】、【本地主机端口】、【远端主机地址】和【远端协议端口】。 该函数不会阻塞。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 int socket(int domain, int type, int protocol); // 1) domain 参数：互联网协议族，常用的有以下 // AF_INET： 表示通过IPv4,通信方式(通过IPv4网络连接起来的主机),应用程序间的通信(32位IPv4地址+16位端口号),地址结构(sockaddr_in) // AF_INET6：表示通过IPv6,通信方式(通过IPv6网络连接起来的主机),应用程序间的通信(128位Ipv6地址+16位端口号),地址结构(sockaddr_in6) // AF_UNIX： 内核中,同一主机间通信,地址格式(路径名),地址结构(sockaddr_un) // AF_ROUTE：路由套接字 // AF_KEY：密钥套接字 // AF_UNSPEC：未指定 // AF：是“Address Family”的简写，INET是“Inetnet”的简写 // 2) type 参数：表示 数据传输方式/套接字类型 // SOCK_STREAM：表示使用 \u0026#34;流格式套接字/面向连接的套接字\u0026#34;，有序的、面向连接的、可靠的双向通信的字节流通信 // SOCK_DGRAM： 表示使用 \u0026#34;数据报套接字/无连接的套接字\u0026#34;，不连接、不可靠、固定长度的数据报通信 // SOCK_NONBLOCK：将socket函数返回的文件描述符指定为非阻塞，可以和上面的宏使用’|’运算（如采用SOCK_STREAM | SOCK_NONBLOCK表示使用TCP协议且是非阻塞），默认是阻塞模式 // SOCK_RDM：表示想使用原始网络通信（如当domain参数设置为PF_INET时就表示直接使用TCP/IP协议族中的ip协议） // SOCK_CLOEXEC：一旦进程exec执行新程序时，自动关闭socket返回的套接字文件描述符，也就是fork的程序不能共用一个socket // 3) protocol 参数：表示传输协议，常用的有以下 // IPPROTO_TCP： 表示TCP传输协议 // IPPTOTO_UDP： 表示UDP传输协议 // IPPROTO_SCTP：表示SCTP传输协议 // IPPROTO_TIPC：表示TIPC传输协议 // 一般该参数默认传入0，socket程序根据前两个参数自动推断类型 // 返回值：成功时返回创建的socket的文件描述符;失败时返回-1，并设置errno错误信息 // 有了地址类型和数据传输方式，还不足以决定采用哪种协议吗？为什么还需要第三个参数呢？ // 1. 一般情况下有了前两个参数就可以创建socket，操作系统会自动推演出协议类型 // 2. 除非遇到这样的情况：有两种不同的协议支持同一种地址类型和数据传输类型 // 3. 如果我们不指明使用哪种协议，操作系统是没办法自动推演的 // int tcp_socket = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); // 满足前面两个参数的只有TCP协议，因此可以写成如下 // int tcp_socket = socket(AF_INET, SOCK_STREAM, 0); // int udp_socket = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP); // 满足前面两个参数的只有UDP协议，因此可以写成如下 // int udp_socket = socket(AF_INET, SOCK_DGRAM, 0); bind() Bind函数将socket与本机上的一个端口相关联，随后你就可以在该端口监听服务请求 给socket绑定一个地址，这样client对这个地址的相应收发数据就能和socket相关联 服务端: 必须要调用bind进行绑定，bind 是绑定本地地址，它不负责对端地址，一般用于服务器端，客户端是系统指定的。 客户端: 非必须调用，如不调用，则系统自动分配一个端口和本地地址来进行和socket绑定 socket函数并没有为套接字绑定本地地址和端口号，对于服务器端则必须显性绑定地址和端口号，bind函数主要是服务器端使用，把一个本地协议地址赋予套接字 该函数不会阻塞。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); // sockfd：参数是调用socket函数返回的socket描述符 // addr：参数是一个指向包含有本机IP地址及端口号等信息的sockaddr类型的指针 // 早期的sockaddr // struct sockaddr { // sa_family_t sa_faily;\t// 地址族,AF_XXX // char sa_data[14];\t// 字符数组，存放ip和端口 // } // 后面出现了IPv4和IPv6，因此把sockaddr结构更详细细分,下面结构都能与sockaddr进行转换 // ipv4 // struct sockaddr_in { // __kernel_sa_family_t sin_family; // 地址族 // __be16 sin_port; // 端口 // struct in_addr sin_addr; // Internet地址 // // 占位,以满足sockaddr_in所占大小与sockaddr相同 // unsigned char __pad[__SOCK_SIZE__ - sizeof(short int) - sizeof(unsigned short int) - sizeof(struct in_addr)]; // } // // Internet地址 // struct in_addr { // __be32 s_addr; // 32为无符号整型数据，正好存储IP地址 // }; // ipv6 // struct sockaddr_in6 { // unsigned short int sin6_family; // AF_INET6 // __be16 sin6_port; // 传输层端口 // __be32 sin6_flowinfo; // IPv6 流信息 // struct in6_addr sin6_addr; // IPv6 地址 // __u32 sin6_scope_id; // scope id (new in RFC2553) // }; // unix addr // #define UNIX_PATH_MAX 108 // struct sockaddr_un { // __kernel_sa_family_t sun_family; // AF_UNIX // char sun_path[UNIX_PATH_MAX]; // }; // addrlen：参数是地址参数的长度sizeof(addr) // 返回值：成功返回0，失败返回-1, 并且设置errno // 比如绑定一个ipv4地址 struct sockaddr_in addr; // 定义结构体变量 addr.sin_family = AF_INET; // 指定协议族为IPv4 addr.sin_port = htons(5006);// 指定端口号 addr.sin_addr.s_addr = inet_addr(\u0026#34;192.168.1.10\u0026#34;); // 指定IP // 进行套接字文件 ip/端口的绑定 ret = bind(sockfd, (struct sockaddr*)\u0026amp;addr, sizeof(addr)); // 其他相关函数 // htonl() 把32位值从主机字节序转换成网络字节序 // htons() 把16位值从主机字节序转换成网络字节序 // ntohl() 把32位值从网络字节序转换成主机字节序 // ntohs() 把16位值从网络字节序转换成主机字节序 // inet_addr() 字符串形式的ip,用于将点分十进制IP转换为IPV4的32位无符号整型IP listen() 仅供服务器端调用，把一个未连接的套接字转换为一个被动套接字，指示内核应该接受指向该套接字的连接请求。 其内部实现归根结底就是设置sock结构的状态，设置其为TCP_LISTEN。 该函数不会阻塞。 listen函数把一个未连接的套接字转换为一个被动套接字，指示内核应接受指向该套接字的连接请求，其内部实现归根到底就是设置sock结构的状态，设置其为TCP_LISTEN。 这个函数也是服务器端调用，其套接字的地址信息状态和bind函数执行之后是一样的，只绑定了本地地址信息，不知道对端的地址信息。 1 2 3 4 5 6 int listen(int sockfd, int backlog); // sockfd：socket()所创建的fd // backlog：在tcp三次握手的时候，第一次握手发送SYN=1，server端接收到之后，在回复了Ack=1之后， // 会把这个还未完成3次握手的连接放入到一个队列中，这个队列需要指定一个长度，该参数就是用来指定这个半连接队列长度的 // 在linux中该参数默认值由cat /proc/sys/net/ipv4/tcp_max_syn_backlog决定，默认1024 accept() 该函数返回一个已建立链接的可用 数据通信 的套接字 当socket模式设置为阻塞，accept函数的功能是阻塞等待client发起三次握手，当3次握手完成的时候，accept解除阻塞，并从全连接队列中取出一个socket，就可以对这个socket连接进行读写操作 该函数会阻塞等待链接。 1 2 3 4 5 int accept(int sockfd, struct sockaddr *cliaddr, socklen_t *addrlen); // 返回值：非负数成功，返回一个新的fd，这个fd用来和对端进行通信，-1 出错 // sockfd：监听后的套接字，也就是listen函数返回的fd // cliaddr：用来接收对端的连接地址信息，如果对客户端信息不感兴趣可以把该值设置成空NULL // addrlen：cliaddr的长度 accept4() accept4()有第四个参数flags，这个参数如果为0，就跟accept()一样。 额外添加的flags参数可以为新连接描述符设置 O_NONBLOCK | O_CLOEXEC (执行exec后关闭)这两个标记。 SOCK_NONBLOCK: 为新打开的文件描述符设置O_NONBLOCK标志位，这跟用fcntl()设置的效果是一样的，区别就是用fcntl()的话需要多调用个函数。 SOCK_CLOEXEC: 为新打开的文件描述符设置FD_CLOEXEC标志位，该标志位的作用是在进程使用fork()加上execve()的时候自动关闭打开的文件描述符。 1 int accept4(int sockfd, struct sockaddr *addr,socklen_t *addrlen, int flags); connect() TCP客户用connect函数来建立与TCP服务器的连接，其实是客户利用connect函数向服务器发出连接请求用户客户端。 1 2 3 int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen); // sockfd：由socket函数返回的套接字描述符 // 第二、三个参数分别是指向套接口地址结构的指针和该结构的大小，套接口地址结构必须含有服务器的IP地址和端口号 read() 从打开文件中读取数据。 1 2 3 4 5 ssize_t read(int fd, void *buf, size_t count); // fd：socket的文件描述符 // buf：读取到的容器 // count：buf的大小 // 返回值：为实际读取到的字节数，如果返回0，表示已达到文件尾或是无可读的数据 ","permalink":"https://heliu.site/posts/golang/netpoll/linux/","summary":"Linux epoll函数简介。","title":"Linux epoll"},{"content":" 以下来自go1.19.3/src/runtime/netpoll_epoll.go文件。 本篇文章是针对netpoll_epoll.go文件的源码走读。 variables 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 var ( // epoll 描述符, epollcreate 函数创建返回的文件描述符 epfd int32 = -1 // epoll descriptor // 保存的是pipe2()或pip()函数创建的读写描述符，pip2()或pip()函数创建的read和write，只要任意一方操作另一方能获取到数据 // netpollBreakRd会被注册到epoll中，当写描述符向里写数据时会触发wait监听函数返回就绪的事件集 // 这对读写描述符的作用在于通信，当有其他协程在wait阻塞等待时，可以通过写描述符写入数据让等待的协程返回 // 主要针对 epoll_wait() 函数阻塞的线程，通过这里的事件使调用 epoll_wait() 函数的线程陷入内核返回。 // 对于 epoll_wait() 的 timeout 参数为0的情况，这里的事件会被忽略 netpollBreakRd, netpollBreakWr uintptr // for netpollBreak // 用于避免重复调用 netpollBreak() // 在向netpollBreakWr中写入数据时，该值会从0变成1，控制只写一次标志符号 // 该参数是原子性的 netpollWakeSig uint32 // used to avoid duplicate calls of netpollBreak ) netpollGenericInit() 初始化netpoll。go1.19.3/src/runtime/netpoll.go文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func netpollGenericInit() { // var netpollInited uint32 // 是否已初始化epoll标志 0.未初始化 1.已初始化 if atomic.Load(\u0026amp;netpollInited) == 0 { // var netpollInitLock mutex 初始化 lockInit(\u0026amp;netpollInitLock, lockRankNetpollInit) lock(\u0026amp;netpollInitLock) // 这里需要判断 netpollInited == 0；原因在于可能存在多个协程并发在等待初始化epoll // 当这些协程获取的锁权限时，这里的netpollInited已被设置成1了，已经被初始化了 if netpollInited == 0 { netpollinit() // 初始化netpoll atomic.Store(\u0026amp;netpollInited, 1)\t// netpollInited } unlock(\u0026amp;netpollInitLock) } } netpollinit() go1.19.3/src/runtime/netpoll_epoll.go。 调用epollcreate创建netpoller。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 func netpollinit() { // epollcreate 函数内会调用 epollcreate1 // _EPOLL_CLOEXEC：当前进程fork出来的任何子进程在执行前都会关闭epoll描述符，也因此，子进程不能够访问epoll实例 epfd = epollcreate1(_EPOLL_CLOEXEC) // 小于0表示创建出错，大于0表示返回的创建后的文件句柄ID if epfd \u0026lt; 0 {\tepfd = epollcreate(1024) if epfd \u0026lt; 0 { println(\u0026#34;runtime: epollcreate failed with\u0026#34;, -epfd) throw(\u0026#34;runtime: netpollinit failed\u0026#34;) } // 系统调用 fcntl 设置 FD_CLOEXEC，参看 epollcreate1 函数参数 // fcntl：fd, F_SETFD, FD_CLOEXEC closeonexec(epfd) } // 创建一个用于通信的管道,返回读写,主要用于那些等待在IO轮询中的线程通信 // 创建一个非阻塞式pipe，用来唤醒阻塞中的 netpoller。 // pipe2(_O_NONBLOCK | _O_CLOEXEC) r, w, errno := nonblockingPipe() // 主要用于Break相关的函数，主要用于网络轮询唤醒信号 if errno != 0 { println(\u0026#34;runtime: pipe failed with\u0026#34;, -errno) throw(\u0026#34;runtime: pipe failed\u0026#34;) } // epollevent 是事件类型 // type epollevent struct { //\tevents uint32 // 事件类型 //\tdata [8]byte // 存储用户数据，刚好是一个指针存储的大小，该数据用户是可以修改的 // } ev := epollevent{ // 注意：这里默认注册的是水平触发，因此会一直触发 events: _EPOLLIN, // EPOLLIN 表示对应的文件描述符可以读（包括对端SOCKET正常关闭） } // var netpollBreakRd uintptr *(**uintptr)(unsafe.Pointer(\u0026amp;ev.data)) = \u0026amp;netpollBreakRd // ev.data = \u0026amp;netpollBreakRd // 将读取数据的文件描述符加入监听，当使用w写数据时，该r会被触发 // func epollctl(epfd, op, fd int32, ev *epollevent) int32 // _EPOLL_CTL_ADD 将目标文件描述符fd添加到epoll描述符epfd中，并将事件event与fd链接的内部文件关联起来。 errno = epollctl(epfd, _EPOLL_CTL_ADD, r, \u0026amp;ev) // r 被添加到epoll中 if errno != 0 { println(\u0026#34;runtime: epollctl failed with\u0026#34;, -errno) throw(\u0026#34;runtime: epollctl failed\u0026#34;) } // netpollBreakRd、netpollBreakWr 是非阻塞管道两端的文件描述符，分别被用作读取端和写入端。 // 读取端 netpollBreakRd 被添加到 epoll 中监听 _EPOLLIN 事件，后续从写入端netpollBreakWr // 写入数据就能唤醒阻塞中的 poller。 netpollBreakRd = uintptr(r) // netpollBreakRd保存pip2的read netpollBreakWr = uintptr(w) // netpollBreakRd保存pip2的write } netpollopen() 把要监听的文件描述符fd和与之关联的pollDesc结构添加到poller实例中。 该方法对于一个socket只需调用一次即可，表示注册fd到epoll中。 参数： fd uintptr：文件描述符。 pd *pollDesc：用户数据。 返回值：int32：0-注册成功。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func netpollopen(fd uintptr, pd *pollDesc) int32 { // type epollevent struct { // events uint32 // 事件类型 // data [8]byte // 存储用户数据，刚好是一个指针存储的大小，该数据用户是可以修改的 // } var ev epollevent // EPOLLIN：表示对应的文件描述符可以读（包括对端SOCKET正常关闭） // EPOLLOUT：表示对应的文件描述符可以写 // EPOLLRDHUP：对端描述符产生一个挂断事件，比如来自对端的socket挂断事件等 // EPOLLET：将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的 // pollDesc：类型的数据结构pd作为与fd关联的自定数据会被一同添加到epoll中。 ev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET // epollevent 是由events和data组成，data来自用户空间传入的数据 *(**pollDesc)(unsafe.Pointer(\u0026amp;ev.data)) = pd // ev.data = pd // _EPOLL_CTL_ADD 将目标文件描述符fd添加到epoll描述符epfd中，并将事件event与fd链接的内部文件关联起来。 return -epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), \u0026amp;ev) } 触发模式LT\\ ET： 水平触发：LT 对于读操作，只要缓冲内容不为空，LT模式返回读就绪。 对于写操作，只要缓冲区还不满，LT模式会返回写就绪。 水平触发描述： 当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。 如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你。 如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。 边缘触发：ET 对于读操作： 当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候。 当有新数据到达时，即缓冲区中的待读数据变多的时候。 当缓冲区有数据可读，且应用进程对相应的描述符进行EPOLL_CTL_MOD修改EPOLLIN事件时。 对于写操作： 当缓冲区由不可写变为可写时。 当有旧数据被发送走，即缓冲区中的内容变少的时候。 当缓冲区有空间可写，且应用进程对相应的描述符进行EPOLL_CTL_MOD修改EPOLLOUT事件时。 边缘触发描述： 当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。 如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。 这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。 在ET模式下，缓冲区从不可读变成可读，会唤醒应用进程，缓冲区数据变少的情况，则不会再唤醒应用进程。 举例： 举例1： 读缓冲区刚开始是空的 读缓冲区写入2KB数据 水平触发和边缘触发模式此时都会发出可读信号 收到信号通知后，读取了1KB的数据，读缓冲区还剩余1KB数据 水平触发会再次进行通知，而边缘触发不会再进行通知 举例2： 水平触发：0为无数据，1为有数据。缓冲区有数据则一直为1，则一直触发。 边缘触发：0为无数据，1为有数据，只要在0变到1的上升沿才触发。 netpollclose() 把文件描述符fd从poller实例中移除，也就是从epoll中删除。 1 2 3 4 5 6 func netpollclose(fd uintptr) int32 { var ev epollevent // _EPOLL_CTL_DEL 从epoll文件描述符epfd中删除目标文件描述符fd。 // 该事件被忽略，可以为NULL。 return -epollctl(epfd, _EPOLL_CTL_DEL, int32(fd), \u0026amp;ev)\t} netpollIsPollDescriptor() 判断是否是顶层poll，以及是pip2创建的读和写文件描述符。 判断文件描述符是否被poller使用。epfd、netpollBreakRd、netpollBreakWr属于被poller使用的描述符。 1 2 3 func netpollIsPollDescriptor(fd uintptr) bool { return fd == uintptr(epfd) || fd == netpollBreakRd || fd == netpollBreakWr } netpollBreak() 用来唤醒阻塞中的netpoll，它实际上就是向netpollBreakWr描述符中写入数据，这样一来epoll就会监听到。 netpollBreakRd的EPOLLIN事件(EPOLLIN表示对应的文件描述符可以读（包括对端SOCKET正常关闭）)。netpollBreak中断epollwait。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // netpollBreak interrupts an epollwait. func netpollBreak() { // netpollWakeSig信号主要用于本轮已经通知过IO轮询，但是还没处理有其他的调用此方法时 // 使用原子操作将netpollWakeSig由0变成1，表示正在唤醒epoll。 if atomic.Cas(\u0026amp;netpollWakeSig, 0, 1) {\tfor { var b byte // 向netpollBreakWr中写入数据，会导致那些阻塞在netpoll函数中的线程直接返回去执行后面代码 // netpollBreakWr在pipe2函数中注册时已经设置了非阻塞。因此这里不会阻塞。 n := write(netpollBreakWr, unsafe.Pointer(\u0026amp;b), 1) // 写入成功 if n == 1 { break } // 在写入任何数据之前，调用被信号中断。 if n == -_EINTR { continue // 重试。 } // 已使用 O_NONBLOCK 选择了非阻塞 I/O，并且写入将阻塞。 // _EAGAIN：表示目前没有可用的数据 if n == -_EAGAIN { return } println(\u0026#34;runtime: netpollBreak write failed with\u0026#34;, -n) throw(\u0026#34;runtime: netpollBreak write failed\u0026#34;) } } } netpoll() netpoll检查准备就绪的网络连接。返回可运行的goroutine列表。 参数： delay \u0026lt; 0：无限期阻塞。 delay == 0：不阻塞，立即返回。 delay \u0026gt; 0：阻塞长达delay纳秒。 返回值：gList：一组就绪的goroutine。 根据入参delay设置调用epoll_wait的timeout值，调用epoll_wait从epoll的eventpoll.rdllist双向列表中获取IO就绪的fd列表，遍历epoll_wait返回的fd列表， 根据调用epoll_ctl注册fd时封装的上下文信息组装可运行的goroutine并返回。 执行完netpoll之后，会返回一个就绪fd列表对应的goroutine列表，接下来将就绪的goroutine加入到调度队列中，等待调度运行。 netpoll的调用时机： 在调度器中执行runtime.schedule()，该方法中会执行runtime.findrunnable()函数中调用了runtime.netpoll获取待执行的goroutine。 Go runtime在程序启动的时候会创建一个独立的sysmon监控线程，sysmon每20us~10ms运行一次，每次运行会检查距离上一次执行netpoll是否超过10ms，如果是则会调用一次runtime.netpoll。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 // netpoll checks for ready network connections. // Returns list of goroutines that become runnable. // // delay \u0026lt; 0: blocks indefinitely;\t// delay == 0: does not block, just polls; // delay \u0026gt; 0: block for up to that many nanoseconds; func netpoll(delay int64) gList { // 1) epoll没有初始化 if epfd == -1 {\treturn gList{} } // 2) 下面把纳秒级的 delay 转换成毫秒级的 waitms。 var waitms int32 if delay \u0026lt; 0 { waitms = -1 // 永久阻塞，直到事件就绪返回 } else if delay == 0 { waitms = 0 // 不阻塞，立即返回 } else if delay \u0026lt; 1e6 { // 小于1毫秒，修改为阻塞1毫秒 waitms = 1 // 阻塞1毫秒 } else if delay \u0026lt; 1e15 { // 小于 11.5 day // 1e6 表示 1毫秒 waitms = int32(delay / 1e6) // 阻塞指定毫秒 } else { // An arbitrary cap on how long to wait for a timer. // 1e9 ms == ~11.5 days. waitms = 1e9 // 最长 11.5天 } // 3) 通过epollwait函数等待IO事件，缓冲区大小为128个epollevent。 // 超时时间是 waitms 毫秒。如果 epollwait函数被中断打断，就通过goto来重试。 // waitms 大于0时不会重试，因为需要返回调用者中去重新计算超时时间。 // 下面传入epollwait的数量是128，表示一次最大就绪128个事件 // 这样可能存在此次大于128数量时，需要等到下一个IO轮询时间窗口 // type epollevent struct { // events uint32 // 事件类型 // data [8]byte // 存储用户数据，刚好是一个指针存储的大小，该数据用户是可以修改的 // } var events [128]epollevent // 用于存储已经准备好的描述符的事件数据 retry: // 调用epollwait等待文件描述符转换成可写或可读，如果没有epollwait会阻塞 n := epollwait(epfd, \u0026amp;events[0], int32(len(events)), waitms) // 返回活跃的数量n if n \u0026lt; 0 { // EBADF：epfd 不是有效的文件描述符。 // EFAULT：事件指向的内存区域无法用写权限访问。 // EINVAL：epfd 不是epoll文件描述符，或者maxevents(第三个参数)小于等于0。 if n != -_EINTR { // EINTR 被CPU中断 println(\u0026#34;runtime: epollwait on fd\u0026#34;, epfd, \u0026#34;failed with\u0026#34;, -n) throw(\u0026#34;runtime: netpoll failed\u0026#34;) } // If a timed sleep was interrupted, just return to // recalculate how long we should sleep now. // // 如果定时睡眠被中断，只需返回重新计算我们现在应该睡多久。 // _EINTR: 在任何请求的事件发生或超时到期之前，该调用被信号处理程序中断。 if waitms \u0026gt; 0 { return gList{} } // 被中断 AND waitms \u0026lt;= 0 情况重试 goto retry } // type gList struct { head guintptr } var toRun gList // 意味着被监控的文件描述符出现了待处理的事件 for i := int32(0); i \u0026lt; n; i++ { // 就绪的IO事件集 ev := \u0026amp;events[i] // 当前就绪描述符没有事件类型，直接跳过 if ev.events == 0 { continue } // 事件来源是否是netpollBreakRd，该描述符来之pipe2函数创建 // 来自pipe2函数创建的通信，netpollBreakRd是LT水平触发如果不读取会一直触发 // 该事件来自 netpollBreak() 方法，该方法只会在创建timer时和findRunnable()函数中被调用。 if *(**uintptr)(unsafe.Pointer(\u0026amp;ev.data)) == \u0026amp;netpollBreakRd { // 对于文件描述符 netpollBreakRd 而言，只有 _EPOLLIN 事件是正常的，其他都会被视为异常。 if ev.events != _EPOLLIN { println(\u0026#34;runtime: netpoll: break fd ready for\u0026#34;, ev.events) throw(\u0026#34;runtime: netpoll: break fd ready for something unexpected\u0026#34;) } // 这种情况下只处理不是立即返回情况下，如果是立即返回情况时，数据并未被读取，下次还会触发该信号 // 这种情况下只在runtime.findrunnable()函数中存在，线程在寻找g无果时，最后只能在IO轮询处等待 // 只有在 delay 不为0，也就是阻塞式netpoll时，才读取netpollBreakRd中的数据。 if delay != 0 { // netpollBreakRd 的本意也是只唤醒delay != 0的netpoll，因为这些在阻塞需要返回 // netpollBreak could be picked up by a // nonblocking poll. Only read the byte // if blocking. // netpollBreak 可以通过非阻塞轮询来获取。 仅在阻塞时读取字节。 var tmp [16]byte // 把写入的数据读取让缓存区为空 read(int32(netpollBreakRd), noescape(unsafe.Pointer(\u0026amp;tmp[0])), int32(len(tmp)))\t// 将netpollWakeSig由1变成0，表示当前事件已被读取 atomic.Store(\u0026amp;netpollWakeSig, 0)\t} continue } // 根据epoll返回的IO事件标志位为mode赋值 // r 表示可读，w 表示可写，r+w 表示既可读又可写。 // 检测IO事件中的错误标志位，并相应的为pd.everr赋值。 // 判断发生的事件类型,读类型或者写类型 var mode int32\t// 存储当前类型 // EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭） // EPOLLRDHUP：对端描述符产生一个挂断事件 // EPOLLHUP：本端描述符产生一个挂断事件，默认监测事件 // EPOLLERR：表示对应的文件描述符发生错误 if ev.events\u0026amp;(_EPOLLIN|_EPOLLRDHUP|_EPOLLHUP|_EPOLLERR) != 0 { mode += \u0026#39;r\u0026#39; } // EPOLLOUT：表示对应的文件描述符可以写 // EPOLLHUP：本端描述符产生一个挂断事件，默认监测事件 // EPOLLERR：表示对应的文件描述符发生错误 if ev.events\u0026amp;(_EPOLLOUT|_EPOLLHUP|_EPOLLERR) != 0 { mode += \u0026#39;w\u0026#39; } // mode不为0，表示有IO事件，需要从ev.data字段得到与IO事件关联的pollDesc。 if mode != 0 { // 取出保存在 epollevent 里的pollDesc，因为要根据这个内容去恢复g如果g已被挂起时 pd := *(**pollDesc)(unsafe.Pointer(\u0026amp;ev.data)) // *pollDesc // 对应的_EPOLLERR文件描述符出现错误时，标记错误 pd.setEventErr(ev.events == _EPOLLERR)\t// 设置pollDesc的EpollErr错误位，如果是这种状态 netpollready(\u0026amp;toRun, pd, mode)\t// 处理就绪的描述符 } } return toRun } netpollready() go1.19.3/src/runtime/runtime/netpoll.go。 netpollready由特定于平台的netpoll函数调用。它声明与pd相关的fd已经为I/O做好了准备。 toRun参数用于构建一个从netpoll返回的goroutines列表。mode参数是'r'、'w'或'r'+'w'，表示fd是否准备好读、写或同时读和写。 这可能会在整个系统停止时运行，因此不允许设置写屏障。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // netpollready is called by the platform-specific netpoll function. // It declares that the fd associated with pd is ready for I/O. // The toRun argument is used to build a list of goroutines to return // from netpoll. The mode argument is \u0026#39;r\u0026#39;, \u0026#39;w\u0026#39;, or \u0026#39;r\u0026#39;+\u0026#39;w\u0026#39; to indicate // whether the fd is ready for reading or writing or both. // // This may run while the world is stopped, so write barriers are not allowed. //go:nowritebarrier func netpollready(toRun *gList, pd *pollDesc, mode int32) { var rg, wg *g if mode == \u0026#39;r\u0026#39; || mode == \u0026#39;r\u0026#39;+\u0026#39;w\u0026#39; { // netpollunblock 可能返回 goroutine 或 nil rg = netpollunblock(pd, \u0026#39;r\u0026#39;, true) } if mode == \u0026#39;w\u0026#39; || mode == \u0026#39;r\u0026#39;+\u0026#39;w\u0026#39; { wg = netpollunblock(pd, \u0026#39;w\u0026#39;, true) } if rg != nil { // 并入 toRun 中，这部分 goroutine 等待放入调度池中 toRun.push(rg) } if wg != nil { toRun.push(wg) } } netpollunblock() go1.19.3/src/runtime/runtime/netpoll.go。 netpollunblock解除阻塞。 参数： pd *pollDesc：pollDesc。 mode int32：读r或写w。 ioready bool：true-I/O读（用于从pollDesc中获取 goroutine），false-读写超时从pollDesc中获取goroutine。 返回值：*g返回就绪的goroutine，可能是nil。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 func netpollunblock(pd *pollDesc, mode int32, ioready bool) *g { // 根据 mode 从rg或wg取出 goroutine。 gpp := \u0026amp;pd.rg if mode == \u0026#39;w\u0026#39; { gpp = \u0026amp;pd.wg } for { // 原子读取 old := gpp.Load() // pdReady：表示fd的数据已经就绪，可供读取或写。该值从g修改pdReady。 // 这种情况可能 goroutine 已经被返回给调用者了。什么都不做直接返回。 if old == pdReady { return nil } // nil：没有什么可做的 if old == 0 \u0026amp;\u0026amp; !ioready { // Only set pdReady for ioready. runtime_pollWait // will check for timeout/cancel before waiting. // // 只在ioready中设置pdReady。runtime_pollWait将在等待之前检查 timeout/cancel。 return nil } // old是0、goroutine、pdWait这三种情况。 var new uintptr if ioready { // 修改为pdReady，表示数据已就绪或写 new = pdReady } // CAS 交换 if gpp.CompareAndSwap(old, new) { // pdWait：表示某个goroutine即将挂起并等待fd的可读可写事件。 if old == pdWait { old = 0 // nil } return (*g)(unsafe.Pointer(old)) // nil 或 *g } } } wakeNetPoller() 该函数在time源码中被调用，用于判断是否需要发起I/O网络轮询。 该方法是为了防止定时器触发时间到了没有线程能触发的情况，当只剩阻塞在netpoll的线程或所有的线程都处于等待中时，timer可能不能按时触发的情况。 wakeenetpoller唤醒在网络轮询器(network poller)中睡眠的线程，如果它不打算在when参数之前被唤醒; 或者唤醒一个空闲的P来服务计时器(timers)和网络轮询器(network poller)(如果还没有的话)。 when int64：表示最近的timer触发的时间点，因此为了避免当前最近的timer到时间能准时触发，需要调整netpoll的阻塞事件点。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // wakeNetPoller wakes up the thread sleeping in the network poller if it isn\u0026#39;t // going to wake up before the when argument; or it wakes an idle P to service // timers and the network poller if there isn\u0026#39;t one already. func wakeNetPoller(when int64) { // sched.lastpoll：记录的是上次执行netpoll的时间，如果等于0，则表示某个线程正在阻塞式地执行netpoll。 // sched.lastpoll 被设置为0只会在 findrunnable 函数中。 if atomic.Load64(\u0026amp;sched.lastpoll) == 0 { // In findrunnable we ensure that when polling the pollUntil // field is either zero or the time to which the current // poll is expected to run. This can have a spurious wakeup // but should never miss a wakeup. // // 在 findrunnable 中，我们要确保轮询时 pollUntil 字段要么是0，要么为当前poll预期运行的时间。 // 这里可能会是一个虚假的唤醒，但不应该错过唤醒。 // sched.pollUntil：表示阻塞式地netpoll将在何时被唤醒。该值在 findrunnable 函数中被设置。 // sched.pollUntil 值大于0时，表示最近的timer触发时间段。 pollerPollUntil := int64(atomic.Load64(\u0026amp;sched.pollUntil)) // pollerPollUntil \u0026gt; when：存在最新的计时器被加入when时间段后触发 if pollerPollUntil == 0 || pollerPollUntil \u0026gt; when { netpollBreak() } } else { // There are no threads in the network poller, try to get // one there so it can handle new timers. if GOOS != \u0026#34;plan9\u0026#34; { // Temporary workaround - see issue #42303. wakep() // 尝试唤醒一个空闲的P起来服务timer和network poller。 } } } netpollarm() 该函数在linux上不会调用，充当一个占位作用。 1 2 3 func netpollarm(pd *pollDesc, mode int) { throw(\u0026#34;runtime: unused\u0026#34;) // runtime: 未使用的 } 参考 详解Go语言I/O多路复用netpoller模型 epoll详解 epoll源码解析(1) epoll_create ","permalink":"https://heliu.site/posts/golang/netpoll/epoll/","summary":"Golang 封装的底层epoll代码。","title":"Golang epoll"},{"content":" Let's Encrypt 参考自 古道轻风。 Let\u0026rsquo;s Encrypt 是一个由非营利性组织 互联网安全研究小组（ISRG）提供的免费、自动化和开放的证书颁发机构（CA）。 acme.sh 参考官方 github 教程。 acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书。 本篇文章主要是根据acme.sh配置安装的，记录acme.sh配置的一些歧义地方。 安装 acme.sh 安装 acme.sh。 # 创建 .acme.sh 目录 mkdir ~/.acme.sh # 切换到 .acme.sh cd ~/.acme.sh # 执行安装命令，注意邮箱改成自己的 curl https://get.acme.sh | sh -s email=my@example.com 添加别名。 vi ~/.bashrc # 把下面这行加入到最后 # alias acme.sh=~/.acme.sh/acme.sh # 最后执行，使配置生效 source ~/.bashrc 生成证书 因为我的nginx在docker里，不确定nginx的方式能否可行。 所以采用的手动 dns 验证。我用的华为云参考https://github.com/acmesh-official/acme.sh/wiki/dnsapi2#dns_huaweicloud。 # 配置环境变量 export HUAWEICLOUD_Username=\u0026#34;\u0026lt;Your IAM Username\u0026gt;\u0026#34; export HUAWEICLOUD_Password=\u0026#34;\u0026lt;Your Password\u0026gt;\u0026#34; export HUAWEICLOUD_DomainName=\u0026#34;\u0026lt;Your DomainName\u0026gt;\u0026#34; # 再执行 acme.sh --issue --dns dns_huaweicloud -d example.com -d *.example.com 安装证书 acme.sh --install-cert -d example.com \\ --key-file /path/to/keyfile/in/nginx/key.pem \\ --fullchain-file /path/to/fullchain/nginx/cert.pem \\ --reloadcmd \u0026#34;docker exec -it nginx nginx -s reload\u0026#34; 更新证书 $ crontab -l 44 6 * * * \u0026#34;/root/.acme.sh\u0026#34;/acme.sh --cron --home \u0026#34;/root/.acme.sh\u0026#34; \u0026gt; /dev/null ","permalink":"https://heliu.site/posts/ssl/acme/","summary":"acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书。","title":"acme.sh"},{"content":"安装前准备 查看服务器信息。 1 2 3 4 5 # 查看服务器系统内核 $ cat /etc/redhat-release # 查看服务器内核版本 $ uname -r 卸载旧版本： 1 2 3 4 5 6 7 8 9 $ yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine \\ docker-selinux 安装 yum 工具。 1 $ yum install -y yum-utils device-mapper-persistent-data lvm2 配置 docker 的 yum 源（更新为阿里源）。 1 2 3 $ yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo $ sed -i \u0026#39;s+download.docker.com+mirrors.aliyun.com/docker-ce+\u0026#39; /etc/yum.repos.d/docker-ce.repo 更新 yum，建立缓存。 1 yum makecache fast 安装 docker Docker 从 17.03 版本之后分为两个版本：社区版（Community Edition，缩写 CE）和企业版（Enterprise Edition，缩写 EE）。企业版包含了一些收费服务，个人开发者一般用不到，所以我们只需要安装社区版docker-ce版本。\n安装 Docker。 1 $ install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 启动 docker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 启动Docker systemctl start docker # 停止Docker systemctl stop docker # 重启 systemctl restart docker # 设置开机自启 systemctl enable docker # 查看Docker版本 docker version # 执行docker ps命令，如果不报错，说明安装启动成功 docker ps 配置镜像加速 以阿里云镜像加速为例。https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建目录 mkdir -p /etc/docker # 复制内容，注意把其中的镜像加速地址改成你自己的 tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://xxxx.mirror.aliyuncs.com\u0026#34;] } EOF # 重新加载配置 systemctl daemon-reload # 重启Docker systemctl restart docker ","permalink":"https://heliu.site/posts/docker/install/","summary":"centos7 安装 docker。","title":"linux 安装 docker"},{"content":" 仓库（repository）：docker仓库是用来保存镜像的地方。镜像构建完成后，可以直接在当前宿主机上运行，但是但是如果需要在其他服务器上使用这个镜像，就需要一个集中存储、分发镜像的服务，docker仓库就是这样的一个服务。 镜像（image）：保存了应用和需要的依赖环境，比如运行的runtime和webapp等。 容器（Container）：镜像的实例。一个容器代表一个正在运行的应用程序、进程或服务。 Docker官方提供了一个专门管理、存储镜像的网站，并对外开放了镜像上传、下载的权利。https://hub.docker.com/ 快速入门 Docker 快速的安装了 mysql。 docker run -d ：创建并运行一个容器，-d 则是让容器以后台进程运行。 \u0026ndash;name mysql : 给容器起个名字叫mysql，可以是其他名称。 -p 3306:3306 : 设置端口映射。 容器是隔离环境，外界不可访问。但是可以将宿主机端口映射容器内到端口，当访问宿主机指定端口时，就是在访问容器内的端口了。 容器内端口往往是由容器内的进程决定，例如MySQL进程默认端口是3306，因此容器内端口一定是3306；而宿主机端口则可以任意指定，一般与容器内保持一致。 格式： -p 宿主机端口:容器内端口，示例中就是将宿主机的3306映射到容器内的3306端口。 -e TZ=Asia/Shanghai : 配置容器内进程运行时的一些参数。 格式：-e KEY=VALUE，KEY和VALUE都由容器内进程决定。 案例中，TZ=Asia/Shanghai是设置时区；MYSQL_ROOT_PASSWORD=123是设置MySQL默认密码。 mysql : 设置镜像名称，Docker 会根据这个名字搜索并下载镜像。 格式：REPOSITORY:TAG，例如 mysql:8.0，其中 REPOSITORY 可以理解为镜像名，TAG 是版本号。 在未指定TAG的情况下，默认是最新版本，也就是 mysql:latest。 1 2 3 4 5 6 $ docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123 \\ mysql docker 基础 常见命令 \u0026mdash;\u0026mdash;\u0026ndash; 命令 \u0026mdash;\u0026mdash;\u0026ndash; 说明 docker pull 拉取镜像 docker push 推送镜像到DockerRegistry docker images 查看本地镜像 docker rmi 删除本地镜像 docker run 创建并运行容器（不能重复创建） docker stop 停止指定容器 docker start 重新启动容器 docker rm 删除指定容器 docker ps 查看容器 docker logs 查看容器运行日志 docker exec 进入容器 docker save 保存镜像到本地压缩文件 docker load 加载本地压缩文件到镜像 docker inspect 查看容器详细信息 默认情况下，每次重启虚拟机我们都需要手动启动Docker和Docker中的容器。通过命令可以实现开机自启： 1 2 3 4 5 # Docker开机自启 systemctl enable docker # Docker容器开机自启 docker update --restart=always [容器名/容器id] 使用示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # 第1步，去DockerHub查看nginx镜像仓库及相关信息 # 第2步，拉取Nginx镜像 docker pull nginx # 第3步，查看镜像 docker images # 结果如下： REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest 605c77e624dd 16 months ago 141MB mysql latest 3218b38490ce 17 months ago 516MB # 第4步，创建并允许Nginx容器 docker run -d --name nginx -p 80:80 nginx # 第5步，查看运行中容器 docker ps # 也可以加格式化方式访问，格式会更加清爽 docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第6步，访问网页，地址：http://虚拟机地址 # 第7步，停止容器 docker stop nginx # 第8步，查看所有容器 docker ps -a --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第9步，再次启动nginx容器 docker start nginx # 第10步，再次查看容器 docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第11步，查看容器详细信息 docker inspect nginx # 第12步，进入容器,查看容器内目录 docker exec -it nginx bash # 或者，可以进入MySQL docker exec -it mysql mysql -uroot -p # 第13步，删除容器 docker rm nginx # 发现无法删除，因为容器运行中，强制删除容器 docker rm -f nginx 命名别名 给常用Docker命令起别名，方便我们访问。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 修改/root/.bashrc文件 vi /root/.bashrc 内容如下： # .bashrc # User specific aliases and functions alias rm=\u0026#39;rm -i\u0026#39; alias cp=\u0026#39;cp -i\u0026#39; alias mv=\u0026#39;mv -i\u0026#39; alias dps=\u0026#39;docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34;\u0026#39; alias dis=\u0026#39;docker images\u0026#39; # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # 执行命令使别名生效 source /root/.bashrc 数据卷 容器是隔离环境，容器内程序的文件、配置、运行时产生的容器都在容器内部，我们要读写容器内的文件非常不方便。\n简介 数据卷（volume）是一个虚拟目录，是容器内目录与宿主机目录之间映射的桥梁。 数据卷（volume）是一个虚拟目录，是容器内目录与宿主机目录之间映射的桥梁。 html：放置一些静态资源 conf：放置配置文件 如果我们要让Nginx代理我们的静态资源，最好是放到html目录；如果我们要修改Nginx的配置，最好是找到conf下的nginx.conf文件。 但遗憾的是，容器运行的Nginx所有的文件都在容器内部。所以我们必须利用数据卷将两个目录与宿主机目录关联，方便我们操作。 常见命令 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 命令 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 说明 docker volume create 创建数据卷 docker volume ls 查看所有数据卷 docker volume rm 删除指定数据卷 docker volume inspect 查看某个数据卷的详情 docker volume prune 清除数据卷 注意：容器与数据卷的挂载要在创建容器时配置，对于创建好的容器，是不能设置数据卷的。而且创建容器的过程中，数据卷会自动创建。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 1.首先创建容器并指定数据卷，注意通过 -v 参数来指定数据卷 docker run -d --name nginx -p 80:80 -v html:/usr/share/nginx/html nginx # 2.然后查看数据卷 docker volume ls # 结果 DRIVER VOLUME NAME local 29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f local html # 3.查看数据卷详情 docker volume inspect html # 结果 [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2024-05-17T19:57:08+08:00\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: null, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/html/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;html\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] # 4.查看/var/lib/docker/volumes/html/_data目录 ll /var/lib/docker/volumes/html/_data # 可以看到与nginx的html目录内容一样，结果如下： 总用量 8 -rw-r--r--. 1 root root 497 12月 28 2021 50x.html -rw-r--r--. 1 root root 615 12月 28 2021 index.html # 5.进入该目录，并随意修改index.html内容 cd /var/lib/docker/volumes/html/_data vi index.html # 6.打开页面，查看效果 # 7.进入容器内部，查看/usr/share/nginx/html目录内的文件是否变化 docker exec -it nginx bash 挂载目录或文件 可以发现，数据卷的目录结构较深，如果我们去操作数据卷目录会不太方便。在很多情况下，我们会直接将容器目录与宿主机指定目录挂载。挂载语法与数据卷类似： 1 2 3 4 # 挂载本地目录 -v 本地目录:容器内目录 # 挂载本地文件 -v 本地文件:容器内文件 注意：本地目录或文件必须以 / 或 ./开头，如果直接以名字开头，会被识别为数据卷名而非本地目录名。\n例如： 1 2 -v mysql:/var/lib/mysql # 会被识别为一个数据卷叫mysql，运行时会自动创建这个数据卷 -v ./mysql:/var/lib/mysql # 会被识别为当前目录下的mysql目录，运行时如果不存在会创建目录 镜像 Dockerfile 这种记录镜像结构的文件就称为Dockerfile，其对应的语法可以参考官方文档：https://docs.docker.com/engine/reference/builder/ 命令 说明 示例 FROM 指定基础镜像 FROM centos:6 ENV 设置环境变量，可在后面指令使用 ENV key value COPY 拷贝本地文件到镜像的指定目录 COPY ./xx.jar /tmp/app.jar RUN 执行Linux的shell命令，一般是安装过程的命令 RUN yum install gcc EXPOSE 指定容器运行时监听的端口，是给镜像使用者看的 EXPOSE 8080 ENTRYPOINT 镜像中应用的启动命令，容器运行时调用 ENTRYPOINT java -jar xx.jar 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 FROM golang:1.22-alpine AS builder LABEL stage=gobuilder ENV CGO_ENABLED 0 ENV GOPROXY https://goproxy.cn,direct RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\u0026#39; /etc/apk/repositories RUN apk update --no-cache \u0026amp;\u0026amp; apk add --no-cache tzdata WORKDIR /build ADD go.mod . ADD go.sum . RUN go mod download COPY . . COPY greet/api/etc /app/etc RUN go build -ldflags=\u0026#34;-s -w\u0026#34; -o /app/greet-api greet/api/greet.go FROM scratch COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/ca-certificates.crt COPY --from=builder /usr/share/zoneinfo/Asia/Shanghai /usr/share/zoneinfo/Asia/Shanghai ENV TZ Asia/Shanghai WORKDIR /app COPY --from=builder /app/greet-api /app/greet-api COPY --from=builder /app/etc /app/etc EXPOSE 8888 CMD [\u0026#34;./greet-api\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;etc/greet.yaml\u0026#34;] 构建镜像 当Dockerfile文件写好以后，就可以利用命令来构建镜像了。 docker build : 就是构建一个docker镜像。 -t docker-demo:1.0 ：-t参数是指定镜像的名称（repository和tag）。 . : 最后的点是指构建时Dockerfile所在路径，由于我们进入了demo目录，所以指定的是.代表当前目录，也可以直接指定Dockerfile目录： 1 2 # 直接指定Dockerfile目录 docker build -t docker-demo:1.0 /root/demo 网络 \u0026mdash;\u0026mdash;\u0026ndash; 命令 \u0026mdash;\u0026mdash;\u0026ndash; 说明 docker network create 创建一个网络 docker network ls 查看所有网络 docker network rm 删除指定网络 docker network prune 清除未使用的网络 docker network connect 使指定容器连接加入某网络 docker network disconnect 使指定容器连接离开某网络 docker network inspect 查看网络详细信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 1.首先通过命令创建一个网络 docker network create hmall # 2.然后查看网络 docker network ls # 结果： NETWORK ID NAME DRIVER SCOPE 639bc44d0a87 bridge bridge local 403f16ec62a2 hmall bridge local 0dc0f72a0fbb host host local cd8d3e8df47b none null local # 其中，除了hmall以外，其它都是默认的网络 # 3.让dd和mysql都加入该网络，注意，在加入网络时可以通过--alias给容器起别名 # 这样该网络内的其它容器可以用别名互相访问！ # 3.1.mysql容器，指定别名为db，另外每一个容器都有一个别名是容器名 docker network connect hmall mysql --alias db # 3.2.db容器，也就是我们的java项目 docker network connect hmall dd # 4.进入dd容器，尝试利用别名访问db # 4.1.进入容器 docker exec -it dd bash # 4.2.用db别名访问 ping db # 结果 PING db (172.18.0.2) 56(84) bytes of data. 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.070 ms 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.056 ms # 4.3.用容器名访问 ping mysql # 结果： PING mysql (172.18.0.2) 56(84) bytes of data. 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.044 ms 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.054 ms 参考 https://b11et3un53m.feishu.cn/wiki/MWQIw4Zvhil0I5ktPHwcoqZdnec ","permalink":"https://heliu.site/posts/docker/use/","summary":"docker 常用命令。","title":"docker 用法"},{"content":"FROM FROM 指令用于指定其后构建新镜像所使用的基础镜像。 FROM 指令必是 Dockerfile 文件中的首条命令，启动构建流程后，Docker 将会基于该镜像构建新镜像，FROM 后的命令也会基于这个基础镜像。意味着接下来所写的指令将作为镜像的第一层开始。 语法： 三种写法，其中\u0026lt;tag\u0026gt;和\u0026lt;digest\u0026gt;是可选项，如果没有选择，那么默认值为 latest。 FROM 必须 是 Dockerfile 中第一条非注释命令。 在一个 Dockerfile 文件中创建多个镜像时，FROM 可以多次出现。只需在每个新命令 FROM 之前，记录提交上次的镜像 ID。 FROM \u0026lt;image\u0026gt; FROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; FROM \u0026lt;image\u0026gt;:\u0026lt;digest\u0026gt; 示例： FROM nginx FROM mysql:5.6.0 RUN 在镜像的构建过程中执行特定的命令，并生成一个中间镜像。 格式： # shell格式。在linux操作系统上默认\u0026#39;/bin/sh -c\u0026#39;；在windows操作系统上默认\u0026#39;cmd /S /C\u0026#39;。 RUN \u0026lt;command\u0026gt; # exec格式。类似于函数调用。可将executable理解成为可执行文件，后面就是两个参数。 RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] RUN 指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定 \u0026ndash;no-cache 参数，如：docker build \u0026ndash;no-cache。\n示例：\nRUN /bin/bash -c \u0026#39;source $HOME/.bashrc; echo $HOME\u0026#39; RUN [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo hello\u0026#34;] 注意：多行命令不要写多个 RUN，原因是 Dockerfile 中每一个指令都会建立一层。多少个RUN就构建了多少层镜像，会造成镜像的臃肿、多层，不仅仅增加了构件部署的时间，还容易出错。RUN书写时的换行符是 \\。 CMD CMD 用于指定在容器启动时所要执行的命令。 CMD 有三种格式： # 可执行文件加上参数的形式 CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] # 省略可执行文件的 exec 格式，这种写法使 CMD 中的参数当做 ENTRYPOINT 的默认参数 # 配合 ENTRYPOINT CMD [\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] # shell 格式 CMD command param1 param2 示例： 这里边包括参数的一定要用双引号，就是\u0026quot;,不能是单引号。千万不能写成单引号。 原因是参数传递后，docker解析的是一个JSON array。 CMD [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo $HOME\u0026#34; ] CMD [ \u0026#34;echo\u0026#34;, \u0026#34;$HOME\u0026#34; ] 与 RUN 指令的区别：RUN 在构建的时候执行，并生成一个新的镜像，CMD 在容器运行的时候执行，在构建时不进行任何操作。 ENTRYPOINT ENTRYPOINT 用于给容器配置一个可执行程序。(启动时的默认命令) 每次使用镜像创建容器时，通过 ENTRYPOINT 指定的程序都会被设置为默认程序。 Dockerfile 中只允许有一个 ENTRYPOINT 命令，多指定时会覆盖前面的设置，而只执行最后的 ENTRYPOINT 指令。 ENTRYPOINT 有以下两种格式： # 可执行文件加参数 ENTRYPOINT [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] # shell 格式 ENTRYPOINT command param1 param2 与CMD比较。\n相同点：只能写一条，如果写了多条，那么只有最后一条生效；容器启动时才运行，运行时机相同。 不同点：ENTRYPOINT 不会被运行的 command 覆盖，而 CMD 则会被覆盖。如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD指令不是一个完整的可执行命令，那么CMD指定的内容将会作为ENTRYPOINT的参数。 示例：\nFROM ubuntu # 最终执行 top -b -c ENTRYPOINT [\u0026#34;top\u0026#34;, \u0026#34;-b\u0026#34;] CMD [\u0026#34;-c\u0026#34;] 如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效。 FROM ubuntu # 那么将执行ls -al ,top -b不会执行。 ENTRYPOINT [\u0026#34;top\u0026#34;, \u0026#34;-b\u0026#34;] CMD ls -al Docker 官方关于 ENTRYPOINT 和CMD不同组合的执行情况。 No ENTRYPOINT ENTRYPOINT exec_entry p1_entry ENTRYPOINT [\u0026ldquo;exec_entry\u0026rdquo;, \u0026ldquo;p1_entry\u0026rdquo;] No CMD error,not allowed /bin/sh -c exec_entry p1_entry exec_entry p1_entry CMD [\u0026ldquo;exec_cmd\u0026rdquo;, \u0026ldquo;p1_cmd\u0026rdquo;] exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry; exec_cmd p1_cmd CMD [\u0026ldquo;p1_cmd\u0026rdquo;, \u0026ldquo;p2_cmd\u0026rdquo;] p1_cmd p2_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry p1_cmd p2_cmd CMD exec_cmd p1_cmd /bin/sh -c exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd COPY COPY 指令将从构建上下文目录中\u0026lt;src\u0026gt;的文件/目录复制到新的一层的镜像内的\u0026lt;dest\u0026gt;位置。。 语法： # 类似于命令行。从 src 到 dest。 COPY \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; # 类似于函数调用。从 src 到 dest。 COPY [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 示例： # 拷贝构建上下文的 package.json 文件到容器 /usr/src/app/ COPY package.json /usr/src/app/ \u0026lt;src\u0026gt;可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则。 COPY hom* /mydir/ COPY hom?.txt /mydir/ \u0026lt;dest\u0026gt;可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。\u0026lt;dest\u0026gt;不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。 ADD ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。 比如\u0026lt;src\u0026gt;可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到\u0026lt;dest\u0026gt;去。（类似于wget命令） \u0026lt;src\u0026gt;可以是一个本地文件或者是一个本地压缩文件，还可以是一个url。 语法： # 类似于命令行。从 src 到 dest。 ADD \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; # 类似于函数调用。从 src 到 dest。 ADD [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 示例： ADD test relativeDir/ ADD test /relativeDir ADD http://example.com/foobar / 尽量不要把\u0026lt;scr\u0026gt;写成一个文件夹，如果\u0026lt;src\u0026gt;是一个文件夹了，复制整个目录的内容,包括文件系统元数据。 如果 docker 发现文件内容被改变，则接下来的指令都不会再使用缓存。 LABEL LABEL 用于为镜像添加元数据，元数以键值对的形式指定： 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔（或**\\**）。 推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 LABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... LABEL会继承基础镜像种的LABEL，如遇到key相同，则值覆盖。 示例： LABEL version=\u0026#34;1.0\u0026#34; description=\u0026#34;web\u0026#34; bx=\u0026#34;it\u0026#34; 指定后可以通过docker inspect查看： $ docker inspect itbilu/test \u0026#34;Labels\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;bx\u0026#34;: \u0026#34;it\u0026#34; }, MAINTAINER 指定作者。语法： MAINTAINER \u0026lt;name\u0026gt; EXPOSE 为构建的镜像设置监听端口，使容器在运行时监听。格式： EXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;...] EXPOSE 指令并不会让容器监听 host 的端口，如果需要，需要在 docker run 时使用 -p、-P 参数来发布容器端口到 host 的某个端口上。 ENV 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 语法有两种：两者的区别就是第一种是一次设置一个，第二种是一次设置多个。 ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... 示例： ENV VERSION=1.0 DEBUG=on \\ NAME=\u0026#34;Ht\u0026#34; USER 设置启动容器的用户，可以是用户名或UID，所以，只有下面的两种写法是正确的。 注意：如果设置了容器以daemon用户去运行，那么RUN, CMD 和 ENTRYPOINT 都会以这个用户去运行。 镜像构建完成后，通过 docker run 运行容器时，可以通过 -u 参数来覆盖所指定的用户。 USER daemo USER UID 使用USER指定用户时，可以使用用户名、UID 或 GID，或是两者的组合。以下都是合法的指定试： USER user USER user:group USER uid USER uid:gid USER user:gid USER uid:group ARG ARG用于指定传递给构建运行时的变量： ARG \u0026lt;name\u0026gt;[=\u0026lt;default value\u0026gt;] 如，通过ARG指定两个变量： ARG site ARG build_user=it 以上我们指定了 site 和 build_user 两个变量，其中 build_user 指定了默认值。在使用 docker build 构建镜像时，可以通过 --build-arg \u0026lt;varname\u0026gt;=\u0026lt;value\u0026gt; 参数来指定或重设置这些变量的值。 docker build --build-arg site=xxx.com -t itbilu/test . 这样我们构建了 itbilu/test 镜像，其中site会被设置为 itbilu.com，由于没有指定 build_user，其值将是默认值 it。 ONBUILD ONBUILD用于设置镜像触发器：这个命令只对当前镜像的子镜像生效。 ONBUILD [INSTRUCTION] 比如当前镜像为A，在Dockerfile种添加：ONBUILD RUN ls -al，这个 ls -al 命令不会在A镜像构建或启动的时候执行，此时有一个镜像B是基于A镜像构建的，那么这个ls -al 命令会在B镜像构建的时候被执行。 STOPSIGNAL STOPSIGNAL用于设置停止容器所要发送的系统调用信号： STOPSIGNAL signal 所使用的信号必须是内核系统调用表中的合法的值，如：SIGKILL。 WORKDIR WORKDIR用于在容器内设置一个工作目录： WORKDIR /path/to/workdir 通过WORKDIR设置工作目录后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT、ADD、COPY 等命令都会在该目录下执行。 例如： WORKDIR /a WORKDIR b WORKDIR c # pwd执行的结果是/a/b/c RUN pwd WORKDIR也可以解析环境变量。 ENV DIRPATH /path WORKDIR $DIRPATH/$DIRNAME # pwd的执行结果是/path/$DIRNAME RUN pwd VOLUME VOLUME用于创建挂载点，即向基于所构建镜像创始的容器添加卷： VOLUME [\u0026#34;/data\u0026#34;] 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 卷可以容器间共享和重用 容器并不一定要和其它容器共享卷 修改卷后会立即生效 对卷的修改不会对镜像产生影响 卷会一直存在，直到没有任何容器在使用它 VOLUME 让我们可以将源代码、数据或其它内容添加到镜像中，而又不并提交到镜像中，并使我们可以多个容器间共享这些内容。 [\u0026quot;/data\u0026quot;]可以是一个JsonArray ，也可以是多个值。所以如下几种写法都是正确的 VOLUME [\u0026#34;/var/log/\u0026#34;] VOLUME /var/log VOLUME /var/log /var/db 一般的使用场景为需要持久化存储数据时。容器使用的是AUFS，这种文件系统不能持久化数据，当容器关闭后，所有的更改都会丢失。所以当数据需要持久化时用这个命令。 Dockerfile 示例 构建 nginx 运行环境。 # 指定基础镜像 FROM sameersbn/ubuntu:14.04.20161014 # 维护者信息 MAINTAINER sameer@damagehead.com # 设置环境 ENV RTMP_VERSION=1.1.10 \\ NPS_VERSION=1.11.33.4 \\ LIBAV_VERSION=11.8 \\ NGINX_VERSION=1.10.1 \\ NGINX_USER=www-data \\ NGINX_SITECONF_DIR=/etc/nginx/sites-enabled \\ NGINX_LOG_DIR=/var/log/nginx \\ NGINX_TEMP_DIR=/var/lib/nginx \\ NGINX_SETUP_DIR=/var/cache/nginx # 设置构建时变量，镜像建立完成后就失效 ARG BUILD_LIBAV=false ARG WITH_DEBUG=false ARG WITH_PAGESPEED=true ARG WITH_RTMP=true # 复制本地文件到容器目录中 COPY setup/ ${NGINX_SETUP_DIR}/ RUN bash ${NGINX_SETUP_DIR}/install.sh # 复制本地配置文件到容器目录中 COPY nginx.conf /etc/nginx/nginx.conf COPY entrypoint.sh /sbin/entrypoint.sh # 运行指令 RUN chmod 755 /sbin/entrypoint.sh # 允许指定的端口 EXPOSE 80/tcp 443/tcp 1935/tcp # 指定网站目录挂载点 VOLUME [\u0026#34;${NGINX_SITECONF_DIR}\u0026#34;] ENTRYPOINT [\u0026#34;/sbin/entrypoint.sh\u0026#34;] CMD [\u0026#34;/usr/sbin/nginx\u0026#34;] ","permalink":"https://heliu.site/posts/docker/file/","summary":"dockerfile 命令。","title":"Dockerfile"},{"content":" github 相关 docker-compose 地址 https://github.com/docker/compose/tags。 docker-compose 依赖 Docker，请先安装 Docker。 安装 docker-compose 需要注意与 docker 的版本匹配，更多参看具体版本详情。 curl 下载安装 下载 docker-compose 1 2 # 注意替换成自己想要的版本号，由于是访问github的资源，下载速度有时候可能会非常慢 $ sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.18.0/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 授予权限。 1 $ sudo chmod +x /usr/local/bin/docker-compose 测试安装结果。 1 $ docker-compose --version 手动安装 进入 docker-compose 的 github 发布页，选择合适的版本。 把下载的文件上传到 linux。 docker-compose二进制文件上传到服务器目录后，需要将二进制文件拷贝到/usr/local/bin目录下，并且更改名字为docker-compose。 # 拷贝文件到/usr/local/bin，如果文件已经在/usr/local/bin目录，忽略此步骤 # 假如二进制文件docker-compose-linux-x86_64上传的目录是：/opt/docker cp /opt/docker/docker-compose-linux-x86_64 /usr/local/bin # 更改二进制文件名字 mv docker-compose-linux-x86_64 docker-compose 授予权限。 1 $ sudo chmod +x /usr/local/bin/docker-compose 测试安装结果。 1 $ docker-compose --version ","permalink":"https://heliu.site/posts/docker/compose-install/","summary":"centos7 安装 docker-compose","title":"linux 安装 docker-compose"},{"content":" Docker-Compose 项目是Docker官方的开源项目，负责实现对Docker容器集群的快速编排。 Docker-Compose 项目由 Python 编写，调用 Docker 服务提供的API来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用它来进行编排管理。 允许用户通过一个docker-compose.yml模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 模板文件默认路径是当前目录下的docker-compose.yml，可以使用.yml或.yaml作为文件扩展名。 标准模板文件应该包含version、services、networks 三大部分，最关键的是services和networks两个部分。 docker-compose.yml version 指定本 yml 依从的 compose 哪个版本制定的。 services image 指定镜像名称或镜像ID。 如果镜像不存在，将尝试从互联网拉取这个镜像，例如：image: ubuntu、image: a4bc65fd。 指定服务的镜像名，若本地不存在，则会去仓库拉取这个镜像。 services: redis6: image: redis:6.2.3 build 指定 Dockerfile 所在文件夹的路径。 它会利用他自动构建这个镜像，然后使用这个镜像。 services: redis6: # 绝对路径 build: /path/to/build/dir services: redis6: # 相对路径，只要上下文确定就可以读取到Dockerfile。 build: ./dir 设定上下文根目录，然后以该目录为准指定Dockerfile。 services: redis6: # 相对路径，只要上下文确定就可以读取到Dockerfile。 build: context: ../ dockerfile: path/of/Dockerfile build都是一个目录，如果要指定Dockerfile文件需要在build标签的子级标签中使用dockerfile标签指定。 如果同时指定image和build两个标签，那么Compose会构建镜像并且把镜像命名为image值指定的名字。 context context选项可以是Dockerfile的文件路径，也可以是到链接到git仓库的url，当提供的值是相对路径时，被解析为相对于撰写文件的路径，此目录也是发送到Docker守护进程的context。 services: redis6: # 相对路径，只要上下文确定就可以读取到Dockerfile。 build: context: ./dir dockerfile 使用dockerfile文件来构建，必须指定构建路径。 services: redis6: # 相对路径，只要上下文确定就可以读取到Dockerfile。 build: context: . dockerfile: Dockerfile-alternate command 覆盖容器启动后默认执行的命令。 services: redis6: image: redis:6.2.3 command: redis-server /etc/redis/redis.conf ports ports用于映射端口的标签。 使用 HOST:CONTAINER 格式或者只是指定容器的端口，宿主机会随机映射端口。 当使用 HOST:CONTAINER 格式来映射端口时，如果使用的容器端口小于60可能会得到错误得结果，因为YAML将会解析xx:yy这种数字格式为60进制。所以建议采用字符串格式。 services: redis6: ports: - \u0026#34;3000\u0026#34; - \u0026#34;8000:8000\u0026#34; - \u0026#34;49100:22\u0026#34; - \u0026#34;127.0.0.1:8001:8001\u0026#34; container_name 容器名称格式是：\u0026lt;项目名称\u0026gt;\u0026lt;服务名称\u0026gt;\u0026lt;序号\u0026gt;。 可以自定义项目名称、服务名称，但如果想完全控制容器的命名，可以使用标签指定： services: redis6: image: redis:6.2.3 container_name: redis6 depends_on 一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。 例如在没启动数据库容器的时候启动应用容器，应用容器会因为找不到数据库而退出。 depends_on标签用于解决容器的依赖、启动先后的问题。 version: \u0026#39;2\u0026#39; services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 上述YAML文件定义的容器会先启动redis和db两个服务，最后才启动 web 服务。 PID 将PID模式设置为主机PID模式，跟主机系统共享进程命名空间。容器使用pid标签将能够访问和操纵其他容器和宿主机的名称空间。 pid: \u0026#34;host\u0026#34; extra_hosts 添加主机名的标签，会在/etc/hosts文件中添加一些记录。 extra_hosts: - \u0026#34;somehost:162.242.195.82\u0026#34; - \u0026#34;otherhost:50.31.209.229\u0026#34; 启动后查看容器内部hosts： 162.242.195.82 somehost 50.31.209.229 otherhost volumes 挂载一个目录或者一个已存在的数据卷容器，可以直接使用 [HOST:CONTAINER] 格式，或者使用 [HOST:CONTAINER:ro] 格式，后者对于容器来说，数据卷是只读的，可以有效保护宿主机的文件系统。 数据卷指定路径可以是相对路径，使用 . 或者 .. 来指定相对目录。 volumes: // 只是指定一个路径，Docker 会自动在创建一个数据卷（这个路径是容器内部的）。 - /var/lib/mysql // 使用绝对路径挂载数据卷 - /opt/data:/var/lib/mysql // 以 Compose 配置文件为中心的相对路径作为数据卷挂载到容器。 - ./cache:/tmp/cache // 使用用户的相对路径（~/ 表示的目录是 /home/\u0026lt;用户目录\u0026gt;/ 或者 /root/）。 - ~/configs:/etc/configs/:ro // 已经存在的命名的数据卷。 - datavolume:/var/lib/mysql 如果不使用宿主机的路径，可以指定一个volume_driver。 volumes_from 从另一个服务或容器挂载其数据卷： volumes_from: - service_name - container_name dns 自定义DNS服务器。可以是一个值，也可以是一个列表。 dns：8.8.8.8 dns： - 8.8.8.8 - 9.9.9.9 expose 暴露端口，但不映射到宿主机，只允许能被连接的服务访问。仅可以指定内部端口为参数，如下所示： expose: - \u0026#34;3000\u0026#34; - \u0026#34;8000\u0026#34; links 链接到其它服务中的容器。使用服务名称（同时作为别名），或者服务名称:服务别名（如 SERVICE:ALIAS），例如 links: - db - db:database - redis 示例 version: \u0026#39;3.9\u0026#39; services: redis6: image: redis:6.2.3 container_name: redis6 privileged: true restart: unless-stopped command: redis-server /etc/redis/redis.conf #ports: # - \u0026#34;6379:6379\u0026#34; volumes: - /app/docker/redis7/data:/data - ./docker/redis/redis.conf:/etc/redis/redis.conf - /etc/localtime:/etc/localtime:ro logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;20m\u0026#34; max-file: \u0026#34;3\u0026#34; healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;redis-cli\u0026#34;, \u0026#34;ping\u0026#34; ] interval: 10s timeout: 1s retries: 3 network_mode: \u0026#34;container:nginx20\u0026#34; depends_on: - nginx20 mysql8: image: mysql:8.0.19 container_name: mysql8 privileged: true restart: unless-stopped environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: test character-set-server: utf8mb4 collation-server: utf8mb4_general_ci default-authentication-plugin: mysql_native_password volumes: - ./docker/mysql/initdb:/docker-entrypoint-initdb.d - ./docker/mysql/my.cnf:/etc/mysql/conf.d/my.cnf - /app/docker/mysql8/data:/var/lib/mysql - /etc/localtime:/etc/localtime:ro #ports: # - \u0026#34;3306:3306\u0026#34; logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;20m\u0026#34; max-file: \u0026#34;3\u0026#34; healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;mysqladmin\u0026#34; ,\u0026#34;ping\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;localhost\u0026#34;, \u0026#34;--silent\u0026#34; ] interval: 10s timeout: 10s retries: 3 network_mode: \u0026#34;container:nginx20\u0026#34; depends_on: - nginx20 nginx20: image: nginx:${NGINX_VERSION:-1.20.2} container_name: nginx20 privileged: true restart: unless-stopped ports: - \u0026#34;80:80\u0026#34; - \u0026#34;443:443\u0026#34; - \u0026#34;3306:3306\u0026#34; - \u0026#34;6379:6379\u0026#34; - \u0026#34;8080:8080\u0026#34; - \u0026#34;8888:8888\u0026#34; volumes: - ./docker/nginx/html:/usr/share/nginx/html - ./docker/nginx/cert:/etc/nginx/cert - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf - ./docker/nginx/conf.d:/etc/nginx/conf.d - /app/docker/nginx/logs:/var/log/nginx environment: - TZ=Asia/Shanghai healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;curl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;http://localhost\u0026#34; ] interval: 30s timeout: 10s retries: 3 networks: - default_net api: container_name: greet-api build: context: ./greet/api dockerfile: Dockerfile privileged: true command: [ \u0026#34;/app/wait-for-it.sh\u0026#34;, \u0026#34;localhost:3306\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;30\u0026#34;, \u0026#34;--\u0026#34;, \u0026#34;/app/wait-for-it.sh\u0026#34;, \u0026#34;localhost:6379\u0026#34;, \u0026#34;-t\u0026#34;, \u0026#34;30\u0026#34;, \u0026#34;--\u0026#34;, \u0026#34;/app/main\u0026#34; ] depends_on: - nginx20 - mysql8 - redis6 #ports: # - \u0026#34;8888:8888\u0026#34; network_mode: \u0026#34;container:nginx20\u0026#34; networks: default_net: driver: bridge ","permalink":"https://heliu.site/posts/docker/compose/","summary":"docker-compose 介绍。","title":"docker-compose"},{"content":"epoll 服务器启动以后，服务端会去调用epoll_create，创建一个epoll实例，epoll实例中包含两个数据。 红黑树（为空）：rb_root 用来去记录需要被监听的FD。 链表（为空）：list_head，用来存放已经就绪的FD。 创建好了之后，会去调用epoll_ctl函数，此函数会会将需要监听的数据添加到rb_root中去，并且对当前这些存在于红黑树的节点设置回调函数，当这些被监听的数据一旦准备完成，就会被调用，而调用的结果就是将红黑树的fd添加到list_head中去(但是此时并没有完成)。 当第二步完成后，就会调用epoll_wait函数，这个函数会去校验是否有数据准备完毕（因为数据一旦准备就绪，就会被回调函数添加到list_head中），在等待了一段时间后(可以进行配置)，如果等够了超时时间，则返回没有数据，如果有，则进一步判断当前是什么事件，如果是建立连接时间，则调用accept() 接受客户端socket，拿到建立连接的socket，然后建立起来连接，如果是其他事件，则把数据进行写出。 redis 流程 redis 单线程网络模型流程。 redis 多线程网络模型流程。 redis 思考 Redis到底是单线程还是多线程？ 如果仅仅聊Redis的核心业务部分（命令处理），答案是单线程 如果是聊整个Redis，那么答案就是多线程 在Redis版本迭代过程中，在两个重要的时间节点上引入了多线程的支持： Redis v4.0：引入多线程异步处理一些耗时较旧的任务，例如异步删除命令unlink。 Redis v6.0：在核心网络模型中引入多线程，进一步提高对于多核CPU的利用率。 因此，对于Redis的核心网络模型，在Redis 6.0之前确实都是单线程。是利用epoll（Linux系统）这样的IO多路复用技术在事件循环中不断处理客户端情况。 为什么Redis要选择单线程？ 抛开持久化不谈，Redis是纯内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。 多线程会导致过多的上下文切换，带来不必要的开销。 引入多线程会面临线程安全问题，必然要引入线程锁这样的安全手段，实现复杂度增高，而且性能也会大打折扣。 ","permalink":"https://heliu.site/posts/redis/theory/","summary":"redis IO多路复用。","title":"redis 网络模型"},{"content":"过期 key Redis之所以性能强，最主要的原因就是基于内存存储。然而单节点的Redis其内存大小不宜过大，会影响持久化或主从同步性能。 我们可以通过修改配置文件来设置Redis的最大内存： # 格式 # maxmemory \u0026lt;bytes\u0026gt; # 设置redis最大内存为 1GB maxmemory 1gb 当内存使用达到上限时，就无法存储更多数据了。Redis提供了一些策略实现内存回收。 比如通过expire命令给Redis的key设置TTL（存活时间）。 当key的TTL到期以后，再次访问name返回的是nil，说明这个key已经不存在了，对应的内存也得到释放。从而起到内存回收的目的。 Redis本身是一个典型的key-value内存存储数据库，因此所有的key、value都保存在Dict（字典）结构中。不过有两个Dict：一个用来记录key-value；另一个用来记录key-TTL。 Redis是如何知道一个key是否过期呢？ 利用两个Dict分别记录key-value对及key-ttl对。 是不是TTL到期就立即删除了呢？ 不是，redis有两种策略，惰性删除、周期性删除。 惰性删除 不是在TTL到期后就立刻删除，而是在访问一个key的时候，检查该key的存活时间，如果已经过期才执行删除。 周期性删除 通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。 执行周期有两种：SLOW、FAST模式。 SLOW 模式：Redis服务初始化函数initServer()中设置定时任务，按照server.hz（默认10）的频率来执行过期key清理。 执行频率受server.hz影响，默认为10，即每秒执行10次，每个执行周期100ms。 执行清理耗时不超过一次执行周期的25%，默认slow模式耗时不超过25ms。 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期。 如果没达到时间上限（25ms）并且过期key比例大于10%，再进行一次抽样，否则结束。 FAST 模式：Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理。（过期key比例小于10%不执行 ） 执行频率受beforeSleep()调用频率影响，但两次FAST模式间隔不低于2ms。 执行清理耗时不超过1ms。 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期，如果没达到时间上限（1ms）并且过期key比例大于10%，再进行一次抽样，否则结束。 总结 RedisKey的TTL记录方式： 在RedisDB中通过一个Dict记录每个Key的TTL时间。 过期key的删除策略： 惰性清理：每次查找key时判断是否过期，如果过期则删除。 定期清理：定期抽样部分key，判断是否过期，如果过期则删除。 定期清理的两种模式： SLOW模式执行频率默认为10，每次不超过25ms。 FAST模式执行频率不固定，但两次间隔不低于2ms，每次耗时不超过1ms。 内存淘汰策略 当Redis内存使用达到设置的上限时，主动挑选部分key删除以释放更多内存的流程。 Redis支持8种不同策略来选择要删除的key： noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。 volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰。 allkeys-random：对全体key，随机进行淘汰。也就是直接从db-\u0026gt;dict中随机挑选。 volatile-random：对设置了TTL的key，随机进行淘汰。也就是从db-\u0026gt;expires中随机挑选。 allkeys-lru： 对全体key，基于LRU算法进行淘汰。 volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰。 allkeys-lfu： 对全体key，基于LFU算法进行淘汰。 volatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰。 LRU（Least Recently Used），最少最近使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。 LFU（Least Frequently Used），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。 # redis过期key的移除策略 maxmemory-policy noeviction ","permalink":"https://heliu.site/posts/redis/memory/","summary":"redis 内存回收策略。","title":"redis 内存回收"},{"content":" redis 支持两种持久化方案：RDB、AOF持久化。 RDB 持久化 RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。 当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。 执行时机 RDB持久化在四种情况下会执行： 执行save命令。 执行bgsave命令。 Redis停机时。 触发RDB条件时。 save 命令 执行下save命令，可以立即执行一次RDB。 save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。 $ save ok bgsave 命令 bgsave 命令可以异步执行RDB。 bgsave 命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。 $ bgsave Background saving started 停机时 Redis停机时会执行一次save命令，实现RDB持久化。 触发RDB条件 Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下： # 如果是save \u0026#34;\u0026#34; 则表示禁用RDB # 900秒内，如果至少有1个key被修改，则执行bgsave save 900 1 # 300秒内，如果至少有10个key被修改，则执行bgsave save 300 10 # 60秒内，如果至少有10000个key被修改，则执行bgsave save 60 10000 RDB的其它配置也可以在redis.conf文件中设置。 # 是否压缩 ,建议不开启 # 压缩也会消耗cpu，磁盘的话不值钱 rdbcompression yes # 备份的RDB文件名称 dbfilename dump.rdb # 备份文件保存的路径目录 dir ./ RDB 原理 bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。 fork采用的是copy-on-write技术： 当主进程执行读操作时，访问共享内存。 当主进程执行写操作时，则会拷贝一份数据，执行写操作。 总结 RDB方式bgsave的基本流程？ fork主进程得到一个子进程，共享内存空间。 子进程读取内存数据并写入新的RDB文件。 用新RDB文件替换旧的RDB文件。 RDB会在什么时候执行？save 60 1000代表什么含义？ 默认是服务停止时。 代表60秒内至少执行1000次修改则触发RDB。 RDB的缺点？ RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险。 fork子进程、压缩、写出RDB文件都比较耗时。 AOF 持久化 AOF 原理 AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。 AOF 配置 AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF。 # 是否开启AOF功能，默认是no appendonly yes # AOF文件的名称 appendfilename \u0026#34;appendonly.aof\u0026#34; AOF的命令记录的频率也可以通过redis.conf文件来配。 # 表示每执行一次写命令，立即记录到AOF文件 appendfsync always # 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案 appendfsync everysec # 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘 appendfsync no 三种策略对比。 配置 刷盘时机 优点 缺点 always 同步刷盘 可靠性高，几乎不丢数据 性能影响大 everysec 每秒刷盘 性能适中 最多丢失1秒数据 no 操作系统控制 性能最好 可靠性较差，可能丢失大量数据 AOF 文件重写 因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。 通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。 AOF原本有三个命令，但是set count 20 和 set count 12 都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。 所以重写命令后，AOF文件内容就是：mset count 12 age 18。 Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置。 # AOF文件比上次文件 增长超过多少百分比则触发重写 auto-aof-rewrite-percentage 100 # AOF文件体积最小多大以上才触发重写 auto-aof-rewrite-min-size 64mb RDB 与 AOF 对比 RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会结合两者来使用。 RDB AOF 持久化方式 定时对整个内存做快照 记录每一次执行的命令 数据完整性 不完整，两次备份之间会丢失 相对完整，取决于刷盘策略 文件大小 会有压缩，文件体积小 记录命令，文件体积很大 宕机恢复速度 很快 慢 数据恢复优先级 低，因为数据完整性不如AOF 高，因为数据完整性更高 系统资源占用 高，大量CPU和内存消耗 低，主要时磁盘IO资源，但AOF重写时会占用大量CPU和内存资源 使用场景 可以容忍数分钟的数据丢失，追求更快的启动速度 对数据安全性要求较高常见 ","permalink":"https://heliu.site/posts/redis/persistence/","summary":"redis 数据持久化。","title":"redis 持久化"},{"content":"主从架构 单节点 Redis 的并发能力是有上限的，要进一步提高 Redis 的并发能力，就需要搭建主从集群，实现读写分离。 同步原理 全量同步 主从第一次建立连接时，会执行全量同步，将master节点的所有数据都拷贝给slave节点。 replication id 和 offset。 Replication Id：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid。 offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。 master如何得知salve是第一次来连接？ slave做数据同步，必须向master声明自己的replication id和offset，master才可以判断到底需要同步哪些数据。 slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。 master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。 master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。 因此，master判断一个节点是否是第一次同步的依据，就是看replid是否一致。 完整流程描述： slave节点请求增量同步。 master节点判断replid，发现不一致，拒绝增量同步。 master将完整内存数据生成RDB，发送RDB到slave。 slave清空本地数据，加载master的RDB。 master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave。 slave执行接收到的命令，保持与master之间的同步。 增量同步 全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做增量同步。 什么是增量同步？就是只更新slave与master存在差异的部分数据。 repl_backlog repl_backlog 文件是一个固定大小的数组，只不过数组是环形，也就是说角标到达数组末尾后，会再次从0开始读写，这样数组头部的数据就会被覆盖。 repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset。 随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset。 但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset。 棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。 注意：repl_backlog 文件大小是有上线的，写满后会覆盖最早的数据。如果slave断开时间太久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步。 优化 主从同步可以保证主从数据的一致性，非常重要。 可以从以下几个方面来优化Redis主从就集群： 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。 Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO。 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步。 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力。 总结 全量同步和增量同步区别？ 全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。 增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave。 什么时候执行全量同步？ slave节点第一次连接master节点时。 slave节点断开时间太久，repl_baklog中的offset已经被覆盖时。 什么时候执行增量同步？ slave节点断开又恢复，并且在repl_baklog中能找到offset时。 优点 解决了单机版并发量大，导致亲求延迟或者redis宕机服务停止的问题。 从数据库分担主数据库的读压力，若是主数据库只是写模式，那么实现读写分离，主数据库就没有读压力了。 解决了单机版单点故障的问题，若是主数据库挂了，那么从数据库可以随时顶上来。 缺点 数据的一致性问题，假如主数据库写操作完成，那么他的数据会被复制到从数据库，若是还没有及时复制到从数据库，读请求又来了，此时读取的数据就不是最新的数据。 主从同步的过程网络出故障了，导致主从同步失败，也会出现数据一致性的问题。 不具备自动容错和恢复的功能，一旦主数据库挂掉，从节点晋升为主数据库的过程需要人为操作，维护的成本就会升高，并且主节点的写能力，存储能力都会受到限制。 主从集群搭建 准备三台redis，一台master，两台slave。 开启主从关系命令。配置主从可以使用 replicaof 或者 slaveof（5.0以前）命令。 有临时和永久两种模式： 修改配置文件（永久生效）：在redis.conf中添加一行配置 slaveof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt;。 使用redis-cli客户端连接到redis服务，执行slaveof命令（重启后失效）：slaveof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt;。 注意：在5.0以后新增命令replicaof，与salveof效果一致。 在从服务器上执行 slaveof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; 命令，masterip 主ip，masterport 主端口。 在主节点上查看集群信息命令，info replication。 slave 配置 slave 节点 redis.conf 配置文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # 监听来自任意网络接口的连接 bind 0.0.0.0 # 关闭保护模式，接收远程连接 protected-mode no # 监听端口 port 6379 # 指定客户端空闲多少秒后关闭连接 # 设置为 0，则不会因为客户端空闲而关闭连接 # 设置为正整数，表示客户端在指定的时间内没有发送任何指令，连接将被关闭 time 0 # 默认数据库数量 databases 1 #用守护线程的方式启动 daemonize no # yes : RDB快照保存失败后 客户端不可写入redis，只可读。 # no : 禁用此功能 stop-writes-on-bgsave-error yes # 是否检查rdb快照的完整性，损失大概 百分之十 的性能 rdbchecksum yes #您可以配置副本实例以接受或不接受写入。 #就是主从复制中，slave节点是否可以写入数据（yes：不能写入；no：可以写入） replica-read-only yes # 配置RDB持久化模式 # 900s内至少一次写操作则执行bgsave进行RDB持久化 # asve \u0026#34;\u0026#34; save 900 1 save 300 10 save 60 10000 # RDB是否压缩 ,建议不开启 # 压缩也会消耗cpu，磁盘的话不值钱 rdbcompression no # 备份的RDB文件名称 dbfilename dump.rdb # 备份文件保存的路径目录 dir ./ # 开启 AOF 持久化 appendonly yes # AOF 每秒刷盘 appendfsync everysec # AOF文件的名称 appendfilename \u0026#34;appendonly.aof\u0026#34; # 节点登录口令 requirepass 12345678 # 配置主从，当前从节点加入主节点 slaveof redis-master 6379 # 主节点口令 masterauth 12345678 master 配置 master 节点 redis.conf 配置文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 # 监听来自任意网络接口的连接 bind 0.0.0.0 # 关闭保护模式，接收远程连接 protected-mode no # 监听端口 port 6379 # 指定客户端空闲多少秒后关闭连接 # 设置为 0，则不会因为客户端空闲而关闭连接 # 设置为正整数，表示客户端在指定的时间内没有发送任何指令，连接将被关闭 time 0 # 默认数据库数量 databases 1 #用守护线程的方式启动 daemonize no #yes : RDB快照保存失败后 客户端不可写入redis，只可读。 #no : 禁用此功能 stop-writes-on-bgsave-error yes # 是否检查rdb快照的完整性，损失大概 百分之十 的性能 rdbchecksum yes #当使用无盘复制时，master 在开始传输之前等待一段可配置的时间（以秒为单位）， #希望多个副本到达并且传输可以并行化。对于慢速磁盘和快速（大带宽）网络，无盘复制效果更好。 repl-diskless-sync yes #您可以配置副本实例以接受或不接受写入。 #就是主从复制中，slave节点是否可以写入数据（yes：不能写入；no：可以写入） replica-read-only yes # 配置RDB持久化模式 # 900s内至少一次写操作则执行bgsave进行RDB持久化 # asve \u0026#34;\u0026#34; save 900 1 save 300 10 save 60 10000 # RDB是否压缩 ,建议不开启 # 压缩也会消耗cpu，磁盘的话不值钱 rdbcompression no # 备份的RDB文件名称 dbfilename dump.rdb # 备份文件保存的路径目录 dir ./ # 开启 AOF 持久化 appendonly yes # AOF 每秒刷盘 appendfsync everysec # AOF文件的名称 appendfilename \u0026#34;appendonly.aof\u0026#34; # 节点登录口令 requirepass 12345678 docker-compose.yml redis.conf 配置文件可以到 github 取下载，https://github.com/redis/redis/tree/6.2.3。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 version: \u0026#39;3\u0026#39; services: redis-master: container_name: redis-master image: redis:6.2.3 privileged: true restart: unless-stopped command: redis-server /etc/redis/redis.conf ports: - \u0026#34;7001:6379\u0026#34; volumes: - /app/docker/redis/master/data:/data - ./docker/redis/master/redis.conf:/etc/redis/redis.conf - /etc/localtime:/etc/localtime:ro logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;20m\u0026#34; max-file: \u0026#34;3\u0026#34; healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;redis-cli\u0026#34;, \u0026#34;ping\u0026#34; ] interval: 10s timeout: 1s retries: 3 networks: redis-network: ipv4_address: 172.30.1.2 redis-slave1: container_name: redis-slave1 image: redis:6.2.3 privileged: true restart: unless-stopped command: redis-server /etc/redis/redis.conf ports: - \u0026#34;7002:6379\u0026#34; volumes: - /app/docker/redis/slave1/data:/data - ./docker/redis/slave1/redis.conf:/etc/redis/redis.conf - /etc/localtime:/etc/localtime:ro logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;20m\u0026#34; max-file: \u0026#34;3\u0026#34; healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;redis-cli\u0026#34;, \u0026#34;ping\u0026#34; ] interval: 10s timeout: 1s retries: 3 networks: redis-network: ipv4_address: 172.30.1.3 redis-slave2: container_name: redis-slave2 image: redis:6.2.3 privileged: true restart: unless-stopped command: redis-server /etc/redis/redis.conf ports: - \u0026#34;7003:6379\u0026#34; volumes: - /app/docker/redis/slave2/data:/data - ./docker/redis/slave2/redis.conf:/etc/redis/redis.conf - /etc/localtime:/etc/localtime:ro logging: driver: \u0026#34;json-file\u0026#34; options: max-size: \u0026#34;20m\u0026#34; max-file: \u0026#34;3\u0026#34; healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;redis-cli\u0026#34;, \u0026#34;ping\u0026#34; ] interval: 10s timeout: 1s retries: 3 networks: redis-network: ipv4_address: 172.30.1.4 networks: redis-network: driver: bridge ipam: driver: default config: - subnet: 172.30.1.0/24 使用 docker-compose 启动服务。 $ docker-compose -p redis-cluster up -d ","permalink":"https://heliu.site/posts/redis/slave/","summary":"redis 主从同步。","title":"redis 主从同步"},{"content":"哨兵结构 哨兵的作用如下： 监控：Sentinel 会不断检查您的master和slave是否按预期工作。 自动故障恢复：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主。 通知：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端。 监控集群原理 Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令： 主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。 客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。 集群故障恢复 一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的： 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点。 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举。 如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高。 最后是判断slave节点的运行id大小，越小优先级越高。 当选出一个新的master后，切换流程： sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master。 sentinel给所有其它slave发送slaveof 192.168.150.101 7002命令，让这些slave成为新master的从节点，开始从新的master上同步数据。 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点。 总结 Sentinel的三个作用是：监控、故障转移、通知。 Sentinel判断一个redis实例是否健康： 每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线。 如果大多数sentinel都认为实例主观下线，则判定服务下线。 故障转移步骤： 首先选定一个slave作为新的master，执行slaveof no one。 然后让所有节点都执行slaveof 新master。 修改故障节点配置，添加slaveof 新master。 搭建 以前一篇主从搭建为基础。 配置 sentinel.conf 文件，github下载对应版本。 修改以下内容。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # sentinel1.conf # docker对外开放的端口 port 37376 requirepass 12345678 # 服务后台运行 # 因为使用docker启动时使用了-d参数，所以需要设置为no, 非docker设置为yes daemonize no dir /tmp # 这里配置的是监控的redis的地址，mymaster为默认的主节点名字 # 后面的2为客观掉线的票数，一般为集群数除二 # mymasterr：主节点名称，自定义，任意写 # 172.30.1.2 7001：主节点的ip和端口 # 2：选举master时的quorum值 sentinel monitor mymaster 172.30.1.2 7001 2 sentinel auth-pass mymaster 12345678 # # 超过30秒master还没有连接上，则认为master已经停止，30000ms，默认30秒 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 # 故障转移超时时间 默认3分钟 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # sentinel2.conf # docker对外开放的端口 port 37377 requirepass 12345678 # 服务后台运行 # 因为使用docker启动时使用了-d参数，所以需要设置为no, 非docker设置为yes daemonize no dir /tmp # 这里配置的是监控的redis的地址，mymaster为默认的主节点名字 # 后面的2为客观掉线的票数，一般为集群数除二 # mymasterr：主节点名称，自定义，任意写 # 172.30.1.2 7001：主节点的ip和端口 # 2：选举master时的quorum值 sentinel monitor mymaster 172.30.1.2 7001 2 sentinel auth-pass mymaster 12345678 # # 超过30秒master还没有连接上，则认为master已经停止，30000ms，默认30秒 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 # 故障转移超时时间 默认3分钟 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # sentinel3.conf # docker对外开放的端口 port 37378 requirepass 12345678 # 服务后台运行 # 因为使用docker启动时使用了-d参数，所以需要设置为no, 非docker设置为yes daemonize no dir /tmp # 这里配置的是监控的redis的地址，mymaster为默认的主节点名字 # 后面的2为客观掉线的票数，一般为集群数除二 # mymasterr：主节点名称，自定义，任意写 # 172.30.1.2 7001：主节点的ip和端口 # 2：选举master时的quorum值 sentinel monitor mymaster 172.30.1.2 7001 2 sentinel auth-pass mymaster 12345678 # # 超过30秒master还没有连接上，则认为master已经停止，30000ms，默认30秒 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 # 故障转移超时时间 默认3分钟 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 version: \u0026#39;3\u0026#39; services: redis-sentinel1: image: redis:6.2.3 container_name: redis-sentinel1 restart: always ports: - 37376:37376 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - /home/redis/config/sentinel1.conf:/usr/local/etc/redis/sentinel.conf # - ./data/redis-sentinel:/data sysctls: # 必要的内核参数 net.core.somaxconn: \u0026#39;511\u0026#39; redis-sentinel2: image: redis:6.2.3 container_name: redis-sentinel2 restart: always ports: - 37377:37377 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - /home/redis/config/sentinel2.conf:/usr/local/etc/redis/sentinel.conf # - ./data/redis-sentinel:/data sysctls: # 必要的内核参数 net.core.somaxconn: \u0026#39;511\u0026#39; redis-sentinel3: image: redis:6.2.3 container_name: redis-sentinel3 restart: always ports: - 37378:37378 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - /home/redis/config/sentinel3.conf:/usr/local/etc/redis/sentinel.conf # - ./data/redis-sentinel:/data sysctls: # 必要的内核参数 net.core.somaxconn: \u0026#39;511\u0026#39; $ docker-compose -f docker-sentinel.yml up -d 参考 https://www.cnblogs.com/coolxin1024/p/17182557.html ","permalink":"https://heliu.site/posts/redis/sentinel/","summary":"redis 哨兵机制。","title":"redis 哨兵"},{"content":"简介 主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决： 海量数据存储问题、高并发写的问题。 使用分片集群可以解决上述问题，如图: 分片集群特征： 集群中有多个master，每个master保存不同数据。 每个master都可以有多个slave节点。 master之间通过ping监测彼此健康状态。 客户端请求可以访问集群任意节点，最终都会被转发到正确节点。 散列插槽 插槽原理 Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到。 M: xxxxxxxxxxxxxxxxxxxxxxxx 172.30.1.2:7001 slots:[0-5460] (5461 slots) master M: xxxxxxxxxxxxxxxxxxxxxxxx 172.30.1.2:7002 slots:[5461-10922] (5462 slots) master M: xxxxxxxxxxxxxxxxxxxxxxxx 172.30.1.2:7003 slots:[10923-16383] (5461 slots) master 数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况： key中包含 \u0026quot;{}\u0026quot;，且 \u0026quot;{}\u0026quot; 中至少包含1个字符，\u0026quot;{}\u0026quot; 中的部分是有效部分。 key中不包含 \u0026quot;{}\u0026quot;，整个key都是有效部分。 例如：key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用CRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。 在7001这个节点执行set a 1时，对a做hash运算，对16384取余，得到的结果是15495，因此要存储到7003节点。 到了7003后，执行get num时，对num做hash运算，对16384取余，得到的结果是2765，因此需要切换到7001节点。 $ set a 1 -\u0026gt; Redirected to slot [15495] located at 172.30.1.2:7003 OK $ get num -\u0026gt; Redirected to slot [2765] located at 172.30.1.2:7001 Redis如何判断某个key应该在哪个实例： 将16384个插槽分配到不同的实例。 根据key的有效部分计算哈希值，对16384取余。 余数作为插槽，寻找插槽所在实例即可。 如何将同一类数据固定的保存在同一个Redis实例：这一类数据使用相同的有效部分，例如key都以{typeId}为前缀。 集群伸缩 redis-cli \u0026ndash;cluster 提供了很多操作集群的命令，可以通过下面方式查看： $ redis-cli --cluster help 添加新节点到集群 $ redis-cli --cluster add-node 192.168.150.101:7004 192.168.150.101:7001 查看集群状态。 $ redis-cli -p 7001 cluster nodes 转移插槽 转移插槽命令：redis-cli \u0026ndash;cluster reshard host:port。 host:port 从这个位置转移到其他位置。 故障转移 自动故障转移 redis 集群会自动故障转移。 手动故障转移 利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。 failover命令可以指定三种模式： \u0026ldquo;\u0026quot;：默认的流程，如图1~6歩。 force：省略了对offset的一致性校验。 takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见。 在从节点执行： $ CLUSTER FAILOVER 搭建集群 分片集群需要的节点数量较多，这里我们搭建一个最小的分片集群，包含3个master节点，每个master包含一个slave节点。 IP PORT 角色 172.30.2.11 7001 master 172.30.2.12 7002 master 172.30.2.13 7003 master 172.30.2.21 8001 slave 172.30.2.22 8002 slave 172.30.2.23 8003 slave redis.conf redis.conf 文件准备。github 官网下载 redis 相应版本的配置文件。 对每个redis.conf都做以下修改。分片集群的redis主从的redis.conf目前都是一样的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 port 6379 # 开启集群功能 cluster-enabled yes # 集群的配置文件名称，不需要我们创建，由redis自己维护 cluster-config-file /data/nodes.conf # 节点心跳失败的超时时间 cluster-node-timeout 5000 # 持久化文件存放目录 dir /data # 绑定地址 bind 0.0.0.0 # no 非后台守护运行 daemonize no # 保护模式 protected-mode no # 数据库数量 databases 1 # 日志 logfile /data/run.log docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 version: \u0026#39;3.8\u0026#39; networks: redis-sharding: driver: bridge ipam: driver: default config: - subnet: 172.30.2.0/24 services: master1: container_name: master1 image: redis:6.2.3 volumes: - ./master1/conf:/usr/local/etc/redis ports: - \u0026#34;7001:6379\u0026#34; command: [\u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34;] networks: redis-sharding: ipv4_address: 172.30.2.11 master2: container_name: master2 image: redis:6.2.3 volumes: - ./master2/conf:/usr/local/etc/redis ports: - \u0026#34;7002:6379\u0026#34; command: [ \u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34; ] networks: redis-sharding: ipv4_address: 172.30.2.12 master3: container_name: master3 image: redis:6.2.3 volumes: - ./master3/conf:/usr/local/etc/redis ports: - \u0026#34;7003:6379\u0026#34; command: [ \u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34; ] networks: redis-sharding: ipv4_address: 172.30.2.13 replica1: container_name: replica1 image: redis:6.2.3 volumes: - ./replica1/conf:/usr/local/etc/redis ports: - \u0026#34;8001:6379\u0026#34; command: [ \u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34; ] networks: redis-sharding: ipv4_address: 172.30.2.21 replica2: container_name: replica2 image: redis:6.2.3 volumes: - ./replica2/conf:/usr/local/etc/redis ports: - \u0026#34;8002:6379\u0026#34; command: [ \u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34; ] networks: redis-sharding: ipv4_address: 172.30.2.22 replica3: container_name: replica3 image: redis:6.2.3 volumes: - ./replica3/conf:/usr/local/etc/redis ports: - \u0026#34;8003:6379\u0026#34; command: [ \u0026#34;redis-server\u0026#34;, \u0026#34;/usr/local/etc/redis/redis.conf\u0026#34; ] networks: redis-sharding: ipv4_address: 172.30.2.23 $ docker-compose -p redis-sharding up -d 构建集群 下面的命令都在 master1 容器里执行。\n自动分配主从关系 创建了一个集群，包括三个主节点和三个从节点，每个主节点分配一个从节点作为副本，前3个ip为主节点，后3个为从节点，主节点的从节点随机分配。 $ redis-cli --cluster create 172.30.2.11:6379 172.30.2.12:6379 172.30.2.13:6379 172.30.2.21:6379 172.30.2.22:6379 172.30.2.23:6379 --cluster-replicas 1 手动分配主从关系 分配 master 集群。 $ redis-cli --cluster create 172.30.2.11:6379 172.30.2.12:6379 172.30.2.13:6379 --cluster-replicas 0 查看3个主节点的ID。 $ redis-cli -h 172.30.2.11 -p 6379 cluster nodes 将3个从节点加入集群中，其中172.30.2.11可以是三个主节点的任意一个。 $ redis-cli -h 172.30.2.21 -p 6379 cluster meet 172.30.2.11 6379 $ redis-cli -h 172.30.2.22 -p 6379 cluster meet 172.30.2.11 6379 $ redis-cli -h 172.30.2.23 -p 6379 cluster meet 172.30.2.11 6379 为每个从节点指定主节点。 $ redis-cli -h 172.30.2.21 -p 6379 cluster replicate \u0026lt;master-ID\u0026gt; $ redis-cli -h 172.30.2.22 -p 6379 cluster replicate \u0026lt;master-ID\u0026gt; $ redis-cli -h 172.30.2.23 -p 6379 cluster replicate \u0026lt;master-ID\u0026gt; 验证 通过以下命令查看集群中每个节点的id、角色、ip、port、插槽范围等信息。 $ redis-cli -h 172.30.2.11 -p 6379 cluster nodes 往集群存入4个键值。 $ redis-cli -c -h 172.30.2.11 -p 6379 set key1 value1 $ redis-cli -c -h 172.30.2.11 -p 6379 set key2 value2 $ redis-cli -c -h 172.30.2.11 -p 6379 set key3 value3 $ redis-cli -c -h 172.30.2.11 -p 6379 set key4 value4 查看每个主节点现有的键值，会发现每个节点只有一部分键值。 $ redis-cli -h 172.30.2.11 -p 6379 --scan $ redis-cli -h 172.30.2.12 -p 6379 --scan $ redis-cli -h 172.30.2.13 -p 6379 --scan ","permalink":"https://heliu.site/posts/redis/cluster/","summary":"redis 分片集群原理和搭建。","title":"redis 分片集群"},{"content":" redis官方网站：https://redis.io/ redis官方命令文档：https://redis.io/docs/latest/commands/ redis是 NoSql 数据库，以键值对的形式存储。 redis 命令行客户端 Redis 安装完成后就自带了命令行客户端：redis-cli，使用方式如下： redis-cli [options] [commonds] 其中常见的 options 有： -h 127.0.0.1：指定要连接的 redis 节点的 IP 地址，默认是 127.0.0.1。 -p 6379：指定要连接的 redis 节点的端口，默认是 6379。 -a 123456：指定redis的访问密码。 commonds 就是 Redis 的操作命令，例如： ping：与redis服务端做心跳测试，服务端正常会返回pong。 不指定commond时，会进入redis-cli的交互控制台。 Redis 默认有16个仓库，编号从0至15。通过配置文件可以设置仓库数量，但是不超过16，并且不能自定义仓库名称。(建议只设置一个数据库) 如果是基于 redis-cli 连接 Redis 服务，可以通过 select 命令来选择数据库：select 0。 redis 通用命令 通用指令是部分数据类型的，都可以使用的指令。 官网地址：https://redis.io/docs/latest/commands/?group=generic redis客户端查询命令：help @generic。 COPY 将一个key的值复制到一个新key。\n语法：\nCOPY source destination [DB destination-db] [REPLACE] 使用示例： # 设置key/value SET dolly \u0026#34;sheep\u0026#34; # 克隆dolly COPY dolly clone GET clone DEL 删除一个或多个key。\n语法：\nDEL key [key ...] 使用示例： redis\u0026gt; SET key1 \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; SET key2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; DEL key1 key2 key3 (integer) 2 DUMP 返回存储在键中的值的序列化表示形式。\n语法：\nDUMP key 使用示例： \u0026gt; SET mykey 10 OK \u0026gt; DUMP mykey \u0026#34;\\x00\\xc0\\n\\n\\x00n\\x9fWE\\x0e\\xaec\\xbb\u0026#34; EXISTS 确定是否存在一个或多个key。\n语法：\nEXISTS key [key ...] 示例： redis\u0026gt; SET key1 \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; EXISTS key1 (integer) 1 redis\u0026gt; EXISTS nosuchkey (integer) 0 redis\u0026gt; SET key2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; EXISTS key1 key2 nosuchkey (integer) 2 EXPIRE 以秒为单位设置密钥的过期时间（单位/秒）。 语法： NX - 仅当key没有过期时间时有效。 XX - 仅当key有过期时间时有效。 GT - 仅当新过期时间大于当前过期时间时有效。 LT - 仅当新过期时间小于当前过期时间时有效。 EXPIRE key seconds [NX | XX | GT | LT] 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; EXPIRE mykey 10 (integer) 1 redis\u0026gt; TTL mykey (integer) 10 redis\u0026gt; SET mykey \u0026#34;Hello World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; TTL mykey (integer) -1 redis\u0026gt; EXPIRE mykey 10 XX (integer) 0 redis\u0026gt; TTL mykey (integer) -1 redis\u0026gt; EXPIRE mykey 10 NX (integer) 1 redis\u0026gt; TTL mykey (integer) 10 EXPIREAT 将key的过期时间设置为Unix时间戳。 语法： NX - 仅当key没有过期时间时有效。 XX - 仅当key有过期时间时有效。 GT - 仅当新过期时间大于当前过期时间时有效。 LT - 仅当新过期时间小于当前过期时间时有效。 EXPIREAT key unix-time-seconds [NX | XX | GT | LT] 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; EXISTS mykey (integer) 1 redis\u0026gt; EXPIREAT mykey 1293840000 (integer) 1 redis\u0026gt; EXISTS mykey (integer) 0 EXPIRETIME 以Unix时间戳形式返回key的过期时间。 语法： PEXPIRETIME key 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; PEXPIREAT mykey 33177117420000 (integer) 1 redis\u0026gt; PEXPIRETIME mykey (integer) 33177117420000 KEYS 返回与模式匹配的所有key名。（正式环境中不建议使用）\n语法：\nKEYS pattern 支持的全局样式模式: h?llo matches hello, hallo and hxllo h*llo matches hllo and heeeello h[ae]llo matches hello and hallo, but not hillo h[^e]llo matches hallo, hbllo, \u0026hellip; but not hello h[a-b]llo matches hallo and hbllo 果要逐字匹配特殊字符，请使用\\来转义它们。\n示例： # 设置firstname Jack、lastname Stuntman、age 35 redis\u0026gt; MSET firstname Jack lastname Stuntman age 35 \u0026#34;OK\u0026#34; redis\u0026gt; KEYS *name* 1) \u0026#34;lastname\u0026#34; 2) \u0026#34;firstname\u0026#34; redis\u0026gt; KEYS a?? 1) \u0026#34;age\u0026#34; redis\u0026gt; KEYS * 1) \u0026#34;lastname\u0026#34; 2) \u0026#34;firstname\u0026#34; 3) \u0026#34;age\u0026#34; MIGRATE 自动将密钥从一个Redis实例传输到另一个Redis实例。 语法： MIGRATE host port \u0026lt;key | \u0026#34;\u0026#34;\u0026gt; destination-db timeout [COPY] [REPLACE] [AUTH password | AUTH2 username password] [KEYS key [key ...]] 示例： MIGRATE 192.168.1.34 6379 \u0026#34;\u0026#34; 0 5000 KEYS key1 key2 key3 MOVE 将key移动到另一个数据库。 语法： MOVE key db OBJECT ENCODING 返回Redis对象的内部编码。（查看key的数据结构） 语法： OBJECT ENCODING key OBJECT FREQ 返回一个Redis对象的对数访问频率计数器。 语法： OBJECT FREQ key OBJECT IDLETIME 返回上一次访问Redis对象后的时间（秒）。 语法： OBJECT IDLETIME key 示例： # 距离上一次访问name经过了多少秒 127.0.0.1:6379\u0026gt; OBJECT idletime name (integer) 141 127.0.0.1:6379\u0026gt; OBJECT idletime name (integer) 147 127.0.0.1:6379\u0026gt; OBJECT idletime name (integer) 149 OBJECT REFCOUNT 返回key值的引用计数。 语法： OBJECT REFCOUNT key 示例： 127.0.0.1:6379\u0026gt; OBJECT REFCOUNT name (integer) 1 PERSIST 删除key的过期时间。 语法： PERSIST key 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; EXPIRE mykey 10 (integer) 1 redis\u0026gt; TTL mykey (integer) 10 redis\u0026gt; PERSIST mykey (integer) 1 redis\u0026gt; TTL mykey (integer) -1 PEXPIRE 以毫秒为单位设置key的过期时间。 语法： PEXPIRE key milliseconds [NX | XX | GT | LT] NX - 仅当key没有过期时间时有效。\nXX - 仅当key有过期时间时有效。\nGT - 仅当新过期时间大于当前过期时间时有效。\nLT - 仅当新过期时间小于当前过期时间时有效。\n示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; PEXPIRE mykey 1500 (integer) 1 redis\u0026gt; TTL mykey (integer) 2 redis\u0026gt; PTTL mykey (integer) 1499 redis\u0026gt; PEXPIRE mykey 1000 XX (integer) 1 redis\u0026gt; TTL mykey (integer) 1 redis\u0026gt; PEXPIRE mykey 1000 NX (integer) 0 redis\u0026gt; TTL mykey (integer) 1 PEXPIREAT 将key的过期时间设置为Unix毫秒时间戳。 语法： PEXPIREAT key unix-time-milliseconds [NX | XX | GT | LT] NX - 仅当key没有过期时间时有效。\nXX - 仅当key有过期时间时有效。\nGT - 仅当新过期时间大于当前过期时间时有效。\nLT - 仅当新过期时间小于当前过期时间时有效。\n示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; PEXPIREAT mykey 1555555555005 (integer) 1 redis\u0026gt; TTL mykey (integer) -2 redis\u0026gt; PTTL mykey (integer) -2 PEXPIRETIME 以Unix毫秒时间戳的形式返回key的过期时间。\n语法：\nPEXPIRETIME key 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; PEXPIREAT mykey 33177117420000 (integer) 1 redis\u0026gt; PEXPIRETIME mykey (integer) 33177117420000 PTTL 以毫秒为单位返回key的过期时间。\n语法：\nPTTL key 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; EXPIRE mykey 1 (integer) 1 redis\u0026gt; PTTL mykey (integer) 999 RANDOMKEY 从数据库返回一个随机的key名。\n语法：\nRANDOMKEY 示例： [root@hcss-ecs-7943 ~]# docker exec -it redis redis-cli 127.0.0.1:6379\u0026gt; RANDOMKEY \u0026#34;name\u0026#34; RENAME 重命名key并覆盖目标。\n语法：\nRENAME key newkey 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; RENAME mykey myotherkey \u0026#34;OK\u0026#34; redis\u0026gt; GET myotherkey \u0026#34;Hello\u0026#34; RENAMENX 仅当目标key名（newkey）不存在时才重命名key。\n语法：\nRENAMENX key newkey 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; SET myotherkey \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; RENAMENX mykey myotherkey (integer) 0 redis\u0026gt; GET myotherkey \u0026#34;World\u0026#34; RESTORE 从值的序列化表示创建key。\n语法：\nRESTORE key ttl serialized-value [REPLACE] [ABSTTL] [IDLETIME seconds] [FREQ frequency] 示例： redis\u0026gt; DEL mykey 0 redis\u0026gt; RESTORE mykey 0 \u0026#34;\\n\\x17\\x17\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x03\\x00\\ x00\\xc0\\x01\\x00\\x04\\xc0\\x02\\x00\\x04\\xc0\\x03\\x00\\ xff\\x04\\x00u#\u0026lt;\\xc0;.\\xe9\\xdd\u0026#34; OK redis\u0026gt; TYPE mykey list redis\u0026gt; LRANGE mykey 0 -1 1) \u0026#34;1\u0026#34; 2) \u0026#34;2\u0026#34; 3) \u0026#34;3\u0026#34; SCAN 遍历数据库中的key名。\n语法：\nSCAN cursor [MATCH pattern] [COUNT count] [TYPE type] 示例： redis 127.0.0.1:6379\u0026gt; scan 0 1) \u0026#34;17\u0026#34; 2) 1) \u0026#34;key:12\u0026#34; 2) \u0026#34;key:8\u0026#34; 3) \u0026#34;key:4\u0026#34; 4) \u0026#34;key:14\u0026#34; 5) \u0026#34;key:16\u0026#34; 6) \u0026#34;key:17\u0026#34; 7) \u0026#34;key:15\u0026#34; 8) \u0026#34;key:10\u0026#34; 9) \u0026#34;key:3\u0026#34; 10) \u0026#34;key:7\u0026#34; 11) \u0026#34;key:1\u0026#34; redis 127.0.0.1:6379\u0026gt; scan 17 1) \u0026#34;0\u0026#34; 2) 1) \u0026#34;key:5\u0026#34; 2) \u0026#34;key:18\u0026#34; 3) \u0026#34;key:0\u0026#34; 4) \u0026#34;key:2\u0026#34; 5) \u0026#34;key:19\u0026#34; 6) \u0026#34;key:13\u0026#34; 7) \u0026#34;key:6\u0026#34; 8) \u0026#34;key:9\u0026#34; 9) \u0026#34;key:11\u0026#34; SORT 对列表、集合或已排序集合中的元素进行排序，并可选择存储结果。\n语法：\nSORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern ...]] [ASC | DESC] [ALPHA] [STORE destination] SORT_RO 返回列表、集合或已排序集合的已排序元素。\n语法：\nSORT_RO key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern ...]] [ASC | DESC] [ALPHA] 示例： SORT_RO mylist BY weight_*-\u0026gt;fieldname GET object_*-\u0026gt;fieldname TOUCH 在更新最后一次访问key的时间后，返回指定键中现有key的个数。\n语法：\nTOUCH key [key ...] 示例： redis\u0026gt; SET key1 \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; SET key2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; TOUCH key1 key2 (integer) 2 TTL 以秒为单位返回key的过期时间。\n语法：\nTTL key 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; EXPIRE mykey 10 (integer) 1 redis\u0026gt; TTL mykey (integer) 10 TYPE 确定存储在key中的值的类型。\n语法：\nTYPE key 示例： redis\u0026gt; SET key1 \u0026#34;value\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; LPUSH key2 \u0026#34;value\u0026#34; (integer) 1 redis\u0026gt; SADD key3 \u0026#34;value\u0026#34; (integer) 1 redis\u0026gt; TYPE key1 \u0026#34;string\u0026#34; redis\u0026gt; TYPE key2 \u0026#34;list\u0026#34; redis\u0026gt; TYPE key3 \u0026#34;set\u0026#34; UNLINK 异步删除一个或多个key。\n语法：\nUNLINK key [key ...] 示例： redis\u0026gt; SET key1 \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; SET key2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; UNLINK key1 key2 key3 (integer) 2 WAIT 阻塞，直到连接发送的上述所有写命令的异步复制完成。\n语法：\nWAIT numreplicas timeout 示例： \u0026gt; SET foo bar OK \u0026gt; WAIT 1 0 (integer) 1 \u0026gt; WAIT 2 1000 (integer) 1 WAITAOF 阻塞，直到连接发送的所有上述写命令都被写入主服务器和/或副本的仅追加文件。\n语法：\nWAITAOF numlocal numreplicas timeout 示例： \u0026gt; SET foo bar OK \u0026gt; WAITAOF 1 0 0 1) (integer) 1 2) (integer) 0 \u0026gt; WAITAOF 0 1 1000 1) (integer) 1 2) (integer) 0 ","permalink":"https://heliu.site/posts/redis/command/","summary":"redis 命令介绍。","title":"redis 通用命令"},{"content":" 官网命令地址：https://redis.io/commands/?group=string。 redis客户端查询命令：help @string string string类型，也就是字符串类型，是Redis中最简单的存储类型。 其value是字符串，不过根据字符串的格式不同，又可以分为3类： string：普通字符串。 int：整数类型，可以做自增，自减操作。 float：浮点类型，可以做自增.自减操作。 KEY Value message hello world number 18 score 87.6 APPEND 将字符串附加到key的值。如果key不存在，则创建该key。\n语法：\nAPPEND key value 示例： redis\u0026gt; EXISTS mykey (integer) 0 redis\u0026gt; APPEND mykey \u0026#34;Hello\u0026#34; (integer) 5 redis\u0026gt; APPEND mykey \u0026#34; World\u0026#34; (integer) 11 redis\u0026gt; GET mykey \u0026#34;Hello World\u0026#34; DECR 将key的整数值减1。如果key不存在，则使用0作为初始值。\n语法：\nDECR key 示例： redis\u0026gt; SET mykey \u0026#34;10\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; DECR mykey (integer) 9 redis\u0026gt; SET mykey \u0026#34;234293482390480948029348230948\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; DECR mykey (error) value is not an integer or out of range DECRBY 从key的整数值中减去一个数字。如果key不存在，则使用0作为初始值。\n语法：\nDECRBY key decrement 示例： redis\u0026gt; SET mykey \u0026#34;10\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; DECRBY mykey 3 (integer) 7 GET 返回key的字符串值。\n语法：\nGET key 示例： redis\u0026gt; GET nonexisting (nil) redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; GET mykey \u0026#34;Hello\u0026#34; Go代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package example_commands_test import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; ) func ExampleClient_Set_and_get() { ctx := context.Background() rdb := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;localhost:6379\u0026#34;, Password: \u0026#34;\u0026#34;, // no password docs DB: 0, // use default DB }) err := rdb.Set(ctx, \u0026#34;bike:1\u0026#34;, \u0026#34;Process 134\u0026#34;, 0).Err() if err != nil { panic(err) } fmt.Println(\u0026#34;OK\u0026#34;) value, err := rdb.Get(ctx, \u0026#34;bike:1\u0026#34;).Result() if err != nil { panic(err) } fmt.Printf(\u0026#34;The name of the bike is %s\u0026#34;, value) } GETDEL 在删除key后返回key的字符串值。\n语法：\nGETDEL key 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; GETDEL mykey \u0026#34;Hello\u0026#34; redis\u0026gt; GET mykey (nil) GETEX 在设置key的过期时间后返回key的字符串值。\n语法：\nGETEX key [EX seconds | PX milliseconds | EXAT unix-time-seconds | PXAT unix-time-milliseconds | PERSIST] EX seconds \u0026ndash; 设置指定的过期时间，以秒为单位。 PX milliseconds \u0026ndash; 设置指定的过期时间，以毫秒为单位。 EXAT timestamp-seconds \u0026ndash; 设置key到期的指定Unix时间，以秒为单位。 PXAT timestamp-milliseconds \u0026ndash; 设置key到期的指定Unix时间，以毫秒为单位。 PERSIST \u0026ndash; 删除与该key关联的生存时间。 示例： redis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; GETEX mykey \u0026#34;Hello\u0026#34; redis\u0026gt; TTL mykey (integer) -1 redis\u0026gt; GETEX mykey EX 60 \u0026#34;Hello\u0026#34; redis\u0026gt; TTL mykey (integer) 60 GETRANGE 返回存储在key中的字符串的子字符串。\n语法：\nGETRANGE key start end 示例： redis\u0026gt; SET mykey \u0026#34;This is a string\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; GETRANGE mykey 0 3 \u0026#34;This\u0026#34; redis\u0026gt; GETRANGE mykey -3 -1 \u0026#34;ing\u0026#34; redis\u0026gt; GETRANGE mykey 0 -1 \u0026#34;This is a string\u0026#34; redis\u0026gt; GETRANGE mykey 10 100 \u0026#34;string\u0026#34; GETSET 将key设置为新值后返回key的前一个字符串值。\n语法：\nGETSET key value 示例： redis\u0026gt; INCR mycounter (integer) 1 redis\u0026gt; GETSET mycounter \u0026#34;0\u0026#34; \u0026#34;1\u0026#34; redis\u0026gt; GET mycounter \u0026#34;0\u0026#34; INCR 将key的整数值加1。如果key不存在，则使用0作为初始值。\n语法：\nINCR key 示例： redis\u0026gt; SET mykey \u0026#34;10\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; INCR mykey (integer) 11 redis\u0026gt; GET mykey \u0026#34;11\u0026#34; INCRBY 将key的整数值增加一个数字。如果key不存在，则使用0作为初始值。\n语法：\nINCRBY key increment 示例： redis\u0026gt; SET mykey \u0026#34;10\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; INCRBY mykey 5 (integer) 15 INCRBYFLOAT 将key的浮点值增加一个数字。如果key不存在，则使用0作为初始值。\n语法：\nINCRBYFLOAT key increment 示例： redis\u0026gt; SET mykey 10.50 \u0026#34;OK\u0026#34; redis\u0026gt; INCRBYFLOAT mykey 0.1 \u0026#34;10.6\u0026#34; redis\u0026gt; INCRBYFLOAT mykey -5 \u0026#34;5.6\u0026#34; redis\u0026gt; SET mykey 5.0e3 \u0026#34;OK\u0026#34; redis\u0026gt; INCRBYFLOAT mykey 2.0e2 \u0026#34;5200\u0026#34; LCS 查找最长的公共子字符串。\n语法：\nLCS key1 key2 [LEN] [IDX] [MINMATCHLEN min-match-len] [WITHMATCHLEN] 示例： \u0026gt; MSET key1 ohmytext key2 mynewtext OK \u0026gt; LCS key1 key2 \u0026#34;mytext\u0026#34; \u0026gt; LCS key1 key2 LEN (integer) 6 \u0026gt; LCS key1 key2 IDX 1) \u0026#34;matches\u0026#34; 2) 1) 1) 1) (integer) 4 1) (integer) 7 1) 1) (integer) 5 1) (integer) 8 2) 1) 1) (integer) 2 2) (integer) 3 1) 1) (integer) 0 1) (integer) 1 3) \u0026#34;len\u0026#34; 4) (integer) 6 MGET 自动返回一个或多个key的字符串值。\n语法：\nMGET key [key ...] 示例： redis\u0026gt; SET key1 \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; SET key2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; MGET key1 key2 nonexisting 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;World\u0026#34; 3) (nil) MSET 自动创建或修改一个或多个key的字符串值。\n语法：\nMSET key value [key value ...] 示例： redis\u0026gt; MSET key1 \u0026#34;Hello\u0026#34; key2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; GET key1 \u0026#34;Hello\u0026#34; redis\u0026gt; GET key2 \u0026#34;World\u0026#34; MSETNX 仅在不存在所有key时才自动修改一个或多个key的字符串值。（仅当key不存在时才会设置value）\n语法：\nMSETNX key value [key value ...] 示例： redis\u0026gt; MSETNX key1 \u0026#34;Hello\u0026#34; key2 \u0026#34;there\u0026#34; (integer) 1 redis\u0026gt; MSETNX key2 \u0026#34;new\u0026#34; key3 \u0026#34;world\u0026#34; (integer) 0 redis\u0026gt; MGET key1 key2 key3 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;there\u0026#34; 3) (nil) PSETEX 设置key的字符串值和过期时间(以毫秒为单位)。如果key不存在，则创建该key。\n语法：\nPSETEX key milliseconds value 示例： redis\u0026gt; PSETEX mykey 1000 \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; PTTL mykey (integer) 998 redis\u0026gt; GET mykey \u0026#34;Hello\u0026#34; SET 设置key的字符串值，忽略其类型。如果key不存在，则创建该key。\n语法：\nSET key value [NX | XX] [GET] [EX seconds | PX milliseconds | EXAT unix-time-seconds | PXAT unix-time-milliseconds | KEEPTTL] EX seconds \u0026ndash; 设置指定的过期时间，单位为秒(正整数)。 PX milliseconds \u0026ndash; 设置指定的过期时间，单位为毫秒(正整数)。 EXAT timestamp-seconds \u0026ndash; 设置key到期的指定Unix时间，以秒为单位(一个正整数)。 PXAT timestamp-milliseconds \u0026ndash; 设置key到期的指定Unix时间，以毫秒为单位(正整数)。 NX \u0026ndash; 仅在key不存在时设置该key。 XX \u0026ndash; 只有当key已经存在时才设置它。 KEEPTTL \u0026ndash; 保留与该key关联的生存时间。 GET \u0026ndash; 返回存储在key处的旧字符串，如果key不存在则返回nil。如果存储在key处的值不是字符串，则返回错误并终止\u0026rsquo; SET \u0026lsquo;。 注意:由于SET命令选项可以取代SETNX, SETEX, PSETEX, GETSET，在Redis的未来版本中，这些命令可能会被弃用并最终被删除。\n示例：\nredis\u0026gt; SET mykey \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; GET mykey \u0026#34;Hello\u0026#34; redis\u0026gt; SET anotherkey \u0026#34;will expire in a minute\u0026#34; EX 60 \u0026#34;OK\u0026#34; Go代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package example_commands_test import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/redis/go-redis/v9\u0026#34; ) func ExampleClient_Set_and_get() { ctx := context.Background() rdb := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;localhost:6379\u0026#34;, Password: \u0026#34;\u0026#34;, // no password docs DB: 0, // use default DB }) err := rdb.Set(ctx, \u0026#34;bike:1\u0026#34;, \u0026#34;Process 134\u0026#34;, 0).Err() if err != nil { panic(err) } fmt.Println(\u0026#34;OK\u0026#34;) value, err := rdb.Get(ctx, \u0026#34;bike:1\u0026#34;).Result() if err != nil { panic(err) } fmt.Printf(\u0026#34;The name of the bike is %s\u0026#34;, value) } SETEX 设置key的字符串值和过期时间。如果key不存在，则创建该key。\n语法：等价于SET key value EX seconds\nSETEX key seconds value 示例： redis\u0026gt; SETEX mykey 10 \u0026#34;Hello\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; TTL mykey (integer) 10 redis\u0026gt; GET mykey \u0026#34;Hello\u0026#34; SETNX 仅当key不存在时才设置该key的字符串值。\n语法：\nSETNX key value 示例： redis\u0026gt; SETNX mykey \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; SETNX mykey \u0026#34;World\u0026#34; (integer) 0 redis\u0026gt; GET mykey \u0026#34;Hello\u0026#34; SETRANGE 将字符串值的一部分以偏移量覆盖另一部分。如果key不存在，则创建该key。\n语法：\nSETRANGE key offset value 示例： redis\u0026gt; SET key1 \u0026#34;Hello World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; SETRANGE key1 6 \u0026#34;Redis\u0026#34; (integer) 11 redis\u0026gt; GET key1 \u0026#34;Hello Redis\u0026#34; redis\u0026gt; SETRANGE key2 6 \u0026#34;Redis\u0026#34; (integer) 11 redis\u0026gt; GET key2 \u0026#34;Redis\u0026#34; STRLEN 返回字符串值的长度。\n语法：\nSTRLEN key 示例： redis\u0026gt; SET mykey \u0026#34;Hello world\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; STRLEN mykey (integer) 11 redis\u0026gt; STRLEN nonexisting (integer) 0 SUBSTR 从字符串值返回子字符串。\n语法：\nSUBSTR key start end 示例： redis\u0026gt; SET mykey \u0026#34;This is a string\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; GETRANGE mykey 0 3 \u0026#34;This\u0026#34; redis\u0026gt; GETRANGE mykey -3 -1 \u0026#34;ing\u0026#34; redis\u0026gt; GETRANGE mykey 0 -1 \u0026#34;This is a string\u0026#34; redis\u0026gt; GETRANGE mykey 10 100 \u0026#34;string\u0026#34; ","permalink":"https://heliu.site/posts/redis/string/","summary":"redis string介绍。","title":"redis string"},{"content":" 官网命令地址：https://redis.io/commands/?group=hash redis客户端查询命令：help @hash hash Hash类型，也叫散列，其value是一个无序字典，类似于go中的map结构。 String结构是将对象序列化为JSON字符串后存储，当需要修改对象某个字段时很不方便。 KEY Value re:user:1001 {name:\u0026ldquo;JK\u0026rdquo;, age: 18} re:user:1002 {name:\u0026ldquo;Re\u0026rdquo;, age: 14} Hash结构可以将对象中的每个字段独立存储，可以针对单个字段做CRUD。 HDEL 从hash中删除一个或多个字段及其值。如果没有字段保留，则删除hash。\n语法：\nHDEL key field [field ...] 示例： redis\u0026gt; HSET myhash field1 \u0026#34;foo\u0026#34; (integer) 1 redis\u0026gt; HDEL myhash field1 (integer) 1 redis\u0026gt; HDEL myhash field2 (integer) 0 HEXISTS 确定一个字段是否存在于hash中。\n语法：\nHEXISTS key field 示例： redis\u0026gt; HSET myhash field1 \u0026#34;foo\u0026#34; (integer) 1 redis\u0026gt; HEXISTS myhash field1 (integer) 1 redis\u0026gt; HEXISTS myhash field2 (integer) 0 HGET 返回hash中某个字段的值。\n语法：\nHGET key field 示例： redis\u0026gt; HSET myhash field1 \u0026#34;foo\u0026#34; (integer) 1 redis\u0026gt; HGET myhash field1 \u0026#34;foo\u0026#34; redis\u0026gt; HGET myhash field2 (nil) HGETALL 返回hash中的所有字段和值。\n语法：\nHGETALL key 语法： redis\u0026gt; HSET myhash field1 \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; HSET myhash field2 \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; HGETALL myhash 1) \u0026#34;field1\u0026#34; 2) \u0026#34;Hello\u0026#34; 3) \u0026#34;field2\u0026#34; 4) \u0026#34;World\u0026#34; HINCRBY 将hash中字段的整数值增加一个数字。如果字段不存在，则使用0作为初始值。\n语法：\nHINCRBY key field increment 示例： redis\u0026gt; HSET myhash field 5 (integer) 1 redis\u0026gt; HINCRBY myhash field 1 (integer) 6 redis\u0026gt; HINCRBY myhash field -1 (integer) 5 redis\u0026gt; HINCRBY myhash field -10 (integer) -5 HINCRBYFLOAT 将字段的浮点值增加一个数字。如果字段不存在，则使用0作为初始值。\n语法：\nHINCRBYFLOAT key field increment 示例： redis\u0026gt; HSET mykey field 10.50 (integer) 1 redis\u0026gt; HINCRBYFLOAT mykey field 0.1 \u0026#34;10.6\u0026#34; redis\u0026gt; HINCRBYFLOAT mykey field -5 \u0026#34;5.6\u0026#34; redis\u0026gt; HSET mykey field 5.0e3 (integer) 0 redis\u0026gt; HINCRBYFLOAT mykey field 2.0e2 \u0026#34;5200\u0026#34; HKEYS 以hash形式返回所有字段。\n语法：\nHKEYS key 示例： redis\u0026gt; HSET myhash field1 \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; HSET myhash field2 \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; HKEYS myhash 1) \u0026#34;field1\u0026#34; 2) \u0026#34;field2\u0026#34; HLEN 返回hash中的字段数。\n语法：\nHLEN key 示例： redis\u0026gt; HSET myhash field1 \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; HSET myhash field2 \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; HLEN myhash (integer) 2 HMGET 返回hash中所有字段的值。\n语法：\nHMGET key field [field ...] 示例： redis\u0026gt; HSET myhash field1 \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; HSET myhash field2 \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; HMGET myhash field1 field2 nofield 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;World\u0026#34; 3) (nil) HMSET 设置多个字段的值。\n语法：\nHMSET key field value [field value ...] 示例： redis\u0026gt; HMSET myhash field1 \u0026#34;Hello\u0026#34; field2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; HGET myhash field1 \u0026#34;Hello\u0026#34; redis\u0026gt; HGET myhash field2 \u0026#34;World\u0026#34; HRANDFIELD 从hash中返回一个或多个随机字段。\n语法：\nHRANDFIELD key [count [WITHVALUES]] 示例： redis\u0026gt; HSET coin heads obverse tails reverse edge null (integer) 3 redis\u0026gt; HRANDFIELD coin \u0026#34;heads\u0026#34; redis\u0026gt; HRANDFIELD coin \u0026#34;heads\u0026#34; redis\u0026gt; HRANDFIELD coin -5 WITHVALUES 1) \u0026#34;tails\u0026#34; 2) \u0026#34;reverse\u0026#34; 3) \u0026#34;edge\u0026#34; 4) \u0026#34;null\u0026#34; 5) \u0026#34;heads\u0026#34; 6) \u0026#34;obverse\u0026#34; 7) \u0026#34;heads\u0026#34; 8) \u0026#34;obverse\u0026#34; 9) \u0026#34;tails\u0026#34; 10) \u0026#34;reverse\u0026#34; HSCAN 遍历hash的字段和值。\n语法：\nHSCAN key cursor [MATCH pattern] [COUNT count] HSET 创建或修改hash中某个字段的值。\n语法：\nHSET key field value [field value ...] 示例： redis\u0026gt; HSET myhash field1 \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; HGET myhash field1 \u0026#34;Hello\u0026#34; redis\u0026gt; HSET myhash field2 \u0026#34;Hi\u0026#34; field3 \u0026#34;World\u0026#34; (integer) 2 redis\u0026gt; HGET myhash field2 \u0026#34;Hi\u0026#34; redis\u0026gt; HGET myhash field3 \u0026#34;World\u0026#34; redis\u0026gt; HGETALL myhash 1) \u0026#34;field1\u0026#34; 2) \u0026#34;Hello\u0026#34; 3) \u0026#34;field2\u0026#34; 4) \u0026#34;Hi\u0026#34; 5) \u0026#34;field3\u0026#34; 6) \u0026#34;World\u0026#34; HSETNX 仅当字段不存在时，才在hash中设置字段的值。\n语法：\nHSETNX key field value 示例： redis\u0026gt; HSETNX myhash field \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; HSETNX myhash field \u0026#34;World\u0026#34; (integer) 0 redis\u0026gt; HGET myhash field \u0026#34;Hello\u0026#34; HSTRLEN 返回字段值的长度。\n语法：\nHSTRLEN key field 示例： redis\u0026gt; HSET myhash f1 HelloWorld f2 99 f3 -256 (integer) 3 redis\u0026gt; HSTRLEN myhash f1 (integer) 10 redis\u0026gt; HSTRLEN myhash f2 (integer) 2 redis\u0026gt; HSTRLEN myhash f3 (integer) 4 HVALS 返回hash中的所有值。\n语法：\nHVALS key 示例： redis\u0026gt; HSET myhash field1 \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; HSET myhash field2 \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; HVALS myhash 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;World\u0026#34; ","permalink":"https://heliu.site/posts/redis/hash/","summary":"redis hash介绍。","title":"redis hash"},{"content":" 官方文档地址：https://redis.io/commands/?group=list redis客户端查询命令：help @list list Redis中的List类型是一个双向链表结构。既可以支持正向检索和也可以支持反向检索。 特点是：有序、元素可以重复、插入和删除快、查询速度一般。 常用来存储一个有序数据，例如：朋友圈点赞列表，评论列表等。 BLMOVE 从list中弹出一个元素，将其推入另一个list并返回。阻塞，直到元素可用为止。如果最后一个元素被移动，则删除list。\n语法：\nBLMOVE source destination \u0026lt;LEFT | RIGHT\u0026gt; \u0026lt;LEFT | RIGHT\u0026gt; timeout BLMPOP 从多个list中弹出第一个元素。阻塞，直到元素可用为止。如果弹出最后一个元素，则删除list。\n语法：\nBLMPOP timeout numkeys key [key ...] \u0026lt;LEFT | RIGHT\u0026gt; [COUNT count] BLPOP 移除并返回list中的第一个元素。阻塞，直到元素可用为止。如果弹出最后一个元素，则删除list。\n语法：\nBLPOP key [key ...] timeout 示例： redis\u0026gt; DEL list1 list2 (integer) 0 redis\u0026gt; RPUSH list1 a b c (integer) 3 redis\u0026gt; BLPOP list1 list2 0 1) \u0026#34;list1\u0026#34; 2) \u0026#34;a\u0026#34; BRPOP 移除并返回list中的最后一个元素。阻塞，直到元素可用为止。如果弹出最后一个元素，则删除list。\n语法：\nBRPOP key [key ...] timeout 示例： redis\u0026gt; DEL list1 list2 (integer) 0 redis\u0026gt; RPUSH list1 a b c (integer) 3 redis\u0026gt; BRPOP list1 list2 0 1) \u0026#34;list1\u0026#34; 2) \u0026#34;c\u0026#34; BRPOPLPUSH 从list中弹出一个元素，将其推入另一个list并返回。阻塞，直到元素可用为止。如果弹出最后一个元素，则删除list。\n语法：\nBRPOPLPUSH source destination timeout LINDEX 根据索引从list中返回一个元素。\n语法：\nLINDEX key index 示例： redis\u0026gt; LPUSH mylist \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; LPUSH mylist \u0026#34;Hello\u0026#34; (integer) 2 redis\u0026gt; LINDEX mylist 0 \u0026#34;Hello\u0026#34; redis\u0026gt; LINDEX mylist -1 \u0026#34;World\u0026#34; redis\u0026gt; LINDEX mylist 3 (nil) LINSERT 将一个元素插入list中另一个元素之前或之后。\n语法：\nLINSERT key \u0026lt;BEFORE | AFTER\u0026gt; pivot element 示例： redis\u0026gt; RPUSH mylist \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;World\u0026#34; (integer) 2 redis\u0026gt; LINSERT mylist BEFORE \u0026#34;World\u0026#34; \u0026#34;There\u0026#34; (integer) 3 redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;There\u0026#34; 3) \u0026#34;World\u0026#34; LLEN Returns the length of a list.\n返回list的长度。\n语法：\nLLEN key 示例： redis\u0026gt; LPUSH mylist \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; LPUSH mylist \u0026#34;Hello\u0026#34; (integer) 2 redis\u0026gt; LLEN mylist (integer) 2 LMOVE 从一个list中弹出元素并将其压入另一个list后返回该元素。如果最后一个元素被移动，则删除list。\n语法：\nLMOVE source destination \u0026lt;LEFT | RIGHT\u0026gt; \u0026lt;LEFT | RIGHT\u0026gt; 示例： redis\u0026gt; RPUSH mylist \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;two\u0026#34; (integer) 2 redis\u0026gt; RPUSH mylist \u0026#34;three\u0026#34; (integer) 3 redis\u0026gt; LMOVE mylist myotherlist RIGHT LEFT \u0026#34;three\u0026#34; redis\u0026gt; LMOVE mylist myotherlist LEFT RIGHT \u0026#34;one\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;two\u0026#34; redis\u0026gt; LRANGE myotherlist 0 -1 1) \u0026#34;three\u0026#34; 2) \u0026#34;one\u0026#34; LMPOP 从list中删除多个元素后返回它们。如果弹出最后一个元素，则删除list。\n语法：\nLMPOP numkeys key [key ...] \u0026lt;LEFT | RIGHT\u0026gt; [COUNT count] 示例： redis\u0026gt; LMPOP 2 non1 non2 LEFT COUNT 10 (error) object of type \u0026#39;NoneType\u0026#39; has no len() redis\u0026gt; LPUSH mylist \u0026#34;one\u0026#34; \u0026#34;two\u0026#34; \u0026#34;three\u0026#34; \u0026#34;four\u0026#34; \u0026#34;five\u0026#34; (integer) 5 redis\u0026gt; LMPOP 1 mylist LEFT 1) \u0026#34;mylist\u0026#34; 2) 1) \u0026#34;five\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;four\u0026#34; 2) \u0026#34;three\u0026#34; 3) \u0026#34;two\u0026#34; 4) \u0026#34;one\u0026#34; redis\u0026gt; LMPOP 1 mylist RIGHT COUNT 10 1) \u0026#34;mylist\u0026#34; 2) 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; 4) \u0026#34;four\u0026#34; redis\u0026gt; LPUSH mylist \u0026#34;one\u0026#34; \u0026#34;two\u0026#34; \u0026#34;three\u0026#34; \u0026#34;four\u0026#34; \u0026#34;five\u0026#34; (integer) 5 redis\u0026gt; LPUSH mylist2 \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34; \u0026#34;d\u0026#34; \u0026#34;e\u0026#34; (integer) 5 redis\u0026gt; LMPOP 2 mylist mylist2 right count 3 1) \u0026#34;mylist\u0026#34; 2) 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;five\u0026#34; 2) \u0026#34;four\u0026#34; redis\u0026gt; LMPOP 2 mylist mylist2 right count 5 1) \u0026#34;mylist\u0026#34; 2) 1) \u0026#34;four\u0026#34; 2) \u0026#34;five\u0026#34; redis\u0026gt; LMPOP 2 mylist mylist2 right count 10 1) \u0026#34;mylist2\u0026#34; 2) 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34; 4) \u0026#34;d\u0026#34; 5) \u0026#34;e\u0026#34; redis\u0026gt; EXISTS mylist mylist2 (integer) 0 LPOP Returns the first elements in a list after removing it. Deletes the list if the last element was popped.\n返回删除list后的第一个元素。如果弹出最后一个元素，则删除list。\n语法：\nLPOP key [count] 示例： redis\u0026gt; RPUSH mylist \u0026#34;one\u0026#34; \u0026#34;two\u0026#34; \u0026#34;three\u0026#34; \u0026#34;four\u0026#34; \u0026#34;five\u0026#34; (integer) 5 redis\u0026gt; LPOP mylist \u0026#34;one\u0026#34; redis\u0026gt; LPOP mylist 2 1) \u0026#34;two\u0026#34; 2) \u0026#34;three\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;four\u0026#34; 2) \u0026#34;five\u0026#34; LPOS 返回list中匹配元素的索引。 语法： LPOS key element [RANK rank] [COUNT num-matches] [MAXLEN len] 示例： redis\u0026gt; RPUSH mylist a b c d 1 2 3 4 3 3 3 (integer) 11 redis\u0026gt; LPOS mylist 3 (integer) 6 redis\u0026gt; LPOS mylist 3 COUNT 0 RANK 2 1) (integer) 8 2) (integer) 9 3) (integer) 10 LPUSH 将一个或多个元素添加到list中。如果键不存在，则创建该键。\n语法：\nLPUSH key element [element ...] 示例： redis\u0026gt; LPUSH mylist \u0026#34;world\u0026#34; (integer) 1 redis\u0026gt; LPUSH mylist \u0026#34;hello\u0026#34; (integer) 2 redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;hello\u0026#34; 2) \u0026#34;world\u0026#34; LPUSHX 仅当list存在时，将一个或多个元素添加到list中。\n语法：\nLPUSHX key element [element ...] 示例： redis\u0026gt; LPUSH mylist \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; LPUSHX mylist \u0026#34;Hello\u0026#34; (integer) 2 redis\u0026gt; LPUSHX myotherlist \u0026#34;Hello\u0026#34; (integer) 0 redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;World\u0026#34; redis\u0026gt; LRANGE myotherlist 0 -1 (empty array) LRANGE 返回list中的元素范围。\n语法：\nLRANGE key start stop 示例： redis\u0026gt; RPUSH mylist \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;two\u0026#34; (integer) 2 redis\u0026gt; RPUSH mylist \u0026#34;three\u0026#34; (integer) 3 redis\u0026gt; LRANGE mylist 0 0 1) \u0026#34;one\u0026#34; redis\u0026gt; LRANGE mylist -3 2 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; redis\u0026gt; LRANGE mylist -100 100 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; redis\u0026gt; LRANGE mylist 5 10 (empty array) LREM 从list中删除元素。如果最后一个元素被删除，则删除list。\n语法：\nLREM key count element 示例： redis\u0026gt; RPUSH mylist \u0026#34;hello\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;hello\u0026#34; (integer) 2 redis\u0026gt; RPUSH mylist \u0026#34;foo\u0026#34; (integer) 3 redis\u0026gt; RPUSH mylist \u0026#34;hello\u0026#34; (integer) 4 redis\u0026gt; LREM mylist -2 \u0026#34;hello\u0026#34; (integer) 2 redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;hello\u0026#34; 2) \u0026#34;foo\u0026#34; LSET 根据list中元素的索引设置元素的值。\n语法：\nLSET key index element 示例： redis\u0026gt; RPUSH mylist \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;two\u0026#34; (integer) 2 redis\u0026gt; RPUSH mylist \u0026#34;three\u0026#34; (integer) 3 redis\u0026gt; LSET mylist 0 \u0026#34;four\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; LSET mylist -2 \u0026#34;five\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;four\u0026#34; 2) \u0026#34;five\u0026#34; 3) \u0026#34;three\u0026#34; LTRIM 从list两端移除元素。如果所有元素都被修剪，则删除list。\n语法：\nLTRIM key start stop 示例： redis\u0026gt; RPUSH mylist \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;two\u0026#34; (integer) 2 redis\u0026gt; RPUSH mylist \u0026#34;three\u0026#34; (integer) 3 redis\u0026gt; LTRIM mylist 1 -1 \u0026#34;OK\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;two\u0026#34; 2) \u0026#34;three\u0026#34; RPOP 返回并删除list的最后一个元素。如果弹出最后一个元素，则删除list。\n语法：\nRPOP key [count] 示例： redis\u0026gt; RPUSH mylist \u0026#34;one\u0026#34; \u0026#34;two\u0026#34; \u0026#34;three\u0026#34; \u0026#34;four\u0026#34; \u0026#34;five\u0026#34; (integer) 5 redis\u0026gt; RPOP mylist \u0026#34;five\u0026#34; redis\u0026gt; RPOP mylist 2 1) \u0026#34;four\u0026#34; 2) \u0026#34;three\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; RPOPLPUSH 将list的最后一个元素移除并压入另一个list后返回该元素。如果弹出最后一个元素，则删除list。\n语法：\nRPOPLPUSH source destination 示例： redis\u0026gt; RPUSH mylist \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;two\u0026#34; (integer) 2 redis\u0026gt; RPUSH mylist \u0026#34;three\u0026#34; (integer) 3 redis\u0026gt; RPOPLPUSH mylist myotherlist \u0026#34;three\u0026#34; redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; redis\u0026gt; LRANGE myotherlist 0 -1 1) \u0026#34;three\u0026#34; RPUSH 将一个或多个元素附加到list中。如果键不存在，则创建该键。\n语法：\nRPUSH key element [element ...] 示例： redis\u0026gt; RPUSH mylist \u0026#34;hello\u0026#34; (integer) 1 redis\u0026gt; RPUSH mylist \u0026#34;world\u0026#34; (integer) 2 redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;hello\u0026#34; 2) \u0026#34;world\u0026#34; RPUSHX 仅当list存在时才将元素追加到list。\n语法：\nRPUSHX key element [element ...] 示例： redis\u0026gt; RPUSH mylist \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; RPUSHX mylist \u0026#34;World\u0026#34; (integer) 2 redis\u0026gt; RPUSHX myotherlist \u0026#34;World\u0026#34; (integer) 0 redis\u0026gt; LRANGE mylist 0 -1 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;World\u0026#34; redis\u0026gt; LRANGE myotherlist 0 -1 (empty array) ","permalink":"https://heliu.site/posts/redis/list/","summary":"redis list介绍。","title":"redis list"},{"content":" 官方命令地址：https://redis.io/commands/?group=set 客户端查看命令：help @set set set 类似go的map，但是value值是struct{}。它具备以下特征： 无序、元素不可重复、查找快、支持交集.并集.差集等功能 SADD 向set添加一个或多个成员。如果key不存在，则创建该key。\n语法：\nSADD key member [member ...] 示例： redis\u0026gt; SADD myset \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;World\u0026#34; (integer) 0 redis\u0026gt; SMEMBERS myset 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;World\u0026#34; SCARD 返回set中成员的数目。\n语法：\nSCARD key 示例： redis\u0026gt; SADD myset \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; SCARD myset (integer) 2 SDIFF 返回多个set的差值。\n语法：\nSDIFF key [key ...] 示例： redis\u0026gt; SADD key1 \u0026#34;a\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;b\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;e\u0026#34; (integer) 1 redis\u0026gt; SDIFF key1 key2 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; SDIFFSTORE 将多个set的差异存储在一个键中。\n语法：\nSDIFFSTORE destination key [key ...] 示例： redis\u0026gt; SADD key1 \u0026#34;a\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;b\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;e\u0026#34; (integer) 1 redis\u0026gt; SDIFFSTORE key key1 key2 (integer) 2 redis\u0026gt; SMEMBERS key 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; SINTER 返回多个set的交点。\n语法：\nSINTER key [key ...] 示例： redis\u0026gt; SADD key1 \u0026#34;a\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;b\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;e\u0026#34; (integer) 1 redis\u0026gt; SINTER key1 key2 1) \u0026#34;c\u0026#34; SINTERCARD 返回多个set相交的成员数。\n语法：\nSINTERCARD numkeys key [key ...] [LIMIT limit] 示例： redis\u0026gt; SADD key1 \u0026#34;a\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;b\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;e\u0026#34; (integer) 1 redis\u0026gt; SINTER key1 key2 1) \u0026#34;c\u0026#34; 2) \u0026#34;d\u0026#34; redis\u0026gt; SINTERCARD 2 key1 key2 (integer) 2 redis\u0026gt; SINTERCARD 2 key1 key2 LIMIT 1 (integer) 1 SINTERSTORE 在一个key中存储多个set的相交。\n语法：\nSINTERSTORE destination key [key ...] 示例： redis\u0026gt; SADD key1 \u0026#34;a\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;b\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;e\u0026#34; (integer) 1 redis\u0026gt; SINTERSTORE key key1 key2 (integer) 1 redis\u0026gt; SMEMBERS key 1) \u0026#34;c\u0026#34; SISMEMBER 确定成员是否属于set。\n语法：\nSISMEMBER key member 示例： redis\u0026gt; SADD myset \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; SISMEMBER myset \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; SISMEMBER myset \u0026#34;two\u0026#34; (integer) 0 SMEMBERS 返回set的所有成员。\n语法：\nSMEMBERS key 示例： redis\u0026gt; SADD myset \u0026#34;Hello\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;World\u0026#34; (integer) 1 redis\u0026gt; SMEMBERS myset 1) \u0026#34;Hello\u0026#34; 2) \u0026#34;World\u0026#34; SMISMEMBER 确定多个成员是否属于一个set。\n语法：\nSMISMEMBER key member [member ...] 示例： redis\u0026gt; SADD myset \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;one\u0026#34; (integer) 0 redis\u0026gt; SMISMEMBER myset \u0026#34;one\u0026#34; \u0026#34;notamember\u0026#34; 1) (integer) 1 2) (integer) 0 SMOVE 将一个成员从一个set移动到另一个set。\n语法：\nSMOVE source destination member 示例： redis\u0026gt; SADD myset \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; SADD myotherset \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; SMOVE myset myotherset \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; SMEMBERS myset 1) \u0026#34;one\u0026#34; redis\u0026gt; SMEMBERS myotherset 2) \u0026#34;three\u0026#34; 3) \u0026#34;two\u0026#34; SPOP 从set中删除一个或多个随机成员后返回它们。如果最后一个成员被弹出，则删除该set。\n语法：\nSPOP key [count] 示例： redis\u0026gt; SADD myset \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; SPOP myset \u0026#34;one\u0026#34; redis\u0026gt; SMEMBERS myset 1) \u0026#34;two\u0026#34; 2) \u0026#34;three\u0026#34; redis\u0026gt; SADD myset \u0026#34;four\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;five\u0026#34; (integer) 1 redis\u0026gt; SPOP myset 3 3) \u0026#34;two\u0026#34; 4) \u0026#34;three\u0026#34; 5) \u0026#34;four\u0026#34; redis\u0026gt; SMEMBERS myset 6) \u0026#34;five\u0026#34; SRANDMEMER 从set中获取一个或多个随机成员\n语法：\nSRANDMEMBER key [count] 示例： redis\u0026gt; SADD myset one two three (integer) 3 redis\u0026gt; SRANDMEMBER myset \u0026#34;two\u0026#34; redis\u0026gt; SRANDMEMBER myset 2 1) \u0026#34;two\u0026#34; 2) \u0026#34;three\u0026#34; redis\u0026gt; SRANDMEMBER myset -5 3) \u0026#34;three\u0026#34; 4) \u0026#34;one\u0026#34; 5) \u0026#34;three\u0026#34; 6) \u0026#34;two\u0026#34; 7) \u0026#34;three\u0026#34; SREM 从set中删除一个或多个成员。如果最后一个成员被删除，则删除该set。\n语法：\nSREM key member [member ...] 示例： redis\u0026gt; SADD myset \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; SADD myset \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; SREM myset \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; SREM myset \u0026#34;four\u0026#34; (integer) 0 redis\u0026gt; SMEMBERS myset 1) \u0026#34;two\u0026#34; 2) \u0026#34;three\u0026#34; SSCAN 遍历set的成员。\n语法：\nSSCAN key cursor [MATCH pattern] [COUNT count] SUNION 返回多个set的并集。\n语法：\nSUNION key [key ...] 示例： redis\u0026gt; SADD key1 \u0026#34;a\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;b\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;e\u0026#34; (integer) 1 redis\u0026gt; SUNION key1 key2 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34; 4) \u0026#34;d\u0026#34; 5) \u0026#34;e\u0026#34; SUNIONSTORE 将多个set的并集存储在一个key中。\n语法：\nSUNIONSTORE destination key [key ...] 示例： redis\u0026gt; SADD key1 \u0026#34;a\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;b\u0026#34; (integer) 1 redis\u0026gt; SADD key1 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;c\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;d\u0026#34; (integer) 1 redis\u0026gt; SADD key2 \u0026#34;e\u0026#34; (integer) 1 redis\u0026gt; SUNIONSTORE key key1 key2 (integer) 5 redis\u0026gt; SMEMBERS key 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34; 4) \u0026#34;d\u0026#34; 5) \u0026#34;e\u0026#34; ","permalink":"https://heliu.site/posts/redis/set/","summary":"redis set介绍。","title":"redis set"},{"content":" 官方命令地址：https://redis.io/commands/?group=sorted-set sortSet sortedSet是一个可排序的set集合。 SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表（SkipList）加 hash表。 SortedSet具备下列特性：可排序、元素不重复、查询速度快。 因为SortedSet的可排序特性，经常被用来实现排行榜这样的功能。 ZADD 向sortSet添加一个或多个成员，或更新其分数。如果key不存在，则创建该key。\n语法：\nZADD key [NX | XX] [GT | LT] [CH] [INCR] score member [score member ...] XX: 只更新已经存在的元素。不要添加新元素。 NX: 只添加新元素。不要更新已经存在的元素。 LT: 只有当新score小于当前分数时才更新现有元素。这个标志不会阻止添加新元素。 GT: 只有当新score大于当前分数时才更新现有元素。这个标志不会阻止添加新元素。 CH: 将返回值从添加的新元素数修改为更改的元素总数(CH是changed的缩写)。更改的元素是新添加的元素和已经存在的元素更新的分数。因此，在命令行中指定的具有与过去相同分数的元素不会被计算在内。注意:通常\u0026rsquo; ZADD \u0026lsquo;的返回值只计算添加的新元素的数量。 INCR: 当指定该选项时，\u0026lsquo;ZADD\u0026rsquo;的行为类似于\u0026lsquo;ZINCRBY\u0026rsquo;。在这种模式下只能指定一个分数-元素对。\n示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 1 \u0026#34;uno\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 2 \u0026#34;two\u0026#34; 3 \u0026#34;three\u0026#34; (integer) 2 redis\u0026gt; ZRANGE myzset 0 -1 WITHSCORES 1) \u0026#34;one\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;uno\u0026#34; 4) \u0026#34;1\u0026#34; 5) \u0026#34;two\u0026#34; 6) \u0026#34;2\u0026#34; 7) \u0026#34;three\u0026#34; 8) \u0026#34;3\u0026#34; ZCARD 返回已sortSet中成员的数目。\n语法：\nZCARD key 示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZCARD myzset (integer) 2 ZCOUNT 返回排序集中分数在一定范围内的成员的计数。\n语法：\nZCOUNT key min max 示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZCOUNT myzset -inf +inf (integer) 3 redis\u0026gt; ZCOUNT myzset (1 3 (integer) 2 ZDIFF 返回多个排序集之间的差值。\n语法：\nZDIFF numkeys key [key ...] [WITHSCORES] 示例： redis\u0026gt; ZADD zset1 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset1 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset1 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZDIFF 2 zset1 zset2 1) \u0026#34;three\u0026#34; redis\u0026gt; ZDIFF 2 zset1 zset2 WITHSCORES 2) \u0026#34;three\u0026#34; 3) \u0026#34;3\u0026#34; ZDIFFSTORE 将多个排序集的差值存储在一个键中。\n语法：\nZDIFFSTORE destination numkeys key [key ...] 示例： redis\u0026gt; ZADD zset1 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset1 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset1 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZDIFFSTORE out 2 zset1 zset2 (integer) 1 redis\u0026gt; ZRANGE out 0 -1 WITHSCORES 1) \u0026#34;three\u0026#34; 2) \u0026#34;3\u0026#34; ZINCRBY 增加已sortSet中成员的分数。\n语法：\nZINCRBY key increment member 示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZINCRBY myzset 2 \u0026#34;one\u0026#34; \u0026#34;3\u0026#34; redis\u0026gt; ZRANGE myzset 0 -1 WITHSCORES 1) \u0026#34;two\u0026#34; 2) \u0026#34;2\u0026#34; 3) \u0026#34;one\u0026#34; 4) \u0026#34;3\u0026#34; ZINTER 返回多个排序集的相交。\n语法：\nZINTER numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE \u0026lt;SUM | MIN | MAX\u0026gt;] [WITHSCORES] 示例： redis\u0026gt; ZADD zset1 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset1 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZINTER 2 zset1 zset2 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; redis\u0026gt; ZINTER 2 zset1 zset2 WITHSCORES 3) \u0026#34;one\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;two\u0026#34; 6) \u0026#34;4\u0026#34; ZINTERCARD 返回多个排序集相交的成员数。\n语法：\nZINTERCARD numkeys key [key ...] [LIMIT limit] 示例： redis\u0026gt; ZADD zset1 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset1 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZINTER 2 zset1 zset2 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; redis\u0026gt; ZINTERCARD 2 zset1 zset2 (integer) 2 redis\u0026gt; ZINTERCARD 2 zset1 zset2 LIMIT 1 (integer) 1 ZINTERSTORE 将多个排序集的相交存储在一个键中。\n语法：\nZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE \u0026lt;SUM | MIN | MAX\u0026gt;] 语法： redis\u0026gt; ZADD zset1 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset1 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD zset2 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 (integer) 2 redis\u0026gt; ZRANGE out 0 -1 WITHSCORES 1) \u0026#34;one\u0026#34; 2) \u0026#34;5\u0026#34; 3) \u0026#34;two\u0026#34; 4) \u0026#34;10\u0026#34; ZLEXCOUNT 返回字典顺序范围内已sortSet中的成员数。\n语法：\nZLEXCOUNT key min max 示例： redis\u0026gt; ZADD myzset 0 a 0 b 0 c 0 d 0 e (integer) 5 redis\u0026gt; ZADD myzset 0 f 0 g (integer) 2 redis\u0026gt; ZLEXCOUNT myzset - + (integer) 7 redis\u0026gt; ZLEXCOUNT myzset [b [f (integer) 5 ZMPOP 从一个或多个已排序的集合中返回删除后得分最高或最低的成员。如果弹出最后一个成员，则删除排序集。\n语法：\nZMPOP numkeys key [key ...] \u0026lt;MIN | MAX\u0026gt; [COUNT count] 示例： redis\u0026gt; ZMPOP 1 notsuchkey MIN (error) object of type \u0026#39;NoneType\u0026#39; has no len() redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; 2 \u0026#34;two\u0026#34; 3 \u0026#34;three\u0026#34; (integer) 3 redis\u0026gt; ZMPOP 1 myzset MIN 1) \u0026#34;myzset\u0026#34; 2) 1) 1) \u0026#34;one\u0026#34; 1) \u0026#34;1\u0026#34; redis\u0026gt; ZRANGE myzset 0 -1 WITHSCORES 3) \u0026#34;two\u0026#34; 4) \u0026#34;2\u0026#34; 5) \u0026#34;three\u0026#34; 6) \u0026#34;3\u0026#34; redis\u0026gt; ZMPOP 1 myzset MAX COUNT 10 7) \u0026#34;myzset\u0026#34; 8) 1) 1) \u0026#34;three\u0026#34; 2) \u0026#34;3\u0026#34; 2) 1) \u0026#34;two\u0026#34; 1) \u0026#34;2\u0026#34; redis\u0026gt; ZADD myzset2 4 \u0026#34;four\u0026#34; 5 \u0026#34;five\u0026#34; 6 \u0026#34;six\u0026#34; (integer) 3 redis\u0026gt; ZMPOP 2 myzset myzset2 MIN COUNT 10 9) \u0026#34;myzset2\u0026#34; 10) 1) 1) \u0026#34;four\u0026#34; 1) \u0026#34;4\u0026#34; 1) 1) \u0026#34;five\u0026#34; 1) \u0026#34;5\u0026#34; 2) 1) \u0026#34;six\u0026#34; 1) \u0026#34;6\u0026#34; redis\u0026gt; ZRANGE myzset 0 -1 WITHSCORES (empty array) redis\u0026gt; ZMPOP 2 myzset myzset2 MAX COUNT 10 (error) object of type \u0026#39;NoneType\u0026#39; has no len() redis\u0026gt; ZRANGE myzset2 0 -1 WITHSCORES (empty array) redis\u0026gt; EXISTS myzset myzset2 (integer) 0 ZMSCORE 返回已sortSet中一个或多个成员的分数。\n语法：\nZMSCORE key member [member ...] 示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZMSCORE myzset \u0026#34;one\u0026#34; \u0026#34;two\u0026#34; \u0026#34;nofield\u0026#34; 1) \u0026#34;1\u0026#34; 2) \u0026#34;2\u0026#34; 3) (nil) ZPOPMAX 从已排序的集合中删除得分最高的成员后返回它们。如果弹出最后一个成员，则删除排序集。 ZPOPMAX key [count] 示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZPOPMAX myzset 1) \u0026#34;three\u0026#34; 2) \u0026#34;3\u0026#34; ZPOPMIN 从已排序的集合中删除得分最低的成员后返回它们。如果弹出最后一个成员，则删除排序集。\n语法：\nZPOPMIN key [count] 示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 2 \u0026#34;two\u0026#34; (integer) 1 redis\u0026gt; ZADD myzset 3 \u0026#34;three\u0026#34; (integer) 1 redis\u0026gt; ZPOPMIN myzset 1) \u0026#34;one\u0026#34; 2) \u0026#34;1\u0026#34; ZRANDMEMBER 从已排序的集合中返回一个或多个随机成员。\n语法：\nZRANDMEMBER key [count [WITHSCORES]] 示例： redis\u0026gt; ZADD dadi 1 uno 2 due 3 tre 4 quattro 5 cinque 6 sei (integer) 6 redis\u0026gt; ZRANDMEMBER dadi \u0026#34;quattro\u0026#34; redis\u0026gt; ZRANDMEMBER dadi \u0026#34;due\u0026#34; redis\u0026gt; ZRANDMEMBER dadi -5 WITHSCORES 1) \u0026#34;uno\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;tre\u0026#34; 4) \u0026#34;3\u0026#34; 5) \u0026#34;quattro\u0026#34; 6) \u0026#34;4\u0026#34; 7) \u0026#34;cinque\u0026#34; 8) \u0026#34;5\u0026#34; 9) \u0026#34;cinque\u0026#34; 10) \u0026#34;5\u0026#34; ZRANGE 返回索引范围内已sortSet中的成员。\n语法：\nZRANGE key start stop [BYSCORE | BYLEX] [REV] [LIMIT offset count] [WITHSCORES] 示例： redis\u0026gt; ZADD myzset 1 \u0026#34;one\u0026#34; 2 \u0026#34;two\u0026#34; 3 \u0026#34;three\u0026#34; (integer) 3 redis\u0026gt; ZRANGE myzset 0 -1 1) \u0026#34;one\u0026#34; 2) \u0026#34;two\u0026#34; 3) \u0026#34;three\u0026#34; redis\u0026gt; ZRANGE myzset 2 3 4) \u0026#34;three\u0026#34; redis\u0026gt; ZRANGE myzset -2 -1 5) \u0026#34;two\u0026#34; 6) \u0026#34;three\u0026#34; ZRANGEBYLEX 返回字典顺序范围内已sortSet中的成员。\n语法：\nZRANGEBYLEX key min max [LIMIT offset count] 示例： redis\u0026gt; ZADD myzset 0 a 0 b 0 c 0 d 0 e 0 f 0 g (integer) 7 redis\u0026gt; ZRANGEBYLEX myzset - [c 1) \u0026#34;a\u0026#34; 2) \u0026#34;b\u0026#34; 3) \u0026#34;c\u0026#34; redis\u0026gt; ZRANGEBYLEX myzset - (c 4) \u0026#34;a\u0026#34; 5) \u0026#34;b\u0026#34; redis\u0026gt; ZRANGEBYLEX myzset [aaa (g 6) \u0026#34;b\u0026#34; 7) \u0026#34;c\u0026#34; 8) \u0026#34;d\u0026#34; 9) \u0026#34;e\u0026#34; 10) \u0026#34;f\u0026#34; ZRANGEBYSCORE Returns members in a sorted set within a range of scores. ZRANGESTORE tores a range of members from sorted set in a key. ZRANK Returns the index of a member in a sorted set ordered by ascending scores. ZREM Removes one or more members from a sorted set. Deletes the sorted set if all members were removed. ZREMRANGEBYLEX Removes members in a sorted set within a lexicographical range. Deletes the sorted set if all members were removed. ZREMRANGEBYRANK Removes members in a sorted set within a range of indexes. Deletes the sorted set if all members were removed. ZREMRANGEBYSCORE Removes members in a sorted set within a range of scores. Deletes the sorted set if all members were removed. ZREVRANGE Returns members in a sorted set within a range of indexes in reverse order. ZREVRANGEBYLEX Returns members in a sorted set within a lexicographical range in reverse order. ZREVRANGEBYSCORE Returns members in a sorted set within a range of scores in reverse order. ZREVRANK Returns the index of a member in a sorted set ordered by descending scores. ZSCAN Iterates over members and scores of a sorted set. ZSCORE Returns the score of a member in a sorted set. ZUNION Returns the union of multiple sorted sets. ZUNIONSTORE Stores the union of multiple sorted sets in a key. BZMPOP Removes and returns a member by score from one or more sorted sets. Blocks until a member is available otherwise. Deletes the sorted set if the last element was popped. BZPOPMAX Removes and returns the member with the highest score from one or more sorted sets. Blocks until a member available otherwise. Deletes the sorted set if the last element was popped. BZPOPMIN Removes and returns the member with the lowest score from one or more sorted sets. Blocks until a member is available otherwise. Deletes the sorted set if the last element was popped. ","permalink":"https://heliu.site/posts/redis/sortset/","summary":"redis sortSet介绍。","title":"redis sortSet"},{"content":" 官网命令地址：https://redis.io/commands/?group=bitmap redis客户端查询命令：help @string bitmap BITCOUNT 对字符串中设置的位数(总体计数)进行计数。（计数1的数量）\n语法：\nBITCOUNT key [start end [BYTE | BIT]] 示例： redis\u0026gt; SET mykey \u0026#34;foobar\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; BITCOUNT mykey (integer) 26 redis\u0026gt; BITCOUNT mykey 0 0 (integer) 4 redis\u0026gt; BITCOUNT mykey 1 1 (integer) 6 redis\u0026gt; BITCOUNT mykey 1 1 BYTE (integer) 6 redis\u0026gt; BITCOUNT mykey 5 30 BIT (integer) 17 BITFIELD 对字符串执行任意位域整数操作。\n语法：\nBITFIELD key [GET encoding offset | [OVERFLOW \u0026lt;WRAP | SAT | FAIL\u0026gt;] \u0026lt;SET encoding offset value | INCRBY encoding offset increment\u0026gt; [GET encoding offset | [OVERFLOW \u0026lt;WRAP | SAT | FAIL\u0026gt;] \u0026lt;SET encoding offset value | INCRBY encoding offset increment\u0026gt; ...]] 用法： \u0026gt; BITFIELD mykey INCRBY i5 100 1 GET u4 0 1) (integer) 1 2) (integer) 0 \u0026gt; BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1 3) (integer) 1 4) (integer) 1 \u0026gt; BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1 5) (integer) 2 6) (integer) 2 \u0026gt; BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1 7) (integer) 3 2) (integer) 3 \u0026gt; BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1 3) (integer) 0 4) (integer) 3 BITFIELD_RO 对字符串执行任意只读位域整数操作。\n语法：\nBITFIELD_RO key [GET encoding offset [GET encoding offset ...]] 示例： BITFIELD_RO hello GET i8 16 BITOP 对多个字符串执行按位操作，并存储结果。\n语法：\nBITOP \u0026lt;AND | OR | XOR | NOT\u0026gt; destkey key [key ...] 用法： redis\u0026gt; SET key1 \u0026#34;foobar\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; SET key2 \u0026#34;abcdef\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; BITOP AND dest key1 key2 (integer) 6 redis\u0026gt; GET dest \u0026#34;`bc`ab\u0026#34; BITPOS 查找字符串中的第一个set(1)或clear(0)位。\n语法：\nBITPOS key bit [start [end [BYTE | BIT]]] 用法： redis\u0026gt; SET mykey \u0026#34;\\xff\\xf0\\x00\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; BITPOS mykey 0 (integer) 0 redis\u0026gt; SET mykey \u0026#34;\\x00\\xff\\xf0\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; BITPOS mykey 1 0 (integer) 1 redis\u0026gt; BITPOS mykey 1 2 (integer) 18 redis\u0026gt; BITPOS mykey 1 2 -1 BYTE (integer) 18 redis\u0026gt; BITPOS mykey 1 7 15 BIT (integer) 9 redis\u0026gt; set mykey \u0026#34;\\x00\\x00\\x00\u0026#34; \u0026#34;OK\u0026#34; redis\u0026gt; BITPOS mykey 1 (integer) 1 redis\u0026gt; BITPOS mykey 1 7 -3 BIT (integer) 9 GETBIT 按偏移量返回位值。\n语法：\nGETBIT key offset 示例： redis\u0026gt; SETBIT mykey 7 1 (integer) 0 redis\u0026gt; GETBIT mykey 0 (integer) 0 redis\u0026gt; GETBIT mykey 7 (integer) 1 redis\u0026gt; GETBIT mykey 100 (integer) 0 SETBIT 设置或清除字符串值的偏移位。如果key不存在，则创建该key。\n语法：\nSETBIT key offset value 示例： redis\u0026gt; SETBIT mykey 7 1 (integer) 0 redis\u0026gt; SETBIT mykey 7 0 (integer) 1 redis\u0026gt; GET mykey \u0026#34;\u0026#34; ","permalink":"https://heliu.site/posts/redis/bitmap/","summary":"redis bitmap命令介绍。","title":"redis bitmap"},{"content":"基础结构 动态字符串SDS 字符串是redis中比较常见的有一种结构，比如string类型的key和value都是字符串。 Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String），简称SDS。 Redis是C语言实现的，其中SDS是一个结构体。 SDS之所以叫做动态字符串，是因为它具备动态扩容的能力。 如果新字符串小于1M，则新空间为扩展后字符串长度的两倍+1。 如果新字符串大于1M，则新空间为扩展后字符串长度+1M+1。称为内存预分配。 redis不推荐键值对存储音频视频这种大内存数据。 整数集合Intset IntSet是Redis中set集合的一种实现方式，基于整数数组来实现，并且具备长度可变、有序等特征。 为了方便查找，Redis会将intset中所有的整数按照升序依次保存在contents数组中。 Intset可以看做是特殊的整数数组，具备一些特点： Redis会确保Intset中的元素唯一、有序。 具备类型升级机制，可以节省内存空间。 底层采用二分查找方式来查询。 字典Dict Redis是一个键值型（Key-Value Pair）的数据库，我们可以根据键实现快速的增删改查。而键与值的映射关系正是通过Dict来实现的。 Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）。 当我们向Dict添加键值对时，Redis首先根据key计算出hash值（h），然后利用 h \u0026amp; sizemask来计算元素应该存储到数组中的哪个索引位置。 我们存储k1=v1，假设k1的哈希值h =1，则1\u0026amp;3 =1，因此k1=v1要存储到数组角标1位置。 双端链表ZipList ZipList 是一种特殊的“双端链表” ，由一系列特殊编码的连续内存块组成。 可以在任意一端进行压入/弹出操作, 并且该操作的时间复杂度为 O(1)。 属性 类型 长度 用途 zlbytes uint32_t 4 字节 记录整个压缩列表占用的内存字节数 zltail uint32_t 4 字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过这个偏移量，可以确定表尾节点的地址。 zllen uint16_t 2 字节 记录了压缩列表包含的节点数量。 最大值为UINT16_MAX （65534），如果超过这个值，此处会记录为65535，但节点的真实数量需要遍历整个压缩列表才能计算得出。 entry 列表节点 不定 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend uint8_t 1 字节 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 ZipList 中的Entry并不像普通链表那样记录前后节点的指针，因为记录两个指针要占用16个字节，浪费内存。而是采用了下面的结构： previous_entry_length：前一节点的长度，占1个或5个字节。 如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值。 如果前一节点的长度大于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长 encoding：编码属性，记录content的数据类型（字符串还是整数）以及长度，占用1个、2个或5个字节。 contents：负责保存节点的数据，可以是字符串或整数。 ZipListEntry中的encoding编码分为字符串和整数两种：字符串：如果encoding是以“00”、“01”或者“10”开头，则证明content是字符串。 编码 编码长度 字符串大小 |00pppppp| 1 bytes \u0026lt;= 63 bytes |01pppppp|qqqqqqqq| 2 bytes \u0026lt;= 16383 bytes |10000000|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| 5 bytes \u0026lt;= 4294967295 bytes 整数：如果encoding是以“11”开始，则证明content是整数，且encoding固定只占用1个字节 编码 编码长度 整数类型 11000000 1 int16_t（2 bytes） 11010000 1 int32_t（4 bytes） 11100000 1 int64_t（8 bytes） 11110000 1 24位有符整数(3 bytes) 11111110 1 8位有符整数(1 bytes) 1111xxxx 1 直接在xxxx位置保存数值，范围从0001~1101，减1后结果为实际值 双端链表QuickList ZipList虽然节省内存，但申请内存必须是连续空间，如果内存占用较多，申请内存效率很低。 为了避免QuickList中的每个ZipList中entry过多，Redis提供了一个配置项：list-max-ziplist-size来限制。如果值为正，则代表ZipList的允许的entry个数的最大值。如果值为负，则代表ZipList的最大内存大小，分5种情况： -1：每个ZipList的内存占用不能超过4kb -2：每个ZipList的内存占用不能超过8kb -3：每个ZipList的内存占用不能超过16kb -4：每个ZipList的内存占用不能超过32kb -5：每个ZipList的内存占用不能超过64kb 跳表SkipList SkipList（跳表）首先是链表，但与传统链表相比有几点差异：元素按照升序排列存储、节点可能包含多个指针，指针跨度不同。 SkipList的特点： 跳跃表是一个双向链表，每个节点都包含score和ele值 节点按照score值排序，score值一样则按照ele字典排序 每个节点都可以包含多层指针，层数是1到32之间的随机数 不同层指针到下一个节点的跨度不同，层级越高，跨度越大 增删改查效率与红黑树基本一致，实现却更简单 RedisObject Redis中的任意数据类型的键和值都会被封装为一个RedisObject，也叫做Redis对象。 Redis中会根据存储的数据类型不同，选择不同的编码方式，共包含11种不同类型。 编号 编码方式 说明 0 OBJ_ENCODING_RAW raw编码动态字符串 1 OBJ_ENCODING_INT long类型的整数的字符串 2 OBJ_ENCODING_HT hash表（字典dict） 3 OBJ_ENCODING_ZIPMAP 已废弃 4 OBJ_ENCODING_LINKEDLIST 双端链表 5 OBJ_ENCODING_ZIPLIST 压缩列表 6 OBJ_ENCODING_INTSET 整数集合 7 OBJ_ENCODING_SKIPLIST 跳表 8 OBJ_ENCODING_EMBSTR embstr的动态字符串 9 OBJ_ENCODING_QUICKLIST 快速列表 10 OBJ_ENCODING_STREAM Stream流 Redis中会根据存储的数据类型不同，选择不同的编码方式。 数据类型 编码方式 OBJ_STRING int、embstr、raw OBJ_LIST LinkedList和ZipList(3.2以前)、QuickList（3.2以后） OBJ_SET intset、HT OBJ_ZSET ZipList、HT、SkipList OBJ_HASH ZipList、HT String String是Redis中最常见的数据存储类型：其基本编码方式是RAW，基于简单动态字符串（SDS）实现，存储上限为512mb。 如果存储的SDS长度小于44字节，则会采用EMBSTR编码，此时object head与SDS是一段连续空间。申请内存时只需要调用一次内存分配函数，效率更高。 如果存储的字符串是整数值，并且大小在LONG_MAX范围内，则会采用INT编码：直接将数据保存在RedisObject的ptr指针位置（刚好8字节），不再需要SDS了。 Set Set是Redis中的单列集合，满足下列特点：不保证有序性、保证元素唯一、求交集，并集，差集。 List Redis的List结构类似一个双端链表，可以从首、尾操作列表中的元素。 Hash 底层实现方式：压缩列表ziplist 或者 字典dict。 当Hash中数据项比较少的情况下，Hash底层才⽤压缩列表ziplist进⾏存储数据，当数据量较大时，Hash结构会转为HT编码，也就是Dict，触发条件有两个： ZipList中的元素数量超过了hash-max-ziplist-entries（默认512） ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节） Redis的hash之所以这样设计，是因为当ziplist变得很⼤的时候，它有如下几个缺点： 每次插⼊或修改引发的realloc操作会有更⼤的概率造成内存拷贝，从而降低性能。 ⼀旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更⼤的⼀块数据。 当ziplist数据项过多的时候，在它上⾯查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。 总之，ziplist本来就设计为各个数据项挨在⼀起组成连续的内存空间，这种结构并不擅长做修改操作。⼀旦数据发⽣改动，就会引发内存realloc，可能导致内存拷贝。 ZSet ZSet也就是SortedSet，其中每一个元素都需要指定一个score值和member值： 可以根据score值排序后 member必须唯一 可以根据member查询分数 因此，zset底层数据结构必须满足键值存储、键必须唯一、可排序这几个需求。之前学习的哪种编码结构可以满足？ SkipList：可以排序，并且可以同时存储score和ele值（member） HT（Dict）：可以键值存储，并且可以根据key找value 当元素数量不多时，HT和SkipList的优势不明显，而且更耗内存。因此zset还会采用ZipList结构来节省内存，不过需要同时满足两个条件： 元素数量小于zset_max_ziplist_entries，默认值128 每个元素都小于zset_max_ziplist_value字节，默认值64 ziplist本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现： ZipList是连续内存，因此score和element是紧挨在一起的两个entry， element在前，score在后 score越小越接近队首，score越大越接近队尾，按照score值升序排列 ","permalink":"https://heliu.site/posts/redis/struct/","summary":"redis 数据结构介绍。","title":"redis 数据结构"},{"content":"缓存穿透 缓存穿透：缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。 常见的解决方案有两种： 缓存空对象 优点：实现简单，维护方便。 缺点：额外的内存消耗、可能造成短期的不一致。 布隆过滤 优点：内存占用较少，没有多余key。 实现复杂、存在误判可能、不能更改否则全部重新缓存。 缓存空对象： 当我们客户端访问不存在的数据时，先请求redis，但是此时redis中没有数据，此时会访问到数据库，但是数据库中也没有数据，这个数据穿透了缓存 直击数据库，我们都知道数据库能够承载的并发不如redis这么高，如果大量的请求同时过来访问这种不存在的数据，这些请求就都会访问到数据库 简单的解决方案就是哪怕这个数据在数据库中也不存在，我们也把这个数据存入到redis中去，这样，下次用户过来访问这个不存在的数据，那么在redis中也能找到这个数据就不会进入到缓存了 布隆过滤： 布隆过滤器其实采用的是哈希思想来解决这个问题，通过一个庞大的二进制数组，走哈希思想去判断当前这个要查询的这个数据是否存在，如果布隆过滤器判断存在，则放行 这个请求会去访问redis，哪怕此时redis中的数据过期了，但是数据库中一定存在这个数据，在数据库中查询出来这个数据后，再将其放入到redis中，假设布隆过滤器判断这个数据不存在，则直接返回 这种方式优点在于节约内存空间，存在误判，误判原因在于：布隆过滤器走的是哈希思想，只要哈希思想，就可能存在哈希冲突 缓存雪崩 缓存雪崩：是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。 解决方案：给不同的Key的TTL添加随机值、利用Redis集群提高服务的可用性、给缓存业务添加降级限流策略、给业务添加多级缓存。 缓存击穿 缓存击穿：问题也叫热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。 常见的解决方案有两种：互斥锁、逻辑过期。 逻辑分析：假设线程1在查询缓存之后，本来应该去查询数据库，然后把这个数据重新加载到缓存的，此时只要线程1走完这个逻辑，其他线程就都能从缓存中加载这些数据了，但是假设在线程1没有走完的时候，后续的线程2，线程3，线程4同时过来访问当前这个方法， 那么这些线程都不能从缓存中查询到数据，那么他们就会同一时刻来访问查询缓存，都没查到，接着同一时间去访问数据库，同时的去执行数据库代码，对数据库访问压力过大。 采用互斥锁方案： 逻辑过期：我们之所以会出现这个缓存击穿问题，主要原因是在于我们对key设置了过期时间，假设我们不设置过期时间，其实就不会有缓存击穿的问题，但是不设置过期时间，这样数据不就一直占用我们内存了吗，我们可以采用逻辑过期方案。 我们把过期时间设置在 redis的value中，注意：这个过期时间并不会直接作用于redis，而是我们后续通过逻辑去处理。假设线程1去查询缓存，然后从value中判断出来当前的数据已经过期了，此时线程1去获得互斥锁，那么其他线程会进行阻塞，获得了锁的线程他会开启一个 线程去进行 以前的重构数据的逻辑，直到新开的线程完成这个逻辑后，才释放锁， 而线程1直接进行返回，假设现在线程3过来访问，由于线程线程2持有着锁，所以线程3无法获得锁，线程3也直接返回数据，只有等到新开的线程2把重建数据构建完后，其他线程才能走返回正确的数据。 这种方案巧妙在于，异步的构建缓存，缺点在于在构建完缓存之前，返回的都是脏数据。 **互斥锁方案：**由于保证了互斥性，所以数据一致，且实现简单，因为仅仅只需要加一把锁而已，也没其他的事情需要操心，所以没有额外的内存消耗，缺点在于有锁就有死锁问题的发生，且只能串行执行性能肯定受到影响 逻辑过期方案： 线程读取过程中不需要等待，性能好，有一个额外的线程持有锁去进行重构数据，但是在重构数据完成前，其他的线程只能返回之前的数据，且实现起来麻烦 ","permalink":"https://heliu.site/posts/redis/use/","summary":"redis 使用场景。","title":"redis 场景"},{"content":" SQL语句可以单行或多行书写，以分号结尾。 SQL语句可以使用空格/缩进来增强语句的可读性。 MySQL数据库的SQL语句不区分大小写，关键字建议使用大写。 注释： 单行注释：\u0026ndash; 注释内容 或 # 注释内容 多行注释：/* 注释内容 */ SQL分类 SQL语句，根据其功能，主要分为四类：DDL、DML、DQL、DCL。 DDL（Data Definition Language）：数据定义语言，用来定义数据库对象(数据库，表，字段)。 DML（Data Manipulation Language）：数据操作语言，用来对数据库表中的数据进行增删。 DQL（Data Query Language）：数据查询语言，用来查询数据库中表的记录。 DCL（Data Control Language）：数据控制语言，用来创建数据库用户、控制数据库的访问权限。 DDL 数据定义语言，用来定义数据库对象(数据库，表，字段)。 数据库操作 查询所有数据库。 show databases; 查询当前数据库。 select database(); 创建数据库。 create database [ if not exists ] 数据库名 [ default charset 字符集 ] [ collate 排序规则 ]; 删除数据库。 drop database [ if exists ] 数据库名; 切换数据库。 use 数据库名; 表操作 查询当前数据库所有表。 show tables; 查看指定表结构。 desc 表名; 查询指定表的建表语句。 show create table 表名; 创建表结构。 CREATE TABLE 表名( 字段1 字段1类型 [COMMENT 字段1注释 ], 字段2 字段2类型 [COMMENT 字段2注释 ], 字段3 字段3类型 [COMMENT 字段3注释 ], ...... 字段n 字段n类型 [COMMENT 字段n注释 ] ) [ COMMENT 表注释 ]; -- 注意: [...] 内为可选参数，最后一个字段后面没有逗号 create table emp( id int comment \u0026#39;编号\u0026#39;, workno varchar(10) comment \u0026#39;工号\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, gender char(1) comment \u0026#39;性别\u0026#39;, age tinyint unsigned comment \u0026#39;年龄\u0026#39;, idcard char(18) comment \u0026#39;身份证号\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39; ) comment \u0026#39;员工表\u0026#39;; 添加字段。 ALTER TABLE 表名 ADD 字段名 类型 (长度) [ COMMENT 注释 ] [ 约束 ]; -- 为emp表增加一个新的字段”昵称”为nickname，类型为varchar(20) ALTER TABLE emp ADD nickname varchar(20) COMMENT \u0026#39;昵称\u0026#39;; 修改数据类型。 ALTER TABLE 表名 MODIFY 字段名 新数据类型 (长度); 修改字段名和字段类型。 ALTER TABLE 表名 CHANGE 旧字段名 新字段名 类型 (长度) [ COMMENT 注释 ] [ 约束 ]; -- 将emp表的nickname字段修改为username，类型为varchar(30) ALTER TABLE emp CHANGE nickname username varchar(30) COMMENT \u0026#39;昵称\u0026#39;; 删除字段。 ALTER TABLE 表名 DROP 字段名; -- 将emp表的字段username删除 ALTER TABLE emp DROP username; 修改表名。 ALTER TABLE 表名 RENAME TO 新表名; -- 将emp表的表名修改为 employee ALTER TABLE emp RENAME TO employee; 删除表：可选项 IF EXISTS 代表，只有表名存在时才会删除该表，表名不存在，则不执行删除操作(如果不 加该参数项，删除一张不存在的表，执行将会报错)。 DROP TABLE [ IF EXISTS ] 表名; -- 如果tb_user表存在，则删除tb_user表 DROP TABLE IF EXISTS tb_user; 删除指定表, 并重新创建表。 -- 注意: 在删除表的时候，表中的全部数据也都会被删除。 TRUNCATE TABLE 表名; DML DML英文全称是Data Manipulation Language(数据操作语言)，用来对数据库中表的数据记录进行增、删、改操作。 添加数据(INSERT) 给指定字段添加数据。 INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...); -- 给employee表所有的字段添加数据 insert into employee(id,workno,name,gender,age,idcard,entrydate) values(1,\u0026#39;1\u0026#39;,\u0026#39;Itcast\u0026#39;,\u0026#39;男\u0026#39;,10,\u0026#39;123456789012345678\u0026#39;,\u0026#39;2000-01-01\u0026#39;); 给全部字段添加数据。 INSERT INTO 表名 VALUES (值1, 值2, ...); insert into employee values(2,\u0026#39;2\u0026#39;,\u0026#39;张无忌\u0026#39;,\u0026#39;男\u0026#39;,18,\u0026#39;123456789012345670\u0026#39;,\u0026#39;2005-01-01\u0026#39;); 批量添加数据。 INSERT INTO 表名 (字段名1, 字段名2, ...) VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...); INSERT INTO 表名 VALUES (值1, 值2, ...), (值1, 值2, ...), (值1, 值2, ...); -- 批量插入数据到employee表 -- 插入数据时，指定的字段顺序需要与值的顺序是一一对应的。 -- 字符串和日期型数据应该包含在引号中。 -- 插入的数据大小，应该在字段的规定范围内 insert into employee values(3,\u0026#39;3\u0026#39;,\u0026#39;韦\u0026#39;,\u0026#39;男\u0026#39;,38,\u0026#39;123456789012345670\u0026#39;,\u0026#39;2005-01-01\u0026#39;), (4,\u0026#39;4\u0026#39;,\u0026#39;赵\u0026#39;,\u0026#39;女\u0026#39;,18,\u0026#39;123456789012345670\u0026#39;,\u0026#39;2005-01-01\u0026#39;); 修改数据(UPDATE) 修改数据的具体语法。 UPDATE 表名 SET 字段名1 = 值1 , 字段名2 = 值2 , .... [ WHERE 条件 ] ; -- 修改id为1的数据，将name修改为ia update employee set name = \u0026#39;ia\u0026#39; where id = 1; -- 修改id为1的数据, 将name修改为x, gender修改为 女 update employee set name = \u0026#39;x\u0026#39; , gender = \u0026#39;女\u0026#39; where id = 1; -- 将所有的员工入职日期修改为 2008-01-01 update employee set entrydate = \u0026#39;2008-01-01\u0026#39;; 注意：修改语句的条件可以有，也可以没有，如果没有条件，则会修改整张表的所有数据。 删除数据(DELETE) 删除数据的具体语法。 DELETE FROM 表名 [ WHERE 条件 ]; -- 删除gender为女的员工 delete from employee where gender = \u0026#39;女\u0026#39;; -- 删除所有员工 delete from employee; 注意事项： DELETE 语句的条件可以有，也可以没有，如果没有条件，则会删除整张表的所有数据。 DELETE 语句不能删除某一个字段的值(可以使用UPDATE，将该字段值置为NULL即可)。 DQL DQL英文全称是Data Query Language(数据查询语言)，数据查询语言，用来查询数据库中表的记录。 DQL查询语句，语法结构如下： SELECT 字段列表 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 ORDER BY 排序字段列表 LIMIT 分页参数 基础查询 在基本查询的DQL语句中，不带任何的查询条件，查询的语法如下：\n查询多个字段 SELECT 字段1, 字段2, 字段3 ... FROM 表名; -- * 号代表查询所有字段，在实际开发中尽量少用（不直观、影响效率）。 SELECT * FROM 表名; 字段设置别名 SELECT 字段1 [ AS 别名1 ] , 字段2 [ AS 别名2 ] ... FROM 表名; SELECT 字段1 [ 别名1 ] , 字段2 [ 别名2 ] ... FROM 表名; 去除重复记录 SELECT DISTINCT 字段列表 FROM 表名; -- 查询公司员工的上班地址有哪些(不要重复) select distinct workaddress \u0026#39;工作地址\u0026#39; from emp; 条件查询 SELECT 字段列表 FROM 表名 WHERE 条件列表 ; 常用的比较运算符如下： \u0026mdash;\u0026mdash;\u0026mdash;-比较运算符\u0026mdash;\u0026mdash;\u0026mdash;- 功能 \u0026gt; 大于 \u0026gt;= 大于等于 \u0026lt; 小于 \u0026lt;= 小于等于 = 等于 \u0026lt;\u0026gt; 或 != 不等于 BETWEEN \u0026hellip; AND \u0026hellip; 在某个范围之内(含最小、最大值) IN(\u0026hellip;) 在in之后的列表中的值，多选 LIKE 占位符 模糊匹配(_匹配单个字符, %匹配任意个字符) IS NULL 是NULL 常用的逻辑运算符如下： \u0026mdash;\u0026mdash;\u0026mdash;-比较运算符\u0026mdash;\u0026mdash;\u0026mdash;- 功能 AND 或 \u0026amp;\u0026amp; 并且 (多个条件同时成立) OR 或 || 或者 (多个条件任意一个成立) NOT 或 ! 非 , 不是 聚合函数 将一列数据作为一个整体，进行纵向计算。 常见的聚合函数。 函数 功能 count 统计数量 max 最大值 min 最小值 avg 平均值 sum 求和 语法： SELECT 聚合函数(字段列表) FROM 表名 ; 注意: NULL值是不参与所有聚合函数运算的。 分组查询 SELECT 字段列表 FROM 表名 [ WHERE 条件 ] GROUP BY 分组字段名 [ HAVING 分组后过滤条件 ]; where与having区别： 执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组之后对结果进行过滤。 判断条件不同：where不能对聚合函数进行判断，而having可以。 注意事项: 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义。 执行顺序: where \u0026gt; 聚合函数 \u0026gt; having 。 支持多字段分组, 具体语法为 : group by columnA,columnB。 排序查询 SELECT 字段列表 FROM 表名 ORDER BY 字段1 排序方式1 , 字段2 排序方式2 ; 排序方式：ASC-升序(默认值)、DESC-降序。 注意事项： 如果是升序, 可以不指定排序方式ASC; 如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序; 分页查询 SELECT 字段列表 FROM 表名 LIMIT 起始索引, 查询记录数; 注意事项： 起始索引从0开始，起始索引 = （查询页码 - 1）* 每页显示记录数。 分页查询是数据库的方言，不同的数据库有不同的实现，MySQL中是LIMIT。 如果查询的是第一页数据，起始索引可以省略，直接简写为 limit 10。 执行顺序 DQL语句在执行时的执行顺序，也就是先执行那一部分，后执行那一部分。 DCL DCL英文全称是Data Control Language(数据控制语言)，用来问权限。\n管理用户 查询用户。 -- Host代表当前用户访问的主机, 如果为localhost, 仅代表只能够在当前本机访问，是不可以远程访问的 -- User代表的是访问该数据库的用户名。在MySQL中需要通过Host和User来唯一标识一个用户。 select * from mysql.user; 创建用户。 CREATE USER \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39; IDENTIFIED BY \u0026#39;密码\u0026#39;; -- 创建用户ic, 只能够在当前主机localhost访问, 密码123456 create user \u0026#39;ic\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;123456\u0026#39;; -- 创建用户hl, 可以在任意主机访问该数据库, 密码123456 create user \u0026#39;hl\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;123456\u0026#39;; 修改用户密码。 ALTER USER \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;新密码\u0026#39;; -- 修改用户hl的访问密码为1234 alter user \u0026#39;hl\u0026#39;@\u0026#39;%\u0026#39; identified with mysql_native_password by \u0026#39;1234\u0026#39;; 删除用户。 DROP USER \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39;; -- 删除 hl@localhost 用户 drop user \u0026#39;hl\u0026#39;@\u0026#39;localhost\u0026#39;; 注意事项： 在MySQL中需要通过用户名@主机名的方式，来唯一标识一个用户。 主机名可以使用 % 通配。 这类SQL开发人员操作的比较少，主要是DBA（ Database Administrator 数据库管理员）使用。 权限控制 MySQL中定义了很多种权限，但是常用的就以下几种： 权限 说明 ALL, ALL PRIVILEGES 所有权限 SELECT 查询数据 INSERT 插入数据 UPDATE 修改数据 DELETE 删除数据 ALTER 修改表 DROP 删除数据库/表/视图 CREATE 创建数据库/表 查询权限。 SHOW GRANTS FOR \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39; ; 授予权限。 GRANT 权限列表 ON 数据库名.表名 TO \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39;; 撤销权限。 REVOKE 权限列表 ON 数据库名.表名 FROM \u0026#39;用户名\u0026#39;@\u0026#39;主机名\u0026#39;; 注意： 多个权限之间，使用逗号分隔 授权时， 数据库名和表名可以使用 * 进行通配，代表所有 函数 字符串函数 函数 功能 CONCAT(S1,S2,\u0026hellip;Sn) 字符串拼接，将S1，S2，\u0026hellip; Sn拼接成一个字符串 LOWER(str) 将字符串str全部转为小写 UPPER(str) 将字符串str全部转为大写 LPAD(str,n,pad) 左填充，用字符串pad对str的左边进行填充，达到n个字符串长度 RPAD(str,n,pad) 右填充，用字符串pad对str的右边进行填充，达到n个字符串长度 TRIM(str) 去掉字符串头部和尾部的空格 SUBSTRING(str,start,len) 返回从字符串str从start位置起的len个长度的字符串 数值函数 函数 功能 CEIL(x) 向上取整 FLOOR(x) 向下取整 MOD(x,y) 返回x/y的模 RAND() 返回0~1内的随机数 ROUND(x,y) 求参数x的四舍五入的值，保留y位小数 日期函数 函数 功能 CURDATE() 返回当前日期 CURTIME() 返回当前时间 NOW() 返回当前日期和时间 YEAR(date) 获取指定date的年份 MONTH(date) 获取指定date的月份 DAY(date) 获取指定date的日期 DATE_ADD(date, INTERVAL expr type) 返回一个日期/时间值加上一个时间间隔expr后的时间值 DATEDIFF(date1,date2) 返回起始时间date1 和 结束时间date2之间的天数 流程函数 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;函数\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 功能 IF(value , t , f) 如果value为true，则返回t，否则返回 f IFNULL(value1 , value2) 如果value1不为空，返回value1，否则返回value2 CASE WHEN [ val1 ] THEN [res1] \u0026hellip; ELSE [ default ] END 如果val1为true，返回res1，\u0026hellip; 否则返回default默认值 CASE [ expr ] WHEN [ val1 ] THEN [res1] \u0026hellip; ELSE [ default ] END 如果expr的值等于val1返回res1，\u0026hellip; 否则返回default默认值 约束 约束是作用于表中字段上的规则，用于限制存储在表中的数据。 保证数据库中数据的正确、有效性和完整性。 约束是作用于表中字段上的，可以在创建表/修改表的时候添加约束。 约束 描述 关键字 非空约束 限制该字段的数据不能为null NOT NULL 唯一约束 保证该字段的所有数据都是唯一、不重复的 UNIQUE 主键约束 主键是一行数据的唯一标识，要求非空且唯一 PRIMARY KEY 默认约束 保存数据时，如果未指定该字段的值，则采用默认值 DEFAULT 检查约束(8.0.16版本之后) 保证字段值满足某一个条件 CHECK 外键约束 用来让两张表的数据之间建立连接，保证数据的一致性和完整性 FOREIGN KEY 示例： 字段名 字段含义 字段类型 约束条件 约束关键字 id ID唯一标识 int 主键，并且自动增长 PRIMARY KEY, AUTO_INCREMENT name 姓名 varchar(10) 不为空，并且唯一 NOT NULL, UNIQUE age 年龄 int 大于0，并且小于等于120 CHECK status 状态 char(1) 如果没有指定该值，默认为1 DEFAULT gender 性别 char(1) 无 对应的建表语句为： CREATE TABLE tb_user( id int AUTO_INCREMENT PRIMARY KEY COMMENT \u0026#39;ID唯一标识\u0026#39;, name varchar(10) NOT NULL UNIQUE COMMENT \u0026#39;姓名\u0026#39; , age int check (age \u0026gt; 0 \u0026amp;\u0026amp; age \u0026lt;= 120) COMMENT \u0026#39;年龄\u0026#39; , status char(1) default \u0026#39;1\u0026#39; COMMENT \u0026#39;状态\u0026#39;, gender char(1) COMMENT \u0026#39;性别\u0026#39; ) 外键约束 外键：用来让两张表的数据之间建立连接，从而保证数据的一致性和完整性。 添加外键。 CREATE TABLE 表名( 字段名 数据类型, ... [CONSTRAINT] [外键名称] FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名) ); ALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段名) REFERENCES 主表 (主表列名) ; 删除外键。 ALTER TABLE 表名 DROP FOREIGN KEY 外键名称; 添加了外键之后，再删除父表数据时产生的约束行为，我们就称为删除/更新行为。具体的删除/更新行为有以下几种：\n行为 说明 NO ACTION 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除/更新。 (与 RESTRICT 一致) 默认行为 RESTRICT 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有则不允许删除/更新。 (与 NO ACTION 一致) 默认行为 CASCADE 当在父表中删除/更新对应记录时，首先检查该记录是否有对应外键，如果有，则也删除/更新外键在子表中的记录 SET NULL 当在父表中删除对应记录时，首先检查该记录是否有对应外键，如果有则设置子表中该外键值为null（这就要求该外键允许取null） SET DEFAULT 父表有变更时，子表将外键列设置成一个默认的值 (Innodb不支持) 具体语法：\nALTER TABLE 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (外键字段) REFERENCES 主表名 (主表字段名) ON UPDATE CASCADE ON DELETE CASCADE; 数据类型 数值类型 类型 大小/bytes 有符号范围 无符号范围(unsigned) 描述 TINYINT 1 (-128, 127) (0, 255) 1字节整数 SMALLINT 2 (-32768, 32767) (0, 65535) 2字节整数 MEDIUMINT 3 (-8388608, 8388607) (0, 16777215) 3字节整数 INT/INTEGER 4 (-2147483648, 2147483647) (0, 4294967295) 4字节整数 BIGINT 8 (-2^63, 2^63-1) (0, 2^64-1) 8字节整数 FLOAT 4 (-3.402823466 E+38, 3.402823466351 E+38) (1.175494351 E-38, 3.402823466 E+38) 与 0 单精度浮点数 DOUBLE 8 (-1.7976931348623157 E+308, 1.7976931348623157 E+308) (2.2250738585072014 E-308, 1.7976931348623157 E+308) 与 0 双精度浮点数 DECIMAL 依赖于M(精度)和D(标度)的值 依赖于M(精度)和D(标度)的值 小数值(精确点数) 字符串类型 char 与 varchar 都可以描述字符串，char是定长字符串，指定长度多长，就占用多少个字符，和字段值的长度无关。 而varchar是变长字符串，指定的长度为最大占用长度 。相对来说，char的性能会更高些。 类型 大小/bytes 描述 CHAR 0-255 定长字符串(需要指定长度) VARCHAR 0-65535 变长字符串(需要指定长度) TINYBLOB 0-255 不超过255个字符的二进制数据 TINYTEXT 0-255 短文本字符串 BLOB 0-65535 二进制形式的长文本数据 TEXT 0-65535 长文本数据 MEDIUMBLOB 0-16777215 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16777215 中等长度文本数据 LONGBLOB 0-4294967295 二进制形式的极大文本数据 LONGTEXT 0-4294967295 极大文本数据 日期时间类型 类型 大小/bytes 范围 格式 描述 DATE 3 1000-01-01 至 9999-12-31 YYYY-MM-DD 日期值 TIME 3 -838:59:59 至 838:59:59 HH:MM:SS 时间值或持续时间 YEAR 1 1901 至 2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00 至 9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:01 至 2038-01-19 03:14:07 YYYY-MM-DD HH:MM:SS 混合日期和时间值 ","permalink":"https://heliu.site/posts/mysql/use/","summary":"DDL、DCL、DQL、DML","title":"mysql 语法"},{"content":"多表关系 一对多：一个部门对应多个员工。 多对多：一个学生可以选修多门课程，一门课程也可以供多个学生选择。 一对一：一对一关系，多用于单表拆分，将一张表的基础字段放在一张表中，其他详情字段放在另一张表中，以提升操作效率。 内连接 内连接查询的是两张表交集部分的数据。 内连接的语法分为两种: 隐式内连接、显式内连接。 隐式内连接： SELECT 字段列表 FROM 表1 , 表2 WHERE 条件 ... ; 显式内连接： SELECT 字段列表 FROM 表1 [ INNER ] JOIN 表2 ON 连接条件 ... ; 外连接 外连接分为两种，分别是：左外连接和右外连接。 左外连接：左外连接相当于查询表1(左表)的所有数据，当然也包含表1和表2交集部分的数据。 SELECT 字段列表 FROM 表1 LEFT [ OUTER ] JOIN 表2 ON 条件 ... ; 右外连接：右外连接相当于查询表2(右表)的所有数据，当然也包含表1和表2交集部分的数据。 SELECT 字段列表 FROM 表1 RIGHT [ OUTER ] JOIN 表2 ON 条件 ... ; 注意事项：左外连接和右外连接是可以相互替换的，只需要调整在连接查询时SQL中，表结构的先后顺序就可以了。而我们在日常开发使用时，更偏向于左外连接。 自连接 自连接查询：自己连接自己，也就是把一张表连接查询多次。 而对于自连接查询，可以是内连接查询，也可以是外连接查询。 SELECT 字段列表 FROM 表A 别名A JOIN 表A 别名B ON 条件 ... ; 对于union查询，就是把多次查询的结果合并起来，形成一个新的查询结果集。 对于联合查询的多张表的列数必须保持一致，字段类型也需要保持一致。 union all 会将全部的数据直接合并在一起，union 会对合并之后的数据去重。 SELECT 字段列表 FROM 表A ... UNION [ ALL ] SELECT 字段列表 FROM 表B ....; 子查询 SQL语句中嵌套SELECT语句，称为嵌套查询，又称子查询。 子查询外部的语句可以是INSERT / UPDATE / DELETE / SELECT 的任何一个。 SELECT * FROM t1 WHERE column1 = ( SELECT column1 FROM t2 ); 标量子查询 子查询返回的结果是单个值（数字、字符串、日期等），最简单的形式，这种子查询称为标量子查询。 常用的操作符：=、\u0026lt;\u0026gt;、\u0026gt;、\u0026gt;=、\u0026lt;、\u0026lt;=。 -- 查询指定入职日期之后入职的员工信息 select * from emp where entrydate \u0026gt; (select entrydate from emp where name = \u0026#39;张三\u0026#39;); 列子查询 子查询返回的结果是一列（可以是多行），这种子查询称为列子查询。 常用的操作符：IN、NOT IN、ANY、SOME、ALL。 | 操作符 | 描述 | | IN | 在指定的集合范围之内，多选一 | | NOT IN | 不在指定的集合范围之内 | | ANY | 子查询返回列表中，有任意一个满足即可 | | SOME | 与ANY等同，使用SOME的地方都可以使用ANY | | ALL | 子查询返回列表的所有值都必须满足 |\n-- 根据部门ID, 查询员工信息 select * from emp where dept_id in ( select id from dept where name = \u0026#39;销售部\u0026#39; orname = \u0026#39;市场部\u0026#39; ); -- 比 财务部 所有人工资都高的员工信息 select * from emp where salary \u0026gt; all ( select salary from emp where dept_id = (select id from dept where name = \u0026#39;财务部\u0026#39;) ); -- 比研发部其中任意一人工资高的员工信息 select * from emp where salary \u0026gt; any ( select salary from emp where dept_id = (select id from dept where name = \u0026#39;研发部\u0026#39;) ); 行子查询 子查询返回的结果是一行（可以是多列），这种子查询称为行子查询。 常用的操作符：= 、\u0026lt;\u0026gt; 、IN 、NOT IN。 select * from emp where (salary,managerid) = ( select salary, managerid from emp where name = \u0026#39;张无忌\u0026#39; ); 表子查询 子查询返回的结果是多行多列，这种子查询称为表子查询。 常用的操作符：IN select * from emp where (job,salary) in ( select job, salary from emp where name =\u0026#39;XS\u0026#39; or name = \u0026#39;DS\u0026#39; ); ","permalink":"https://heliu.site/posts/mysql/join/","summary":"mysql Join 语法。","title":"mysql 多表查询"},{"content":" 事务：是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。 默认MySQL的事务是自动提交的，也就是说，当执行完一条DML语句时，MySQL会立即隐式的提交事务。 控制事务 查看/设置事务提交。 -- 查看事务设置 SELECT @@autocommit; -- 设置事务提交规则 SET @@autocommit = 0 ; 开启事务。 START TRANSACTION; -- 或 BEGIN; 提交事务。 COMMIT; 回滚事务。 ROLLBACK; 事务四大特性 原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。 一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态。 隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。 持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。 并发事务问题 赃读：一个事务读到另外一个事务还没有提交的数据。 不可重复读：一个事务先后读取同一条记录，但两次读取的数据不同，称之为不可重复读。 幻读：一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了 \u0026ldquo;幻影\u0026rdquo;。 事务隔离级别 为了解决并发事务所引发的问题，在数据库中引入了事务隔离级别。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;隔离级别\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 脏读 不可重复读 幻读 Read uncommitted √ √ √ Read committed × √ √ Repeatable Read(默认) × × √ Serializable × × × 查看事务隔离级别。 SELECT @@TRANSACTION_ISOLATION; 设置事务隔离级别。 SET [ SESSION | GLOBAL ] TRANSACTION ISOLATION LEVEL { READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE } ","permalink":"https://heliu.site/posts/mysql/transaction/","summary":"mysql 事务。","title":"mysql 事务"},{"content":"B+Tree 所有的数据都会出现在叶子节点。 叶子节点形成一个单向链表。 非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的。 MySQL索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点 的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能，利于排序。 索引分类 在MySQL数据库，将索引的具体类型主要分为以下几类：主键索引、唯一索引、常规索引、全文索引。 分类 含义 特点 关键字 主键索引 针对于表中主键创建的索引 默认自动创建, 只能有一个 PRIMARY 唯一索引 避免同一个表中某数据列中的值重复 可以有多个 UNIQUE 常规索引 快速定位特定数据 可以有多个 全文索引 全文索引查找的是文本中的关键词，而不是比较索引中的值 可以有多个 FULLTEXT 而在InnoDB存储引擎中，根据索引的存储形式，又可以分为以下两种： \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;分类\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 含义 特点 聚集索引(Clustered Index) 将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据 必须有,而且只有一个 二级索引(Secondary Index) 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 可以存在多个 聚集索引选取规则： 如果存在主键，主键索引就是聚集索引。 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引。 聚集索引和二级索引的具体结构如下： 聚集索引的叶子节点下挂的是这一行的数据。 二级索引的叶子节点下挂的是该字段值对应的主键值。 InnoDB主键索引的B+tree高度为多高呢? 一行数据大小为1k，一页中可以存储16行这样的数据。InnoDB的指针占用6个字节的空间，主键即使为bigint，占用字节数为8。 如果树的高度为2，则可以存储 18000 多条记录。 如果树的高度为3，则可以存储 2200w 左右的记录。 索引语法 创建索引。 CREATE [ UNIQUE | FULLTEXT ] INDEX index_name ON table_name (index_col_name,... ); -- name字段为姓名字段，该字段的值可能会重复，为该字段创建索引。 CREATE INDEX idx_user_name ON tb_user(name); -- phone手机号字段的值，是非空，且唯一的，为该字段创建唯一索引。 CREATE UNIQUE INDEX idx_user_phone ON tb_user(phone); -- 为profession、age、status创建联合索引。 CREATE INDEX idx_user_pro_age_sta ON tb_user(profession,age,status); -- 为email建立合适的索引来提升查询效率。 CREATE INDEX idx_email ON tb_user(email); 查看索引。 SHOW INDEX FROM table_name; 删除索引。 DROP INDEX index_name ON table_name; SQL性能分析 SQL执行频率 MySQL 客户端连接成功后，通过 show [session|global] status 命令可以提供服务器状态信息。 通过如下指令，可以查看当前数据库的INSERT、UPDATE、DELETE、SELECT的访问频次： -- session 是查看当前会话; -- global 是查询全局数据; SHOW GLOBAL STATUS LIKE \u0026#39;Com_______\u0026#39;; -- Com_delete: 删除次数 -- Com_insert: 插入次数 -- Com_select: 查询次数 -- Com_update: 更新次数 慢查询日志 慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有SQL语句的日志。 MySQL的慢查询日志默认没有开启，我们可以查看一下系统变量 slow_query_log。 show variables like \u0026#39;slow_query_log\u0026#39;; -- OFF-关闭 ON-开启 如果要开启慢查询日志，需要在MySQL的配置文件（/etc/my.cnf）中配置如下信息：(重启mysql) # 开启MySQL慢日志查询开关 slow_query_log=1 # 设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志 long_query_time=2 检查慢查询日志：慢日志文件是 localhost-slow.log。 $ tail -f localhost-slow.log profile详情 show profiles 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。 通过have_profiling参数，能够看到当前MySQL是否支持profile操作。 SELECT @@have_profiling; -- Yes-支持 SELECT @@profiling; -- 0-关闭 -- 开启，session/global级别开启profiling SET profiling = 1; 查看每一条sql耗时情况： -- 查看所有sql show profiles; -- 查看指定sql，Query_ID show profile for query 12; explain EXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序。 -- 直接在select语句之前加上关键字 explain / desc EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件 ; Explain 执行计划中各个字段的含义: 字段 含义 id select查询的序列号，表示查询中执行select子句或者是操作表的顺序(id相同，执行顺序从上到下；id不同，值越大，越先执行) select_type 表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION 中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE之后包含了子查询）等 type 表示连接类型，性能由好到差的连接类型为NULL、system、const、eq_ref、ref、range、index、all possible_key 显示可能应用在这张表上的索引，一个或多个 key 实际使用的索引，如果为NULL，则没有使用索引 key_len 表示索引中使用的字节数，该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好 rows MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值，可能并不总是准确的 filtered 表示返回结果的行数占需读取行数的百分比， filtered的值越大越好 索引使用 最左前缀法则 如果索引了多列（联合索引），要遵守最左前缀法则。 最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。 如果跳跃某一列，索引将会部分失效(后面的字段索引失效)。 注意：最左前缀法则中指的最左边的列，是指在查询时，联合索引的最左边的字段(即是第一个字段)必须存在，与我们编写SQL时，条件编写的先后顺序无关。 范围查询 联合索引中，出现范围查询(\u0026gt;,\u0026lt;)，范围查询右侧的列索引失效。 -- tb_user 表存在联合索引 (profession, age, status) -- 下面sql中age使用了\u0026gt;符号导致status索引失效，但是profession, age索引还是有用 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age \u0026gt; 30 and status = \u0026#39;0\u0026#39;; 在业务允许的情况下，尽可能的使用类似于 \u0026gt;= 或 \u0026lt;= 这类的范围查询，而避免使用 \u0026gt; 或 \u0026lt;。 -- 这种情况下，所有索引都生效了 explain select * from tb_user where profession = \u0026#39;软件工程\u0026#39; and age \u0026gt;= 30 and status = \u0026#39;0\u0026#39;; 索引失效 索引列运算 不要在索引列上进行运算操作，索引将失效。 -- tb_user表phone是单字段索引，因为使用了函数导致失效 explain select * from tb_user where substring(phone,10,2) = \u0026#39;15\u0026#39;; 字符串不加引号 字符串类型字段使用时，不加引号，索引将失效。 如果字符串不加单引号，对于查询结果，没什么影响，但是数据库存在隐式类型转换，索引将失效。 -- tb_user表phone是单字段索引，类型是varchar explain select * from tb_user where phone = \u0026#39;17799990015\u0026#39;; -- 没加引号，索引失效 explain select * from tb_user where phone = 17799990015; 模糊查询 如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。 -- profession 索引生效 explain select * from tb_user where profession like \u0026#39;软件%\u0026#39;; -- profession 索引失效 explain select * from tb_user where profession like \u0026#39;%工程\u0026#39;; -- profession 索引失效 explain select * from tb_user where profession like \u0026#39;%工%\u0026#39;; or连接条件 用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。 当or连接的条件，左右两侧字段都有索引时，索引才会生效。 -- id是主键，age没有索引，该sql不会使用任何索引 explain select * from tb_user where id = 10 or age = 23; -- phone是普通索引，age没有索引，该sql不会使用任何索引 explain select * from tb_user where phone = \u0026#39;17799990017\u0026#39; or age = 23; 数据分布影响 如果MySQL评估使用索引比全表更慢，则不使用索引。 -- 不会使用 phone 索引，因为全表扫描更快 select * from tb_user where phone \u0026gt;= \u0026#39;17799990005\u0026#39;; -- 会使用 phone 索引 select * from tb_user where phone \u0026gt;= \u0026#39;17799990015\u0026#39;; 因为MySQL在查询时，会评估使用索引的效率与走全表扫描的效率，如果走全表扫描更快，则放弃索引，走全表扫描。 因为索引是用来索引少量数据的，如果通过索引查询返回大批量的数据，则还不如走全表扫描来的快，此时索引就会失效。 is null 与 is not null 操作是否走索引？ 查询时MySQL会评估，走索引快，还是全表扫描快，如果全表扫描更快，则放弃索引走全表扫描。 因此，is null 、is not null是否走索引，得具体情况具体分析，并不是固定的。 explain select * from tb_user where profession is null; explain select * from tb_user where profession is not null; SQL提示 SQL提示，是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优化操作的目的。 use index ： 建议MySQL使用哪一个索引完成此次查询（仅仅是建议，mysql内部还会再次进行评估）。 explain select * from tb_user use index(idx_user_pro) where profession = \u0026#39;xsss\u0026#39;; ignore index：忽略指定的索引。 explain select * from tb_user ignore index(idx_user_pro) where profession = \u0026#39;xsss\u0026#39;; force index：强制使用索引。 explain select * from tb_user force index(idx_user_pro) where profession = \u0026#39;xsss\u0026#39;; 覆盖索引 覆盖索引是指查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到。 尽量使用覆盖索引，减少select *。 一张表, 有四个字段(id, username, password, status), 由于数据量大, 需要对以下SQL语句进行优化, 该如何进行才是最优方案: -- 针对于 username, password建立联合索引 -- sql为: create index idx_user_name_pass on tb_user(username,password); select id,username,password from tb_user where username =\u0026#39;st\u0026#39;; 前缀索引 当字段类型为字符串（varchar，text，longtext等）时，有时候需要索引很长的字符串，这会让索引变得很大，查询时，浪费大量的磁盘IO， 影响查询效率。 此时可以只将字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。 create index idx_xxxx on table_name(column(n)); -- 为tb_user表的email字段，建立长度为5的前缀索引 create index idx_email_5 on tb_user(email(5)); 前缀长度，可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值，索引选择性越高则查询效率越高， 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。 select count(distinct email) / count(*) from tb_user ; select count(distinct substring(email,1,5)) / count(*) from tb_user ; 单列索引与联合索引 单列索引：即一个索引只包含单个列。查询条件中有多个单列索引只会选择一个。 联合索引：即一个索引包含了多个列。 在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引，而非单列索引。 索引设计原则 针对于数据量较大，且查询比较频繁的表建立索引。 针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引。 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率。 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增删改的效率。 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含NULL值时，它可以更好地确定哪个索引最有效地用于查询。 ","permalink":"https://heliu.site/posts/mysql/tree/","summary":"mysql B+Tree。","title":"mysql 索引"},{"content":"插入数据 insert 如果我们需要一次性往数据库表中插入多条记录，可以从以下三个方面进行优化。 insert into tb_test values(1,\u0026#39;t\u0026#39;); insert into tb_test values(2,\u0026#39;c\u0026#39;); insert into tb_test values(3,\u0026#39;j\u0026#39;); -- ..... 优化方案一：批量插入数据 Insert into tb_test values(1,\u0026#39;t\u0026#39;),(2,\u0026#39;c\u0026#39;),(3,\u0026#39;j\u0026#39;); 优化方案二：手动控制事务 start transaction; insert into tb_test values(1,\u0026#39;t\u0026#39;),(2,\u0026#39;c\u0026#39;),(3,\u0026#39;j\u0026#39;); insert into tb_test values(4,\u0026#39;t\u0026#39;),(5,\u0026#39;c\u0026#39;),(6,\u0026#39;j\u0026#39;); insert into tb_test values(7,\u0026#39;t\u0026#39;),(8,\u0026#39;c\u0026#39;),(9,\u0026#39;j\u0026#39;); commit; 优化方案三：主键顺序插入，性能要高于乱序插入 主键乱序插入: 8 1 9 21 88 2 4 15 89 5 7 3 主键顺序插入: 1 2 3 4 5 7 8 9 15 21 88 89 大批量插入数据 如果一次性需要插入大批量数据(比如: 几百万的记录)，使用insert语句插入性能较低，此时可以使用MySQL数据库提供的load指令进行插入。 可以执行如下指令，将数据脚本文件中的数据加载到表结构中： -- 客户端连接服务端时，加上参数 -–local-infile mysql –-local-infile -u root -p -- 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关 set global local_infile = 1; -- 执行load指令将准备好的数据，加载到表结构中 load data local infile \u0026#39;/root/sql1.log\u0026#39; into table tb_user fields terminated by \u0026#39;,\u0026#39; lines terminated by \u0026#39;\\n\u0026#39; ; 主键优化 满足业务需求的情况下，尽量降低主键的长度。 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键。 尽量不要使用UUID做主键或者是其他自然主键，如身份证号。 业务操作时，避免对主键的修改。 order by优化 MySQL的排序，有两种方式： Using filesort: 通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区sort buffer中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序。 Using index: 通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高。 对于以上的两种排序方式，Using index的性能高，而Using filesort的性能低，我们在优化排序操作时，尽量要优化为 Using index。 order by优化原则： 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则。 尽量使用覆盖索引。 多字段排序, 一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC/DESC）。 如果不可避免的出现filesort，大数据量排序时，可以适当增大排序缓冲区大小sort_buffer_size(默认256k)。 group by优化 在分组操作时，可以通过索引来提高效率。 分组操作时，索引的使用也是满足最左前缀法则的。 limit优化 在数据量比较大时，如果进行limit分页查询，在查询时，越往后，分页查询效率越低。 当在进行分页查询时，如果执行 limit 2000000,10 ，此时需要MySQL排序前2000010 记录，仅仅返回 2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大。 一般分页查询时，通过创建 覆盖索引 能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化。 explain select * from tb_sku t , ( select id from tb_sku order by id limit 2000000,10 ) a where t.id = a.id; count优化 如果数据量很大，在执行count操作时，是非常耗时的。 MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；但是如果是带条件的count，MyISAM也慢。 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。 select count(*) from tb_user; count用法 count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是NULL，累计值就加 1，否则不加，最后返回累计值。 count用法 含义 count(主键) InnoDB 引擎会遍历整张表，把每一行的主键id 值都取出来，返回给服务层。服务层拿到主键后，直接按行进行累加(主键不可能为null) count(字段) 没有not null约束: InnoDB引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为null，不为null，计数累加。有not null约束：InnoDB引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，直接按行进行累加 count(数字) InnoDB 引擎遍历整张表，但不取值。服务层对于返回的每一行，放一个数字\u0026quot;1\u0026quot;进去，直接按行进行累加 count(*) InnoDB引擎并不会把全部字段取出来，而是专门做了优化，不取值，服务层直接按行进行累加 按照效率排序的话，count(字段) \u0026lt; count(主键 id) \u0026lt; count(1) ≈ count(*)，所以尽量使用count(*)。 update优化 我们在执行删除的SQL语句时，会锁定id为1这一行的数据，然后事务提交之后，行锁释放。 update course set name = \u0026#39;php\u0026#39; where id = 1; 当我们开启多个事务，在执行上述的SQL时，我们发现行锁升级为了表锁。 导致该update语句的性能大大降低。 update course set name = \u0026#39;javascript\u0026#39; where name = \u0026#39;PHP\u0026#39;; InnoDB的行锁是针对索引加的锁，不是针对记录加的锁 ,并且该索引不能失效，否则会从行锁升级为表锁。 ","permalink":"https://heliu.site/posts/mysql/sql/","summary":"mysql sql优化。","title":"mysql sql 优化"},{"content":"全局锁 全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语句，已经更新操作的事务提交语句都将被阻塞。 其典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完性。 对数据库进行进行逻辑备份之前，先对整个数据库加上全局锁，一旦加了全局锁之后，其他的DDL、DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态，而数据备份就是查询操作。那么数据在进行逻辑备份的过程中，数据库中的数据就是不会发生变化的，这样就保证了数据的一致性和完整性。 语法 加全局锁。 flush tables with read lock; 数据备份。 mysqldump -uroot –p1234 ic \u0026gt; ic.sql 释放锁。 unlock tables; 特点 数据库中加全局锁，是一个比较重的操作，存在以下问题： 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。 在InnoDB引擎中，我们可以在备份时加上参数 \u0026ndash;single-transaction 参数来完成不加锁的一致性数据备份。 mysqldump --single-transaction -uroot –p123456 ic \u0026gt; ic.sql 表级锁 表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。 表锁 对于表锁，分为两类：表共享读锁（read lock）、表独占写锁（write lock）。 语法： -- 加锁 lock tables 表名 read; -- 读锁 lock tables 表名 write; -- 写锁 -- 释放锁 unlock tables; 读锁：左侧为客户端一，对指定表加了读锁，不会影响右侧客户端二的读，但是会阻塞右侧客户端的写。 写锁：左侧为客户端一，对指定表加了写锁，会阻塞右侧客户端的读和写。 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写。 元数据锁 meta data lock，元数据锁，简写MDL。 MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。 MDL锁主要作用是维护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免DML与DDL冲突，保证读写的正确性。 这里的元数据，大家可以简单理解为就是一张表的表结构。也就是说，某一张表涉及到未提交的事务时，是不能够修改这张表的表结构的。 在MySQL5.5中引入了MDL，当对一张表进行增删改查的时候，加MDL读锁(共享)；当对表结构进行变更操作的时候，加MDL写锁(排他)。 常见的SQL操作时，所添加的元数据锁： \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-对应Sql\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- 锁类型 说明 lock tables xxx read/write SHARED_READ_ONLY（可读）/ SHARED_NO_READ_WRITE（不可读写） select 、select \u0026hellip; lock in share mode SHARED_READ(读锁) 与SHARED_READ、SHARED_WRITE兼容，与EXCLUSIVE互斥 insert 、update、delete、select \u0026hellip; for update SHARED_WRITE(写锁/排他) 与SHARED_READ、SHARED_WRITE兼容，与EXCLUSIVE互斥 alter table \u0026hellip; EXCLUSIVE 与其他的MDL都互斥 当执行SELECT、INSERT、UPDATE、DELETE等语句时，添加的是元数据共享锁（SHARED_READ/SHARED_WRITE），之间是兼容的。 通过下面的SQL，来查看数据库中的元数据锁的情况： select object_type,object_schema,object_name,lock_type,lock_duration from performance_schema.metadata_locks; 意向锁 为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。 意向共享锁(IS): 由语句select \u0026hellip; lock in share mode添加。与表锁共享锁(read)兼容，与表锁排他锁(write)互斥。 意向排他锁(IX): 由insert、update、delete、select\u0026hellip;for update添加。与表锁共享锁(read)及排他锁(write)都互斥，意向锁之间不会互斥。 一旦事务提交了，意向共享锁、意向排他锁，都会自动释放。 行级锁 行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在InnoDB存储引擎中。 InnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。对于行级锁，主要分为以下三类： 行锁（Record Lock）：锁定单个行记录的锁，防止其他事务对此行进行update和delete。在RC、RR隔离级别下都支持。 间隙锁（Gap Lock）：锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下都支持。 临键锁（Next-Key Lock）：行锁和间隙锁组合，同时锁住数据，并锁住数据前面的间隙Gap。在RR隔离级别下支持。 行级 InnoDB实现了以下两种类型的行锁： 共享锁（S）(read)：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。 排他锁（X）(write)：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他锁。 当前锁类型\\请求锁类型 S(共享锁) X(排他锁) S(共享锁) 兼容 冲突 X(排他锁) 冲突 冲突 常见的SQL语句，在执行时，所加的行锁如下： \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-SQL\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- 行锁类型 说明 INSERT \u0026hellip; 排他锁 自动加锁 UPDATE \u0026hellip; 排他锁 自动加锁 DELETE \u0026hellip; 排他锁 自动加锁 SELECT（正常） 不加任何锁 SELECT \u0026hellip; LOCK IN SHARE MODE 共享锁 需要手动在SELECT之后加LOCK IN SHARE MODE SELECT \u0026hellip; FOR UPDATE 排他锁 需要手动在SELECT之后加FOR UPDATE 默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用next-key锁进行搜索和索引扫描，以防止幻读。 针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。 InnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，此时就会升级为表锁。(修改条件没有用到索引，则会使用表锁) 可以通过以下SQL，查看意向锁及行锁的加锁情况： select object_schema,object_name,index_name,lock_type,lock_mode,lock_data from performance_schema.data_locks; 间隙锁\u0026amp;临键锁 默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用next-key锁进行搜索和索引扫描，以防止幻读。 索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁。 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock退化为间隙锁。 索引上的范围查询(唯一索引)\u0026ndash;会访问到不满足条件的第一个值为止。 注意：间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。 ","permalink":"https://heliu.site/posts/mysql/lock/","summary":"mysql 全局锁、表锁、行锁。","title":"mysql 锁"},{"content":"mysql 引擎 InnoDB InnoDB是一种兼顾高可靠性和高性能的通用存储引擎，在MySQL 5.5之后，InnoDB是默认的MySQL存储引擎。 特点： DML操作遵循ACID模型，支持事务。 行级锁，提高并发访问性能。 支持外键FOREIGN KEY约束，保证数据的完整性和正确性。 xxx.ibd：xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm-早期的 、sdi-新版的）、数据和索引。 如果该参数开启，代表对于InnoDB引擎的表，每一张表都对应一个ibd文件。 show variables like \u0026#39;innodb_file_per_table\u0026#39;; MyIsam MyISAM是MySQL早期的默认存储引擎。 特点： 不支持事务，不支持外键。 支持表锁，不支持行锁。 访问速度快。 文件： xxx.sdi：存储表结构信息。 xxx.MYD: 存储数据。 xxx.MYI: 存储索引。 Memory Memory引擎的表数据时存储在内存中的，由于受到硬件问题、或断电问题的影响，只能将这些表作为临时表或缓存使用。 特点：内存存放、hash索引（默认）。 文件：xxx.sdi：存储表结构信息 对比 特点 InnoDB MyIsam Memory 存储限制 64TB 有 有 事务安全 支持 - - 锁机制 行锁 表锁 表锁 B+tree索引 支持 支持 支持 Hash索引 - - 支持 全文索引 支持(5.6版本之后) 支持 - 空间使用 高 低 N/A 内存使用 高 低 中等 批量插入速度 低 高 高 支持外键 支持 - - InnoDB引擎与MyISAM引擎的区别： InnoDB引擎, 支持事务, 而MyISAM不支持。 InnoDB引擎, 支持行锁和表锁, 而MyISAM仅支持表锁, 不支持行锁。 InnoDB引擎, 支持外键, 而MyISAM是不支持的。 InnoDB引擎 架构 MySQL5.5 版本开始，默认使用InnoDB存储引擎，它擅长事务处理，具有崩溃恢复特性，在日常开发中使用非常广泛。 下面是InnoDB架构图，左侧为内存结构，右侧为磁盘结构。 内存结构 Buffer Pool：缓冲池 Buffer Pool，是主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增删改查操作时，先操作缓冲池中的数据（若缓冲池没有数据，则从磁盘加载并缓存），然后再以一定频率刷新到磁盘，从而减少磁盘IO，加快处理速度。 在专用服务器上，通常将多达80％的物理内存分配给缓冲池。 参数设置：show variables like \u0026lsquo;innodb_buffer_pool_size\u0026rsquo;。 Change Buffer：更改缓冲区（针对于非唯一二级索引页），在执行DML语句时，如果这些数据Page没有在Buffer Pool中，不会直接操作磁盘，而会将数据变更存在更改缓冲区Change Buffer中，在未来数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中。 Adaptive Hash Index：自适应hash索引，用于优化对Buffer Pool数据的查询。InnoDB存储引擎会监控对表上各索引页的查询，如果观察到在特定的条件下hash索引可以提升速度，则建立hash索引，称之为自适应hash索引。 Log Buffer：日志缓冲区，用来保存要写入到磁盘中的log日志数据（redo log 、undo log），默认大小为 16MB，日志缓冲区的日志会定期刷新到磁盘中。如果需要更新、插入或删除许多行的事务，增加日志缓冲区的大小可以节省磁盘I/O。参数： innodb_log_buffer_size：缓冲区大小 innodb_flush_log_at_trx_commit：日志刷新到磁盘时机，取值主要包含以下三个： 1: 日志在每次事务提交时写入并刷新到磁盘，默认值。 0: 每秒将日志写入并刷新到磁盘一次。 2: 日志在每次事务提交后写入，并每秒刷新到磁盘一次。 磁盘结构 System Tablespace：系统表空间是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。参数 innodb_data_file_path。 File-Per-Table Tablespaces：如果开启了innodb_file_per_table开关 ，则每个表的文件表空间包含单个InnoDB表的数据和索引，并存储在文件系统上的单个数据文件中。开关参数 innodb_file_per_table ，该参数默认开启。 General Tablespaces：通用表空间，需要通过 CREATE TABLESPACE 语法创建通用表空间，在创建表时，可以指定该表空间。 Undo Tablespaces：撤销表空间，MySQL实例在初始化时会自动创建两个默认的undo表空间（初始大小16M），用于存储undo log日志。 Temporary Tablespaces：InnoDB 使用会话临时表空间和全局临时表空间。存储用户创建的临时表等数据。 Doublewrite Buffer Files：双写缓冲区，innoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件中，便于系统异常时恢复数据。 Redo Log：重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中, 用于在刷新脏页到磁盘时,发生错误时, 进行数据恢复使用。 后台线程 在InnoDB的后台线程中，分为4类，分别是：Master Thread 、IO Thread、Purge Thread、Page Cleaner Thread。 Master Thread：核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中, 保持数据的一致性，还包括脏页的刷新、合并插入缓存、undo页的回收。 IO Thread：在InnoDB存储引擎中大量使用了AIO来处理IO请求, 这样可以极大地提高数据库的性能，而IO Thread主要负责这些IO请求的回调。通过 show engine innodb status \\G; 查看。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;线程类型\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 默认个数 职责 Read thread 4 负责读操作 Write thread 4 负责写操作 Log thread 1 负责将日志缓冲区刷新到磁盘 Insert buffer thread 1 负责将写缓冲区内容刷新到磁盘 Purge Thread：主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。 Page Cleaner Thread：协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。 事务原理 事务：是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。 特性： 原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。 一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态。 隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。 持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。 而对于这四大特性，实际上分为两个部分。 其中的原子性、一致性、持久化，实际上是由InnoDB中的两份日志来保证的，一份是redo log日志，一份是undo log日志。 而持久性是通过数据库的锁，加上MVCC来保证的。 redo log 重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。 该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log file）,前者是在内存中，后者在磁盘中。 当事务提交之后会把所有修改信息都存到该日志文件中, 用于在刷新脏页到磁盘,发生错误时, 进行数据恢复使用。 有了redolog之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redo log buffer中。在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据恢复，这样就保证了事务的持久性。而如果脏页成功刷新到磁盘或者涉及到的数据已经落盘，此时redolog就没有作用了，就可以删除了，所以存在的两个redolog文件是循环写的。 在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 这种先写日志的方式，称之为WAL（Write-Ahead Logging）。 undo log 回滚日志，用于记录数据被修改前的信息,作用包含两个: 提供回滚(保证事务的原子性)和MVCC(多版本并发控制)。 undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。 Undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于MVCC。 Undo log存储：undo log采用段的方式进行管理和记录，存放在前面介绍的rollback segment回滚段中，内部包含1024个undo log segment。 MVCC 基本概念 当前读 读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。 对于我们日常的操作，如：(都是一种当前读) select \u0026hellip; lock in share mode (共享锁) select \u0026hellip; for update、update、insert、delete (排他锁) 在默认的RR隔离级别下，事务A第(5)步能读取到事务B第(3)步提交的数据。 因为在查询语句后面加上了lock in share mode共享锁，此时是当前读操作。 当然，当我们加排他锁的时候，也是当前读操作。 快照读 简单的select（不加锁）就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。 Read Committed (读已提交)：每次select，都生成一个快照读。 Repeatable Read (可重复读)：开启事务后第一个select语句才是快照读的地方。 Serializable (串行化)：快照读会退化为当前读。 MVCC 全称 Multi-Version Concurrency Control，多版本并发控制。 指维护一个数据的多个版本，使得读写操作没有冲突，快照读为MySQL实现MVCC提供了一个非阻塞读功能。 MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undo log日志、readView。 隐藏字段 当我们创建一张表时，除了我们自己定义的字段外，InnoDB还会自动给我们添加三个隐藏字段。 前两个字段是肯定会添加的，是否添加最后一个字段DB_ROW_ID，得看当前表有没有主键，如果有主键，则不会添加该隐藏字段。 隐藏字段 含义 DB_TRX_ID 最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID DB_ROLL_PTR 回滚指针，指向这条记录的上一个版本，用于配合undo log，指向上一个版本 DB_ROW_ID 隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段 undo log 回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。 当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除。 而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除。 版本链 有一张表原始数据为： DB_TRX_ID：代表最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID，是自增的。 DB_ROLL_PTR：由于这条数据是才插入的，没有被更新过，所以该字段值为null。 id age name DB_TRX_ID DB_ROLL_PTR 30 30 A30 1 null 然后，有四个并发事务同时在访问这张表。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务A\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务B\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务C\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务D\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 开始事务 开始事务 开始事务 开始事务 修改id为30记录，age为3 查询id为30的记录 当事务A执行第一条修改语句时，会记录undo log日志，记录数据变更之前的样子；然后更新记录，并且记录本次操作的事务ID，回滚指针，回滚指针用来指定如果发生回滚，回滚到哪一个版本。 然后，事务A提交事务，事务B更新记录。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务A\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;事务B\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务C\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务D\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 开始事务 开始事务 开始事务 开始事务 修改id为30记录，age为3 查询id为30的记录 提交事务 修改id为30记录，name为A3 当事务B执行第一条修改语句时，也会记录undo log日志，记录数据变更之前的样子；然后更新记录，并且记录本次操作的事务ID，回滚指针，回滚指针用来指定如果发生回滚，回滚到哪一个版本。 紧接着，事务B提交，事务C更新记录。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务A\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;事务B\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;事务C\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026ndash;事务D\u0026mdash;\u0026mdash;\u0026ndash; 开始事务 开始事务 开始事务 开始事务 修改id为30记录，age为3 查询id为30的记录 提交事务 修改id为30记录，name为A3 查询id为30的记录 提交事务 修改id为30记录，age为10 查询id为30的记录 查询id为30的记录 提交事务 当事务C执行第一条修改语句时，也会记录undo log日志，记录数据变更之前的样子；然后更新记录，并且记录本次操作的事务ID，回滚指针，回滚指针用来指定如果发生回滚，回滚到哪一个版本。 不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录。 readview ReadView（读视图）是快照读SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id。 ReadView中包含了四个核心字段： 字段 含义 m_ids 当前活跃的事务ID集合 min_trx_id 最小活跃事务ID max_trx_id 预分配事务ID，当前最大事务ID+1（因为事务ID是自增的） creator_trx_id ReadView创建者的事务ID 而在readview中就规定了版本链数据的访问规则：trx_id 代表当前undolog版本链对应事务ID。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-条件\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- 是否可以访问 说明 trx_id == creator_trx_id 可以访问该版本 数据是当前这个 trx_id \u0026lt; min_trx_id 可以访问该版本 数据已经提交了 trx_id \u0026gt; max_trx_id 不可以访问该版本 该事务是在ReadView生成后才开启 min_trx_id \u0026lt;= trx_id \u0026lt;= max_trx_id 如果trx_id不在m_ids中，是可以访问该版本的 数据已经提交 不同的隔离级别，生成ReadView的时机不同 READ COMMITTED (读已提交)：在事务中每一次执行快照读时生成ReadView。 REPEATABLE READ (可重复读)：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 原理分析 RC隔离级别 RC隔离级别下，在事务中每一次执行快照读时生成ReadView。 分析事务D中，两次快照读读取数据，是如何获取数据的。在事务D中，查询了两次id为30的记录，由于隔离级别为Read Committed，所以每一次进行快照读都会生成一个ReadView，那么两次生成的ReadView。 先来看第一次快照读具体的读取过程： 当trx_id=3代入判断规则中，(1)~(4)都不满足。 当trx_id=2代入判断规则中，(1)都不满足，(2)满足。因此读取的是这条数据。 第二次快照读具体的读取过程： 当trx_id=4代入判断规则中，(1)~(4)都不满足。 当trx_id=3代入判断规则中，(1)都不满足，(2)满足。因此读取的是这条数据。 RR隔离级别 RR隔离级别下，仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 而RR是可重复读，在一个事务中，执行两次相同的select语句，查询到的结果是一样的。 第一次与RC一样： 当trx_id=3代入判断规则中，(1)~(4)都不满足。 当trx_id=2代入判断规则中，(1)都不满足，(2)满足。因此读取的是这条数据。 第二次快照读具体的读取过程： 当trx_id=4代入判断规则中，(1)~(4)都不满足。 当trx_id=3代入判断规则中，(1)~(4)都不满足。 当trx_id=2代入判断规则中，(1)都不满足，(2)满足。因此读取的是这条数据。 可以看出同一个事务内多次读确实是同一数据。 总结 MVCC的实现原理就是通过InnoDB表的隐藏字段、UndoLog 版本链、ReadView来实现的。 而MVCC + 锁，则实现了事务的隔离性。 而一致性则是由redolog与undolog保证。 ","permalink":"https://heliu.site/posts/mysql/innodb/","summary":"mysql innodb、MVCC。","title":"mysql innodb"},{"content":"系统数据库 Mysql数据库安装完成后，自带了一下四个数据库，具体作用如下： 数据库 含义 mysql 存储MySQL服务器正常运行所需要的各种信息 （时区、主从、用户、权限等） information_schema 提供了访问数据库元数据的各种表和视图，包含数据库、表、字段类型及访问权限等 performance_schema 为MySQL服务器运行时状态提供了一个底层监控功能，主要用于收集数据库服务器性能参数 sys 包含了一系列方便 DBA 和开发人员利用 performance_schema 性能数据库进行性能调优和诊断的视图 mysql mysql不是指mysql服务，而是指mysql的客户端工具。 语法： mysql [options] [database] 选项： -u, --user=name # 指定用户名 -p, --password[=name] # 指定密码 -h, --host=name # 指定服务器IP或域名 -P, --port=port # 指定连接端口 -e, --execute=name # 执行SQL语句并退出 -e选项可以在Mysql客户端执行SQL语句，而不用连接到MySQL数据库再执行，对于一些批处理脚本，这种方式尤其方便。 mysql -uroot –p123456 db01 -e \u0026#34;select * from table\u0026#34;; mysqladmin mysqladmin 是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前状态、创建并删除数据库等。 -- 帮助文档 mysqladmin --help 语法: mysqladmin [options] command ... 选项: -u, --user=name # 指定用户名 -p, --password[=name] # 指定密码 -h, --host=name # 指定服务器IP或域名 -P, --port=port # 指定连接端口 -- 删除库test01 mysqladmin -uroot –p1234 drop \u0026#39;test01\u0026#39;; -- 查看版本 mysqladmin -uroot –p1234 version; mysqlbinlog 由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到mysqlbinlog 日志管理工具。 语法： mysqlbinlog [options] log-files1 log-files2 ... 选项： -d, --database=name # 指定数据库名称，只列出指定的数据库相关操作。 -o, --offset=n # 忽略掉日志中的前n行命令。 -r,--result-file=name # 将输出的文本格式日志输出到指定文件。 -s, --short-form # 显示简单格式， 省略掉一些信息。 --start-datatime=date1 --stop-datetime=date2 # 指定日期间隔内的所有日志。 --start-position=pos1 --stop-position=pos2 # 指定位置间隔内的所有日志。 查看 binlog.000008 这个二进制文件中的数据信息。 mysqlbinlog -s binlog.000008 mysqlshow mysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引。 语法： mysqlshow [options] [db_name [table_name [col_name]]] 选项： --count # 显示数据库及表的统计信息（数据库，表 均可以不指定） -i # 显示指定数据库或者指定表的状态信息 -- 查询test库中每个表中的字段书，及行数 mysqlshow -uroot -p2143 test --count -- 查询test库中book表的详细情况 mysqlshow -uroot -p2143 test book --count -- 查询每个数据库的表的数量及表中记录的数量 mysqlshow -uroot -p1234 --count -- 查看数据库db01的统计信息 mysqlshow -uroot -p1234 db01 --count -- 查看数据库db01中的course表的信息 mysqlshow -uroot -p1234 db01 course --count -- 查看数据库db01中的course表的id字段的信息 mysqlshow -uroot -p1234 db01 course id --count mysqldump mysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表，及插入表的SQL语句。 语法： mysqldump [options] db_name [tables] mysqldump [options] --database/-B db1 [db2 db3...] mysqldump [options] --all-databases/-A 连接选项： -u, --user=name # 指定用户名 -p, --password[=name] # 指定密码 -h, --host=name # 指定服务器ip或域名 -P, --port= # 指定连接端口 输出选项： --add-drop-database # 在每个数据库创建语句前加上 drop database 语句 --add-drop-table # 在每个表创建语句前加上 drop table 语句 , 默认开启 ; 不开启 (--skip-add-drop-table) -n, --no-create-db # 不包含数据库的创建语句 -t, --no-create-info # 不包含数据表的创建语句 -d --no-data # 不包含数据 -T, --tab=name # 自动生成两个文件：一个.sql文件，创建表结构的语句；一个.txt文件，数据文件 -- 备份db01数据库 mysqldump -uroot -p1234 db01 \u0026gt; db01.sql -- 备份db01数据库中的表数据，不备份表结构(-t) mysqldump -uroot -p1234 -t db01 \u0026gt; db01.sql -- 将db01数据库的表的表结构与数据分开备份(-T) mysqldump -uroot -p1234 -T /root db01 score mysqlimport/source mysqlimport mysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件。 语法： mysqlimport [options] db_name textfile1 [textfile2...] mysqlimport -uroot -p2143 test /tmp/city.txt source 如果需要导入sql文件,可以使用mysql中的source指令: 语法： source /root/xxxxx.sql ","permalink":"https://heliu.site/posts/mysql/tool/","summary":"mysql 常用工具。","title":"mysql 工具"},{"content":" 主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。 MySQL支持一台主库同时向多台从库进行复制，从库同时也可以作为其他从服务器的主库，实现链状复制。 MySQL的主从复制并不是数据库磁盘上的文件直接拷贝，而是通过逻辑的 binlog 日志复制到要同步的服务器本地，然后由本地的线程读取日志里面的 SQL 语句，重新应用到 MySQL 数据库中。 MySQL 复制的优点主要包含以下三个方面： 做数据的热备，主库宕机后备库能够及时替换主库，保证业务可用性，能一定程度避免数据丢失。 实现读写分离，主库写，从库读，减小主库的读写压力。当主库执行写过程加锁时，不会堵塞从库读操作，从而提高了数据的查询效率。 应对业务量越来越大，I/O 访问频率过高，单机无法满足的问题。增加多个从库做负载，能够降低整体 I/O 访问频率，提高单个机器 I/O 性能。 原理 MySQL主从复制的核心就是二进制日志，具体的过程如下： 基于 binlog 复制模式 MySQL 主从复制默认是异步的模式，复制分成三步： Master 主库在事务提交时，会把数据变更（增删改）记录在二进制日志文件 Binlog 中。 当slave节点连接master时，从库读取主库的二进制日志文件Binlog，写入到从库的中继日志 Relay Log。 slave重做中继日志中的事件，将改变反映它自己的数据。 GTID 复制模式 在传统的复制里面，当发生故障，需要主从切换，需要找到 Binlog 和 位点信息，恢复完成数据之后将主节点指向新的主节点。 在 MySQL 5.6里面，提供了新的数据恢复思路，只需要知道主节点的 IP、端口以及账号密码就行，因为复制是自动的，MySQL会通过内部机制 GTID 自动找点同步。 GTID 是什么 GTID 指的是全局事务 ID，全程是 Global Transaction Identifier，在整个事务流程中每一个事务 ID 是全局唯一的，且在整个主从复制架构中该 ID 都不会相同。 GTID 主从复制方式 基于 GTID 的主从复制方式的出现，主要是用于替换传统的日志点 复制方式。 通过GTID 可以保证每个主库提交的事务在集群中都有唯一的一个事务 ID。 强化了数据库主从的一致性和故障恢复数据的容错能力，在主库 宕机发生主从切换 的情况下，GTID 方式可以让其他从库自动找到新主库复制的位置。而且 GTID 可以忽略已经执行过的事务，减少了数据发生错误的概率。 GTID 的组成 GTID 由server_uuid + tid 组成，其中： server_uuid： server_uuid 是在 Mysql 首次启动过程中自动生成的一个uuid(128位)随机值，生成后会将该值存储到数据目录的auto.cnf中。因为是随机值，所以不同服务器的 Mysql 的server_uuid 都是不相同的。 tid：代表了该实例上已经提交的事务数量，是一个整数，初始值是 1 ，每次提交事务的时候分配给这个事务并加1。 GTID 复制工作原理 假设从库开启了 binlog，那么执行流程如下： 主节点执行事务提交前会产生一个 GTID ，其会随着事务一起记录到 binlog 日志中。 从节点I/O Thread会读取主节点的binlog日志文件并存储在从节点的relaylog日志中。从节点将主节点的GTID这个值配置到gtid_next中，即下一个要读取的GTID值。 从节点读取gtid_next中的值，然后查找自己的binlog日志中是否有这个GTID。 如果有这个记录，说明这个GTID的事务已经执行过了，就忽略掉。 如果没有这个记录，从节点就会执行该GTID事务，并记录到自己的binlog日志中。在读取执行事务前会先检查其他session中是否持有该GTID ，确保不被重复执行。 在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。 GTID 使用中的限制条件 GTID 复制是针对事务来说的，一个事务只对应一个 GTID，好多的限制就在于此。其中主要限制如下： 不能使用create table table_name select * from table_name 。 在一个事务中既包含事务表（使用 InnoDB 存储引擎的表）的操作又包含非事务表（使用 MyISAM 存储引擎的表）。 不支持创建或删除临时表操作，如 CREATE TEMPORARY TABLE or DROP TEMPORARY TABLE 语句操作。 使用 GTID 复制从库跳过错误时，不支持执行该 ql_slave_skip_counter 参数的语法。 搭建 docker-compose.yml 文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 version: \u0026#39;3.9\u0026#39; services: mysql-master: container_name: mysql-master hostname: mysql-master image: mysql:8.0.19 ports: - 3306:3306 volumes: - ./master/data:/var/lib/mysql - ./master/my.cnf:/etc/mysql/conf.d/my.cnf - ./master/init_db/:/docker-entrypoint-initdb.d/ - /etc/localtime:/etc/localtime:ro environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: test character-set-server: utf8mb4 collation-server: utf8mb4_general_ci default-authentication-plugin: mysql_native_password restart: unless-stopped privileged: true healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;mysqladmin\u0026#34; ,\u0026#34;ping\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;localhost\u0026#34;, \u0026#34;--silent\u0026#34; ] interval: 10s timeout: 10s retries: 3 networks: basenetwork: ipv4_address: 172.16.0.101 mysql-slave1: container_name: mysql-slave1 hostname: mysql-slave1 image: mysql:8.0.19 ports: - 3307:3306 volumes: - ./slave01/data:/var/lib/mysql - ./slave01/my.cnf:/etc/mysql/conf.d/my.cnf - ./slave01/init_db/:/docker-entrypoint-initdb.d/ - /etc/localtime:/etc/localtime:ro environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: test character-set-server: utf8mb4 collation-server: utf8mb4_general_ci default-authentication-plugin: mysql_native_password restart: unless-stopped privileged: true healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;mysqladmin\u0026#34; ,\u0026#34;ping\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;localhost\u0026#34;, \u0026#34;--silent\u0026#34; ] interval: 10s timeout: 10s retries: 3 networks: basenetwork: ipv4_address: 172.16.0.102 mysql-slave2: container_name: mysql-slave2 hostname: mysql-slave2 image: mysql:8.0.19 ports: - 3308:3306 volumes: - ./slave02/data:/var/lib/mysql - ./slave02/my.cnf:/etc/mysql/conf.d/my.cnf - ./slave02/init_db/:/docker-entrypoint-initdb.d/ - /etc/localtime:/etc/localtime:ro environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: test character-set-server: utf8mb4 collation-server: utf8mb4_general_ci default-authentication-plugin: mysql_native_password restart: unless-stopped privileged: true healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;mysqladmin\u0026#34; ,\u0026#34;ping\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;localhost\u0026#34;, \u0026#34;--silent\u0026#34; ] interval: 10s timeout: 10s retries: 3 networks: basenetwork: ipv4_address: 172.16.0.103 networks: basenetwork: driver: bridge ipam: driver: default config: - subnet: 172.16.0.0/24 master配置 修改配置文件 /etc/my.cnf。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 [mysqld] # 开启 gtid 模式 gtid_mode=on # 配置不允许任何事务违反 GTID 一致性,用于保证数据一致性 enforce_gtid_consistency=on # 开启二进制日志 binlog log-bin=mysql-bin # mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 232-1，默认为1 server-id=1 # 从节点从主节点接收到更新且执行，是否将记录存到从节点的 binlog 日志中（可选） log-slave-updates=on # 当从数据库启动的时候，从节点不会启动复制（可选） #skip-slave-start=1 # 是否只读,1 代表只读, 0 代表读写 read-only=0 # 不需要复制的数据库名（mysql库一般不同步） binlog-ignore-db=mysql #binlog-ignore-db=performation_schema #binlog-ignore-db=information_schema # 指定同步的数据库 #binlog-do-db=db01 # 只保留7天的二进制日志，以防磁盘被日志占满(可选) #expire-logs-days = 7 # 主从复制的格式（mixed,statement,row，默认格式是statement） #binlog_format = mixed # 为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存 # binlog_cache_size = 1M 创建远程连接账号并授予主从复制权限。 1 2 3 4 5 6 7 8 -- 创建ic用户，并设置密码，该用户可在任意主机连接该MySQL服务 CREATE USER \u0026#39;ic\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;Root@123456\u0026#39;; -- 为 \u0026#39;ic\u0026#39;@\u0026#39;%\u0026#39; 用户分配主从复制权限 GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \u0026#39;ic\u0026#39;@\u0026#39;%\u0026#39;; -- 刷新权限 FLUSH PRIVILEGES; 通过指令，查看二进制日志坐标：show master status; file： 从哪个日志文件开始推送日志文件。(用于从同步) position：从哪个位置开始推送日志。(用于从同步) binlog_ignore_db：指定不需要同步的数据库。 查看master数据有那些slave。 select * from information_schema.processlist as p where p.command = \u0026#39;Binlog Dump\u0026#39;; slave 配置 slave1的my.cnf。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [mysqld] # 开启 gtid 模式 gtid_mode=on # 配置不允许任何事务违反 GTID 一致性,用于保证数据一致性 enforce_gtid_consistency=on # 开启二进制日志 binlog log-bin=mysql-bin # mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 232-1，默认为1 server-id=2 # 从节点从主节点接收到更新且执行，是否将记录存到从节点的 binlog 日志中（可选） log-slave-updates=on # 当从数据库启动的时候，从节点不会启动复制（可选） #skip-slave-start=1 # 是否只读,1 代表只读, 0 代表读写 read-only=1 # 不需要复制的数据库名（mysql库一般不同步） binlog-ignore-db=mysql # 指定同步的数据库 #binlog-do-db=db01 # 只保留7天的二进制日志，以防磁盘被日志占满(可选) #expire-logs-days = 7 # 主从复制的格式（mixed,statement,row，默认格式是statement） #binlog_format = mixed # 为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存 # binlog_cache_size = 1M slave2的my.cnf。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [mysqld] # 开启 gtid 模式 gtid_mode=on # 配置不允许任何事务违反 GTID 一致性,用于保证数据一致性 enforce_gtid_consistency=on # 开启二进制日志 binlog log-bin=mysql-bin # mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 232-1，默认为1 server-id=3 # 从节点从主节点接收到更新且执行，是否将记录存到从节点的 binlog 日志中（可选） log-slave-updates=on # 当从数据库启动的时候，从节点不会启动复制（可选） #skip-slave-start=1 # 是否只读,1 代表只读, 0 代表读写 read-only=1 # 不需要复制的数据库名（mysql库一般不同步） binlog-ignore-db=mysql # 指定同步的数据库 #binlog-do-db=db01 # 只保留7天的二进制日志，以防磁盘被日志占满(可选) #expire-logs-days = 7 # 主从复制的格式（mixed,statement,row，默认格式是statement） #binlog_format = mixed # 为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存 # binlog_cache_size = 1M 设置主库配置。 1 2 3 4 -- 8.0.23中的语法 CHANGE REPLICATION SOURCE TO SOURCE_HOST=\u0026#39;mysql-master\u0026#39;, SOURCE_USER=\u0026#39;ic\u0026#39;, SOURCE_PASSWORD=\u0026#39;Root@123456\u0026#39;, SOURCE_PORT=3306, SOURCE_LOG_FILE=\u0026#39;binlog.000004\u0026#39;, SOURCE_LOG_POS=663; 1 2 3 4 -- mysql8.0.23 之前的版本 CHANGE MASTER TO MASTER_HOST=\u0026#39;mysql-master\u0026#39;, MASTER_USER=\u0026#39;ic\u0026#39;, MASTER_PASSWORD=\u0026#39;Root@123456\u0026#39;, MASTER_PORT=3306, MASTER_LOG_FILE=\u0026#39;binlog.000004\u0026#39;, MASTER_LOG_POS=663; 参数名 含义 8.0.23前 SOURCE_HOST 主库IP地址 MASTER_HOST SOURCE_USER 连接主库的用户名 MASTER_USER SOURCE_PASSWORD 连接主库的密码 MASTER_PASSWORD SOURCE_LOG_FILE binlog日志文件名 MASTER_LOG_FILE SOURCE_LOG_POS binlog日志文件位置 MASTER_LOG_POS SOURCE_CONNECT_RETRY 连接失败，重试的时间间隔/秒，默认60秒 MASTER_CONNECT_RETRY 开启同步操作。(从库执行) 1 2 3 4 5 -- mysql8.0.22版本之后 start replica; -- mysql8.0.22版本之前 start slave; 查看主从同步状态。(从库执行) 1 2 3 4 5 -- mysql8.0.22版本之后 show replica status; -- mysql8.0.22版本之前 show slave status; 测试 在master运行如下代码。 create database db01; use db01; create table tb_user( id int(11) primary key not null auto_increment, name varchar(50) not null, sex varchar(1) )engine=innodb default charset=utf8mb4; insert into tb_user(id,name,sex) values(null,\u0026#39;Tom\u0026#39;, \u0026#39;1\u0026#39;),(null,\u0026#39;Trigger\u0026#39;,\u0026#39;0\u0026#39;),(null,\u0026#39;Dawn\u0026#39;,\u0026#39;1\u0026#39;); 在slave01和slave02中分别验证。 查看master数据有那些slave。 select * from information_schema.processlist as p where p.command = \u0026#39;Binlog Dump\u0026#39;; 注意 CHANGE MASTER 只能同步后续变化数据，首次数据需要，自己手动在所有slave上运行一遍。 github 完整的代码请前往github, https://github.com/helium-chain/master-slave。 ","permalink":"https://heliu.site/posts/mysql/master/","summary":"mysql 主从复制。","title":"mysql 主从复制"},{"content":" 随着互联网及移动互联网的发展，应用系统的数据量也是成指数式增长，若采用单数据库进行数据存储，存在以下性能瓶颈： IO瓶颈：热点数据太多，数据库缓存不足，产生大量磁盘IO，效率较低。请求数据太多，带宽不够，网络IO瓶颈。 CPU瓶颈：排序、分组、连接查询、聚合统计等SQL会耗费大量的CPU资源，请求数太多，CPU出现瓶颈。 为了解决上述问题，我们需要对数据库进行分库分表处理。分库分表的中心思想都是将数据分散存储，使得单一数据库/表的数据量变小来缓解单一数据库的性能问题，从而达到提升数据库性能的目的。 拆分策略 分库分表的形式，主要是两种：垂直拆分和水平拆分。 而拆分的粒度，一般又分为分库和分表，所以组成的拆分策略最终如下： \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;垂直拆分\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;水平拆分\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 垂直分库 水平分库 垂直分表 水平分表 垂直拆分 垂直分库 垂直分库：以表为依据，根据业务将不同表拆分到不同库中。 特点： 每个库的表结构都不一样。 每个库的数据也不一样。 所有库的并集是全量数据。 比较常用垂直分库，比如产品维度分商品表库和购物车表库。 垂直分表 垂直分表：以字段为依据，根据字段属性将不同字段拆分到不同表中。 特点： 每个表的结构都不一样。 每个表的数据也不一样，一般通过一列（主键/外键）关联。 所有表的并集是全量数据。 当我们的数据表有很多冗余字段时，可采取垂直分表，这样能把热点字段分为一个表，其他字段分为一个表。 水平拆分 水平分库 水平分库：以字段为依据，按照一定策略，将一个库的数据拆分到多个库中。 特点： 每个库的表结构都一样。 每个库的数据都不一样。 所有库的并集是全量数据。 水平分库很少见，不推荐这种。 水平分表 水平分表：以字段为依据，按照一定策略，将一个表的数据拆分到多个表中。 特点： 每个表的表结构都一样。 每个表的数据都不一样。 所有表的并集是全量数据。 水平分表比较常见，比如一张表的数据太大了超千万级别，导致索引检索变慢，可以采用水平分表。 一旦涉及水平分布，则需要考虑主键ID(雪花算法)、分多少张表，以及后面扩容问题。 常见的几种策略： hash取模：假设有用户表user，将其分成3个表user0,user1,user2。路由规则是对3取模,当uid=1时,对应到的是user1,uid=2时,对应的是user2。好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。 范围分片：从1-100w一个表,100w-200w一个表。好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。 地理位置分片：华南区一个表,华北一个表。根据地区划分表。 时间分片：按月分片，按季度分片等等,可以做到冷热数据。 相关中间件 shardingJDBC：基于AOP原理，在应用程序中对本地执行的SQL进行拦截，解析、改写、路由处理。需要自行编码配置实现，只支持java语言，性能较高。 MyCat：数据库分库分表中间件，不用调整代码即可实现分库分表，支持多种语言，性能不及前者。 分库分表问题 分布式事务问题 如果我们做了垂直分库或者水平分库以后,就必然会涉及到跨库执行SQL的问题,这样就引发了互联网界的老大难问题-“分布式事务”。那要如何解决这个问题呢？ 使用分布式事务中间件。 使用MySQL自带的针对跨库的事务一致性方案(XA),不过性能要比单库的慢10倍左右。 能否避免掉跨库操作(比如将用户和商品放在同一个库中) 跨库join的问题 分库分表后表之间的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表，结果原本一次查询能够完成的业务，可能需要多次查询才能完成。粗略的解决方法： 全局表：基础数据，所有库都拷贝一份。 字段冗余：这样有些字段就不用join去查询了。 系统层组装：分别查询出所有，然后组装起来，较复杂。 横向扩容的问题 当我们使用HASH取模做分表的时候,针对数据量的递增,可能需要动态的增加表,此时就需要考虑因为reHash导致数据迁移的问题。 结果集合并、排序的问题 因为我们是将数据分散存储到不同的库、表里的,当我们查询指定数据列表时,数据来源于不同的子库或者子表,就必然会引发结果集合并、排序的问题。如果每次查询都需要排序、合并等操作,性能肯定会受非常大的影响。走缓存可能一条路! ","permalink":"https://heliu.site/posts/mysql/table/","summary":"mysql 分库分表策略。","title":"mysql 分库分表"},{"content":" Mycat是开源的、活跃的、基于Java语言编写的MySQL数据库中间件。可以像使用mysql一样来使用mycat，对于开发人员来说根本感觉不到mycat的存在。 开发人员只需要连接MyCat即可，而具体底层用到几台数据库，每一台数据库服务器里面存储了什么数据，都无需关心。 官网地址：http://www.mycat.org.cn/ 安装 参看后面示例。 目录介绍 bin: 存放可执行文件，用于启动停止mycat。 conf：存放mycat的配置文件。 lib：存放mycat的项目依赖包（jar）。 logs：存放mycat的日志文件。 概念 在MyCat的整体结构中，分为两个部分：上面的逻辑结构、下面的物理结构。 在MyCat的逻辑结构主要负责逻辑库、逻辑表、分片规则、分片节点等逻辑结构的处理，而具体的数据存储还是在物理结构，也就是数据库服务器中存储的。 其他 9066 端口，用于查看MyCat监控信息。 8066 端口，用于与mysql数据交换。 9066 端口支持命令。(通过：mysql -h localhost -uroot -P9066 -p123456 连接) 以下介绍部分命令。更多通过：**show @@help;**查看 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-命令\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- 作用 show @@server 查看服务器状态，包括占用内存等 show @@database 查看数据库 show @@heartbeat 前后端物理库的心跳检测情况,RS_CODE为1表示心跳正常 show @@datanode 查看数据节点 show @@datasource 查看数据源 show @@connection 该命令用于获取 Mycat 的前端连接状态，即应用与 mycat 的连接 show @@backend 查看后端连接状态 show @@cache 查看缓存使用情况，SQLRouteCache：sql路由缓存。TableID2DataNodeCache：缓存表主键与分片对应关系，ER_SQL2PARENTID ：缓存 ER 分片中子表与父表关系 reload @@config 重新加载基本配置，使用这个命令时 mycat服务不可用 show @@sysparam 查看参数 show @@sql.high 执行频率高的 SQL show @@sql.slow 慢 SQL 设置慢 SQL 的命令：reload @@sqlslow=5 MyCat配置 schema.xml schema.xml作为MyCat中最重要的配置文件之一 , 涵盖了MyCat的逻辑库、逻辑表、分片规则、分片节点及数据源的配置。 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- 逻辑库 --\u0026gt; \u0026lt;!-- name: 逻辑库名字 --\u0026gt; \u0026lt;!-- checkSQLschema: 当设置为true时，比如发送一条sql:select * from mycat_order.t_order，那么MyCat会自动去掉mycat_order逻辑库名字前缀，把sql变为：select * from t_order, 这样有效避免报表或视图不存在错误。 如果使用select * from test.t_order ，sql语句中所带的逻辑库名字跟schema标签中的name不一致的话，MyCat不会自动去掉逻辑库名字前缀，如果逻辑库不存在，仍然会报错。 --\u0026gt; \u0026lt;!-- sqlMaxLimit: 如果每次执行的sql语句后面没有跟上limit xx关键字的话，MyCat会自动在sql语句的后面拼上limit 100 --\u0026gt; \u0026lt;!-- dataNode: 用于指定没有分配分片节点的那些表的默认数据节点 --\u0026gt; \u0026lt;schema name=\u0026#34;shopping\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- 逻辑表，以下都没有配置分片规则rule，因为垂直分表不需要它 --\u0026gt; \u0026lt;!-- name: 逻辑表的名字，同一个逻辑库schema中的逻辑表的名称应该唯一 --\u0026gt; \u0026lt;!-- dataNode: 配置逻辑表分布的数据节点，名字需要与dataNode标签的name对应上 --\u0026gt; \u0026lt;!-- rule: 配置逻辑表的分片规则,需要在rule.xml中声明的规则名字对应上 --\u0026gt; \u0026lt;!-- ruleRequired: 指定分片规则是否必须，如果为true,但是没有指定rule，程序会报错 --\u0026gt; \u0026lt;!-- primaryKey: 指定逻辑表对应真实表的主键 --\u0026gt; \u0026lt;!-- type: 指定该逻辑表是全局表还是普通逻辑表。type=\u0026#34;global\u0026#34;表示全局表 --\u0026gt; \u0026lt;!-- autoIncrement: 指定是否自增长主键 --\u0026gt; \u0026lt;!-- needAddLimit: 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 --\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_base\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_brand\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_cat\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_desc\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;goods_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_item\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_item\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_master\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;order_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_pay_log\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;out_trade_no\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user_address\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;!-- 全局表 --\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_provinces\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_city\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_region\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;!-- \u0026lt;table name=\u0026#34;t_order\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;mod-long\u0026#34;\u0026gt; # 定义E-R分片的子表，通过标签上的属性与父表进行关联 # name：子表的名称t_order_detail # primaryKey：子表的主键 # joinKey：新增子表记录的时候，会根据该值查询父表在哪个分片节点上。（子表中字段的名称order_i # parentKey属性：与父表建立关联关系的列，结合joinKey确定好子表记录存放的分片节点，插入子表记录时直接插入到该分片节点上。（父表中字段名称order_id） # needAddLimit属性： 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 \u0026lt;childTable name=\u0026#34;t_order_detail\u0026#34; primaryKey=\u0026#34;od_id\u0026#34; joinKey=\u0026#34;order_id\u0026#34; parentKey=\u0026#34;order_id\u0026#34;\u0026gt;\u0026lt;/childTable\u0026gt; \u0026lt;/table\u0026gt; --\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;!-- 数据节点 --\u0026gt; \u0026lt;!-- name: 指定分片节点的名称，与声明逻辑表table标签中的dataNode名字对应上 --\u0026gt; \u0026lt;!-- dataHost: 指定分片节点所在的节点主机（数据库实例），与dataHost标签声明的name对应 --\u0026gt; \u0026lt;!-- database: 真实数据库名称 --\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;!-- 具体数据库实例 --\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M1\u0026#34; url=\u0026#34;172.16.0.101:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M2\u0026#34; url=\u0026#34;172.16.0.102:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;!-- name: 指定分片主机的名称，供dataNode标签使用 --\u0026gt; \u0026lt;!-- maxCon: 指定读写实例的连接池的最大连接数量 --\u0026gt; \u0026lt;!-- minCon: 指定读写实例的连接池的最小连接数量，初始化连接池的大小 --\u0026gt; \u0026lt;!-- balance: 指定负载均衡的类型 balance = “0” : 不开启读写分离，所有的读请求都发送到可用的writeHost写节点上（不会发readHost） balance = “1” : 全部的readHost与stand by writeHost参与select语句的负载均衡， balance = “2” : 读操作会随机发往writeHost以及 readHost，理论上实现的是负载均衡 balance = “3” : 配置了readHost时读操作会随机发往readHost（不会发writeHost），而没有配置readHost时读操作会发往第一个writeHost。 --\u0026gt; \u0026lt;!-- writeType: writeType=\u0026#34;0\u0026#34;: 所有写操作发送到配置的第一个writeHost，当第一个writeHost宕机时，切换到第二个writeHost，重新启动后以切换后的为准，切换记录在配置文件：dnindex.properties中 writeType=\u0026#34;1\u0026#34;: 所有写操作都随发送到配置的writeHost --\u0026gt; \u0026lt;!-- dbType: 指定后端数据库类型，支持mysql、oracle等 --\u0026gt; \u0026lt;!-- dbDriver: 指定后端数据库连接驱动信息，支持native和jdbc --\u0026gt; \u0026lt;!-- switchType: 指定切换方式 switchType = -1：不自动切换 switchType = 1：自动切换（默认） switchType = 2：基于MySql主从同步的状态来决定是否切换，心跳语句: show slave status switchType = 3: 基于mysql galary cluster的切换机制，心跳语句： show status like \u0026#39;wsrep%\u0026#39; --\u0026gt; \u0026lt;!-- slaveThreshold: --\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost3\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测，指定后端数据库进行心跳检查的语句 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;!-- host: 用于标识不同实例，一般 writeHost 我们使用M1，readHost 我们用S1 --\u0026gt; \u0026lt;!-- url: 后端实例连接地址，如果是使用 native 的 dbDriver，则一般为 address:port 这种形式,用 JDBC 或其他的 dbDriver，则需要特殊指定，使用 JDBC 时则可以这么写：jdbc:mysql://localhost:3306/ --\u0026gt; \u0026lt;!-- user: 后端存储实例需要的用户名 --\u0026gt; \u0026lt;!-- password: 后端存储实例需要的密码 --\u0026gt; \u0026lt;!-- weight: 权重 配置在 readhost 中作为读节点的权重 --\u0026gt; \u0026lt;!-- usingDecrypt: 是否对密码加密默认 0 否 如需要开启配置 1，同时使用加密程序对密码加密 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M3\u0026#34; url=\u0026#34;172.16.0.103:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; schema标签 schema标签用于定义MyCat实例中的逻辑库, 一个MyCat实例中, 可以有多个逻辑库, 可以通过schema标签来划分不同的逻辑库。 MyCat中的逻辑库的概念，等同于MySQL中的database概念，需要操作某个逻辑库下的表时，也需要切换逻辑库(use xxx)。 \u0026lt;!-- 定义逻辑库 --\u0026gt; \u0026lt;schema name=\u0026#34;DB01\u0026#34; checkSQLschema=\u0026#34;true\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- 定义逻辑表 --\u0026gt; \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; rule=\u0026#34;auto-sharding-long\u0026#34;/\u0026gt; \u0026lt;/schema\u0026gt; schema 属性： name：指定自定义的逻辑库库名。 checkSQLschema：在SQL语句操作时指定了数据库名称，执行时是否自动去除；true：自动去除，false：不自动去除。 sqlMaxLimit：如果未指定limit进行查询，列表查询模式查询多少条记录。 table标签定义了MyCat中逻辑库schema下的逻辑表，所有需要拆分的表都需要在table标签中定义。 schema.table 属性： name：定义逻辑表表名，在该逻辑库下唯一。 dataNode：定义逻辑表所属的dataNode，该属性需要与dataNode标签中name对应；多个dataNode逗号分隔。 rule：分片规则的名字，分片规则名字是在rule.xml中定义的。 primaryKey：逻辑表对应真实表的主键。 type：逻辑表的类型，目前逻辑表只有全局表和普通表，如果未配置就是普通表；全局表配置为global。 datanode标签 该标签用于定义节点。 \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;db01\u0026#34; /\u0026gt; dataNode 属性： name：定义数据节点名称。 dataHost：数据库实例主机名称，引用自dataHost标签中name属性。 database：定义分片所属数据库。 datahost标签 该标签在MyCat逻辑库中作为底层标签存在, 直接定义了具体的数据库实例、读写分离、心跳语句。 \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;jdbc\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;master\u0026#34; url=\u0026#34;jdbc:mysql://192.168.200.210:3306? useSSL=false\u0026amp;amp;serverTimezone=Asia/Shanghai\u0026amp;amp;characterEncoding=utf8\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;1234\u0026#34; /\u0026gt; \u0026lt;/dataHost\u0026gt; dataNode 属性： name：唯一标识，供上层标签使用。 maxCon/minCon：最大连接数/最小连接数。 balance：负载均衡策略，取值 0,1,2,3。 writeType：写操作分发方式（0：写操作转发到第一个writeHost，第一个挂了，切换到第二个；1：写操作随机分发到配置的writeHost）。 dbDriver：数据库驱动，支持 native、jdbc。 rule.xml rule.xml中定义所有拆分表的规则, 在使用过程中可以灵活的使用分片算法, 或者对同一个分片算法使用不同的参数, 它让分片过程可配置化。主要包含两类标签：tableRule、Function。 \u0026lt;tableRule name=\u0026#34;auto-sharding-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;rang-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;rang-long\u0026#34; class=\u0026#34;io.mycat.route.function.AutoPartitionByLong\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;autopartition-long.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; autopartition-long.txt # range start-end, data node index # K=1000,M=10000 0-500M=0 500M-1000M=1 1000M-1500M=2 server.xml server.xml配置文件包含了MyCat的系统配置信息，主要有两个重要的标签：system、user。 \u0026lt;user name=\u0026#34;root\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 用户密码 --\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;!-- 用户可访问的逻辑数据库有，多个逻辑库使用英文逗号分隔开 --\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;DB01\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;!-- \u0026lt;privileges check=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;DB01\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dml=\u0026#34;1110\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt; --\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;!-- 用户密码 --\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;!-- 用户可访问的逻辑数据库有，多个逻辑库使用英文逗号分隔开 --\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;DB01\u0026lt;/property\u0026gt; \u0026lt;!-- 用户的读写权限 --\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;!-- 限制前端的连接数量，如果为0或者没有配置表示不限制 --\u0026gt; \u0026lt;property name=\u0026#34;benchmark\u0026#34;\u0026gt;1000\u0026lt;/property\u0026gt; \u0026lt;!-- 开启密码加密功能 默认值为0，表示不进行加密 --\u0026gt; \u0026lt;property name=\u0026#34;usingDecrypt\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; 主要配置MyCat中的系统配置(system)信息，对应的系统配置项及其含义，如下： 属性 取值 含义 charset utf8 设置Mycat的字符集, 字符集需要与MySQL的字符集保持一致 nonePasswordLogin 0,1 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户 useHandshakeV10 0,1 使用该选项主要的目的是为了能够兼容高版本的jdbc驱动, 是否采用HandshakeV10Packet来与client进行通信, 1:是, 0:否 useSqlStat 0,1 开启SQL实时统计, 1 为开启 , 0 为关闭 ;开启之后, MyCat会自动统计SQL语句的执行情况 ; mysql -h 127.0.0.1 -P 9066-u root -p 查看MyCat执行的SQL, 执行效率比较低的SQL , SQL的整体执行情况、读写比例等 ; show @@sql ; show @@sql.slow ; show @@sql.sum useGlobleTableCheck 0,1 是否开启全局表的一致性检测。1为开启 ，0为关闭 sqlExecuteTimeout 1000 SQL语句执行的超时时间 , 单位为 s sequnceHandlerType 0,1,2 用来指定Mycat全局序列类型，0 为本地文件，1 为数据库方式，2 为时间戳列方式，默认使用本地文件方式，文件方式主要用于测试 sequnceHandlerPattern 正则表达式 必须带有MYCATSEQ或者 mycatseq进入序列匹配流程 注意MYCATSEQ_有空格的情况 subqueryRelationshipCheck true,false 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false useCompression 0,1 开启mysql压缩协议 , 0 : 关闭, 1 : 开启 fakeMySQLVersion 5.5,5.6 设置模拟的MySQL版本号 defaultSqlParser 由于MyCat的最初版本使用了FoundationDB的SQL解析器, 在MyCat1.3后增加了Druid解析器, 所以要设置defaultSqlParser属性来指定默认的解析器; 解析器有两个 :druidparser 和 fdbparser, 在MyCat1.4之后,默认是druidparser,fdbparser已经废除了 processors 1,2\u0026hellip;. 指定系统可用的线程数量, 默认值为CPU核心x 每个核心运行线程数量; processors 会影响processorBufferPool,processorBufferLocalPercent,processorExecutor属性, 所有, 在性能调优时, 可以适当地修改processors值 processorBufferChunk 指定每次分配Socket Direct Buffer默认值为4096字节, 也会影响BufferPool长度,如果一次性获取字节过多而导致buffer不够用, 则会出现警告, 可以调大该值 processorExecutor 指定NIOProcessor上共享businessExecutor固定线程池的大小;MyCat把异步任务交给 businessExecutor线程池中, 在新版本的MyCat中这个连接池使用频次不高, 可以适当地把该值调小 packetHeaderSize 指定MySQL协议中的报文头长度, 默认4个字节 maxPacketSize 指定MySQL协议可以携带的数据最大大小, 默认值为16M idleTimeout 30 指定连接的空闲时间的超时长度;如果超时,将关闭资源并回收, 默认30分钟 txIsolation 1,2,3,4 初始化前端连接的事务隔离级别,默认为REPEATED_READ , 对应数字为3READ_UNCOMMITED=1;READ_COMMITTED=2; REPEATED_READ=3;SERIALIZABLE=4 sqlExecuteTimeout 300 执行SQL的超时时间, 如果SQL语句执行超时,将关闭连接; 默认300秒; serverPort 8066 定义MyCat的使用端口, 默认8066 managerPort 9066 定义MyCat的管理端口, 默认9066 MyCat分片 垂直拆分 在业务系统中，涉及以下表结构，但是由于用户与订单每天都会产生大量的数据，单台服务器的数据存储及处理能力是有限的，可以对数据库表进行拆分，原有的数据库表如下。 现在考虑将其进行垂直分库操作，将商品相关的表拆分到一个数据库服务器，订单表拆分的一个数据库服务器，用户及省市区表拆分到一个服务器。 名称 IP 端口 MyCat 172.16.0.10 8066,9066 mysql1 172.16.0.101 3306 mysql2 172.16.0.102 3307 mysql3 172.16.0.103 3308 schema.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- 逻辑库 --\u0026gt; \u0026lt;!-- name: 逻辑库名字 --\u0026gt; \u0026lt;!-- checkSQLschema: 当设置为true时，比如发送一条sql:select * from mycat_order.t_order，那么MyCat会自动去掉mycat_order逻辑库名字前缀，把sql变为：select * from t_order, 这样有效避免报表或视图不存在错误。 如果使用select * from test.t_order ，sql语句中所带的逻辑库名字跟schema标签中的name不一致的话，MyCat不会自动去掉逻辑库名字前缀，如果逻辑库不存在，仍然会报错。 --\u0026gt; \u0026lt;!-- sqlMaxLimit: 如果每次执行的sql语句后面没有跟上limit xx关键字的话，MyCat会自动在sql语句的后面拼上limit 100 --\u0026gt; \u0026lt;!-- dataNode: 用于指定没有分配分片节点的那些表的默认数据节点 --\u0026gt; \u0026lt;schema name=\u0026#34;shopping\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- 逻辑表，以下都没有配置分片规则rule，因为垂直分表不需要它 --\u0026gt; \u0026lt;!-- name: 逻辑表的名字，同一个逻辑库schema中的逻辑表的名称应该唯一 --\u0026gt; \u0026lt;!-- dataNode: 配置逻辑表分布的数据节点，名字需要与dataNode标签的name对应上 --\u0026gt; \u0026lt;!-- rule: 配置逻辑表的分片规则,需要在rule.xml中声明的规则名字对应上 --\u0026gt; \u0026lt;!-- ruleRequired: 指定分片规则是否必须，如果为true,但是没有指定rule，程序会报错 --\u0026gt; \u0026lt;!-- primaryKey: 指定逻辑表对应真实表的主键 --\u0026gt; \u0026lt;!-- type: 指定该逻辑表是全局表还是普通逻辑表。type=\u0026#34;global\u0026#34;表示全局表 --\u0026gt; \u0026lt;!-- autoIncrement: 指定是否自增长主键 --\u0026gt; \u0026lt;!-- needAddLimit: 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 --\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_base\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_brand\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_cat\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_desc\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;goods_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_item\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_item\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_master\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;order_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_pay_log\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;out_trade_no\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user_address\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;!-- 全局表 --\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_provinces\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_city\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_region\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;!-- \u0026lt;table name=\u0026#34;t_order\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;mod-long\u0026#34;\u0026gt; # 定义E-R分片的子表，通过标签上的属性与父表进行关联 # name：子表的名称t_order_detail # primaryKey：子表的主键 # joinKey：新增子表记录的时候，会根据该值查询父表在哪个分片节点上。（子表中字段的名称order_i # parentKey属性：与父表建立关联关系的列，结合joinKey确定好子表记录存放的分片节点，插入子表记录时直接插入到该分片节点上。（父表中字段名称order_id） # needAddLimit属性： 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 \u0026lt;childTable name=\u0026#34;t_order_detail\u0026#34; primaryKey=\u0026#34;od_id\u0026#34; joinKey=\u0026#34;order_id\u0026#34; parentKey=\u0026#34;order_id\u0026#34;\u0026gt;\u0026lt;/childTable\u0026gt; \u0026lt;/table\u0026gt; --\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;!-- 数据节点 --\u0026gt; \u0026lt;!-- name: 指定分片节点的名称，与声明逻辑表table标签中的dataNode名字对应上 --\u0026gt; \u0026lt;!-- dataHost: 指定分片节点所在的节点主机（数据库实例），与dataHost标签声明的name对应 --\u0026gt; \u0026lt;!-- database: 真实数据库名称 --\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;!-- 具体数据库实例 --\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M1\u0026#34; url=\u0026#34;172.16.0.101:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M2\u0026#34; url=\u0026#34;172.16.0.102:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;!-- name: 指定分片主机的名称，供dataNode标签使用 --\u0026gt; \u0026lt;!-- maxCon: 指定读写实例的连接池的最大连接数量 --\u0026gt; \u0026lt;!-- minCon: 指定读写实例的连接池的最小连接数量，初始化连接池的大小 --\u0026gt; \u0026lt;!-- balance: 指定负载均衡的类型 balance = “0” : 不开启读写分离，所有的读请求都发送到可用的writeHost写节点上（不会发readHost） balance = “1” : 全部的readHost与stand by writeHost参与select语句的负载均衡， balance = “2” : 读操作会随机发往writeHost以及 readHost，理论上实现的是负载均衡 balance = “3” : 配置了readHost时读操作会随机发往readHost（不会发writeHost），而没有配置readHost时读操作会发往第一个writeHost。 --\u0026gt; \u0026lt;!-- writeType: writeType=\u0026#34;0\u0026#34;: 所有写操作发送到配置的第一个writeHost，当第一个writeHost宕机时，切换到第二个writeHost，重新启动后以切换后的为准，切换记录在配置文件：dnindex.properties中 writeType=\u0026#34;1\u0026#34;: 所有写操作都随发送到配置的writeHost --\u0026gt; \u0026lt;!-- dbType: 指定后端数据库类型，支持mysql、oracle等 --\u0026gt; \u0026lt;!-- dbDriver: 指定后端数据库连接驱动信息，支持native和jdbc --\u0026gt; \u0026lt;!-- switchType: 指定切换方式 switchType = -1：不自动切换 switchType = 1：自动切换（默认） switchType = 2：基于MySql主从同步的状态来决定是否切换，心跳语句: show slave status switchType = 3: 基于mysql galary cluster的切换机制，心跳语句： show status like \u0026#39;wsrep%\u0026#39; --\u0026gt; \u0026lt;!-- slaveThreshold: --\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost3\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测，指定后端数据库进行心跳检查的语句 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;!-- host: 用于标识不同实例，一般 writeHost 我们使用M1，readHost 我们用S1 --\u0026gt; \u0026lt;!-- url: 后端实例连接地址，如果是使用 native 的 dbDriver，则一般为 address:port 这种形式,用 JDBC 或其他的 dbDriver，则需要特殊指定，使用 JDBC 时则可以这么写：jdbc:mysql://localhost:3306/ --\u0026gt; \u0026lt;!-- user: 后端存储实例需要的用户名 --\u0026gt; \u0026lt;!-- password: 后端存储实例需要的密码 --\u0026gt; \u0026lt;!-- weight: 权重 配置在 readhost 中作为读节点的权重 --\u0026gt; \u0026lt;!-- usingDecrypt: 是否对密码加密默认 0 否 如需要开启配置 1，同时使用加密程序对密码加密 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M3\u0026#34; url=\u0026#34;172.16.0.103:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; server.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:server SYSTEM \u0026#34;server.dtd\u0026#34;\u0026gt; \u0026lt;mycat:server xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;system\u0026gt; \u0026lt;!-- 字符集，需要保证MyCat字符集与数据库字符集一致 --\u0026gt; \u0026lt;property name=\u0026#34;charset\u0026#34;\u0026gt;utf8mb4\u0026lt;/property\u0026gt; \u0026lt;!-- SQL解析器 --\u0026gt; \u0026lt;property name=\u0026#34;defaultSqlParser\u0026#34;\u0026gt;druidparser\u0026lt;/property\u0026gt; \u0026lt;!-- MyCat系统可用的线程数量 --\u0026gt; \u0026lt;property name=\u0026#34;processors\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;!-- 指定MyCat全局序列的类型，0表示本地文件方式 1表示数据库方式 2表示时间戳方式 --\u0026gt; \u0026lt;property name=\u0026#34;sequenceHandlerType\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启实时统计、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useSqlStat\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启全局表一致性检测、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useGlobleTableCheck\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- MyCat的端口，默认为8066 --\u0026gt; \u0026lt;property name=\u0026#34;serverPort\u0026#34;\u0026gt;8066\u0026lt;/property\u0026gt; \u0026lt;!-- MyCat管理端口，默认为9066 --\u0026gt; \u0026lt;property name=\u0026#34;managerPort\u0026#34;\u0026gt;9066\u0026lt;/property\u0026gt; \u0026lt;!-- 服务监听的IP地址，默认为0.0.0.0 --\u0026gt; \u0026lt;property name=\u0026#34;bindIp\u0026#34;\u0026gt;0.0.0.0\u0026lt;/property\u0026gt; \u0026lt;!-- 指定连接的空闲时间的超时长度，如果某个连接的空闲时间超时长度大于idleTimeout，则该连接会被回收，默认30分钟 --\u0026gt; \u0026lt;property name=\u0026#34;idleTimeout\u0026#34;\u0026gt;300000\u0026lt;/property\u0026gt; \u0026lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--\u0026gt; \u0026lt;property name=\u0026#34;handleDistributedTransactions\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 配置是否启用非堆内存处理跨分片结果集。 1开启 0关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useOffHeapForMerge\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;!--是否采用zookeeper协调切换 --\u0026gt; \u0026lt;property name=\u0026#34;useZKSwitch\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/system\u0026gt; \u0026lt;user name=\u0026#34;root\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 用户密码 --\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;!-- 用户可访问的逻辑数据库有，多个逻辑库使用英文逗号分隔开 --\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;shopping\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;privileges check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;shopping\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;tb_goods_base\u0026#34; dml=\u0026#34;1111\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;!-- 用户密码 --\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;!-- 用户可访问的逻辑数据库有，多个逻辑库使用英文逗号分隔开 --\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;shopping\u0026lt;/property\u0026gt; \u0026lt;!-- 用户的读写权限 --\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;/mycat:server\u0026gt; github 完整代码参看github。https://github.com/helium-chain/mycat-vertical 水平分片 在业务系统中,有一张表(日志表),业务系统每天都会产生大量的日志数据,单台服务器的数据存储及处理能力是有限的,可以对数据库表进行拆分。 名称 IP 端口 MyCat 172.16.0.10 8066,9066 mysql1 172.16.0.101 3306 mysql2 172.16.0.102 3307 mysql3 172.16.0.103 3308 schema.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- 逻辑库 --\u0026gt; \u0026lt;!-- name: 逻辑库名字 --\u0026gt; \u0026lt;!-- checkSQLschema: 当设置为true时，比如发送一条sql:select * from mycat_order.t_order，那么MyCat会自动去掉mycat_order逻辑库名字前缀，把sql变为：select * from t_order, 这样有效避免报表或视图不存在错误。 如果使用select * from test.t_order ，sql语句中所带的逻辑库名字跟schema标签中的name不一致的话，MyCat不会自动去掉逻辑库名字前缀，如果逻辑库不存在，仍然会报错。 --\u0026gt; \u0026lt;!-- sqlMaxLimit: 如果每次执行的sql语句后面没有跟上limit xx关键字的话，MyCat会自动在sql语句的后面拼上limit 100 --\u0026gt; \u0026lt;!-- dataNode: 用于指定没有分配分片节点的那些表的默认数据节点 --\u0026gt; \u0026lt;schema name=\u0026#34;shopping\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- 逻辑表，以下都没有配置分片规则rule，因为垂直分表不需要它 --\u0026gt; \u0026lt;!-- name: 逻辑表的名字，同一个逻辑库schema中的逻辑表的名称应该唯一 --\u0026gt; \u0026lt;!-- dataNode: 配置逻辑表分布的数据节点，名字需要与dataNode标签的name对应上 --\u0026gt; \u0026lt;!-- rule: 配置逻辑表的分片规则,需要在rule.xml中声明的规则名字对应上 --\u0026gt; \u0026lt;!-- ruleRequired: 指定分片规则是否必须，如果为true,但是没有指定rule，程序会报错 --\u0026gt; \u0026lt;!-- primaryKey: 指定逻辑表对应真实表的主键 --\u0026gt; \u0026lt;!-- type: 指定该逻辑表是全局表还是普通逻辑表。type=\u0026#34;global\u0026#34;表示全局表 --\u0026gt; \u0026lt;!-- autoIncrement: 指定是否自增长主键 --\u0026gt; \u0026lt;!-- needAddLimit: 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 --\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_base\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_brand\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_cat\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_desc\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;goods_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_goods_item\u0026#34; dataNode=\u0026#34;dn1\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_item\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_master\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;order_id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_order_pay_log\u0026#34; dataNode=\u0026#34;dn2\u0026#34; primaryKey=\u0026#34;out_trade_no\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;table name=\u0026#34;tb_user_address\u0026#34; dataNode=\u0026#34;dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;!-- 全局表 --\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_provinces\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_city\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;table name=\u0026#34;tb_areas_region\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; primaryKey=\u0026#34;id\u0026#34; type=\u0026#34;global\u0026#34;/\u0026gt; \u0026lt;!-- \u0026lt;table name=\u0026#34;t_order\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;mod-long\u0026#34;\u0026gt; # 定义E-R分片的子表，通过标签上的属性与父表进行关联 # name：子表的名称t_order_detail # primaryKey：子表的主键 # joinKey：新增子表记录的时候，会根据该值查询父表在哪个分片节点上。（子表中字段的名称order_i # parentKey属性：与父表建立关联关系的列，结合joinKey确定好子表记录存放的分片节点，插入子表记录时直接插入到该分片节点上。（父表中字段名称order_id） # needAddLimit属性： 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 \u0026lt;childTable name=\u0026#34;t_order_detail\u0026#34; primaryKey=\u0026#34;od_id\u0026#34; joinKey=\u0026#34;order_id\u0026#34; parentKey=\u0026#34;order_id\u0026#34;\u0026gt;\u0026lt;/childTable\u0026gt; \u0026lt;/table\u0026gt; --\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;schema name=\u0026#34;logs\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- 水平分片 --\u0026gt; \u0026lt;!-- rule：分片规则 --\u0026gt; \u0026lt;table name=\u0026#34;tb_log\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;!-- 数据节点 --\u0026gt; \u0026lt;!-- name: 指定分片节点的名称，与声明逻辑表table标签中的dataNode名字对应上 --\u0026gt; \u0026lt;!-- dataHost: 指定分片节点所在的节点主机（数据库实例），与dataHost标签声明的name对应 --\u0026gt; \u0026lt;!-- database: 真实数据库名称 --\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn3\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn4\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;logs\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn5\u0026#34; dataHost=\u0026#34;dhost2\u0026#34; database=\u0026#34;logs\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn6\u0026#34; dataHost=\u0026#34;dhost3\u0026#34; database=\u0026#34;logs\u0026#34; /\u0026gt; \u0026lt;!-- 具体数据库实例 --\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M1\u0026#34; url=\u0026#34;172.16.0.101:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M2\u0026#34; url=\u0026#34;172.16.0.102:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;!-- name: 指定分片主机的名称，供dataNode标签使用 --\u0026gt; \u0026lt;!-- maxCon: 指定读写实例的连接池的最大连接数量 --\u0026gt; \u0026lt;!-- minCon: 指定读写实例的连接池的最小连接数量，初始化连接池的大小 --\u0026gt; \u0026lt;!-- balance: 指定负载均衡的类型 balance = “0” : 不开启读写分离，所有的读请求都发送到可用的writeHost写节点上（不会发readHost） balance = “1” : 全部的readHost与stand by writeHost参与select语句的负载均衡， balance = “2” : 读操作会随机发往writeHost以及 readHost，理论上实现的是负载均衡 balance = “3” : 配置了readHost时读操作会随机发往readHost（不会发writeHost），而没有配置readHost时读操作会发往第一个writeHost。 --\u0026gt; \u0026lt;!-- writeType: writeType=\u0026#34;0\u0026#34;: 所有写操作发送到配置的第一个writeHost，当第一个writeHost宕机时，切换到第二个writeHost，重新启动后以切换后的为准，切换记录在配置文件：dnindex.properties中 writeType=\u0026#34;1\u0026#34;: 所有写操作都随发送到配置的writeHost --\u0026gt; \u0026lt;!-- dbType: 指定后端数据库类型，支持mysql、oracle等 --\u0026gt; \u0026lt;!-- dbDriver: 指定后端数据库连接驱动信息，支持native和jdbc --\u0026gt; \u0026lt;!-- switchType: 指定切换方式 switchType = -1：不自动切换 switchType = 1：自动切换（默认） switchType = 2：基于MySql主从同步的状态来决定是否切换，心跳语句: show slave status switchType = 3: 基于mysql galary cluster的切换机制，心跳语句： show status like \u0026#39;wsrep%\u0026#39; --\u0026gt; \u0026lt;!-- slaveThreshold: --\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost3\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测，指定后端数据库进行心跳检查的语句 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;!-- host: 用于标识不同实例，一般 writeHost 我们使用M1，readHost 我们用S1 --\u0026gt; \u0026lt;!-- url: 后端实例连接地址，如果是使用 native 的 dbDriver，则一般为 address:port 这种形式,用 JDBC 或其他的 dbDriver，则需要特殊指定，使用 JDBC 时则可以这么写：jdbc:mysql://localhost:3306/ --\u0026gt; \u0026lt;!-- user: 后端存储实例需要的用户名 --\u0026gt; \u0026lt;!-- password: 后端存储实例需要的密码 --\u0026gt; \u0026lt;!-- weight: 权重 配置在 readhost 中作为读节点的权重 --\u0026gt; \u0026lt;!-- usingDecrypt: 是否对密码加密默认 0 否 如需要开启配置 1，同时使用加密程序对密码加密 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M3\u0026#34; url=\u0026#34;172.16.0.103:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; server.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:server SYSTEM \u0026#34;server.dtd\u0026#34;\u0026gt; \u0026lt;mycat:server xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;system\u0026gt; \u0026lt;!-- 字符集，需要保证MyCat字符集与数据库字符集一致 --\u0026gt; \u0026lt;property name=\u0026#34;charset\u0026#34;\u0026gt;utf8mb4\u0026lt;/property\u0026gt; \u0026lt;!-- SQL解析器 --\u0026gt; \u0026lt;property name=\u0026#34;defaultSqlParser\u0026#34;\u0026gt;druidparser\u0026lt;/property\u0026gt; \u0026lt;!-- MyCat系统可用的线程数量 --\u0026gt; \u0026lt;property name=\u0026#34;processors\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;!-- 指定MyCat全局序列的类型，0表示本地文件方式 1表示数据库方式 2表示时间戳方式 --\u0026gt; \u0026lt;property name=\u0026#34;sequenceHandlerType\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启实时统计、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useSqlStat\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启全局表一致性检测、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useGlobleTableCheck\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- MyCat的端口，默认为8066 --\u0026gt; \u0026lt;property name=\u0026#34;serverPort\u0026#34;\u0026gt;8066\u0026lt;/property\u0026gt; \u0026lt;!-- MyCat管理端口，默认为9066 --\u0026gt; \u0026lt;property name=\u0026#34;managerPort\u0026#34;\u0026gt;9066\u0026lt;/property\u0026gt; \u0026lt;!-- 服务监听的IP地址，默认为0.0.0.0 --\u0026gt; \u0026lt;property name=\u0026#34;bindIp\u0026#34;\u0026gt;0.0.0.0\u0026lt;/property\u0026gt; \u0026lt;!-- 指定连接的空闲时间的超时长度，如果某个连接的空闲时间超时长度大于idleTimeout，则该连接会被回收，默认30分钟 --\u0026gt; \u0026lt;property name=\u0026#34;idleTimeout\u0026#34;\u0026gt;300000\u0026lt;/property\u0026gt; \u0026lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--\u0026gt; \u0026lt;property name=\u0026#34;handleDistributedTransactions\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 配置是否启用非堆内存处理跨分片结果集。 1开启 0关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useOffHeapForMerge\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;!--是否采用zookeeper协调切换 --\u0026gt; \u0026lt;property name=\u0026#34;useZKSwitch\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/system\u0026gt; \u0026lt;user name=\u0026#34;root\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 用户密码 --\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;!-- 用户可访问的逻辑数据库有，多个逻辑库使用英文逗号分隔开 --\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;shopping,logs\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;privileges check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;shopping\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;tb_goods_base\u0026#34; dml=\u0026#34;1111\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;!-- 用户密码 --\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;123456\u0026lt;/property\u0026gt; \u0026lt;!-- 用户可访问的逻辑数据库有，多个逻辑库使用英文逗号分隔开 --\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;shopping,logs\u0026lt;/property\u0026gt; \u0026lt;!-- 用户的读写权限 --\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;/mycat:server\u0026gt; rule.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;mod-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;mod-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;mod-long\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMod\u0026#34;\u0026gt; \u0026lt;!-- count: 数据节点的数量 --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; github 完整代码参看github。https://github.com/helium-chain/mycat-vertical-horizontal 分片规则 范围分片 根据指定的字段及其配置的范围与数据节点的对应情况，来决定该数据属于哪一个分片。 schema.xml逻辑表配置： \u0026lt;table name=\u0026#34;TB_ORDER\u0026#34; dataNode=\u0026#34;dn1,dn2,dn3\u0026#34; rule=\u0026#34;auto-sharding-long\u0026#34; /\u0026gt; rule.xml分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;auto-sharding-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;!-- 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;rang-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;rang-long\u0026#34; class=\u0026#34;io.mycat.route.function.AutoPartitionByLong\u0026#34;\u0026gt; \u0026lt;!-- mapFile: 对应的外部配置文件 --\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;autopartition-long.txt\u0026lt;/property\u0026gt; \u0026lt;!-- type: 默认值为0 ; 0 表示Integer , 1 表示String --\u0026gt; \u0026lt;property name=\u0026#34;type\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- defaultNode: 默认节点 默认节点的所用:枚举分片时,如果碰到不识别的枚举值, 就让它路由到默认节点, 如果没有默认值,碰到不识别的则报错 --\u0026gt; \u0026lt;property name=\u0026#34;defaultNode\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 在rule.xml中配置分片规则时，关联了一个映射配置文件 autopartition-long.txt，该配置文件的配置如下： # range start-end ,data node index # K=1000,M=10000. # 0-500万之间的值，存储在0号数据节点 0-500M=0 # 500万-1000万之间的数据存储在1号数据节点 500M-1000M=1 # 1000万-1500万的数据节点存储在2号节点 1000M-1500M=2 该分片规则，主要是针对于数字类型的字段适用。 取模分片 根据指定的字段值与节点数量进行求模运算，根据运算结果， 来决定该数据属于哪一个分片。 schema.xml逻辑表配置： \u0026lt;table name=\u0026#34;tb_log\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; rule.xml分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;mod-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;mod-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;mod-long\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMod\u0026#34;\u0026gt; \u0026lt;!-- count: 数据节点的数量 --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 该分片规则，主要是针对于数字类型的字段适用。 一致性hash分片 所谓一致性哈希，相同的哈希因子计算值总是被划分到相同的分区表中，不会因为分区节点的增加而改变原来数据的分区位置，有效的解决了分布式数据的拓容问题。 schema.xml中逻辑表配置： \u0026lt;table name=\u0026#34;tb_order\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-murmur\u0026#34; /\u0026gt; rule.xml中分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-murmur\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;murmur\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;murmur\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMurmurHash\u0026#34;\u0026gt; \u0026lt;!-- seed: 创建murmur_hash对象的种子，默认0 --\u0026gt; \u0026lt;property name=\u0026#34;seed\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt;\u0026lt;!-- 默认是0 --\u0026gt; \u0026lt;!-- count: 要分片的数据库节点数量，必须指定，否则没法分片 --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;!-- virtualBucketTimes: 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160 倍;virtualBucketTimes*count就是虚拟结点数量 ; --\u0026gt; \u0026lt;property name=\u0026#34;virtualBucketTimes\u0026#34;\u0026gt;160\u0026lt;/property\u0026gt; \u0026lt;!-- weightMapFile: 节点的权重，没有指定权重的节点默认是1。以properties文件的 格式填写，以从0开始到count-1的整数值也就是节点索引为key， 以节点权重值为值。所有权重值必须是正整数，否则以1代替 --\u0026gt; \u0026lt;!-- bucketMapPath: 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个 属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出 到这个文件，没有默认值，如果不指定，就不会输出任何东西 --\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 枚举分类 通过在配置文件中配置可能的枚举值, 指定数据分布到不同数据节点上, 本规则适用于按照省份、性别、状态拆分数据等业务。 schema.xml中逻辑表配置： \u0026lt;table name=\u0026#34;tb_user\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-intfile-enumstatus\u0026#34;/\u0026gt; rule.xml中分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-intfile\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 自己增加 tableRule --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-intfile-enumstatus\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;status\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;mod-long\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;!-- defaultNode： 默认节点; 小于0 标识不设置默认节点, 大于等于0代表设置默认节点; 默认节点的所用:枚举分片时,如果碰到不识别的枚举值, 就让它路由到默认节点; 如果没有默认值,碰到不识别的则报错 --\u0026gt; \u0026lt;property name=\u0026#34;defaultNode\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;!-- mapFile: 对应的外部文件 --\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;!-- type: 默认值为0 ; 0 表示Integer , 1 表示String --\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; partition-hash-int.txt，内容如下： 1=0 2=1 3=2 应用指定算法 运行阶段由应用自主决定路由到那个分片 , 直接根据字符子串（必须是数字）计算分片号。 schema.xml中逻辑表配置： \u0026lt;table name=\u0026#34;tb_app\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-substring\u0026#34; /\u0026gt; rule.xml中分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-substrin\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-substring\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-substring\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionDirectBySubString\u0026#34;\u0026gt; \u0026lt;!-- startIndex: 字符子串起始索引 --\u0026gt; \u0026lt;property name=\u0026#34;startIndex\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- zero-based --\u0026gt; \u0026lt;!-- size: 字符长度 --\u0026gt; \u0026lt;property name=\u0026#34;size\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;!-- partitionCount: 分区(分片)数量 --\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;!-- defaultPartition: 默认分片(在分片数量定义时, 字符标示的分片编号不在分片数量内时,使用默认分片) --\u0026gt; \u0026lt;property name=\u0026#34;defaultPartition\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 示例说明： id=05-100000002 , 在此配置中代表根据id中从 startIndex=0，开始，截取siz=2位数字即 05，05就是获取的分区。 如果没找到对应的分片则默认分配到defaultPartition。 固定分片hash算法 该算法类似于十进制的求模运算，但是为二进制的操作，例如取 id 的二进制低 10 位 与 1111111111 进行位 \u0026amp; 运算，位与运算最小值为 0000000000，最大值为1111111111，转换为十进制，也就是位于0-1023之间。 特点： 如果是求模，连续的值，分别分配到各个不同的分片；但是此算法会将连续的值可能分配到相同的分片，降低事务处理的难度。 可以均匀分配，也可以非均匀分配。 分片字段必须为数字类型。 schema.xml中逻辑表配置： \u0026lt;table name=\u0026#34;tb_longhash\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-long-hash\u0026#34; /\u0026gt; rule.xml中分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-long-hash\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-long-hash\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-long-hash\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByLong\u0026#34;\u0026gt; \u0026lt;!-- partitionCount: 分片个数列表 --\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;2,1\u0026lt;/property\u0026gt; \u0026lt;!-- partitionLength: 分片范围列表 --\u0026gt; \u0026lt;property name=\u0026#34;partitionLength\u0026#34;\u0026gt;256,512\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 约束： 分片长度 : 默认最大2^10,为 1024 ; count, length的数组长度必须是一致的; 字符串hash解析算法 截取字符串中的指定位置的子字符串, 进行hash算法，算出分片。 schema.xml中逻辑表配置： \u0026lt;table name=\u0026#34;tb_strhash\u0026#34; dataNode=\u0026#34;dn4,dn5\u0026#34; rule=\u0026#34;sharding-by-stringhash\u0026#34; /\u0026gt; rule.xml中分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-stringhash\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;name\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-stringhash\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-stringhash\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByString\u0026#34;\u0026gt; \u0026lt;!-- partitionLength: hash求模基数 ; length*count=1024 (出于性能考虑) --\u0026gt; \u0026lt;property name=\u0026#34;partitionLength\u0026#34;\u0026gt;512\u0026lt;/property\u0026gt; \u0026lt;!-- zero-based --\u0026gt; \u0026lt;!-- partitionCount: 分区数 --\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;!-- hashSlice: hash运算位 , 根据子字符串的hash运算 0 代表 str.length() -1 代表 str.length()-1 大于0只代表数字自身 可以理解为substring（start，end），start为0则只表示0 --\u0026gt; \u0026lt;property name=\u0026#34;hashSlice\u0026#34;\u0026gt;0:2\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 按天分片算法 按照日期及对应的时间周期来分片。 schema.xml中逻辑表配置： \u0026lt;table name=\u0026#34;tb_datepart\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-date\u0026#34; /\u0026gt; rule.xml中分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-date\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;create_time\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;sharding-by-dat\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;sharding-by-dat\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByDate\u0026#34;\u0026gt; \u0026lt;!-- dateFormat: 日期格式 --\u0026gt; \u0026lt;property name=\u0026#34;dateFormat\u0026#34;\u0026gt;yyyy-MM-dd\u0026lt;/property\u0026gt; \u0026lt;!-- sBeginDate: 开始日期 --\u0026gt; \u0026lt;property name=\u0026#34;sBeginDate\u0026#34;\u0026gt;2022-01-01\u0026lt;/property\u0026gt; \u0026lt;!-- sEndDate: 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 --\u0026gt; \u0026lt;property name=\u0026#34;sEndDate\u0026#34;\u0026gt;2022-01-30\u0026lt;/property\u0026gt; \u0026lt;!-- sPartionDay: 分区天数，默认值 10 ，从开始日期算起，每个10天一个分区 --\u0026gt; \u0026lt;property name=\u0026#34;sPartionDay\u0026#34;\u0026gt;10\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 自然月分片 使用场景为按照月份来分片, 每个自然月为一个分片。 schema.xml中逻辑表配置： \u0026lt;table name=\u0026#34;tb_monthpart\u0026#34; dataNode=\u0026#34;dn4,dn5,dn6\u0026#34; rule=\u0026#34;sharding-by-month\u0026#34; /\u0026gt; rule.xml中分片规则配置： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- name: 规则名称 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-month\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;!-- columns: 标识将要分片的表字段 --\u0026gt; \u0026lt;columns\u0026gt;create_time\u0026lt;/columns\u0026gt; \u0026lt;!-- algorithm: 指定分片函数与function的对应关系 --\u0026gt; \u0026lt;algorithm\u0026gt;partbymonth\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;!-- 分片对应函数 --\u0026gt; \u0026lt;!-- name: 对应tableRule的algorithm标签 --\u0026gt; \u0026lt;!-- class: 指定该分片算法对应的类 --\u0026gt; \u0026lt;function name=\u0026#34;partbymonth\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMonth\u0026#34;\u0026gt; \u0026lt;!-- dateFormat: 日期格式 --\u0026gt; \u0026lt;property name=\u0026#34;dateFormat\u0026#34;\u0026gt;yyyy-MM-dd\u0026lt;/property\u0026gt; \u0026lt;!-- sBeginDate: 开始日期 --\u0026gt; \u0026lt;property name=\u0026#34;sBeginDate\u0026#34;\u0026gt;2022-01-01\u0026lt;/property\u0026gt; \u0026lt;!-- sEndDate: 结束日期，如果配置了结束日期，则代码数据到达了这个日期的分片后，会重复从开始分片插入 --\u0026gt; \u0026lt;property name=\u0026#34;sEndDate\u0026#34;\u0026gt;2022-03-31\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;!-- 从开始时间开始，一个月为一个分片，到达结束时间之后，会重复开始分片插入 配置表的 dataNode 的分片，必须和分片规则数量一致，例如 2022-01-01 到 2022-12-31 ，一共需要12个分片。 --\u0026gt; \u0026lt;/mycat:rule\u0026gt; 双主双丛读写分离 一个主机 Master1 用于处理所有写请求，它的从机 Slave1 和另一台主机 Master2 还有它的从机 Slave2 负责所有读请求。 当 Master1 主机宕机后，Master2 主机负责写请求，Master1、Master2 互为备机。 名称 IP 端口 MyCat 172.16.0.10 8066,9066 M1 172.16.0.101 3306 M2 172.16.0.102 3307 S1 172.16.0.103 3308 S2 172.16.0.104 3309 master01 修改配置文件 /etc/my.cnf。 #mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，默认为1 server-id=1 #指定同步的数据库 binlog-do-db=db01 binlog-do-db=db02 binlog-do-db=db03 # 在作为从数据库的时候，有写入操作也要更新二进制日志文件 log-slave-updates 创建账户并授权。 -- 创建itcast用户，并设置密码，该用户可在任意主机连接该MySQL服务 CREATE USER \u0026#39;masterSlave\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; -- 为 \u0026#39;master\u0026#39;@\u0026#39;%\u0026#39; 用户分配主从复制权限 GRANT REPLICATION SLAVE ON *.* TO \u0026#39;masterSlave\u0026#39;@\u0026#39;%\u0026#39;; 查看二进制日志坐标： show master status; master02 修改配置文件 /etc/my.cnf。 #mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，默认为1 server-id=2 #指定同步的数据库 binlog-do-db=db01 binlog-do-db=db02 binlog-do-db=db03 # 在作为从数据库的时候，有写入操作也要更新二进制日志文件 log-slave-updates 创建账户并授权。 -- 创建itcast用户，并设置密码，该用户可在任意主机连接该MySQL服务 CREATE USER \u0026#39;masterSlave\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; -- 为 \u0026#39;master\u0026#39;@\u0026#39;%\u0026#39; 用户分配主从复制权限 GRANT REPLICATION SLAVE ON *.* TO \u0026#39;masterSlave\u0026#39;@\u0026#39;%\u0026#39;; 查看二进制日志坐标： show master status; salve01 修改配置文件 /etc/my.cnf。 #mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，默认为1 server-id=3 salve02 修改配置文件 /etc/my.cnf。 #mysql 服务ID，保证整个集群环境中唯一，取值范围：1 – 2^32-1，默认为1 server-id=4 从库关联主库 在 slave01/slave02上执行： CHANGE MASTER TO MASTER_HOST=\u0026#39;mysql-master01\u0026#39;, MASTER_USER=\u0026#39;masterSlave\u0026#39;, MASTER_PASSWORD=\u0026#39;Root@123456\u0026#39;, MASTER_LOG_FILE=\u0026#39;binlog.000002\u0026#39;, MASTER_LOG_POS=663; -- 开启主从复制 start slave; -- 查看同步状态，主库S1/S2中查看。 show slave status \\G; -- Slave_IO_Running: Yes -- Slave_SQL_Running: Yes 两主库相互复制 M2 复制 M1，M1 复制 M2。 在M1/M2上执行： -- M1上执行 CHANGE MASTER TO MASTER_HOST=\u0026#39;mysql-master02\u0026#39;, MASTER_USER=\u0026#39;masterSlave\u0026#39;, MASTER_PASSWORD=\u0026#39;123456\u0026#39;, MASTER_LOG_FILE=\u0026#39;mysql-bin.000003\u0026#39;, MASTER_LOG_POS=194; start slave; show slave status \\G; -- M2上执行 CHANGE MASTER TO MASTER_HOST=\u0026#39;mysql-master01\u0026#39;, MASTER_USER=\u0026#39;masterSlave\u0026#39;, MASTER_PASSWORD=\u0026#39;123456\u0026#39;, MASTER_LOG_FILE=\u0026#39;mysql-bin.000003\u0026#39;, MASTER_LOG_POS=194; start slave; show slave status \\G; 测试 分别在两台主库M1、M2上执行DDL、DML语句，查看涉及到的数据库服务器的数据同步情况。 -- M1执行 create table tb_user( id int(11) not null primary key , name varchar(50) not null, sex varchar(1) )engine=innodb default charset=utf8mb4; insert into tb_user(id,name,sex) values(1,\u0026#39;Tom\u0026#39;,\u0026#39;1\u0026#39;); insert into tb_user(id,name,sex) values(2,\u0026#39;Trigger\u0026#39;,\u0026#39;0\u0026#39;); insert into tb_user(id,name,sex) values(3,\u0026#39;Dawn\u0026#39;,\u0026#39;1\u0026#39;); insert into tb_user(id,name,sex) values(4,\u0026#39;Jack Ma\u0026#39;,\u0026#39;1\u0026#39;); insert into tb_user(id,name,sex) values(5,\u0026#39;Coco\u0026#39;,\u0026#39;0\u0026#39;); insert into tb_user(id,name,sex) values(6,\u0026#39;Jerry\u0026#39;,\u0026#39;1\u0026#39;); 配置读写分离 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- 逻辑库 --\u0026gt; \u0026lt;!-- name: 逻辑库名字 --\u0026gt; \u0026lt;!-- checkSQLschema: 当设置为true时，比如发送一条sql:select * from mycat_order.t_order，那么MyCat会自动去掉mycat_order逻辑库名字前缀，把sql变为：select * from t_order, 这样有效避免报表或视图不存在错误。 如果使用select * from test.t_order ，sql语句中所带的逻辑库名字跟schema标签中的name不一致的话，MyCat不会自动去掉逻辑库名字前缀，如果逻辑库不存在，仍然会报错。 --\u0026gt; \u0026lt;!-- sqlMaxLimit: 如果每次执行的sql语句后面没有跟上limit xx关键字的话，MyCat会自动在sql语句的后面拼上limit 100 --\u0026gt; \u0026lt;!-- dataNode: 用于指定没有分配分片节点的那些表的默认数据节点 --\u0026gt; \u0026lt;schema name=\u0026#34;shopping\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34; dataNode=\u0026#34;dn1\u0026#34;\u0026gt; \u0026lt;!-- 逻辑表，以下都没有配置分片规则rule，因为垂直分表不需要它 --\u0026gt; \u0026lt;!-- name: 逻辑表的名字，同一个逻辑库schema中的逻辑表的名称应该唯一 --\u0026gt; \u0026lt;!-- dataNode: 配置逻辑表分布的数据节点，名字需要与dataNode标签的name对应上 --\u0026gt; \u0026lt;!-- rule: 配置逻辑表的分片规则,需要在rule.xml中声明的规则名字对应上 --\u0026gt; \u0026lt;!-- ruleRequired: 指定分片规则是否必须，如果为true,但是没有指定rule，程序会报错 --\u0026gt; \u0026lt;!-- primaryKey: 指定逻辑表对应真实表的主键 --\u0026gt; \u0026lt;!-- type: 指定该逻辑表是全局表还是普通逻辑表。type=\u0026#34;global\u0026#34;表示全局表 --\u0026gt; \u0026lt;!-- autoIncrement: 指定是否自增长主键 --\u0026gt; \u0026lt;!-- needAddLimit: 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 --\u0026gt; \u0026lt;table name=\u0026#34;tb_user\u0026#34; primaryKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;!-- \u0026lt;table name=\u0026#34;t_order\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;mod-long\u0026#34;\u0026gt; # 定义E-R分片的子表，通过标签上的属性与父表进行关联 # name：子表的名称t_order_detail # primaryKey：子表的主键 # joinKey：新增子表记录的时候，会根据该值查询父表在哪个分片节点上。（子表中字段的名称order_i # parentKey属性：与父表建立关联关系的列，结合joinKey确定好子表记录存放的分片节点，插入子表记录时直接插入到该分片节点上。（父表中字段名称order_id） # needAddLimit属性： 指定逻辑表是否在查询的时候自动添加limit去限制返回的结果集记录数，默认为true,如果语句中已经包含了limit关键字，则不会重复添加 \u0026lt;childTable name=\u0026#34;t_order_detail\u0026#34; primaryKey=\u0026#34;od_id\u0026#34; joinKey=\u0026#34;order_id\u0026#34; parentKey=\u0026#34;order_id\u0026#34;\u0026gt;\u0026lt;/childTable\u0026gt; \u0026lt;/table\u0026gt; --\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;!-- 数据节点 --\u0026gt; \u0026lt;!-- name: 指定分片节点的名称，与声明逻辑表table标签中的dataNode名字对应上 --\u0026gt; \u0026lt;!-- dataHost: 指定分片节点所在的节点主机（数据库实例），与dataHost标签声明的name对应 --\u0026gt; \u0026lt;!-- database: 真实数据库名称 --\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;dhost1\u0026#34; database=\u0026#34;shopping\u0026#34; /\u0026gt; \u0026lt;!-- 具体数据库实例 --\u0026gt; \u0026lt;dataHost name=\u0026#34;dhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;1\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!--心跳检测 --\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M1\u0026#34; url=\u0026#34;172.16.0.101:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;!-- 读服务器 --\u0026gt; \u0026lt;readhost host=\u0026#34;S1\u0026#34; url=\u0026#34;172.16.0.103:3308\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;writeHost host=\u0026#34;M2\u0026#34; url=\u0026#34;172.16.0.102:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;!-- 读服务器 --\u0026gt; \u0026lt;readhost host=\u0026#34;S2\u0026#34; url=\u0026#34;172.16.0.104:3309\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;!-- name: 指定分片主机的名称，供dataNode标签使用 --\u0026gt; \u0026lt;!-- maxCon: 指定读写实例的连接池的最大连接数量 --\u0026gt; \u0026lt;!-- minCon: 指定读写实例的连接池的最小连接数量，初始化连接池的大小 --\u0026gt; \u0026lt;!-- balance: 指定负载均衡的类型 balance = “0” : 不开启读写分离，所有的读请求都发送到可用的writeHost写节点上（不会发readHost） balance = “1” : 全部的readHost与stand by writeHost参与select语句的负载均衡， balance = “2” : 读操作会随机发往writeHost以及 readHost，理论上实现的是负载均衡 balance = “3” : 配置了readHost时读操作会随机发往readHost（不会发writeHost），而没有配置readHost时读操作会发往第一个writeHost。 --\u0026gt; \u0026lt;!-- writeType: writeType=\u0026#34;0\u0026#34;: 所有写操作发送到配置的第一个writeHost，当第一个writeHost宕机时，切换到第二个writeHost，重新启动后以切换后的为准，切换记录在配置文件：dnindex.properties中 writeType=\u0026#34;1\u0026#34;: 所有写操作都随发送到配置的writeHost --\u0026gt; \u0026lt;!-- dbType: 指定后端数据库类型，支持mysql、oracle等 --\u0026gt; \u0026lt;!-- dbDriver: 指定后端数据库连接驱动信息，支持native和jdbc --\u0026gt; \u0026lt;!-- switchType: 指定切换方式 switchType = -1：不自动切换 switchType = 1：自动切换（默认） switchType = 2：基于MySql主从同步的状态来决定是否切换，心跳语句: show slave status switchType = 3: 基于mysql galary cluster的切换机制，心跳语句： show status like \u0026#39;wsrep%\u0026#39; --\u0026gt; \u0026lt;!-- slaveThreshold: --\u0026gt; \u0026lt;!--\u0026lt;dataHost name=\u0026#34;dhost3\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!--心跳检测，指定后端数据库进行心跳检查的语句 --\u0026gt; \u0026lt;!--\u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt;--\u0026gt; \u0026lt;!-- 写服务器，如果要配置读写，添加readHost标签即可 --\u0026gt; \u0026lt;!-- host: 用于标识不同实例，一般 writeHost 我们使用M1，readHost 我们用S1 --\u0026gt; \u0026lt;!-- url: 后端实例连接地址，如果是使用 native 的 dbDriver，则一般为 address:port 这种形式,用 JDBC 或其他的 dbDriver，则需要特殊指定，使用 JDBC 时则可以这么写：jdbc:mysql://localhost:3306/ --\u0026gt; \u0026lt;!-- user: 后端存储实例需要的用户名 --\u0026gt; \u0026lt;!-- password: 后端存储实例需要的密码 --\u0026gt; \u0026lt;!-- weight: 权重 配置在 readhost 中作为读节点的权重 --\u0026gt; \u0026lt;!-- usingDecrypt: 是否对密码加密默认 0 否 如需要开启配置 1，同时使用加密程序对密码加密 --\u0026gt; \u0026lt;!--\u0026lt;writeHost host=\u0026#34;M3\u0026#34; url=\u0026#34;172.16.0.103:3306\u0026#34; user=\u0026#34;root\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;/writeHost\u0026gt;--\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; github 完整代码参看 github。https://github.com/helium-chain/mycat-tow 参看其他：https://github.com/baojingyu/docker-mycat-mysql ","permalink":"https://heliu.site/posts/mysql/mycat/","summary":"mysql mycat 分库分表中间件。","title":"mycat 分库分表中间件"},{"content":"nginx 架构 nginx采用的是多进程的方式工作的。 nginx后台进程中包含一个master进程和多个worker进程，master进程主要用来管理worker进程，包含接收外界的信息。 将接收到的信号发送给各个worker进程，监控worker进程的状态，当worker进程出现异常退出后，会自动重新启动新的worker进程。 worker进程则是专门用来处理用户请求的，各个worker进程之间是平等的并且相互独立，处理请求的机会也是一样的。 可以通过 ps -ef | grep nginx 查看nginx进程信息。 nginx 目录结构 conf 目录是nginx所有配置文件目录。 文件 说明 fastcgi.conf fastcgi相关配置文件 fastcgi.conf.default fastcgi.conf的备份文件 fastcgi_params fastcgi的参数文件 fastcgi_params.default fastcgi的参数备份文件 scgi_params scgi的参数文件 scgi_params.default scgi的参数备份文件 uwsgi_params uwsgi的参数文件 uwsgi_params.default uwsgi的参数备份文件 mime.types 记录的是HTTP协议中的Content-Type的值和文件后缀名的对应关系 mime.types.default mime.types的备份文件 nginx.conf 这个是Nginx的核心配置文件 nginx.conf.default nginx.conf的备份文件 koi-utf、koi-win、win-utf 这三个文件都是与编码转换映射相关的配置文件，用来将一种编码转换成另一种编码 html 目录是nginx存放自带的两个静态的Html页面目录 文件 说明 50x.html 50x 失败后的失败页面 index.html 成功访问的默认首页 logs 目录用于记录nginx服务启动后的日志文件。 文件 说明 access.log 请求日志文件 error.log 错误日志文件 nginx.pid 记录 nginx PID sbin 目录用于存放执行程序文件目录。 文件 说明 nginx 控制Nginx的启动和停止命令的可执行文件 nginx 命令 信号控制 查看master进程的进程号ID：\nps -ef | grep nginx 命令。 通过 logs/nginx.pid 文件。 信号：调用命令 kill -signal PID\n信号 说明 举例 TERM/INT 立即关闭整个服务 kill -INT PID / kill -INT `cat /usr/local/nginx/logs/nginx.pid` QUIT \u0026ldquo;优雅\u0026quot;地关闭整个服务 kill -QUIT PID / kill -TERM `cat /usr/local/nginx/logs/nginx.pid` HUP 重读配置文件并使用服务对新配置项生效 kill -HUP PID / kill -TERM `cat /usr/local/nginx/logs/nginx.pid` USR1 重新打开日志文件，可以用来进行日志切割 kill -USR1 PID / kill -TERM `cat /usr/local/nginx/logs/nginx.pid` USR2 平滑升级到最新版的nginx kill -USR2 PID / kill -USR2 `cat /usr/local/nginx/logs/nginx.pid` WINCH 所有子进程不在接收处理新连接，相当于给work进程发送QUIT指令 kill -WINCH PID /kill -WINCH `cat /usr/local/nginx/logs/nginx.pid` 命令行 通过 nginx -h 查看支持那些参数。 参数 说明 举例 -?,-h 显示帮助信息 nginx -h -v 打印版本号信息并退出 nginx -v -V 打印版本号信息和配置信息并退 nginx -V -t 测试nginx的配置文件语法是否正确并退出(常用) nginx -t -T 测试nginx的配置文件语法是否正确并列出用到的配置文件信息然后退出 nginx -T -s 信号(常用) nginx -s reload stop[快速关闭，类似于TERM/INT信号的作用] nginx -s stop quit[优雅的关闭，类似于QUIT信号的作用] nginx -s quit reopen[重新打开日志文件类似于USR1信号的作用] nginx -s reopen reload[类似于HUP信号的作用] nginx -s reload -p 指定Nginx的prefix路径，(默认为: /usr/local/nginx/) 常用指定自定义目录 -c 指定Nginx的配置文件路径,(默认为: conf/nginx.conf) 常用指定自定义文件 -g 用来补充Nginx配置文件，向Nginx服务指定启动时应用全局的配置 安装 docker-compose.yml version: \u0026#39;3.9\u0026#39; services: nginx: image: nginx:1.20.2 container_name: nginx privileged: true restart: unless-stopped ports: - \u0026#34;80:80\u0026#34; - \u0026#34;443:443\u0026#34; volumes: #- ./docker/nginx/html:/usr/share/nginx/html #- ./docker/nginx/cert:/etc/nginx/cert #- ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf #- ./docker/nginx/conf.d:/etc/nginx/conf.d #- /app/docker/nginx/logs:/var/log/nginx environment: - TZ=Asia/Shanghai healthcheck: test: [ \u0026#34;CMD\u0026#34;, \u0026#34;curl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;http://localhost\u0026#34; ] interval: 30s timeout: 10s retries: 3 networks: - default_net networks: default_net: driver: bridge 启动命令。 $ docker-compose -p nginx up -d ","permalink":"https://heliu.site/posts/nginx/install/","summary":"nginx 架构、目录结构、相关命令。","title":"nginx 安装部署"},{"content":" Nginx的核心配置文件默认是放在 /usr/local/nginx/conf/nginx.conf。 Nginx自带的Nginx配置文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 全局块 worker_processes 1; # events块 events { worker_connections 1024; } # http块 http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # http块中可以配置多个server块 # 每个server块又可以配置多个location块 server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 全局块 user指令 用于配置运行Nginx服务器的worker进程的用户和用户组。 设置了该指令，nginx只能访问相关用户和用户的资源，其他的访问不到。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 user user [group] nobody user www master_process指令 指定是否开启工作进程。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 master_process on/off on master_process on worker_processes指令 配置Nginx生成工作进程的数量，这个是Nginx服务器实现并发处理服务的关键所在。 理论上来说workder process的值越大，可以支持的并发处理量也越多，但事实上这个值的设定是需要受到来自服务器自身的限制，建议将该值和服务器CPU的内核数保存一致。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 worker_processes num/auto 1 worker_processes auto daemon指令 设定Nginx是否以守护进程的方式启动。 守护式进程是linux后台执行的一种服务进程，特点是独立于控制终端，不会随着终端关闭而停止。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 daemon on/off on daemon on pid指令 配置Nginx当前master进程的进程号ID存储的文件路径。 该属性可以通过./configure --pid-path=PATH来指定。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 pid file /usr/local/nginx/logs/nginx.pid pid /home/nginx/logs/nginx.pid error_log指令 配置Nginx的错误日志存放路径。 该属性可以通过./configure --error-log-path=PATH来指定。 日志级别的值有：debug|info|notice|warn|error|crit|alert|emerg。设置的时候不要设置成info以下的等级，因为会带来大量的磁盘I/O消耗，影响Nginx的性能。 可以出现在：全局块、http、server、location。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 error_log file [日志级别] logs/error.log error error_log logs/error.log error include指令 引入其他配置文件，使Nginx的配置更加灵活。 可以出现在任何位置。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 include file include conf.d/* events块 accept_mutex指令 设置Nginx网络连接序列化。主要用来解决常说的\u0026quot;惊群\u0026quot;问题。 置为on(开启状态)，将会对多个Nginx进程接收连接进行序列号，一个个来唤醒接收，就防止了多个进程对连接的争抢。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 accept_mutex on/off on accept_mutex on multi_accept指令 设置是否允许同时接收多个网络连接。 如果multi_accept被禁止了，nginx一个工作进程只能同时接受一个新的连接。否则，一个工作进程可以同时接受所有的新连接。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 multi_accept on/off off multi_accept off worker_connections指令 配置单个worker进程最大的连接数。 这里的连接数不仅仅包括和前端用户建立的连接数，而是包括所有可能的连接数。number值不能大于操作系统支持打开的最大文件句柄数量。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 worker_connections number 512 worker_commections 512 use指令 设置Nginx服务器选择哪种事件驱动来处理网络消息。 method的可选值有select/poll/epoll/kqueue等。 也可以在编译的时候使用--with-select_module、--without-select_module、--with-poll_module、--without-poll_module来设置。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 use method 根据操作系统定 use epoll http块 Mime-Type 浏览器中可以显示的内容有HTML、XML、GIF等种类繁多的文件、媒体等资源，浏览器为了区分这些资源，就需要使用MIME Type。 MIME Type是网络资源的媒体类型。Nginx作为web服务器，也需要能够识别前端请求的资源类型。 Nginx的配置文件中，默认有两行配置： # 把mime.types文件中MIMT类型与相关类型文件的文件后缀名的对应关系加入到当前的配置文件中 include mime.types; default_type application/octet-stream; default_type指令 default_type:用来配置Nginx响应前端请求默认的MIME类型。 可以在 http、server、location 中。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 default_type mime-type text/plain default_type text/plain 有些时候请求某些接口的时候需要返回指定的文本字符串或者json字符串，如果逻辑非常简单或者干脆是固定的字符串，那么可以使用nginx快速实现，这样就不用编写程序响应请求了，可以减少服务器资源占用并且响应性能非常快。 location /get_text { #这里也可以设置成text/plain default_type text/html; return 200 \u0026#34;This is nginx\u0026#39;s text\u0026#34;; } location /get_json{ default_type application/json; return 200 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;TOM\u0026#34;,\u0026#34;age\u0026#34;:18}\u0026#39;; } 日志 Nginx中日志的类型分access.log、error.log。 access.log:用来记录用户所有的访问请求。 error.log:记录nginx本身运行时的错误信息，不会记录用户的访问请求。 Nginx服务器支持对服务日志的格式、大小、输出等进行设置，需要使用到两个指令，分别是access_log和log_format指令。 access_log指令 设置用户访问日志的相关属性。 位置可以在 http, server, location。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 access_log path[format[buffer=size]] logs/access.log combined access_log logs/access.log combined log_format指令 指定日志的输出格式。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 log_format name [escape=default|json|none] string\u0026hellip;. combined \u0026ldquo;\u0026hellip;\u0026rdquo; log_format combined \u0026ldquo;\u0026hellip;\u0026rdquo; sendfile指令 设置Nginx服务器是否使用sendfile()传输文件，该属性可以大大提高Nginx处理静态资源的性能。 可以在 http、server、location 中。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 sendfile on/off off sendfile off keepalive_timeout指令 设置长连接的超时时间。 可以在 http、server、location 中。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 keepalive_timeout time 75s keepalive_timeout 75 keepalive_requests指令 设置一个keep-alive连接使用的次数。 可以在 http、server、location 中。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 keepalive_requests number 100 keepalive_requests 100 ","permalink":"https://heliu.site/posts/nginx/conf/","summary":"nginx 全局块、events块、http块指令介绍。","title":"nginx nginx.cnf"},{"content":"server块 listen指令 用来配置监听端口。 语法：默认 listen *:80 | *:8000 listen address[:port] [default_server]...; listen port [default_server]...; 示例： # listen localhost:8000 监听指定的IP和端口 listen 127.0.0.1:8000; # 监听指定IP的所有端口 listen 127.0.0.1; # 监听指定端口上的连接(常用) listen 8000 # 监听指定端口上的连接 listen *:8000; default_server属性是标识符，用来将此虚拟主机设置成默认主机。 所谓的默认主机指的是如果没有匹配到对应的address:port，则会默认执行的。如果不指定默认使用的是第一个server。 server{ listen 8080; server_name 127.0.0.1; location /{ root html; index index.html; } } server{ # default_server 设置默认主机 listen 8080 default_server; server_name localhost; default_type text/plain; return 444 \u0026#39;This is a error request\u0026#39;; } server_name指令 设置虚拟主机服务名称。常用 127.0.0.1、localhost、www.heliu.site、heliu.site。 语法：server_name name \u0026hellip;;，name可以提供多个中间用空格分隔。 server_name的配置方式有三种，分别是：精确匹配、通配符匹配、正则表达式匹配。 匹配顺序： 首先匹配，精确匹配server_name。 其次匹配，通配符在开始时匹配server_name。 然后匹配，通配符在结束时匹配server_name。 接着匹配，正则表达式匹配server_name。 最后匹配，默认的default_server处理，如果没有指定默认找第一个server。 精确匹配 server { listen 80; server_name heliu.site www.heliu.site; } 通配符配置 server_name中支持通配符\u0026quot;*\u0026quot;,但需要注意的是通配符不能出现在域名的中间，只能出现在首段或尾段。 server { listen 80; server_name *.heliu.site www.heliu.*; } 正则表达式匹配 server_name中可以使用正则表达式，并且使用~作为正则表达式字符串的开始标记。 常见正则表达式： 代码 说明 ^ 匹配搜索字符串开始位置 $ 匹配搜索字符串结束位置 . 匹配除换行符\\n之外的任何单个字符 \\ 转义字符，将下一个字符标记为特殊字符 [xyz] 字符集，与任意一个指定字符匹配 [a-z] 字符范围，匹配指定范围内的任何字符 \\w 与以下任意字符匹配 A-Z a-z 0-9 和下划线,等效于[A-Za-z0-9_] \\d 数字字符匹配，等效于[0-9] {n} 正好匹配n次 {n,} 至少匹配n次 {n,m} 匹配至少n次至多m次 * 零次或多次，等效于{0,} + 一次或多次，等效于{1,} ? 零次或一次，等效于{0,1} server{ listen 80; # ~后面不能加空格，括号可以取值 server_name ~^www\\.(\\w+)\\.com$; default_type text/plain; return 200 $1 $2 ..; } location指令 设置请求的URI。 语法：location [ = | ~ | ~* | ^~ | @ ] uri{...} uri变量是待匹配的请求字符串，可以不包含正则表达式，也可以包含正则表达式，那么nginx服务器在搜索匹配location的时候，是先使用不包含正则表达式进行匹配，找到一个匹配度最高的一个，然后在通过包含正则表达式的进行匹配，如果能匹配到直接访问，匹配不到，就使用刚才匹配度最高的那个location来处理请求。 location 匹配 不带符号 要求必须以指定模式开始。 server { listen 80; server_name 127.0.0.1; location /abc{ default_type text/plain; return 200 \u0026#34;access success\u0026#34;; } } # 以下都能匹配到 # http://192.168.200.133/abc # http://192.168.200.133/abc?p1=TOM # http://192.168.200.133/abc/ # http://192.168.200.133/abcdef = 前缀 用于不包含正则表达式的uri前，必须与指定的模式精确匹配。 server { listen 80; server_name 127.0.0.1; location =/abc{ default_type text/plain; return 200 \u0026#34;access success\u0026#34;; } } # 可以匹配到 # http://192.168.200.133/abc # http://192.168.200.133/abc?p1=TOM # 匹配不到 # http://192.168.200.133/abc/ # http://192.168.200.133/abcdef ~ 和 ~* 前缀 ~ ： 用于表示当前uri中包含了正则表达式，并且区分大小写。 ~*：用于表示当前uri中包含了正则表达式，并且不区分大小写。 如果uri包含了正则表达式，需要用上述两个符合来标识。 server { listen 80; server_name 127.0.0.1; location ~^/abc\\w${ default_type text/plain; return 200 \u0026#34;access success\u0026#34;; } } server { listen 80; server_name 127.0.0.1; location ~*^/abc\\w${ default_type text/plain; return 200 \u0026#34;access success\u0026#34;; } } ^~ 前缀 用于不包含正则表达式的uri前，功能和不加符号的一致，唯一不同的是，如果模式匹配，那么就停止搜索其他模式了。 server { listen 80; server_name 127.0.0.1; location ^~/abc{ default_type text/plain; return 200 \u0026#34;access success\u0026#34;; } } @ 前缀 使用location的@符合完成错误信息展示。 server{ error_page 404 @jump_to_error; location @jump_to_error { default_type text/plain; return 404 \u0026#39;Not Found Page...\u0026#39;; } } root指令 设置请求的根目录。 可以在 http、server、location 中。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 root path html root html path 为Nginx服务器接收到请求以后查找资源的根目录路径。 alias指令 更改location的URI。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 alias path alias /usr/local/nginx/htm path为修改后的根路径。 root和alias指令的区别 在/usr/local/nginx/html目录下创建一个 images目录,并在目录下放入一张图片mv.png图片。 location /images { root /usr/local/nginx/html; } # 访问图片的路径为: http://127.0.0.1/images/mv.png 能成功 如果把root改为alias。 location /images { alias /usr/local/nginx/html; } # 再次访问上述地址，页面会出现404的错误，因为地址不对 oot的处理结果是: root路径+location路径，/usr/local/nginx/html/images/mv.png。 alias的处理结果是:使用alias路径替换location路径，/usr/local/nginx/html/mv.png。 修改成这样，alias /usr/local/nginx/html/images;就能访问到。 如果location路径是以/结尾,则alias也必须是以/结尾，root没有要求。 location /images/ { alias /usr/local/nginx/html/images; } # 访问就会出问题，查看错误日志还是路径不对，所以需要把alias后面加上 / index指令 设置网站的默认首页。 可以在 http、server、location 中。 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;语法\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 默认值 示例 index file \u0026hellip; index.html index index.html index后面可以跟多个设置，如果访问的时候没有指定具体访问的资源，则会依次进行查找，找到第一个为止。 location / { root /usr/local/nginx/html; index index.html index.htm; } # 访问该location的时候，可以通过 http://ip:port/， # 地址后面如果不添加任何内容，则默认依次访问index.html和index.htm， # 找到第一个来进行返回 error_page指令 设置网站的错误页面。可以在 http、server、location 中。 语法：error_page code \u0026hellip; [=[response]] uri。 可以指定具体跳转的地址。 server { error_page 404 http://www.baidu.cn; } 指定重定向地址。 server{ error_page 404 /50x.html; error_page 500 502 503 504 /50x.html; location =/50x.html{ root html; } } 使用location的@符合完成错误信息展示。 server{ error_page 404 @jump_to_error; location @jump_to_error { default_type text/plain; return 404 \u0026#39;Not Found Page...\u0026#39;; } } =[response]的作用是用来将相应代码更改为另外一个。 server{ error_page 404 =200 /50x.html; location =/50x.html{ root html; } } ","permalink":"https://heliu.site/posts/nginx/server/","summary":"nginx server块介绍。","title":"nginx server块"},{"content":"资源优化 sendfile指令 用来开启高效的文件传输模式。 可以在 http、server、location 位置。 语法：sendfile on/off。默认值 sendfile off。 sendfile指令能避免静态资源文件从内核缓冲区拷贝到用户缓冲区，又从用户缓冲区拷贝到Socket缓冲区。 server { listen 80; server_name localhost； sendfile on; location / { root html; index index.html; } } tcp_nopush指令 该指令必须在sendfile打开的状态下才会生效，主要是用来提升网络包的传输\u0026rsquo;效率\u0026rsquo;。 该指令开启只要缓冲区有数据就会发送给客户端，而不需要等待缓冲区满了才发送。 可以在 http、server、location 位置。 语法：tcp_nopush on/off。默认值 tcp_nopush off。 server { listen 80; server_name localhost； sendfile on; tcp_nopush on; location / { root html; index index.html; } } tcp_nodelay指令 该指令必须在keep-alive连接开启的情况下才生效，来提高网络包传输的\u0026rsquo;实时性\u0026rsquo;。 可以在 http、server、location 位置。 该指令开启时数据是先存在缓冲区的，等待缓冲区满了再发送给客户端。 语法：tcp_nodelay on/off。默认值 tcp_nodelay on。 server { listen 80; server_name localhost； sendfile on; tcp_nopush on; tcp_nodelay on; location / { root html; index index.html; } } 资源压缩 以下指令都来自ngx_http_gzip_module模块，该模块会在nginx安装的时候内置到nginx的安装环境中。 gzip指令 用于开启或者关闭gzip功能。 可以在 http、server、location 位置。 语法：gzip on/off。默认值 gzip off。 server { listen 80; server_name localhost； gzip on; location / { root html; index index.html; } } gzip_types指令 该指令可以根据响应页的MIME类型选择性地开启Gzip压缩功能。 可以在 http、server、location 位置。 语法：gzip_types mime-type \u0026hellip;。默认值 gzip_types text/html。 所选择的值可以从mime.types文件中进行查找，也可以使用\u0026quot;*\u0026ldquo;代表所有。 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; location / { root html; index index.html; } } gzip_comp_level指令 该指令用于设置Gzip压缩程度，级别从1-9,1表示要是程度最低，要是效率最高，9刚好相反，压缩程度最高，但是效率最低最费时间。 可以在 http、server、location 位置。 语法：gzip_comp_level level。默认值 gzip_comp_level 1。 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; gzip_comp_level 6; # 6是个不错的中间值 location / { root html; index index.html; } } gzip_vary指令 该指令用于设置使用Gzip进行压缩发送是否携带“Vary:Accept-Encoding”头域的响应头部。主要是告诉接收方，所发送的数据经过了Gzip压缩处理。 可以在 http、server、location 位置。 语法：gzip_vary on/off。默认值 gzip_vary off。 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; gzip_comp_level 6; # 6是个不错的中间值 gzip_vary on; location / { root html; index index.html; } } gzip_buffers指令 该指令用于处理请求压缩的缓冲区数量和大小。 可以在 http、server、location 位置。 语法：gzip_buffers number size。默认值 gzip_buffers 32 4k|16 8k。 其中number:指定Nginx服务器向系统申请缓存空间个数，size指的是每个缓存空间的大小。 主要实现的是申请number个每个大小为size的内存空间。 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; gzip_comp_level 6; # 6是个不错的中间值 gzip_vary on; gzip_buffers 16 8k; location / { root html; index index.html; } } gzip_disable指令 针对不同种类客户端发起的请求，可以选择性地开启和关闭Gzip功能。 可以在 http、server、location 位置。 语法：gzip_disable regex \u0026hellip;。 regex:根据客户端的浏览器标志(user-agent)来设置，支持使用正则表达式。指定的浏览器标志不使用Gzip.该指令一般是用来排除一些明显不支持Gzip的浏览器。 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; gzip_comp_level 6; # 6是个不错的中间值 gzip_vary on; gzip_buffers 16 8k; gzip_disable \u0026#34;msie6\u0026#34;; # 禁用IE6的gzip压缩，因为它有bug location / { root html; index index.html; } } gzip_http_version指令 针对不同的HTTP协议版本，可以选择性地开启和关闭Gzip功能。 可以在 http、server、location 位置。 语法：gzip_http_version 1.0|1.1。默认值 gzip_http_version 1.1。 该指令是指定使用Gzip的HTTP最低版本，该指令一般采用默认值即可。 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; gzip_comp_level 6; # 6是个不错的中间值 gzip_vary on; gzip_buffers 16 8k; gzip_disable \u0026#34;msie6\u0026#34;; # 禁用IE6的gzip压缩，因为它有bug gzip_http_version 1.1; location / { root html; index index.html; } } gzip_min_length指令 该指令针对传输数据的大小，可以选择性地开启和关闭Gzip功能。 可以在 http、server、location 位置。 语法：gzip_min_length length。默认值 gzip_min_length 20。 Gzip压缩功能对大数据的压缩效果明显，但是如果要压缩的数据比较小的化，可能出现越压缩数据量越大的情况，因此我们需要根据响应内容的大小来决定是否使用Gzip功能。建议设置为1K或以上。单位：bytes[字节] / kb[千字节] / M[兆]。 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; gzip_comp_level 6; # 6是个不错的中间值 gzip_vary on; gzip_buffers 16 8k; gzip_disable \u0026#34;msie6\u0026#34;; # 禁用IE6的gzip压缩，因为它有bug gzip_http_version 1.1; gzip_min_length 2M; location / { root html; index index.html; } } gzip_proxied指令 该指令设置是否对服务端返回的结果进行Gzip压缩。 可以在 http、server、location 位置。 语法：gzip_proxied off|expired|no-cache|no-store|private|no_last_modified|no_etag|auth|any。 默认值：gzip_proxied off。 off - 关闭Nginx服务器对后台服务器返回结果的Gzip压缩 expired - 启用压缩，如果header头中包含 \u0026ldquo;Expires\u0026rdquo; 头信息 no-cache - 启用压缩，如果header头中包含 \u0026ldquo;Cache-Control:no-cache\u0026rdquo; 头信息 no-store - 启用压缩，如果header头中包含 \u0026ldquo;Cache-Control:no-store\u0026rdquo; 头信息 private - 启用压缩，如果header头中包含 \u0026ldquo;Cache-Control:private\u0026rdquo; 头信息 no_last_modified - 启用压缩,如果header头中不包含 \u0026ldquo;Last-Modified\u0026rdquo; 头信息 no_etag - 启用压缩 ,如果header头中不包含 \u0026ldquo;ETag\u0026rdquo; 头信息 auth - 启用压缩 , 如果header头中包含 \u0026ldquo;Authorization\u0026rdquo; 头信息 any - 无条件启用压缩 server { listen 80; server_name localhost； gzip on; # 多个使用空格隔开 gzip_types text/plain text/css application/json application/javascript text/xml; gzip_comp_level 6; # 6是个不错的中间值 gzip_vary on; gzip_buffers 16 8k; gzip_disable \u0026#34;msie6\u0026#34;; # 禁用IE6的gzip压缩，因为它有bug gzip_http_version 1.1; gzip_min_length 2M; gzip_proxied off; location / { root html; index index.html; } } 小结 这些配置在很多地方可能都会用到，所以我们可以将这些内容抽取到一个配置文件中，然后通过include指令把配置文件再次加载到nginx.conf配置文件中。 include nginx_gzip.conf 开启sendfile以后，在读取磁盘上的静态资源文件的时候，可以减少拷贝的次数，可以不经过用户进程将静态文件通过网络设备发送出去，但是Gzip要想对资源压缩，是需要经过用户进程进行操作的。可以使用ngx_http_gzip_static_module模块(手动加载)的gzip_static指令来解决。压缩文件也需要我们手动压缩好。 语法：gzip_static on | off | always。 资源缓存 缓存的优点：减少网络带宽消耗、降低服务器压力、减少网络延迟，加快页面打开速度。 HTTP协议中和页面缓存相关的字段。 \u0026mdash;\u0026mdash;\u0026ndash;header\u0026mdash;\u0026mdash;\u0026ndash; 说明 Expires 缓存过期的日期和时间 Cache-Control 设置和缓存相关的配置信息 Last-Modified 请求资源最后修改时间 ETag 请求变量的实体标签的当前值，比如文件的MD5值 expires指令 该指令用来控制页面缓存的作用。可以通过该指令控制HTTP应答中的“Expires\u0026quot;和”Cache-Control\u0026rdquo;。 可以在 http、server、location 位置。 语法：默认值 expires off。 epoch: 指定Expires的值为'1 January,1970,00:00:01 GMT\u0026rsquo;(1970-01-01 00:00:00)，Cache-Control的值no-cache epoch: 指定Expires的值为'1 January,1970,00:00:01 GMT\u0026rsquo;(1970-01-01 00:00:00)，Cache-Control的值no-cache max:指定Expires的值为'31 December2037 23:59:59GMT\u0026rsquo; (2037-12-31 23:59:59) ，Cache-Control的值为10年 off:默认不缓存。 expires [modified] time expires epoch|max|off; server { listen 80; server_name localhost； location ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; # 缓存30天 add_header Cache-Control \u0026#34;public, no-transform\u0026#34;; # 添加缓存控制头 } } add_header指令 用来添加指定的响应头和响应值。 可以在 http、server、location 位置。 语法：add_header name value [always]。 server { listen 80; server_name localhost； location ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ { expires 30d; # 缓存30天 add_header Cache-Control \u0026#34;public, no-transform\u0026#34;; # 添加缓存控制头 } } 跨域 同源策略：是一种约定，是浏览器最核心也是最基本的安全功能，如果浏览器少了同源策略，则浏览器的正常功能可能都会受到影响。 有两台服务器分别为A,B,如果从服务器A的页面发送异步请求到服务器B获取数据，如果服务器A和服务器B不满足同源策略，则就会出现跨域问题。 同源：协议、域名(IP)、端口相同即为同源。 http://192.168.200.131/user/1 https://192.168.200.131/user/1 不同源 http://192.168.200.131/user/1 http://192.168.200.132/user/1 不同源 http://192.168.200.131/user/1 http://192.168.200.131:8080/user/1 不同源 http://www.nginx.com/user/1 http://www.nginx.org/user/1 不同源 http://192.168.200.131/user/1 http://192.168.200.131:8080/user/1 不同源 http://www.nginx.org:80/user/1 http://www.nginx.org/user/1 同源 add_header 指令，添加允许跨域标识。 Access-Control-Allow-Origin**: 直译过来是允许跨域访问的源地址信息，可以配置多个(多个用逗号分隔)，也可以使用*代表所有源。 Access-Control-Allow-Methods:直译过来是允许跨域访问的请求方式，值可以为 GET POST PUT DELETE\u0026hellip;,可以全部设置，也可以根据需要设置，多个用逗号分隔。 location /getUser{ add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE; default_type application/json; return 200 \u0026#39;{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;TOM\u0026#34;,\u0026#34;age\u0026#34;:18}\u0026#39;; } 防盗链 HTTP的头信息Referer,当浏览器向web服务器发送请求的时候，一般都会带上Referer,来告诉浏览器该网页是从哪个页面链接过来的。 后台服务器可以根据获取到的这个Referer信息来判断是否为自己信任的网站地址，如果是则放行继续访问，如果不是则可以返回403(服务端拒绝访问)的状态信息。 valid_referers 指令 nginx会通就过查看referer自动和valid_referers后面的内容进行匹配，如果匹配到了就将$invalid_referer变量置0，如果没有匹配到，则将$invalid_referer变量置为1，匹配的过程中不区分大小写。 可以在 server、location 中。 语法：valid_referers none|blocked|server_names|string\u0026hellip;。 none: 如果Header中的Referer为空，允许访问。 blocked:在Header中的Referer不为空，但是该值被防火墙或代理进行伪装过，如不带\u0026quot;http://\u0026quot; 、\u0026ldquo;https://\u0026ldquo;等协议头的资源允许访问。 server_names:指定具体的域名或者IP。 string: 可以支持正则表达式和*的字符串。如果是正则表达式，需要以~开头表示，例如 # 防盗链配置 location ~* \\.(jpg|jpeg|png|gif)$ { # 设置一个referrer白名单，只有referrer是以下域名之一的请求才会被允许 valid_referers none blocked heliu.site *.heliu.site; # 如果referrer不在白名单中，返回一个错误图片或者重定向 if ($invalid_referer) { # 返回一个错误图片 return 403; # 或者你可以选择重定向到一个错误页面或者图片 # rewrite ^/ http://yourdomain.com/403.jpg last; } # 如果referrer有效，正常服务静态文件 try_files $uri /helium.png; } location ~*\\.(png|jpg|gif){ valid_referers none blocked www.baidu.com 192.168.1.222 *.example.com example.* www.example.org ~\\.google\\.; if ($invalid_referer){ return 403; } root /usr/local/nginx/html; } 针对目录进行防盗链。 # images 目录 location /images { valid_referers none blocked www.baidu.com 192.168.200.222 *.example.com example.* www.example.org ~\\.google\\.; if ($invalid_referer){ return 403; } root /usr/local/nginx/html; } 更严格的防盗链参看nginx第三方模块ngx_http_accesskey_module。 ","permalink":"https://heliu.site/posts/nginx/static/","summary":"nginx 静态资源缓存、压缩、防盗链。","title":"nginx 静态资源优化"},{"content":" Nginx使用的是ngx_http_rewrite_module模块来解析和处理Rewrite功能的相关配置。 Rewrite常用全局变量： 变量 说明 $args 变量中存放了请求URL中的请求参数。比如http://192.168.200.133/server?arg1=value1\u0026amp;args2=value2中的\u0026quot;arg1=value1\u0026amp;arg2=value2\u0026quot;，功能和$query_string一样 $http_user_agent 变量存储的是用户访问服务的代理信息(如果通过浏览器访问，记录的是浏览器的相关版本信息) $host 变量存储的是访问服务器的server_name值 $document_uri 变量存储的是当前访问地址的URI。比如http://192.168.200.133/server?id=10\u0026amp;name=zhangsan中的\u0026quot;/server\u0026quot;，功能和$uri一样 $document_root 变量存储的是当前请求对应location的root值，如果未设置，默认指向Nginx自带html目录所在位置 $content_length 变量存储的是请求头中的Content-Length的值 $content_type 变量存储的是请求头中的Content-Type的值 $http_cookie 变量存储的是客户端的cookie信息，可以通过add_header Set-Cookie \u0026lsquo;cookieName=cookieValue\u0026rsquo;来添加cookie数据 $limit_rate 变量中存储的是Nginx服务器对网络连接速率的限制，也就是Nginx配置中对limit_rate指令设置的值，默认是0，不限制。 $remote_addr 变量中存储的是客户端的IP地址 $remote_port 变量中存储了客户端与服务端建立连接的端口号 $remote_user 变量中存储了客户端的用户名，需要有认证模块才能获取 $scheme 变量中存储了访问协议 $server_addr 变量中存储了服务端的地址 $server_name 变量中存储了客户端请求到达的服务器的名称 $server_port 变量中存储了客户端请求到达服务器的端口号 $server_protocol 变量中存储了客户端请求协议的版本，比如\u0026quot;HTTP/1.1\u0026quot; $request_body_file 变量中存储了发给后端服务器的本地文件资源的名称 $request_method 变量中存储了客户端的请求方式，比如\u0026quot;GET\u0026quot;,\u0026ldquo;POST\u0026quot;等 $request_filename 变量中存储了当前请求的资源文件的路径名 $request_uri 变量中存储了当前请求的URI，并且携带请求参数，比如http://192.168.200.133/server?id=10\u0026amp;name=zhangsan中的\u0026rdquo;/server?id=10\u0026amp;name=zhangsan\u0026quot; 相关指令 set指令 设置一个新的变量。 variable:变量的名称，该变量名称要用\u0026quot;$\u0026ldquo;作为变量的第一个字符，且不要与Nginx服务器预设的全局变量同名。 value:变量的值，可以是字符串、其他变量或者变量的组合等。 语法 set $variable value; 默认值 — 位置 server、location、if if指令 用来支持条件判断，并根据条件判断结果选择不同的Nginx配置。 语法 if (condition){\u0026hellip;} 默认值 — 位置 server、location # 1) $param 为空字符串或\u0026#34;0\u0026#34;，if都判断为false if ($param){} # 2) \u0026#34;=\u0026#34;和\u0026#34;!=\u0026#34;比较变量和字符串是否相等，满足条件为true，注意=前后空格 if ($request_method = POST){} # 3) 正则表达式对变量进行匹配，匹配成功返回true，否则返回false。 # - \u0026#34;~\u0026#34;代表匹配正则表达式过程中区分大小写 # - \u0026#34;~\\*\u0026#34;代表匹配正则表达式过程中不区分大小写 # - \u0026#34;!~\u0026#34;和\u0026#34;!~\\*\u0026#34;刚好和上面取相反值，如果匹配上返回false,匹配不上返回true # 正则表达式字符串一般不需要加引号，但是如果字符串中包含\u0026#34;}\u0026#34;或者是\u0026#34;;\u0026#34;等字符时，就需要把引号加上。 if ($http_user_agent ~ MSIE){} # $http_user_agent的值中是否包含MSIE字符串，如果包含返回true # 4) 判断请求的文件是否存在使用\u0026#34;-f\u0026#34;和\u0026#34;!-f\u0026#34; if (-f $request_filename){} # 判断请求的文件是否存在 if (!-f $request_filename){} # 判断请求的文件是否不存在 # 5) 判断请求的目录是否存在使用\u0026#34;-d\u0026#34;和\u0026#34;!-d\u0026#34; if (-d $request_dir){} # 6) 判断请求的目录或者文件是否存在使用\u0026#34;-e\u0026#34;和\u0026#34;!-e\u0026#34; # 7) 判断请求的文件是否可执行使用\u0026#34;-x\u0026#34;和\u0026#34;!-x\u0026#34; break指令 用于中断当前相同作用域中的其他Nginx配置。 与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。 并且break还有另外一个功能就是终止当前的匹配并把当前的URI在本location进行重定向访问处理。 语法 break; 默认值 — 位置 server、location、if location /testbreak{ default_type text/plain; set $username TOM; if ($args){ Set $username JERRY; break; set $username ROSE; } add_header username $username; return 200 $username; } return指令 用于完成对请求的处理，直接向客户端返回。在return后的所有Nginx配置都是无效的。 code:为返回给客户端的HTTP状态代理。可以返回的状态代码为0~999的任意HTTP状态代理。 text:为返回给客户端的响应体内容，支持变量的使用。 URL:为返回给客户端的URL地址。 语法 return code [text]; | return code URL; | return URL; 默认值 — 位置 server、location、if location /testreturn { return 200 success; } location /testreturn { return https://www.baidu.com; # 302重定向到百度 } location /testreturn { return 302 https://www.baidu.com; } location /testreturn { return 302 www.baidu.com; # 不允许这么写 } rewrite指令 通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理。 语法 rewrite regex replacement [flag]; 默认值 — 位置 server、location、if regex参数：用来匹配URI的正则表达式。 replacement参数：匹配成功后，用于替换URI中被截取内容的字符串。如果该字符串是以\u0026quot;http://\u0026ldquo;或者\u0026quot;https://\u0026ldquo;开头的，则不会继续向下对URI进行其他处理，而是直接返回重写后的URI给客户端。 location rewrite { rewrite ^/rewrite/url\\w*$ https://www.baidu.com; rewrite ^/rewrite/(test)\\w*$ /$1; rewrite ^/rewrite/(demo)\\w*$ /$1; } location /test{ default_type text/plain; return 200 test_success; } location /demo{ default_type text/plain; return 200 demo_success; } flag:用来设置rewrite对URI的处理行为： last、break、redirect、permanent last:终止继续在本location块中处理接收到的URI，并将此处重写的URI作为一个新的URI，使用各location块进行处理。该标志将重写后的URI重写在server块中执行，为重写后的URI提供了转入到其他location块的机会。 location rewrite { rewrite ^/rewrite/(test)\\w*$ /$1 last; rewrite ^/rewrite/(demo)\\w*$ /$1 last; } # http://localhost/rewrite/testabc 能命中这 location /test{ default_type text/plain; return 200 test_success; } location /demo{ default_type text/plain; return 200 demo_success; } break：将此处重写的URI作为一个新的URI,在本块中继续进行处理。该标志将重写后的地址在当前的location块中执行，不会将新的URI转向其他的location块。 # http://localhost/rewrite/demoabc 报错 location rewrite { #/test /usr/local/nginx/html/test/index.html rewrite ^/rewrite/(test)\\w*$ /$1 break; rewrite ^/rewrite/(demo)\\w*$ /$1 break; } location /test{ default_type text/plain; return 200 test_success; } location /demo{ default_type text/plain; return 200 demo_success; } redirect：将重写后的URI返回给客户端，状态码为302，指明是临时重定向URI,主要用在replacement变量不是以\u0026quot;http://\u0026ldquo;或者\u0026quot;https://\u0026ldquo;开头的情况。 # http://localhost/rewrite/testabc`请求会被临时重定向，浏览器地址也会发生改变 location rewrite { rewrite ^/rewrite/(test)\\w*$ /$1 redirect; rewrite ^/rewrite/(demo)\\w*$ /$1 redirect; } location /test{ default_type text/plain; return 200 test_success; } location /demo{ default_type text/plain; return 200 demo_success; } permanent：将重写后的URI返回给客户端，状态码为301，指明是永久重定向URI,主要用在replacement变量不是以\u0026quot;http://\u0026ldquo;或者\u0026quot;https://\u0026ldquo;开头的情况。 # http://localhost/rewrite/testabc`请求会被永久重定向，浏览器地址也会发生改变 location rewrite { rewrite ^/rewrite/(test)\\w*$ /$1 permanent; rewrite ^/rewrite/(demo)\\w*$ /$1 permanent; } location /test{ default_type text/plain; return 200 test_success; } location /demo{ default_type text/plain; return 200 demo_success; } rewrite_log指令 该指令配置是否开启URL重写日志的输出功能。 语法 rewrite_log on|off; 默认值 rewrite_log off; 位置 http、server、location、if 开启后，URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件汇总。 rewrite_log on; error_log logs/error.log notice; 域名跳转 将 www.it.cn、www.it.vip 跳转到 www.ix.com。 server { listen 80; server_name www.it.cn www.it.vip; # (.*)捕获请求的URI和相关参数 rewrite ^(.*) http://www.ix.com$1； } 独立域名 一个完整的项目包含多个模块，比如购物网站有商品搜索模块、商品详情模块和购物车模块等，那么我们如何为每一个模块设置独立的域名。 http://search.xxss.com:81 访问商品搜索模块 http://item.xxss.com:82\t访问商品详情模块 http://cart.xxss.com:83\t访问商品购物车模块 server{ listen 81; server_name search.xxss.com; rewrite ^(.*) http://www.xxss.cn/search$1; } server{ listen 82; server_name item.xxss.com; rewrite ^(.*) http://www.xxss.cn/item$1; } server{ listen 83; server_name cart.xxss.com; rewrite ^(.*) http://www.xxss.cn/cart$1; } 防盗链 当出现防盗链的情况，我们可以使用rewrite将请求转发到自定义的一张图片和页面，给用户比较好的提示信息。 location /images { root html; valid_referers none blocked www.baidu.com; if ($invalid_referer){ #return 403; rewrite ^/ /images/forbidden.png break; } } ","permalink":"https://heliu.site/posts/nginx/rewrite/","summary":"nginx 重写地址。","title":"nginx Rewrite"},{"content":" Nginx反向代理模块的指令是由ngx_http_proxy_module模块进行解析，该模块在安装Nginx的时候已经自己加装到Nginx中。 指令 proxy_pass指令 该指令用来设置被代理服务器地址，可以是主机名称、IP地址加端口号形式。 语法 proxy_pass URL; 默认值 — 位置 location URL:为要设置的被代理服务器地址，包含传输协议(http,https://)、主机名称或IP地址加端口号、URI等要素。 server { listen 80; server_name localhost; location / { # 客户端访问 http://localhost/index.html 效果一样没区别 #proxy_pass http://192.168.200.146; #proxy_pass http://192.168.200.146/; } } server{ listen 80; server_name localhost; location /server{ # 客户端访问 http://localhost/server/index.html 地址不变 #proxy_pass http://192.168.200.146; # 客户端访问 http://localhost/server/index.html # 地址变为 http://localhost/index.html #proxy_pass http://192.168.200.146/; } } proxy_set_header指令 该指令可以更改Nginx服务器接收到的客户端请求的请求头信息，然后将新的请求头发送给代理的服务器。 语法 proxy_set_header field value; 默认值 proxy_set_header Host $proxy_host; | proxy_set_header Connection close; 位置 http、server、location server { listen 8080; server_name localhost; location /server { proxy_pass http://192.168.200.146:8080/; proxy_set_header username TOM; } } proxy_redirect指令 该指令是用来重置头信息中的\u0026quot;Location\u0026quot;和\u0026quot;Refresh\u0026quot;的值。 语法 proxy_redirect redirect replacement; | proxy_redirect default; | proxy_redirect off; 默认值 proxy_redirect default; 位置 http、server、location server { listen 8081; server_name localhost; location / { proxy_pass http://192.168.1.146:8081/; # http://192.168.1.146 代码的地址 # http://192.168.1.133 来源的地址 proxy_redirect http://192.168.1.146 http://192.168.1.133; } } proxy_redirect redirect replacement： redirect:目标,Location的值 replacement:要替换的值 proxy_redirect default： 将location块的uri变量作为replacement proxy_redirect off：关闭proxy_redirect的功能。 示例 nginx 代理三台内容不一的服务器。 server { listen 8082; server_name localhost; location /server1 { proxy_pass http://192.168.1.146:9001/; } location /server2 { proxy_pass http://192.168.1.146:9002/; } location /server3 { proxy_pass http://192.168.1.146:9003/; } } ","permalink":"https://heliu.site/posts/nginx/proxy/","summary":"nginx 反向代理及SSL。","title":"nginx 反向代理"},{"content":"正向索引 mysql 就是采用的正向索引。 倒排索引 倒排索引重要概念： 文档（Document）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息。 词条（Term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条。 创建倒排索引是对正向索引的一种特殊处理： 将每一个文档的数据利用算法分词，得到一个个词条。 创建表，每行数据包括词条、词条所在文档id、位置等信息。 因为词条唯一性，可以给词条创建索引，例如hash表结构索引。 搜索流程： 虽然要先查询倒排索引，再查询倒排索引，但是无论是词条、还是文档id都建立了索引，查询速度非常快！无需全表扫描。 正向和倒排 正向索引是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是根据文档找词条的过程。 倒排索引则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的id，然后根据id获取文档。是根据词条找文档的过程。 正向索引优缺点： 优点：可以给多个字段创建索引；根据索引字段搜索、排序速度非常快。 缺点：根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。 倒排索引优缺点： 优点：根据词条搜索、模糊搜索时，速度非常快。 只能给词条创建索引，而不是字段；无法根据字段做排序。 ","permalink":"https://heliu.site/posts/elasticsearch/desc/","summary":"es 正向索引和倒排索引简介。","title":"正向索引和倒排索引"},{"content":"文档和字段 elasticsearch是面向文档（Document）存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为json格式后存储在elasticsearch中。 而Json文档中往往包含很多的字段（Field），类似于数据库中的列。 索引和映射 索引（Index），就是相同类型的文档的集合。 所有用户文档，就可以组织在一起，称为用户的索引。 所有商品的文档，可以组织在一起，称为商品的索引。 所有订单的文档，可以组织在一起，称为订单的索引。 因此，我们可以把索引当做是数据库中的表。 数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引库中就有映射（mapping），是索引中文档的字段约束信息，类似表的结构约束。 mysql与elasticsearch MySQL Elasticsearch 说明 Table Index 索引(index)，就是文档的集合，类似数据库的表(table) Row Document 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 Column Field 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） Schema Mapping Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） SQL DSL DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD 在实际应用中往往是两者结合使用： 对安全性要求较高的写操作，使用mysql实现 对查询性能要求较高的搜索需求，使用elasticsearch实现 两者再基于某种方式，实现数据的同步，保证一致性 ","permalink":"https://heliu.site/posts/elasticsearch/intro/","summary":"es 文档和索引简介。","title":"文档和索引"},{"content":"安装ES 拷贝ES配置文件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # 1)创建网络 docker network create es-net # 2)获取镜像列表 docker search elasticsearch # 3)拉取镜像 docker pull elasticsearch:8.12.0 # 4)查看镜像 docker images # 5)启动容器 docker run -d \\ --name es \\ -e \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34; \\ -e \u0026#34;discovery.type=single-node\u0026#34; \\ --network es-net \\ -p 9200:9200 \\ -p 9300:9300 \\ elasticsearch:8.12.0 # 6)复制容器对应文件 mkdir -p /home/elasticsearch/{data,plugins,config} docker cp es:/usr/share/elasticsearch/config /home/elasticsearch docker cp es:/usr/share/elasticsearch/plugins /home/elasticsearch # 7)移除nginx容器 docker rm -f es # 8)给与目录权限 chmod -R 777 /home/elasticsearch # 9)挂载目录 plugins、data、logs、config/ docker run -d \\ --name es \\ -e \u0026#34;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026#34; \\ -e \u0026#34;discovery.type=single-node\u0026#34; \\ -v /home/elasticsearch/data:/usr/share/elasticsearch/data \\ -v /home/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\ -v /home/elasticsearch/config:/usr/share/elasticsearch/config \\ --privileged \\ --network es-net \\ -p 9200:9200 \\ -p 9300:9300 \\ elasticsearch:8.12.0 相关参数解释：\n-e \u0026quot;cluster.name=es-docker-cluster\u0026quot;：设置集群名称。 -e \u0026quot;http.host=0.0.0.0\u0026quot;：监听的地址，可以外网访问。 -e \u0026quot;ES_JAVA_OPTS=-Xms512m -Xmx512m\u0026quot;：内存大小。 -e \u0026quot;discovery.type=single-node\u0026quot;：非集群模式。 -v es-data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定es的数据目录。 -v es-logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定es的日志目录。 -v es-plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定es的插件目录。 --privileged：授予逻辑卷访问权。 --network es-net ：加入一个名为es-net的网络中。 -p 9200:9200：端口映射配置。 ES的9200端口用于数据的交互，9300端口用于集群的通信。\n验证：浏览器输入http://localhost:9200。\n安装kibana kibana给我们提供一个elasticsearch的可视化界面。 1 2 3 4 5 6 7 8 9 10 # 1)拉取镜像 docker pull kibana:8.12.0 # 2)安装 docker run -d \\ --name kibana \\ -e ELASTICSEARCH_HOSTS=http://es:9200 \\ --network=es-net \\ -p 5601:5601 \\ kibana:7.12.1 相关参数解释： --network es-net ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中。 -e ELASTICSEARCH_HOSTS=http://es:9200\u0026quot;：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch。 -p 5601:5601：端口映射配置。 docker查看启动日志看是否启动成功：docker logs -f kibana。 浏览器输入：http://localhost:5601。 ES安装IK分词器 在线安装 1 2 3 4 5 6 7 8 9 10 11 # 1) 进入ES容器 docker exec -it es /bin/bash # 2) 在线下载并安装 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip # 3) 推出容器 exit # 4) 重启ES docker restart es 离线安装 查看数据卷目录：docker volume inspect es-plugins。 把下载的7.12.1版本包放入。重启ES。 IK分词器 IK分词器包含两种模式： ik_smart：最少切分。 ik_max_word：最细切分。 测试两种分词。 1 2 3 4 5 GET /_analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;美好的一天从清晨开始。\u0026#34; } { \u0026#34;tokens\u0026#34;: [ { \u0026#34;token\u0026#34;: \u0026#34;美好\u0026#34;, \u0026#34;start_offset\u0026#34;: 0, \u0026#34;end_offset\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 0 }, { \u0026#34;token\u0026#34;: \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34;: 2, \u0026#34;end_offset\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34;: 1 }, { \u0026#34;token\u0026#34;: \u0026#34;一天\u0026#34;, \u0026#34;start_offset\u0026#34;: 3, \u0026#34;end_offset\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 2 }, { \u0026#34;token\u0026#34;: \u0026#34;从\u0026#34;, \u0026#34;start_offset\u0026#34;: 5, \u0026#34;end_offset\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34;: 3 }, { \u0026#34;token\u0026#34;: \u0026#34;清晨\u0026#34;, \u0026#34;start_offset\u0026#34;: 6, \u0026#34;end_offset\u0026#34;: 8, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 4 }, { \u0026#34;token\u0026#34;: \u0026#34;开始\u0026#34;, \u0026#34;start_offset\u0026#34;: 8, \u0026#34;end_offset\u0026#34;: 10, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 5 } ] } 1 2 3 4 5 GET /_analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;美好的一天从清晨开始。\u0026#34; } { \u0026#34;tokens\u0026#34;: [ { \u0026#34;token\u0026#34;: \u0026#34;美好\u0026#34;, \u0026#34;start_offset\u0026#34;: 0, \u0026#34;end_offset\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 0 }, { \u0026#34;token\u0026#34;: \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34;: 2, \u0026#34;end_offset\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34;: 1 }, { \u0026#34;token\u0026#34;: \u0026#34;一天\u0026#34;, \u0026#34;start_offset\u0026#34;: 3, \u0026#34;end_offset\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 2 }, { \u0026#34;token\u0026#34;: \u0026#34;一\u0026#34;, \u0026#34;start_offset\u0026#34;: 3, \u0026#34;end_offset\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;TYPE_CNUM\u0026#34;, \u0026#34;position\u0026#34;: 3 }, { \u0026#34;token\u0026#34;: \u0026#34;天\u0026#34;, \u0026#34;start_offset\u0026#34;: 4, \u0026#34;end_offset\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;COUNT\u0026#34;, \u0026#34;position\u0026#34;: 4 }, { \u0026#34;token\u0026#34;: \u0026#34;从\u0026#34;, \u0026#34;start_offset\u0026#34;: 5, \u0026#34;end_offset\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34;: 5 }, { \u0026#34;token\u0026#34;: \u0026#34;清晨\u0026#34;, \u0026#34;start_offset\u0026#34;: 6, \u0026#34;end_offset\u0026#34;: 8, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 6 }, { \u0026#34;token\u0026#34;: \u0026#34;开始\u0026#34;, \u0026#34;start_offset\u0026#34;: 8, \u0026#34;end_offset\u0026#34;: 10, \u0026#34;type\u0026#34;: \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34;: 7 } ] } 扩展/停用词典 找到 plugins/IK/config/IKAnalyzer.cfg.xml 文件，添加如下内容。 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE properties SYSTEM \u0026#34;http://java.sun.com/dtd/properties.dtd\u0026#34;\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;comment\u0026gt;IK Analyzer 扩展配置\u0026lt;/comment\u0026gt; \u0026lt;!--用户可以在这里配置自己的扩展字典 --\u0026gt; \u0026lt;entry key=\u0026#34;ext_dict\u0026#34;\u0026gt;ext.dic\u0026lt;/entry\u0026gt; \u0026lt;!--用户可以在这里配置自己的扩展停止词字典--\u0026gt; \u0026lt;entry key=\u0026#34;ext_stopwords\u0026#34;\u0026gt;stopword.dic\u0026lt;/entry\u0026gt; \u0026lt;!--用户可以在这里配置远程扩展字典 --\u0026gt; \u0026lt;!-- \u0026lt;entry key=\u0026#34;remote_ext_dict\u0026#34;\u0026gt;words_location\u0026lt;/entry\u0026gt; --\u0026gt; \u0026lt;!--用户可以在这里配置远程扩展停止词字典--\u0026gt; \u0026lt;!-- \u0026lt;entry key=\u0026#34;remote_ext_stopwords\u0026#34;\u0026gt;words_location\u0026lt;/entry\u0026gt; --\u0026gt; \u0026lt;/properties\u0026gt; 在 plugins/IK/config/ 目录下添加 ext.dic 和 stopword.dic 文件。重启ES。 一键部署 docker-compose.yml。\n启动命令：docker-compose -p es-node up -d。\n完整代码参看 github。https://github.com/helium-chain/ex-kibana-single-node\n","permalink":"https://heliu.site/posts/elasticsearch/install/","summary":"elasticsearch、kibana安装简介。","title":"安装"},{"content":" mapping是对索引库中文档的约束。 Mapping 属性 type 字段类型，常用的有 text、keyword、integer等。 index 字段是否建立倒排索引，默认为true。 false情况下不能被搜索，但支持集合分析。 index属性用于控制字段值是否应该被索引，即是否可以在搜索时使用这些值。这个属性通常与字段类型定义一起使用，特别是在创建或更新索引的映射（mapping）时。 作用： 索引：如果字段被设置为index: true（默认值），那么Elasticsearch会为该字段创建倒排索引，这使得你可以通过该字段进行搜索。 不索引：如果字段被设置为index: false，那么Elasticsearch不会为该字段创建倒排索引，因此你无法通过该字段进行搜索，但是该字段的值仍然会存储在 _source 中。 使用场景： 当你有一个字段，它的值不需要被搜索，但是你希望将其值存储在 _source 中以供后续使用，可以将index属性设置为false。 如果你希望加快索引的速度并减少索引的大小，可以选择性地索引某些字段。 与enabled属性不同，index属性可以用来控制字段是否可搜索，而enabled属性则可以完全禁用字段的索引和存储。 示例： PUT /my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;index\u0026#34;: true // 默认值，可省略 }, \u0026#34;field2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: false // 不可搜索，但存在于 _source 中 } } } } enable 字段是否建立倒排索引以及doc value，enabled属性是用来控制字段是否会被索引和搜索的。 可以为每个字段设置enabled属性。 作用： 索引：如果字段被设置为enabled: true（默认值），那么该字段的值会被索引，并且可以在搜索时使用。 搜索：如果字段被设置为enabled: false，那么该字段的值不会被索引，因此不能在搜索时使用，但是仍然可以在文档的源字段中看到。 使用场景： 当你有一个字段，它的数据量非常大，但你又不希望在搜索时使用它，可以将其enabled属性设置为false来节省索引空间。 在某些情况下，你可能希望只存储某些信息而不进行分析或搜索，这时候也可以将字段的enabled属性设置为false。 使用示例： PUT /my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;enabled\u0026#34;: true // 默认值，可省略 }, \u0026#34;field2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;enabled\u0026#34;: false // 既不可搜索也不存在于 _source 中 } } } } 与index区别： 索引与存储：index控制字段是否可搜索，但不影响字段是否存储在 _source 中。enabled控制字段是否被索引和存储。 影响：设置index: false，字段仍然存储在 _source 中，但不参与搜索。设置enabled: false，字段既不索引也不存储。 使用场景：如果你希望字段不参与搜索但仍然想保留其原始值，使用index: false。如果你不希望字段以任何形式出现在Elasticsearch中，使用enabled: false。 store 默认false，字段是否额外存储，如果需要查询获取的字段只是文档中的小数据，这些字段可以store，减少IO。而且这个存储是独于 _source 的存储的。 store属性用于控制字段值是否应该被独立存储，这意味着字段值可以被单独检索，而不需要从整个文档的 _source 字段中提取。 作用： 独立存储：如果字段被设置为store: true，那么该字段的值会被独立存储在Elasticsearch中，这意味着你可以通过单独的字段检索来获取它的值。 不独立存储：如果字段被设置为store: false（默认值），那么该字段的值不会独立存储，但它仍然会作为 _source 的一部分被存储。 使用场景： 当你经常需要从Elasticsearch中检索特定字段的值，而不需要检索整个文档时，将store属性设置为true可以提高检索效率。 如果文档非常大，而你只需要访问其中的几个字段，那么独立存储这些字段可以节省磁盘空间，因为你不需要存储整个 _source。 示例： PUT /my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;store\u0026#34;: true // 独立存储字段值 }, \u0026#34;field2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;store\u0026#34;: false // 默认值，不独立存储字段值 } } } } 注意事项： 设置store: true会增加Elasticsearch的存储需求，因为每个字段值都需要额外存储。 即使将store设置为true，如果index设置为false，该字段仍然不会被索引，因此无法用于搜索。 如果你不需要从 _source 中检索整个文档，而是只需要特定的几个字段，那么独立存储这些字段可以减少网络传输的数据量。 doc_values 默认true，优化字段排序聚合脚本访问，耗用磁盘空间。 fields 多字段特性。让一个字段拥有多个子字段类型，使得一个字段能够被多个不同的索引方式进行索引。 norms 默认为true，是否支持评分，如果字段只用来过滤和聚合分析，而不需要被评分，那么可以设置为false； type 为 text 时，默认为 true；而 type 为 keyword 时，默认为 false。 analyzer 指定索引和搜索时的分析器，如果同时指定 search_analyzer 则搜索时会优先使用 search_analyzer。 search_analyzer 指定搜索时的分析器，搜索时的优先级最高。 fielddata 默认false，针对text类型排序、聚合、脚本访问优化，尽量避免，操作昂贵。 index_options 用于设置倒排（索引）列表包含的信息，这些信息用于搜索（Search）和高亮显示： docs：只索引文档编号(Doc Number)； freqs：索引文档编号和词频率（term frequency）； positions：索引文档编号，词频率和词位置（序号）； offsets：索引文档编号，词频率，词偏移量（开始和结束位置）和词位置（序号）。 默认情况下，被分词的字符串（analyzed string）字段使用 positions，其他字段默认使用 docs。 此外，需要注意的是 index_option 是 elasticsearch 特有的设置属性；临近搜索和短语查询时，index_option 必须设置为 offsets，同时高亮也可使用 postings highlighter。记录内容越多，占用存储空间越大。 type 字符串类型 text 会做分词处理，如果一个字段要被全文搜索，应该使用text类型。 设置 text 类型后，字段内容会被分析，在生成倒排索引前，字符串会被分词器分成一个个词条。 text类型的字段不用于排序，且很少用于聚合(Terms Aggregation除外)。 keyword 不会做分词处理，只能通过精确值搜索到。 该类型适用于索引结构化的字段，通常用于过滤、排序、聚合。 注意：ES5以后，不推荐使用string类型。 数字类型 对于数字类型的字段，在满足需求情况下，尽量选择范围小的数据类型。 字段的长度越短，搜因和搜索的效率越高。 对于浮点数来说, 优先考虑使用 scaled_float 类型。 scaled_float 是通过缩放因子把浮点数变成 long 类型，比如价格只需要精确到分，price 字段的取值为 57.34，设置放大因子为 100，存储起来就是 5734。 所有的 API 都会把 price 的取值当作浮点数，事实上 Elasticsearch 底层存储的是整数类型，因为压缩整数比压缩浮点数更加节省存储空间 \u0026mdash;\u0026mdash;-类型\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;-取值范围\u0026mdash;\u0026mdash;- 说明 byte -128 ~ 127 无符号1字节 short -32768 ~ 32767 无符号2字节 integer -2^31 ~ 2^31-1 无符号4字节 long -2^63 ~ 2^63-1 无符号8字节 double 64位双精度IEE754浮点类型 双精度浮点8字节 float 32位单精度IEE754浮点类型 单精度浮点4字节 half_float 16位半精度IEE754浮点类型 2字节 scaled_float 缩放类型浮点数 8字节 日期类型 date 在 ES 中的日期可以是以下几种形式： 格式化日期的字符串，如 “2015-01-01” 或 “2015/01/01 12:10:30” 毫秒时间戳 秒级时间戳 需要注意的是，ES内部会把日期转换为 UTC（世界标准时间），并将其存储为毫秒时间戳，这样做的原因是和字符串相比，数值在存储和处理时更快。 布尔类型 boolean 如果一个字段是布尔类型，可接受的值为 true、false。 Elasticsearch 5.4 版本以前，可以接受被解释为 true 或 false 的字符串和数字，5.4 版本以后只接受 true、false、”true”、”false”。 二进制类型 binary binary 类型数据格式为base64 编码的字符串，默认「不额外存储，也不可搜索」。 范围类型 range integer_range -2^31 至 2^31-1 long_range -2^63 至 2^63-1 float_range 32-bit IEEE 754 double_range 64-bit IEEE 754 date_range 64 位整数，毫秒计时 数组类型 ES中没有专用的数组类型，默认情况下任何字段都可以包含0个或者多个值，但是一个数组中的值必须是同一种类型。 整型数组：[1,3] 嵌套数组：[1,[2,3]]，等价于 [1,2,3] 对象数组: [{\u0026ldquo;name\u0026rdquo;: \u0026ldquo;lili\u0026rdquo;, \u0026ldquo;age\u0026rdquo;: \u0026ldquo;18\u0026rdquo;}, {\u0026ldquo;name\u0026rdquo;: \u0026ldquo;liming\u0026rdquo;, \u0026ldquo;age\u0026rdquo;: \u0026ldquo;20\u0026rdquo;} ] 动态添加数据时，数组的第一个值的类型决定整个数组的类型。混合数组类型是不支持的，比如：[1，”abc”]。 数组可以包含 null 值，空数组[ ]会被当作 missing field 对待。在文档中使用 array 类型不需要提前做任何配置，默认支持 对象类型 对象类型很好理解，即JSON对象，需要注意的是，es中会对嵌套的JSON对象做扁平化处理。 例如如下数据: { \u0026#34;name\u0026#34;:\u0026#34;lili\u0026#34;, \u0026#34;friend\u0026#34;:[ \u0026#34;name\u0026#34;:\u0026#34;xiaohong\u0026#34; ] } // 存储的时候变成这样: { \u0026#34;name\u0026#34;:\u0026#34;lili\u0026#34;, \u0026#34;friend.name\u0026#34;:\u0026#34;xiaohong\u0026#34; } 嵌套类型 嵌套类型是一种特殊的对象类型，es本身会对对象类型字段做扁平化处理，那么当存储的对象类型为对象数组时，会出现关联关系失效的情况。 { \u0026#34;name\u0026#34;:\u0026#34;lili\u0026#34;, \u0026#34;friends\u0026#34;:[ { \u0026#34;name\u0026#34;:\u0026#34;xiaohong\u0026#34;, \u0026#34;age\u0026#34;: 18 }, { \u0026#34;name\u0026#34;:\u0026#34;xiaoming\u0026#34;, \u0026#34;age\u0026#34;: 20 } ] } // 处理后: { \u0026#34;name\u0026#34;:\u0026#34;lili\u0026#34;, \u0026#34;friends.name\u0026#34;:[\u0026#34;xiaohong\u0026#34;,\u0026#34;xiaoming\u0026#34;], \u0026#34;friend.age\u0026#34;:[18, 20] } IP类型 ip 类型的字段用于存储 IPv4 或者 IPv6 的地址。如”192.168.1.1”或”192.168.0.0/16”。 令牌计数类型 (token_count) token_count 用于统计text分词后的词条个数，本质上是一个整数型字段。举个例子，映射中指定 name 为 text 类型，增加name.length 字段用于统计分词后词项的长度，类型为 token_count，分词器为标准分词器，命令如下： { \u0026#34;mappings\u0026#34;: { \u0026#34;my_type\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;length\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;token_count\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34; } } } } } } } 索引库的CRUD 创建 基本语法： 请求方法：PUT 请求路径：/索引名称 请求参数：mapping 有这样一条文档，需要创建索引。 age：类型为 byte；参与搜索，因此需要index为true；无需分词器。 weight：类型为float；参与搜索，因此需要index为true；无需分词器。 isMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器。 info：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart。 email：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器。 score：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器。 name：类型为object，需要定义多个子属性 name.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器。 name.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器。 注意：所有的索引名都必须要小写。 { \u0026#34;age\u0026#34;: 21, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: false, \u0026#34;info\u0026#34;: \u0026#34;美好的一天从清晨开始\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;123456@qq.cn\u0026#34;, \u0026#34;score\u0026#34;: [99.1, 95.5, 98.9], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;三\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } 创建demo。 PUT /users { \u0026#34;aliases\u0026#34;: { \u0026#34;alias_users\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 1, \u0026#34;index.number_of_replicas\u0026#34;: 0, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;3s\u0026#34;, \u0026#34;index.max_result_window\u0026#34;: 1000 }, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;byte\u0026#34; }, \u0026#34;weight\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;isMarried\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, \u0026#34;info\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;score\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;firstName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;lastName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; } } } } } } 查询 基本语法： 请求方法：GET 请求路径：/索引名称 请求参数：无 GET /users 修改 基本语法：\n请求方法：PUT 请求路径：/索引名称/_mapping 请求参数：properties。 倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引库一旦创建，无法修改mapping。\n虽然无法修改mapping中已有的字段，但是却允许添加新的字段到mapping中，因为不会对倒排索引产生影响。\nPUT /users/_mapping { \u0026#34;properties\u0026#34;: { \u0026#34;score\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float\u0026#34; } } } 删除 基本语法： 请求方法：DELETE 请求路径：/索引名称 请求参数：无 DELETE /users ","permalink":"https://heliu.site/posts/elasticsearch/mapping/","summary":"索引的创建、修改、删除。","title":"Mappings"},{"content":" setting属性用于设置当前索引的分片数，副本数等信息,常用的主要有： index.number_of_shards：索引分片数。 index.number_of_replicas：索引副本数。 index.refresh_interval：refresh频率，默认1s。当数据对实时刷新要求不那么高时，可以适当调大改值。当值=-1时，代表不会进行refresh操作，但是请保证es的虚拟机内存足够大，不然会造成内存溢出 使用示例： 1 2 3 4 5 6 7 8 9 10 PUT class_1 { \u0026#34;settings\u0026#34;: { \u0026#34;index\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 3, \u0026#34;number_of_replicas\u0026#34;: 1, \u0026#34;refresh_interval\u0026#34;: \u0026#34;3s\u0026#34; } } } ES的settings分为静态设置和动态设置两种。 常用设置标记成🎈。 静态设置 只能在索引创建时设置，或者在已关闭的索引上设置。静态设置在创建索引时指定。 number_of_shards🎈 索引应具有的主分片数，默认值为1。ES支持的最大分片数默认为1024，可以通过修改index.max_number_of_shards属性修改。 该值用于指定分片数量，也就是当前索引创建几个主分片索引。number_of_shards值不推荐过大，推荐5~10。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 1 } } shard.check_on_startup 分片在打开之前是否检查该分片是否损坏。当检测到分片损坏时，将阻止打开。 可选值： false：不检测，默认值。 checksum：只检查物理结构。 true：检查物理结构和路基损坏，相对比较消耗CPU。 fix：类同false，7.0版本后将废弃。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.shard.check_on_startup\u0026#34;: false } } number_of_routing_shards routing_partition_size 路由分区数，如果设置了该参数，其路由算法为： (hash(_routing) + hash(_id) % index.routing_parttion_size ) % number_of_shards 如果没有设置，路由算法为：_routing默认值为_id。 hash(_routing) % number_of_shardings codec 数据存储的压缩算法，默认值LZ4，可选值best_compression，比LZ4可以获得更好的压缩比例(占用较小的磁盘空间，但是存储性能比LZ4低)。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.codec\u0026#34;: \u0026#34;LZ4\u0026#34; } } 动态设置 number_of_replicas🎈 每个主分片的副本数，默认为 1，该值必须大于等于0，创建索引后该值可以变更。 副本的数量值不宜过大。 1 2 3 4 5 6 7 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2 } } auto_expand_replicas 基于可用节点的数量自动分配副本数量,默认为 false（即禁用此功能）,可设置为：0-all。 1 2 3 4 5 6 7 8 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2, \u0026#34;index.auto_expand_replicas\u0026#34;: false } } refresh_interval🎈 执行刷新操作的频率，这使得索引的最近更改可以被搜索。默认为 1s。可以设置为 -1 以禁用刷新。 1 2 3 4 5 6 7 8 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;1s\u0026#34; } } max_result_window🎈 用于索引搜索的 from+size 的最大值。默认为 10000。 1 2 3 4 5 6 7 8 9 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;index.max_result_window\u0026#34;: 1000 } } max_inner_result_window 用于控制top aggregations，默认100。内部命中和顶部命中聚合占用堆内存，并且时间与from+size成正比，这限制了内存。 1 2 3 4 5 6 7 8 9 10 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;index.max_result_window\u0026#34;: 1000, \u0026#34;index.max_inner_result_window\u0026#34;: 100 } } max_rescore_window 在搜索此索引中 rescore 的 window_size 的最大值。 1 2 3 4 5 6 7 8 9 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;index.max_rescore_window\u0026#34;: 100 } } max_docvalue_fields_search 一次查询最多包含开启doc_values字段的个数，默认为100。 1 2 3 4 5 6 7 8 9 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;index.max_docvalue_fields_search\u0026#34;: 100 } } max_script_fields 查询中允许的最大script_fields数量。默认为32。 1 2 3 4 5 6 7 8 9 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 5, \u0026#34;index.number_of_replicas\u0026#34;: 2, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;index.max_script_fields\u0026#34;: 32 } } max_ngram_diff NGramTokenizer和NGramTokenFilter的min_gram和max_gram之间允许的最大差异。默认为1。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.max_ngram_diff\u0026#34;: 1 } } max_shingle_diff 对于ShingleTokenFilter, max_shingle_size和min_shingle_size之间允许的最大差异。默认为3。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.max_shingle_diff\u0026#34;: 3 } } blocks.read_only 索引数据、索引元数据是否只读，如果设置为true，则不能修改索引数据，也不能修改索引元数据。，false 为允许写入和元数据更改。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.blocks.read_only\u0026#34;: false } } blocks.read_only_allow_delete 与index.blocks.read_only基本类似，唯一的区别是允许删除动作。 1 2 3 4 5 6 7 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.blocks.read_only\u0026#34;: false, \u0026#34;index.blocks.read_only_allow_delete\u0026#34;: false } } blocks.read 设置为 true 可禁用对索引的读取操作。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.blocks.read\u0026#34;: false } } blocks.write 设设置为true以禁用对索引数据的写操作。（针对索引数据，而不是索引元数据） 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.blocks.write\u0026#34;: false } } blocks.metadata 设置为true，表示不允许对索引元数据进行读与写。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.blocks.metadata\u0026#34;: false } } max_refresh_listeners 索引的每个分片上当刷新索引时最大的可用监听器数量。这些侦听器用于实现refresh=wait_for。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.max_refresh_listeners\u0026#34;: 1 } } highlight.max_analyzed_offset 高亮显示的最大字符数。此设置仅在对没有偏移或词向量的索引的文本上适用。默认情况下，此设置在6.x中未设置，默认为-1。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.max_refresh_listeners\u0026#34;: -1 } } max_terms_count Term查询中可以使用的最大Term数。默认为65536。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.max_terms_count\u0026#34;: 65536 } } routing.allocation.enable 控制此索引的分片分配，可选值： all：默认，允许分片所有的分片 primaries：只允许分配主分片 new_primaries：仅允许分配新创建的主分片 none：不允许分配 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.routing.allocation.enable\u0026#34;: \u0026#34;all\u0026#34; } } routing.rebalance.enable 为此索引启用分片重新平衡，可选值： all：默认，允许分片重新平衡 primaries：只允许主分片重新平衡 replicas：只允许副本分片重新平衡 none：不允许分片重新平衡 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.routing.rebalance.enable\u0026#34;: \u0026#34;all\u0026#34; } } gc_deletes 允许已删除文档的版本号，扔可用于进一步版本化操作的时间长度。默认60s。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.gc_deletes\u0026#34;: \u0026#34;60s\u0026#34; } } max_regex_length Regexp Query中可以使用的正则表达式的最大长度，默认为1000。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.max_regex_length\u0026#34;: 1000 } } mapping.coerce true：默认值，强制类型转换，把json中的值转为ES中字段的数据类型，譬如，把字符串\u0026quot;5\u0026quot;转为integer的5。 false：当json的值与ES字段类型不匹配将会拒绝。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;mapping.coerce\u0026#34;: true } } Merging max_thread_count 当个分片节点合并的最大线程数，默认值**Math.max(1, Math.min(4, Runtime.getRuntime().availableProcessors() / 2))**如果是非SSD盘，建议设置为1。。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.merge.scheduler.max_thread_count\u0026#34;: 1 } } max_merged_segment 指定单个segment的最大容量，默认值5GB，可以考虑适当降低此值。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.merge.policy.max_merged_segment\u0026#34;: \u0026#34;5GB\u0026#34; } } segments_per_tier 该属性指定了每层分段的数量，取值越小则segment越少，因此需要merge的操作更多，可以考虑适当增加此值。默认为10，其应该大于等于index.merge.poliycy.max_merge_at_once。 1 2 3 4 5 6 PUT /test { \u0026#34;settings\u0026#34;: { \u0026#34;index.merge.policy.segments_per_tier\u0026#34;: 10 } } Show Log Search Show Log ES提供在查询阶段(Query)和数据获取阶段(Fetch)设置阈值，超过改阈值则记录日志。 查询阶段支持参数，以下值定义查询阶段(Query)阈值，分别表示执行超过10s，打印警告日志。超过5s打印info日志。 1 2 3 4 index.search.slowlog.threshold.query.warn: 10s index.search.slowlog.threshold.query.info: 5s index.search.slowlog.threshold.query.debug: 2s index.search.slowlog.threshold.query.trace: 500ms 数据获取阶段支持参数，以下定义数据获取阶段(Fetch)阈值，分别表示执行超过1s，打印警告日志。超过800ms打印info日志。 1 2 3 4 index.search.slowlog.threshold.fetch.warn: 1s index.search.slowlog.threshold.fetch.info: 800ms index.search.slowlog.threshold.fetch.debug: 500ms index.search.slowlog.threshold.fetch.trace: 200ms 日志输出级别，定义日志输出级别为info，不输出debug、trace级别的日志。注意：上述日志级别为分片日志。 1 index.search.slowlog.level: info log4j配置。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 appender.index_search_slowlog_rolling.type = RollingFile appender.index_search_slowlog_rolling.name = index_search_slowlog_rolling appender.index_search_slowlog_rolling.fileName = ${sys:es.logs}_index_search_slowlog.log appender.index_search_slowlog_rolling.layout.type = PatternLayout appender.index_search_slowlog_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] [%node_name]%marker %.10000m%n appender.index_search_slowlog_rolling.filePattern = ${sys:es.logs}_index_search_slowlog-%d{yyyy-MM-dd}.log #文件切割方案，属于log4j的语法 appender.index_search_slowlog_rolling.policies.type = Policies #基于时间切割，log4j还支持按大小切割，其类为SizeBasedTriggeringPolicy。 appender.index_search_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy #1小时切割成一个文件 appender.index_search_slowlog_rolling.policies.time.interval = 1 #是否修正时间范围, 如果设置为true，则从0时开始计数 appender.index_search_slowlog_rolling.policies.time.modulate = true logger.index_search_slowlog_rolling.name = index.search.slowlog logger.index_search_slowlog_rolling.level = trace logger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rolling logger.index_search_slowlog_rolling.additivity = false Index Show Log 索引慢日志配置。 index.indexing.slowlog.source参数用来记录文档 _source字段字符的个数，默认1000，表示只记录_source的前1000个字符，可以设置为true，表示输出_source字段全部内容，设置为false，表示不记录_source字段的内容。 默认情况下，会对_source字段的输出进行格式化，通常使用一行输出，如果想阻止格式化，可以通过index.indexing.slowlog.reformat设置为false来避免。 1 2 3 4 5 6 index.indexing.slowlog.threshold.index.warn: 10s index.indexing.slowlog.threshold.index.info: 5s index.indexing.slowlog.threshold.index.debug: 2s index.indexing.slowlog.threshold.index.trace: 500ms index.indexing.slowlog.level: info index.indexing.slowlog.source: 1000 在logg4j配置文件中定义日志的输出。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 appender.index_indexing_slowlog_rolling.type = RollingFile appender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rolling appender.index_indexing_slowlog_rolling.fileName = ${sys:es.logs}_index_indexing_slowlog.log appender.index_indexing_slowlog_rolling.layout.type = PatternLayout appender.index_indexing_slowlog_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] [%node_name]%marker %.-10000m%n appender.index_indexing_slowlog_rolling.filePattern = ${sys:es.logs}_index_indexing_slowlog-%d{yyyy-MM-dd}.log appender.index_indexing_slowlog_rolling.policies.type = Policies appender.index_indexing_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy appender.index_indexing_slowlog_rolling.policies.time.interval = 1 appender.index_indexing_slowlog_rolling.policies.time.modulate = true logger.index_indexing_slowlog.name = index.indexing.slowlog.index logger.index_indexing_slowlog.level = trace logger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rolling logger.index_indexing_slowlog.additivity = false Store index.store.type 表示存储类型，该值为静态参数，在索引创建时指定，无法更改。可选值： fs：默认文件系统实现，根据当前操作系统选择最佳存储方式 simplefs：简单的FS类型，使用随机访问文件实现文件系统存储(映射到Lucene SimpleFsDirectory)。并发性能很差(多线程会出现瓶颈)。当需要索引持久性时，通常最好使用niofs。 niofs：基于NIO实现的文件系统，该类型使用NIO在文件系统上存储碎片索引(映射到Lucene NIOFSDirectory)。它允许多个线程同时从同一个文件中读取数据。 mmapfs：基于文件内存映射机制实现的文件系统实现，该方法将文件映射到内存(MMap)来存储文件系统上的碎片索引(映射到Lucene MMapDirectory)。内存映射使用进程中与被映射文件大小相同的部分虚拟内存地址空间。可通过node.store.allow_mmapfs属性来禁用基于内存映射机制，如果节点所在的操作系统没有大量虚拟内存，则可以使用该属性明确禁止使用该文件实现。 index.store.preload 预加载数据到文件系统缓存，如果ES主机重启，则文件系统缓存将清空，此时搜索会比较慢，可以使用index.store.preload设置，通过指定文件扩展名，显示的告诉操作系统应该将哪些文件加载到内存中。 例如，配置到elasticsearch.yml文件中： 1 index.store.preload: [\u0026#34;nvd\u0026#34;,\u0026#34;dvd\u0026#34;] 或者在创建索引的时候设置： 1 2 3 4 5 { \u0026#34;settings\u0026#34;:{ \u0026#34;index.store.preload\u0026#34;:[\u0026#34;nvd\u0026#34;,\u0026#34;dvd\u0026#34;] } } Translog 由于Lucene提交的开销很大，不能每个变更就提交一次(刷写磁盘)，所以每个分片复制都有一个事务日志，称为translog。所有索引和删除操作都是在被内部Lucene索引处理只会写入translog的。在发生崩溃的情况下，当索引恢复的时候，可以通过回放translog中的数据进行恢复。 index.translog.durability translog刷盘方式，可选值：request、async。 request：即每请求一次刷盘，也就是客户端发起一个增删改操作时，会在主分片和副本分片全部刷盘成功后，才会返回成功，是ES的默认模式。 async：异步刷盘模式，此模式频率由index.translog.sync_interval设置，其默认值为5s，该模式会存在数据丢失的可能。 index.translog.sync_interval 如果index.translog.durability设置为async，用该值来设置刷盘的频率，默认为5s。 index.translog.flush_threshold_size ES强制刷新的另外一个维度，如果translog的大小达到该值，则强制将为刷盘的数据强制刷新到Lucene中，默认512M。 index.translog.retention.size 保存跨日志文件的总大小。也就是translog日志文件flush后，并不马上删除，而是保留一段时间，但最新的translog文件已经存储的内容与待删除的文件的间隔不超过改参数设置的值，默认为512M。 index.translog.retention.age 保存translog文件的最大持续时间，默认12h。 参考 https://blog.csdn.net/dwjf321/article/details/103871981 ","permalink":"https://heliu.site/posts/elasticsearch/settings/","summary":"设置当前索引的分片数，副本数等信息。","title":"Settings"},{"content":" 索引别名是用于引用一个或多个现有索引的辅助名称。大多数ES API接受索引别名来代替索引。 别名是一组索引的辅助名称，一个别名可以指向多个索引，一个索引可以有多个别名。 使用别别名，在重建索引数据时，无需停机或更改程序代码。 别名类似Nginx反向代理的感觉，当访问别名时，相当于访问的实际索引的代理。 使用场景 滚动索引 存储大量日志数据的场景，或者 存储几亿订单数据的场景。由于ES索引的单个分片建议大小为30G左右，同时ES的分片数量也不要太大，建议1~5之间。所以，势必要建立多个索引去存储大量数据。比如 按日、按月、按季度、按年 存储等。 此时如果要从这些索引里去查询数据，在不使用Alias的情况下，肯定要在业务代码里写上一堆复杂的逻辑，然后是兼容各种场景和异常，即使感觉做的比较完善了，可能上线后还有未知的问题。 使用Alias后，业务代码无需改动，只需要给相关索引建立同样的别名，然后利用Alias查询，ES会自动将相关的索引数据都查出来。 无缝切换 正在使用的索引A存在部分异常数据，此时可以重新构建索引B，然后将Alias指向索引B，这样可以无缝切换索引，并且业务层无感知。 重建索引 在ES中无法对索引的现有字段做改动，一般的做法是创建新的索引，然后把文档从旧的索引复制到新的索引里。针对这种情况，别名的使用优势就体现出来了，索引别名可以实现旧索引到新索引的平滑迁移。 带过滤条件索引 针对某个索引，有些场景需要固化视图时，就可以设置别名来实现，这样调用方使用起来很方便，无需加入重复的查询条件。比如有个 订单索引，多处需要查询 30天内已支付订单，此时可以利用Alias构建出这样的视图。 使用别名 创建别名 创建索引时指定别名，order索引指定alias_1,alias_2别名。 1 2 3 4 5 6 7 PUT /order { \u0026#34;aliases\u0026#34;: { \u0026#34;alias_1\u0026#34;: {}, \u0026#34;alias_2\u0026#34;: {} } } 创建索引后指定别名。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 POST _aliases { \u0026#34;actions\u0026#34;: [ { \u0026#34;add\u0026#34;: { // order_202201 别名 order_alias \u0026#34;index\u0026#34;: \u0026#34;order_202201\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;order_alias\u0026#34; } }, { \u0026#34;add\u0026#34;: { // order_202202 别名 order_alias \u0026#34;index\u0026#34;: \u0026#34;order_202202\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;order_alias\u0026#34; } } ] } 当索引别名指向多个索引时，进行写操作，其中的一个索引必须被指定为写索引，并且只能指定一个，否则则无法写入。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 POST /_aliases { \u0026#34;actions\u0026#34; : [ { \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;alias1\u0026#34;, \u0026#34;is_write_index\u0026#34; : true } }, { \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;test2\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;alias1\u0026#34; } } ] } 移除别名 1 2 3 4 5 6 7 8 9 10 11 12 POST _aliases { \u0026#34;actions\u0026#34;: [ { // 移除 \u0026#34;remove\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;order_202201\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;order_alias\u0026#34; } } ] } 切换别名 把product索引别名重命名为product_new。(原子操作) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 POST _aliases { \u0026#34;actions\u0026#34;: [ { \u0026#34;remove\u0026#34;: { // 移除 \u0026#34;index\u0026#34;: \u0026#34;product\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;product_old\u0026#34; } }, { \u0026#34;add\u0026#34;: { // 添加 \u0026#34;index\u0026#34;: \u0026#34;product\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;product_new\u0026#34; } } ] } 切换写索引属性，(原子操作)。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 POST /_aliases { \u0026#34;actions\u0026#34; : [ { \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;alias1\u0026#34;, \u0026#34;is_write_index\u0026#34; : false } }, { \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;test2\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;alias1\u0026#34;, \u0026#34;is_write_index\u0026#34; : true } } ] } 过滤视图 创建索引后添加别名并指定过滤条件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 POST /_aliases { \u0026#34;actions\u0026#34; : [ { // order_202303索引创建order_alias别名 // 当前使用order_alias别名查找数据时，默认带上指定的过滤条件 \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;order_202303\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;order_alias\u0026#34;, \u0026#34;filter\u0026#34;: {\u0026#34;term\u0026#34; : {\u0026#34;pay_state\u0026#34;: 1}} } } ] } 查询索引别名 1 2 3 4 5 6 7 8 9 10 // 查询logs_20162801索引的所有别名 GET /logs_20162801/_alias/* // 查询别名为2016的所有索引 GET /_alias/2016 // 查询别名为20开头的所有索引 GET /_alias/20* HEAD /_alias/2016 HEAD /_alias/20* HEAD /logs_20162801/_alias/* 创建索引时指定别名并设置过滤条件。 1 2 3 4 5 6 7 8 9 10 11 PUT /test { \u0026#34;aliases\u0026#34;: { \u0026#34;alias_1\u0026#34;: {}, \u0026#34;alias_2\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;user.id\u0026#34;: \u0026#34;kim\u0026#34; } } } } 区别对比 不使用alias方案 该方案无法实现无缝切换，因为在删除旧的index-A之后，新的index-A还没创建，而且数据还没拷贝完毕。 基于这种方案要想无缝切换，那只能是先创建index-B，通过reindex将index-A的数据拷贝到index-B，然后业务代码改成访问index-B。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 1) 将index_A拷贝到备份index_A_bak POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_A\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_A_bak\u0026#34; } } // 2) 删除index_A DELETE index_A // 3) 创建新的 index_A，此处省去创建新的index_A的过程 // 4) 将备份index_A_bak拷贝到新的index_A POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_A_bak\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;新的index_A\u0026#34; } } // 5) 删除备份index_A_bak DELETE index_A_bak 使用Alias的方案 该方案无需改动代码即可实现无缝切换。后续切换索引只需要操作3、4、5步即可。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // 1) 给index_A添加别名 POST /_aliases { \u0026#34;actions\u0026#34;: [ { \u0026#34;add\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_A\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;index_alias\u0026#34; } } ] } // 2) 业务层的代码改成使用别名操作索引 // 3) 将index_A数据拷贝到index_B POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_A\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_B\u0026#34; } } // 4) 别名切换 POST /_aliases { \u0026#34;actions\u0026#34;: [ { \u0026#34;add\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_A\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;index_alias\u0026#34; }, \u0026#34;remove\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;index_B\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;index_alias\u0026#34; } } ] } // 5) 删除索引index_A DELETE index_A 参考 https://mp.weixin.qq.com/s/U6YAN_yW809NvF1JDntBHw ","permalink":"https://heliu.site/posts/elasticsearch/aliases/","summary":"ElasticSearch 索引别名设置。","title":"Aliases"},{"content":" routing参数是一个可选参数，默认使用文档的_id值，可以用在INDEX, UPDATE,GET, SEARCH, DELETE等各种操作中。 在写入(包括更新)时，用于计算文档所属分片，在查询(GET请求或指定了routing的查询)中用于限制查询范围，提高查询速度。 计算方法 ES通过这样一个公式保证使用相同routing的文档被分配到同一个分片上，当然在默认情况下使用_id作为routing起到将文档均匀分布到多个分片上防止数据倾斜的作用。 shardId = hash(_routing) % num_primary_shards 使用了routing参数可以让routing值相同的文档分配到同一个分片上，从而减少查询时需要查询的shard数，提高查询效率。但是使用该参数容易导致数据倾斜。 为此，ES还提供了一个index.routing_partition_size参数（仅当使用routing参数时可用），用于将routing相同的文档映射到集群分片的一个子集上，这样一方面可以减少查询的分片数，另一方面又可以在一定程度上防止数据倾斜。 shard_num = (hash(_routing) + hash(_id) % routing_partition_size) % num_primary_shards 设置routing为必选 使用routing写入的文档，在进行GET，UPDATE或DELETE操作时如果不指定routing参数会出现异常。 为此ES提供了一个索引mapping级别的设置，_routing.required，来强制用户在INDEX，GET，DELETE，UPDATA一个文档时必须使用routing参数。 当然查询时不受该参数的限制的。该参数的设置方式如下： PUT my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;_doc\u0026#34;: { \u0026#34;_routing\u0026#34;: { \u0026#34;required\u0026#34;: true } } } } 结合别名 routing和别名结合，可以对使用者屏蔽读写时使用routing的细节，降低误操作的风险，提高操作的效率。 POST /_aliases { \u0026#34;actions\u0026#34; : [ { \u0026#34;add\u0026#34; : { \u0026#34;index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;alias\u0026#34; : \u0026#34;alias1\u0026#34;, \u0026#34;routing\u0026#34; : \u0026#34;1\u0026#34; } } ] } ","permalink":"https://heliu.site/posts/elasticsearch/routing/","summary":"ElasticSearch 路由规则。","title":"Routing"},{"content":"创建 基本语法： 请求方法：PUT 请求路径：/索引名称 请求参数：mapping 有这样一条文档，需要创建索引。 age：类型为 byte；参与搜索，因此需要index为true；无需分词器。 weight：类型为float；参与搜索，因此需要index为true；无需分词器。 isMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器。 info：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart。 email：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器。 score：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器。 name：类型为object，需要定义多个子属性 name.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器。 name.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器。 注意：所有的索引名都必须要小写。 1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;age\u0026#34;: 21, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: false, \u0026#34;info\u0026#34;: \u0026#34;美好的一天从清晨开始\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;123456@qq.cn\u0026#34;, \u0026#34;score\u0026#34;: [99.1, 95.5, 98.9], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;三\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } 创建demo。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 PUT /users { \u0026#34;aliases\u0026#34;: { \u0026#34;alias_users\u0026#34;: {} }, \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_shards\u0026#34;: 1, \u0026#34;index.number_of_replicas\u0026#34;: 0, \u0026#34;index.refresh_interval\u0026#34;: \u0026#34;3s\u0026#34;, \u0026#34;index.max_result_window\u0026#34;: 1000 }, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;byte\u0026#34; }, \u0026#34;weight\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;isMarried\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, \u0026#34;info\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;score\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;firstName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; }, \u0026#34;lastName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;false\u0026#34; } } } } } } 查询 基本语法： 请求方法：GET 请求路径：/索引名称 请求参数：无 GET /users 修改 基本语法：\n请求方法：PUT 请求路径：/索引名称/_mapping 请求参数：properties。 倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引库一旦创建，无法修改mapping。\n虽然无法修改mapping中已有的字段，但是却允许添加新的字段到mapping中，因为不会对倒排索引产生影响。\nPUT /users/_mapping { \u0026#34;properties\u0026#34;: { \u0026#34;score\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;float\u0026#34; } } } 删除 基本语法： 请求方法：DELETE 请求路径：/索引名称 请求参数：无 DELETE /users ","permalink":"https://heliu.site/posts/elasticsearch/indexes/","summary":"索引的增删改查。","title":"索引CURD"},{"content":"新增 1 2 3 4 5 6 7 8 9 10 11 12 POST /alias_users/_doc { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50.0, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [92.1, 93.2], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } // 响应结果 { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 0, \u0026#34;_primary_term\u0026#34;: 1 } 1 2 3 4 5 6 7 8 9 10 11 12 13 POST /alias_users/_doc/2 { \u0026#34;age\u0026#34;: 17, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: true, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [96.1, 91.2], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } // 响应结果 { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;result\u0026#34;: \u0026#34;created\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 1, \u0026#34;_primary_term\u0026#34;: 1 } 查看 1 GET /alias_users/_doc/orl0ZZEBrAuQs0dUWDfg // 响应结果 { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;_seq_no\u0026#34;: 0, \u0026#34;_primary_term\u0026#34;: 1, \u0026#34;found\u0026#34;: true, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 92.1, 93.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } } 1 GET /alias_users/_doc/2 // 响应结果 { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;_seq_no\u0026#34;: 1, \u0026#34;_primary_term\u0026#34;: 1, \u0026#34;found\u0026#34;: true, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 17, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: true, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 96.1, 91.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } 删除 DELETE /alias_users/_doc/1 修改 修改有两种方式：\n全量修改：直接覆盖原来的文档。 增量修改：修改文档中的部分字段。 全量修改 全量修改是覆盖原来的文档，其本质是： 根据指定的id删除文档。 新增一个相同id的文档。 注意：如果根据id删除时，id不存在，第二步的新增也会执行，也就从修改变成了新增操作了。 1 2 3 4 5 6 7 8 9 10 11 12 PUT /alias_users/_doc/1 { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 50.0, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [92.1, 93.2], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } 增量修改 增量修改是只修改指定id匹配的文档中的部分字段。 1 2 3 4 5 6 POST /alias_users/_update/2 { \u0026#34;doc\u0026#34;: { \u0026#34;age\u0026#34;: 20 } } // 响应结果 { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_version\u0026#34;: 2, \u0026#34;result\u0026#34;: \u0026#34;updated\u0026#34;, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;_seq_no\u0026#34;: 2, \u0026#34;_primary_term\u0026#34;: 1 } ","permalink":"https://heliu.site/posts/elasticsearch/document/","summary":"文档增删改查。","title":"文档CURD"},{"content":"查询分类 查询所有 match_all 查询出所有数据，一般测试用。 1 2 3 4 5 6 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } 示例： 1 2 3 4 5 6 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } { \u0026#34;took\u0026#34;: 5, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 92.1, 93.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } }, { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: true, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 96.1, 91.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } ] } } 全文检索 利用分词器对用户输入内容分词，然后去倒排索引库中匹配。\nmatch match查询：单字段查询，进行分词匹配查询。 语法说明： 1 2 3 4 5 6 7 8 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;FIELD\u0026#34;: \u0026#34;TEXT\u0026#34; } } } 示例： 1 2 3 4 5 6 7 8 9 10 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { // ik_max_word 分词 // 张、薛、高三、三、高 \u0026#34;info\u0026#34;: \u0026#34;张薛高三薛高\u0026#34; } } } { \u0026#34;took\u0026#34;: 20, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1.2401118, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_score\u0026#34;: 1.2401118, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 92.1, 93.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } }, { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1.2401118, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: true, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 96.1, 91.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } ] } } multi_match multi_match查询：多字段查询，任意一个字段符合条件就算符合查询条件。 语法说明： 1 2 3 4 5 6 7 8 9 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;TEXT\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;FIELD1\u0026#34;, \u0026#34; FIELD12\u0026#34;] } } } 示例：multi_match 要求查询查询字段类型一致。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { // 报错 failed to create query: For input string: \u0026#34;张薛20岁\u0026#34; // ik_max_word 分词 // 张、薛、20、岁 \u0026#34;query\u0026#34;: \u0026#34;张薛20岁\u0026#34;, // 您遇到的错误是因为multi_match查询试图直接将整个字符串 // “张薛20岁” 作为数值来处理，因为它匹配到了数值字段 “age”。 \u0026#34;fields\u0026#34;: [\u0026#34;age\u0026#34;, \u0026#34;info\u0026#34;] } } } 使用不同的查询类型：如果您想在 “age” 字段中搜索数字，并且在其他字段中搜索文本，您应该使用不同的查询类型，比如 bool 查询结合 term 和 match 查询。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ // AND { \u0026#34;match\u0026#34;: { \u0026#34;info\u0026#34;: \u0026#34;张薛20岁\u0026#34; } } ], \u0026#34;should\u0026#34;: [ // OR { \u0026#34;term\u0026#34;: { \u0026#34;age\u0026#34;: 20 } } ] } } } 精确查询 根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。所以不会对搜索条件分词。 注意：大写字母匹配不到，使用小写字母。 term 因为精确查询的字段搜是不分词的字段，因此查询的条件也必须是不分词的词条。 查询时，用户输入的内容跟自动值完全匹配时才认为符合条件。 如果用户输入的内容过多，反而搜索不到数据。 语法说明： 1 2 3 4 5 6 7 8 9 10 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;FIELD\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;Value\u0026#34; } } } } 查询示例： 1 2 3 4 5 6 7 8 9 10 11 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { // \u0026#34;age\u0026#34;: 20 \u0026#34;age\u0026#34;: { // age = 20 \u0026#34;value\u0026#34;: 20 } } } } { \u0026#34;took\u0026#34;: 60, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 1, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: true, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 96.1, 91.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } ] } } terms terms 查询是term的扩展，可以支持多个vlaue匹配，只需要一个匹配就可以了。 1 2 3 4 5 6 7 8 9 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;terms\u0026#34;: { // age IN (18,20,17) \u0026#34;age\u0026#34;: [18,20,17] } } } { \u0026#34;took\u0026#34;: 1, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 92.1, 93.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } }, { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: true, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 96.1, 91.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } ] } } range 范围查询，一般应用在对数值类型做范围过滤的时候。比如做价格范围过滤。 语法说明：支持参数 gte：大于等于。 gt：大于。 lte：小于等于。 lt：等于。 from：从哪里开始。 to：到哪里结束。 include_lower：是否包含范围的左边界，默认是true。 include_upper：是否包含范围的右边界，默认是true。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;FIELD\u0026#34;: { // gte -\u0026gt; \u0026gt;= // gt -\u0026gt; \u0026gt; \u0026#34;gte\u0026#34;: 10, // lte -\u0026gt; \u0026lt;= // lt -\u0026gt; \u0026lt; \u0026#34;lte\u0026#34;: 20 } } } } 查询示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { // age \u0026gt; 10 \u0026#34;gt\u0026#34;: 10, // age \u0026lt;= 20 \u0026#34;lte\u0026#34;: 20 } } } } { \u0026#34;took\u0026#34;: 16, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 92.1, 93.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } }, { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;isMarried\u0026#34;: true, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 96.1, 91.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } ] } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { // 20 \u0026gt; age \u0026gt;= 18 \u0026#34;age\u0026#34;: { \u0026#34;from\u0026#34;: 18, \u0026#34;to\u0026#34;: 20, \u0026#34;include_lower\u0026#34;: true, \u0026#34;include_upper\u0026#34;: false } } } } { \u0026#34;took\u0026#34;: 9, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 1, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangxue@163.com\u0026#34;, \u0026#34;score\u0026#34;: [ 92.1, 93.2 ], \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } } ] } } 1 2 3 4 5 6 7 8 9 10 11 12 13 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;birthday\u0026#34;: { \u0026#34;from\u0026#34;: \u0026#34;1990-10-10\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;2000-05-01\u0026#34;, \u0026#34;include_lower\u0026#34;: true, \u0026#34;include_upper\u0026#34;: false } } } } 通配符 wildcard 允许使用通配符 * 和 ? 来查询。 * 代表0个或多个字符。 ? 代表任意一个字符。 地理坐标 矩形范围 矩形范围查询，也就是geo_bounding_box查询，查询坐标落在某个矩形范围的所有文档。 查询时，需要指定矩形的左上、右下两个点的坐标，然后画出一个矩形，落在该矩形内的都是符合条件的点。 语法说明： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // geo_bounding_box查询 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;geo_bounding_box\u0026#34;: { \u0026#34;FIELD\u0026#34;: { \u0026#34;top_left\u0026#34;: { // 左上点 \u0026#34;lat\u0026#34;: 31.1, \u0026#34;lon\u0026#34;: 121.5 }, \u0026#34;bottom_right\u0026#34;: { // 右下点 \u0026#34;lat\u0026#34;: 30.9, \u0026#34;lon\u0026#34;: 121.7 } } } } } 附近查询 附近查询，也叫做距离查询（geo_distance）：查询到指定中心点小于某个距离值的所有文档。 换句话来说，在地图上找一个点作为圆心，以指定距离为半径，画一个圆，落在圆内的坐标都算符合条件。 语法说明： 1 2 3 4 5 6 7 8 9 10 // geo_distance 查询 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;geo_distance\u0026#34;: { \u0026#34;distance\u0026#34;: \u0026#34;15km\u0026#34;, // 半径 \u0026#34;FIELD\u0026#34;: \u0026#34;31.21,121.5\u0026#34; // 圆心 } } } 复合查询 复合查询可以将其它简单查询组合起来，实现更复杂的搜索逻辑。常见的有两种： fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名。 bool query：布尔查询，利用逻辑关系组合多个其它的查询，实现复杂搜索。 相关度算分 当我们利用match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。 在elasticsearch中，早期使用的打分算法是TF-IDF算法，在后来的5.1版本升级中，elasticsearch将算法改进为BM25算法。 TF-IDF算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而BM25则会让单个词条的算分有一个上限，曲线更加平滑。 算分函数 根据相关度打分是比较合理的需求，但合理的不一定是产品经理需要的。 以百度为例，你搜索的结果中，并不是相关度越高排名越靠前，而是谁掏的钱多排名就越靠前。 要想认为控制相关性算分，就需要利用elasticsearch中的function score 查询了。 语法说明： function score 查询中包含四部分内容： 原始查询条件：query部分，基于这个条件搜索文档，并且基于BM25算法给文档打分，原始算分（query score)。 过滤条件：filter部分，符合该条件的文档才会重新算分。 算分函数：符合filter条件的文档要根据这个函数做运算，得到的函数算分（function score），有四种函数： weight：函数结果是常量。 field_value_factor：以文档中的某个字段值作为函数结果。 random_score：以随机数作为函数结果。 script_score：自定义算分函数算法。 运算模式：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括： multiply：相乘。 replace：用function score替换query score。 其它，例如：sum、avg、max、min。 function score的运行流程如下： 1）根据原始条件查询搜索文档，并且计算相关性算分，称为原始算分（query score） 2）根据过滤条件，过滤文档 3）符合过滤条件的文档，基于算分函数运算，得到函数算分（function score） 4）将原始算分（query score）和函数算分（function score）基于运算模式做运算，得到最终结果，作为相关性算分。 因此，其中的关键点是： 过滤条件：决定哪些文档的算分被修改 算分函数：决定函数算分的算法 运算模式：决定最终算分结果 示例： 需求：给“如家”这个品牌的酒店排名靠前一些 翻译一下这个需求，转换为之前说的四个要点： 原始条件：不确定，可以任意变化 过滤条件：brand = \u0026ldquo;如家\u0026rdquo; 算分函数：可以简单粗暴，直接给固定的算分结果，weight 运算模式：比如求和 最终的DSL语句如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 GET /hotel/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { .... }, // 原始查询，可以是任意条件 \u0026#34;functions\u0026#34;: [ // 算分函数 { \u0026#34;filter\u0026#34;: { // 满足的条件，品牌必须是如家 \u0026#34;term\u0026#34;: { \u0026#34;brand\u0026#34;: \u0026#34;如家\u0026#34; } }, \u0026#34;weight\u0026#34;: 2 // 算分权重为2 } ], \u0026#34;boost_mode\u0026#34;: \u0026#34;sum\u0026#34; // 加权模式，求和 } } } 布尔查询 布尔查询是一个或多个查询子句的组合，每一个子句就是一个子查询。子查询的组合方式有： must：必须匹配每个子查询，类似“与” should：选择性匹配子查询，类似“或” must_not：必须不匹配，不参与算分，类似“非” filter：必须匹配，不参与算分 语法示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 GET /index1/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ // 必选，精确匹配 city {\u0026#34;term\u0026#34;: {\u0026#34;city\u0026#34;: \u0026#34;上海\u0026#34; }} ], \u0026#34;should\u0026#34;: [ {\u0026#34;term\u0026#34;: {\u0026#34;brand\u0026#34;: \u0026#34;皇冠假日\u0026#34; }}, {\u0026#34;term\u0026#34;: {\u0026#34;brand\u0026#34;: \u0026#34;华美达\u0026#34; }} ], \u0026#34;must_not\u0026#34;: [ // 必须不匹配 { \u0026#34;range\u0026#34;: { \u0026#34;price\u0026#34;: { \u0026#34;lte\u0026#34;: 500 } }} ], \u0026#34;filter\u0026#34;: [ { \u0026#34;range\u0026#34;: {\u0026#34;score\u0026#34;: { \u0026#34;gte\u0026#34;: 45 } }} ] } } } 搜索示例： 每一个不同的字段，其查询的条件、方式都不一样，必须是多个不同的查询，而要组合这些查询，就必须用bool查询了。 需要注意的是，搜索时，参与打分的字段越多，查询的性能也越差。因此这种多条件查询时，建议这样做： 搜索框的关键字搜索，是全文检索查询，使用must查询，参与算分。 其它过滤条件，采用filter查询，不参与算分。 搜索名字包含“如家”，价格不高于400，在坐标31.21,121.5周围10km范围内的酒店。 名称搜索，属于全文检索查询，应该参与算分，放到must中。 价格不高于400，用range查询，属于过滤条件，不参与算分，放到must_not中。 周围10km范围内，用geo_distance查询，属于过滤条件，不参与算分，放到filter中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 GET /index1/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: { \u0026#34;match\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;如家\u0026#34;} }, \u0026#34;must_not\u0026#34;: { \u0026#34;range\u0026#34;: {\u0026#34;price\u0026#34;: {\u0026#34;gt\u0026#34;: 400}} }, \u0026#34;filter\u0026#34;: { \u0026#34;geo_distance\u0026#34;: { \u0026#34;distance\u0026#34;: \u0026#34;10km\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;lat\u0026#34;: 31.11, \u0026#34;lon\u0026#34;: 120.21 } } } } } } 搜索结果 排序 elasticsearch默认是根据相关度算分（_score）来排序，但是也支持自定义方式对搜索结果排序。 可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。desc降序，asc升序。 普通字段 keyword、数值、日期类型排序的语法基本一致。 语法： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;sort\u0026#34;: [ { \u0026#34;FIELD\u0026#34;: \u0026#34;desc\u0026#34; // 排序字段、排序方式ASC、DESC }, { \u0026#34;FIELD\u0026#34;: \u0026#34;asc\u0026#34; } ] } 排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;sort\u0026#34;: [ { \u0026#34;age\u0026#34;: \u0026#34;desc\u0026#34; // 排序字段、排序方式ASC、DESC }, { \u0026#34;weight\u0026#34;: \u0026#34;asc\u0026#34; } ] } 地理坐标 地理坐标排序略有不同。 语法说明： 指定一个坐标，作为目标点。 计算每一个文档中，指定字段（必须是geo_point类型）的坐标 到目标点的距离是多少。 根据距离排序。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 GET /indexName/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;sort\u0026#34;: [ { \u0026#34;_geo_distance\u0026#34; : { // 文档中geo_point类型的字段名、目标坐标点 \u0026#34;FIELD\u0026#34; : \u0026#34;纬度，经度\u0026#34;, // 排序方式 \u0026#34;order\u0026#34; : \u0026#34;asc\u0026#34;, // 排序的距离单位 \u0026#34;unit\u0026#34; : \u0026#34;km\u0026#34; } } ] } 示例：实现对酒店数据按照到你的位置坐标的距离升序排序。 获取你的位置的经纬度的方式(高德API)：https://lbs.amap.com/demo/jsapi-v2/example/map/click-to-get-lnglat/。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 GET /alias_users/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;sort\u0026#34;: [ { \u0026#34;_geo_distance\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;lat\u0026#34;: 30.12213, \u0026#34;lon\u0026#34;: 120.3221 }, \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;km\u0026#34; } } ] } 分页 elasticsearch 默认情况下只返回top10的数据。而如果要查询更多数据就需要修改分页参数了。 elasticsearch中通过修改from、size参数来控制要返回的分页结果： from：从第几个文档开始。 size：总共查询几个文档。 类似于mysql中的limit ?, ?。 基本分页 分页的基本语法如下： 1 2 3 4 5 6 7 8 9 10 11 GET /hotel/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;from\u0026#34;: 0, // 分页开始的位置，默认为0 \u0026#34;size\u0026#34;: 10, // 期望获取的文档总数 \u0026#34;sort\u0026#34;: [ {\u0026#34;price\u0026#34;: \u0026#34;asc\u0026#34;} ] } 深度分页 现在，我要查询990~1000的数据，查询逻辑要这么写： 1 2 3 4 5 6 7 8 9 10 11 12 GET /hotel/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, // 这里是查询990开始的数据，也就是第990~第1000条数据。 \u0026#34;from\u0026#34;: 990, // 分页开始的位置，默认为0 \u0026#34;size\u0026#34;: 10, // 期望获取的文档总数 \u0026#34;sort\u0026#34;: [ {\u0026#34;price\u0026#34;: \u0026#34;asc\u0026#34;} ] } 当查询分页深度较大时，汇总数据过多，对内存和CPU会产生非常大的压力，因此elasticsearch会禁止from+ size 超过10000的请求。 针对深度分页，ES提供了两种解决方案，官方文档： search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。 scroll：原理将排序后的文档id形成快照，保存在内存。官方已经不推荐使用。 小结 分页查询的常见实现方案以及优缺点： from + size： 优点：支持随机翻页 缺点：深度分页问题，默认查询上限（from + size）是10000 场景：百度、京东、谷歌、淘宝这样的随机翻页搜索 after search： 优点：没有查询上限（单次查询的size不超过10000） 缺点：只能向后逐页查询，不支持随机翻页 场景：没有随机翻页需求的搜索，例如手机向下滚动翻页 scroll： 优点：没有查询上限（单次查询的size不超过10000） 缺点：会有额外内存消耗，并且搜索结果是非实时的 场景：海量数据的获取和迁移。从ES7.1开始不推荐，建议用 after search方案。 高亮 高亮原理 我们在百度，京东搜索时，关键字会变成红色，比较醒目，这叫高亮显示。 高亮显示的实现分为两步： 给文档中的所有关键字都添加一个标签，例如\u0026lt;em\u0026gt;标签。 页面给\u0026lt;em\u0026gt;标签编写CSS样式。 高亮实现 语法说明： 高亮是对关键字高亮，因此搜索条件必须带有关键字，而不能是范围这样的查询。 默认情况下，高亮的字段，必须与搜索指定的字段一致，否则无法高亮。 如果要对非搜索字段高亮，则需要添加一个属性：required_field_match=false。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 GET /hotel/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { // 查询条件，高亮一定要使用全文检索查询 \u0026#34;FIELD\u0026#34;: \u0026#34;TEXT\u0026#34; } }, \u0026#34;highlight\u0026#34;: { // 指定要高亮的字段 \u0026#34;fields\u0026#34;: { \u0026#34;FIELD\u0026#34;: { // 用来标记高亮字段的前置标签 \u0026#34;pre_tags\u0026#34;: \u0026#34;\u0026lt;em\u0026gt;\u0026#34;, // 用来标记高亮字段的后置标签 \u0026#34;post_tags\u0026#34;: \u0026#34;\u0026lt;/em\u0026gt;\u0026#34; } } } } 示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 GET /hotel/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;7天\u0026#34; }, \u0026#34;from\u0026#34;: 0, \u0026#34;size\u0026#34;: 20, \u0026#34;sort\u0026#34;: [ {\u0026#34;price\u0026#34;: \u0026#34;asc\u0026#34;}, { \u0026#34;_geo_distance\u0026#34;: { \u0026#34;location\u0026#34;: \u0026#34;30.1231,123.3213\u0026#34;, \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;km\u0026#34; } } ], \u0026#34;highlight\u0026#34;: { \u0026#34;fields\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;pre_tags\u0026#34;: \u0026#34;\u0026lt;em\u0026gt;\u0026#34;, \u0026#34;post_tags\u0026#34;: \u0026#34;\u0026lt;/em\u0026gt;\u0026#34; } } } } } 取指定字段 如果想取指定的字段使用_source。 1 2 3 4 5 6 7 8 9 10 11 12 GET /alias_users/_search { \u0026#34;_source\u0026#34;: [\u0026#34;age\u0026#34;, \u0026#34;weight\u0026#34;, \u0026#34;info\u0026#34;, \u0026#34;name\u0026#34;], \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gt\u0026#34;: 10, \u0026#34;lte\u0026#34;: 20 } } } } { \u0026#34;took\u0026#34;: 127, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } }, { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } ] } } 显示要的字段、去除不需要的字段、可以使用通配符*。 1 2 3 4 5 6 7 8 9 10 GET /alias_users/_search { \u0026#34;_source\u0026#34;:{ // 需要字段 \u0026#34;includes\u0026#34;: \u0026#34;addr*\u0026#34;, // 排除字段 \u0026#34;excludes\u0026#34;: [\u0026#34;name\u0026#34;, \u0026#34;bir*\u0026#34;] }, \u0026#34;query\u0026#34;: {\u0026#34;match_all\u0026#34;: {}} } 版本号 1 2 3 4 5 6 7 8 9 10 11 12 13 GET /alias_users/_search { \u0026#34;_source\u0026#34;: [\u0026#34;age\u0026#34;, \u0026#34;weight\u0026#34;, \u0026#34;info\u0026#34;, \u0026#34;name\u0026#34;], \u0026#34;version\u0026#34;: true, \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gt\u0026#34;: 10, \u0026#34;lte\u0026#34;: 20 } } } } { \u0026#34;took\u0026#34;: 48, \u0026#34;timed_out\u0026#34;: false, \u0026#34;_shards\u0026#34;: { \u0026#34;total\u0026#34;: 1, \u0026#34;successful\u0026#34;: 1, \u0026#34;skipped\u0026#34;: 0, \u0026#34;failed\u0026#34;: 0 }, \u0026#34;hits\u0026#34;: { \u0026#34;total\u0026#34;: { \u0026#34;value\u0026#34;: 2, \u0026#34;relation\u0026#34;: \u0026#34;eq\u0026#34; }, \u0026#34;max_score\u0026#34;: 1, \u0026#34;hits\u0026#34;: [ { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;orl0ZZEBrAuQs0dUWDfg\u0026#34;, \u0026#34;_version\u0026#34;: 1, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 18, \u0026#34;weight\u0026#34;: 50, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班张薛\u0026#34;, \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;薛\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;张\u0026#34; } } }, { \u0026#34;_index\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;_version\u0026#34;: 2, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;age\u0026#34;: 20, \u0026#34;weight\u0026#34;: 52.4, \u0026#34;info\u0026#34;: \u0026#34;曾州市第一中学高三一班薛高\u0026#34;, \u0026#34;name\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;高\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;薛\u0026#34; } } } ] } } ","permalink":"https://heliu.site/posts/elasticsearch/query/","summary":"查询文档。","title":"Query"},{"content":" 参加聚合的字段必须是keyword、日期、数值、布尔类型。 Bucket聚合 要统计所有数据中的酒店品牌有几种，其实就是按照品牌对数据分组。此时可以根据酒店品牌的名称做聚合，也就是Bucket聚合。 聚合语法：Bucket聚合用来对文档做分组 GET /indexName/_search { // 设置size为0，结果中不包含文档，只包含聚合结果 \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { // 定义聚合 \u0026#34;brandAgg\u0026#34;: { //给聚合起个名字 \u0026#34;terms\u0026#34;: { // 聚合的类型，按照品牌值聚合，所以选择term \u0026#34;field\u0026#34;: \u0026#34;brand\u0026#34;, // 参与聚合的字段 \u0026#34;size\u0026#34;: 20 // 希望获取的聚合结果数量 } } } } 聚合结果排序 默认情况下，Bucket聚合会统计Bucket内的文档数量，记为_count，并且按照_count降序排序。 我们可以指定order属性，自定义聚合的排序方式： GET /indexName/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;brandAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;brand\u0026#34;, \u0026#34;order\u0026#34;: { \u0026#34;_count\u0026#34;: \u0026#34;asc\u0026#34; // 按照_count升序排列 }, \u0026#34;size\u0026#34;: 20 } } } } 限定聚合范围 默认情况下，Bucket聚合是对索引库的所有文档做聚合，但真实场景下，用户会输入搜索条件，因此聚合必须是对搜索结果聚合。那么聚合必须添加限定条件。 我们可以限定要聚合的文档范围，只要添加query条件即可： GET /hotel/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;price\u0026#34;: { \u0026#34;lte\u0026#34;: 200 // 只对200元以下的文档聚合 } } }, \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;brandAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;brand\u0026#34;, \u0026#34;size\u0026#34;: 20 } } } } Metric聚合 桶聚合对酒店按照品牌分组，形成了一个个桶。现在我们需要对桶内的酒店做运算，获取每个品牌的用户评分的min、max、avg等值。 Metric聚合，例如stat聚合：就可以获取min、max、avg等结果。 这次的score_stats聚合是在brandAgg的聚合内部嵌套的子聚合。因为我们需要在每个桶分别计算。 使用语法： GET /hotel/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;brandAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;brand\u0026#34;, \u0026#34;size\u0026#34;: 20 }, \u0026#34;aggs\u0026#34;: { // 是brands聚合的子聚合，也就是分组后对每组分别计算 \u0026#34;score_stats\u0026#34;: { // 聚合名称 \u0026#34;stats\u0026#34;: { // 聚合类型，这里stats可以计算min、max、avg等 \u0026#34;field\u0026#34;: \u0026#34;score\u0026#34; // 聚合字段，这里是score } } } } } } 另外，我们还可以给聚合结果做个排序，例如按照每个桶的酒店平均分做排序： GET /hotel/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;brandAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;brand\u0026#34;, \u0026#34;size\u0026#34;: 20, \u0026#34;order\u0026#34;: { \u0026#34;scoreAgg.avg\u0026#34;: \u0026#34;desc\u0026#34; } }, \u0026#34;aggs\u0026#34;: { // 是brands聚合的子聚合，也就是分组后对每组分别计算 \u0026#34;score_stats\u0026#34;: { // 聚合名称 \u0026#34;stats\u0026#34;: { // 聚合类型，这里stats可以计算min、max、avg等 \u0026#34;field\u0026#34;: \u0026#34;score\u0026#34; // 聚合字段，这里是score } } } } } } ","permalink":"https://heliu.site/posts/elasticsearch/aggregate/","summary":"桶聚合、度量聚合、管道聚合等。","title":"聚合"},{"content":"同步方案 Mysql数据发生改变时，ElasticSearch也必须跟着改变，这个就是ElasticSearch与Mysql之间的数据同步。\n同步调用 就是Mysql更新/新增/删除数据时，同步调用ElasticSearch接口。 基本步骤如下： hotel-demo对外提供接口，用来修改elasticsearch中的数据。 酒店管理服务在完成数据库操作后，直接调用hotel-demo提供的接口。 优点：实现简单，粗暴；缺点：业务耦合度高。 异步通知 就是Mysql更新/新增/删除数据时，把数据放入MQ中，消费线程再调用ElasticSearch接口。 基本流程： hotel-admin对mysql数据库数据完成增、删、改后，发送MQ消息。 hotel-demo监听MQ，接收到消息后完成elasticsearch数据修改。 优点：低耦合，实现难度一般；缺点：依赖mq的可靠性。 监听binlog 监听 Mysql 的 binlog日志： 给mysql开启binlog功能。 mysql完成增、删、改操作都会记录在binlog中。 hotel-demo基于canal监听binlog变化，实时更新elasticsearch中的内容。 优点：完全解除服务间耦合；缺点：开启binlog增加数据库负担、实现复杂度高。 ","permalink":"https://heliu.site/posts/elasticsearch/sync/","summary":"Mysql数据同步ElasticSearch。","title":"数据同步"},{"content":" 🔥如果觉得我的文章对您有用，帮我买杯☕。您的支持将鼓励我继续创作。🎉🎉🎉\nwechat alipay ","permalink":"https://heliu.site/support/","summary":" 🔥如果觉得我的文章对您有用，帮我买杯☕。您的支持将鼓励我继续创作。🎉🎉🎉\nwechat alipay ","title":"打赏"}]